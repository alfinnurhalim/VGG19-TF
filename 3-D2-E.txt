Student with Knowledge Distillation Approach
Step 0: loss = 56.55967
Training Data Eval:
  Num examples: 50000, Num correct: 5086, Precision @ 1: 0.1017
('Testing Data Eval: EPOCH->', 1)
  Num examples: 10000, Num correct: 1008, Precision @ 1: 0.1008
Step 5: loss = 34.46380
Step 10: loss = 31.11990
Step 15: loss = 23.66595
Step 20: loss = 20.64250
Step 25: loss = 15.83779
Step 30: loss = 12.79501
Step 35: loss = 12.24191
Step 40: loss = 7.67017
Step 45: loss = 11.45201
Step 50: loss = 5.61711
Step 55: loss = 11.02300
Step 60: loss = 7.47436
Step 65: loss = 9.89329
Step 70: loss = 6.10783
Step 75: loss = 8.26885
Step 80: loss = 7.80345
Step 85: loss = 4.85104
Step 90: loss = 4.53046
Step 95: loss = 9.02737
Step 100: loss = 7.23609
Step 105: loss = 4.97468
Step 110: loss = 4.33755
Step 115: loss = 6.79774
Step 120: loss = 5.42305
Step 125: loss = 8.83796
Step 130: loss = 5.45527
Step 135: loss = 5.85658
Step 140: loss = 5.81980
Step 145: loss = 9.80881
Step 150: loss = 2.96723
Step 155: loss = 4.98067
Step 160: loss = 8.76931
Step 165: loss = 3.20225
Step 170: loss = 3.61890
Step 175: loss = 4.88019
Step 180: loss = 4.14938
Step 185: loss = 6.01803
Step 190: loss = 4.26161
Step 195: loss = 5.10005
Step 200: loss = 3.06215
Step 205: loss = 3.04842
Step 210: loss = 7.40235
Step 215: loss = 8.61206
Step 220: loss = 3.27937
Step 225: loss = 5.02155
Step 230: loss = 4.46208
Step 235: loss = 7.55161
Step 240: loss = 3.32788
Step 245: loss = 5.88235
Step 250: loss = 4.74453
Step 255: loss = 6.19238
Step 260: loss = 6.21329
Step 265: loss = 5.79802
Step 270: loss = 8.21625
Step 275: loss = 4.54210
Step 280: loss = 3.38508
Step 285: loss = 4.60269
Step 290: loss = 2.61114
Step 295: loss = 3.70169
Step 300: loss = 2.32222
Step 305: loss = 5.11240
Step 310: loss = 3.23698
Step 315: loss = 6.79891
Step 320: loss = 2.51578
Step 325: loss = 6.72342
Step 330: loss = 3.89266
Step 335: loss = 3.56057
Step 340: loss = 2.62429
Step 345: loss = 2.22687
Step 350: loss = 4.98665
Step 355: loss = 5.16570
Step 360: loss = 2.50798
Step 365: loss = 2.67801
Step 370: loss = 4.73439
Step 375: loss = 4.66033
Step 380: loss = 4.77867
Step 385: loss = 2.79146
Step 390: loss = 6.22398
Step 395: loss = 4.35515
Step 400: loss = 3.38339
Step 405: loss = 3.27815
Step 410: loss = 2.79836
Step 415: loss = 3.15966
Step 420: loss = 3.13175
Step 425: loss = 5.05692
Step 430: loss = 2.41716
Step 435: loss = 3.27053
Step 440: loss = 2.98254
Step 445: loss = 3.83259
Step 450: loss = 4.66050
Step 455: loss = 2.60976
Step 460: loss = 3.04778
Step 465: loss = 6.58917
Step 470: loss = 2.93774
Step 475: loss = 3.05304
Step 480: loss = 2.12694
Step 485: loss = 2.50736
Step 490: loss = 3.46077
Step 495: loss = 3.52945
Step 500: loss = 3.06799
Step 505: loss = 5.98189
Step 510: loss = 5.36283
Step 515: loss = 3.52964
Step 520: loss = 4.83111
Step 525: loss = 2.20669
Step 530: loss = 5.00143
Step 535: loss = 2.43815
Step 540: loss = 3.55455
Step 545: loss = 2.05615
Step 550: loss = 2.79879
Step 555: loss = 2.38590
Step 560: loss = 4.75673
Step 565: loss = 3.66620
Step 570: loss = 1.88773
Step 575: loss = 4.06912
Step 580: loss = 4.09754
Step 585: loss = 3.31466
Step 590: loss = 4.12706
Step 595: loss = 4.04501
Step 600: loss = 3.87107
Step 605: loss = 3.43159
Step 610: loss = 2.00147
Step 615: loss = 4.20991
Step 620: loss = 2.67097
Step 625: loss = 2.29942
Step 630: loss = 2.44756
Step 635: loss = 4.89192
Step 640: loss = 2.36020
Step 645: loss = 3.25341
Step 650: loss = 2.39602
Step 655: loss = 2.11488
Step 660: loss = 2.71605
Step 665: loss = 2.21946
Step 670: loss = 2.69611
Step 675: loss = 2.88481
Step 680: loss = 2.43504
Step 685: loss = 3.23727
Step 690: loss = 2.64894
Step 695: loss = 1.93904
Step 700: loss = 3.77015
Step 705: loss = 3.01609
Step 710: loss = 2.25438
Step 715: loss = 3.31309
Step 720: loss = 2.47875
Step 725: loss = 2.05882
Step 730: loss = 3.35190
Step 735: loss = 4.31198
Step 740: loss = 2.09705
Step 745: loss = 2.81496
Step 750: loss = 4.39939
Step 755: loss = 4.38112
Step 760: loss = 3.44968
Step 765: loss = 2.52649
Step 770: loss = 3.00717
Step 775: loss = 2.40040
Step 780: loss = 2.23193
Step 785: loss = 2.21592
Step 790: loss = 2.93652
Step 795: loss = 4.06355
Step 800: loss = 2.63652
Step 805: loss = 2.41348
Step 810: loss = 2.00481
Step 815: loss = 2.94516
Step 820: loss = 2.45168
Step 825: loss = 3.07860
Step 830: loss = 2.37098
Step 835: loss = 3.47545
Step 840: loss = 4.04966
Step 845: loss = 2.41957
Step 850: loss = 2.19169
Step 855: loss = 1.88705
Step 860: loss = 1.92419
Step 865: loss = 4.76883
Step 870: loss = 5.15387
Step 875: loss = 2.53468
Step 880: loss = 2.30648
Step 885: loss = 2.20831
Step 890: loss = 2.24186
Step 895: loss = 4.08388
Step 900: loss = 2.62065
Step 905: loss = 2.38637
Step 910: loss = 1.85526
Step 915: loss = 2.14880
Step 920: loss = 4.22860
Step 925: loss = 3.76891
Step 930: loss = 2.53447
Step 935: loss = 1.54894
Step 940: loss = 2.40826
Step 945: loss = 2.91629
Step 950: loss = 3.49943
Step 955: loss = 2.15119
Step 960: loss = 3.56134
Step 965: loss = 2.06729
Step 970: loss = 2.94383
Step 975: loss = 2.55877
Step 980: loss = 1.87972
Step 985: loss = 3.11518
Step 990: loss = 1.86761
Step 995: loss = 4.11834
Step 1000: loss = 3.11705
Training Data Eval:
  Num examples: 50000, Num correct: 13982, Precision @ 1: 0.2796
('Testing Data Eval: EPOCH->', 2)
  Num examples: 10000, Num correct: 2234, Precision @ 1: 0.2234
Step 1005: loss = 2.49198
Step 1010: loss = 3.28078
Step 1015: loss = 1.87412
Step 1020: loss = 3.08966
Step 1025: loss = 2.63974
Step 1030: loss = 3.19290
Step 1035: loss = 1.90468
Step 1040: loss = 2.40211
Step 1045: loss = 2.91528
Step 1050: loss = 1.86497
Step 1055: loss = 2.17667
Step 1060: loss = 2.44920
Step 1065: loss = 1.93855
Step 1070: loss = 3.39130
Step 1075: loss = 1.95335
Step 1080: loss = 3.86486
Step 1085: loss = 1.87587
Step 1090: loss = 4.02197
Step 1095: loss = 1.84083
Step 1100: loss = 1.79634
Step 1105: loss = 3.05696
Step 1110: loss = 2.54977
Step 1115: loss = 2.85341
Step 1120: loss = 3.64137
Step 1125: loss = 2.75353
Step 1130: loss = 3.04008
Step 1135: loss = 1.70609
Step 1140: loss = 1.99330
Step 1145: loss = 2.33721
Step 1150: loss = 2.26920
Step 1155: loss = 3.04640
Step 1160: loss = 2.54664
Step 1165: loss = 1.91067
Step 1170: loss = 2.57586
Step 1175: loss = 1.97072
Step 1180: loss = 3.04289
Step 1185: loss = 1.87539
Step 1190: loss = 1.79305
Step 1195: loss = 2.30172
Step 1200: loss = 2.54780
Step 1205: loss = 2.56446
Step 1210: loss = 2.04272
Step 1215: loss = 1.98651
Step 1220: loss = 1.95465
Step 1225: loss = 1.97618
Step 1230: loss = 2.63683
Step 1235: loss = 2.82320
Step 1240: loss = 2.32291
Step 1245: loss = 1.58809
Step 1250: loss = 2.93568
Step 1255: loss = 1.86778
Step 1260: loss = 1.60620
Step 1265: loss = 1.79742
Step 1270: loss = 3.00578
Step 1275: loss = 3.26285
Step 1280: loss = 3.06341
Step 1285: loss = 2.20983
Step 1290: loss = 2.35599
Step 1295: loss = 2.34761
Step 1300: loss = 2.51025
Step 1305: loss = 2.28188
Step 1310: loss = 1.56950
Step 1315: loss = 2.05258
Step 1320: loss = 1.75617
Step 1325: loss = 2.60043
Step 1330: loss = 3.43441
Step 1335: loss = 2.01751
Step 1340: loss = 1.86268
Step 1345: loss = 1.53430
Step 1350: loss = 1.66159
Step 1355: loss = 1.68990
Step 1360: loss = 2.43013
Step 1365: loss = 1.91511
Step 1370: loss = 2.96966
Step 1375: loss = 1.75286
Step 1380: loss = 3.00024
Step 1385: loss = 3.01164
Step 1390: loss = 1.83268
Step 1395: loss = 1.69123
Step 1400: loss = 3.95393
Step 1405: loss = 2.49219
Step 1410: loss = 1.74865
Step 1415: loss = 1.70601
Step 1420: loss = 1.78093
Step 1425: loss = 3.19423
Step 1430: loss = 1.74285
Step 1435: loss = 1.73501
Step 1440: loss = 2.09843
Step 1445: loss = 1.70525
Step 1450: loss = 2.11193
Step 1455: loss = 1.91700
Step 1460: loss = 1.80508
Step 1465: loss = 1.72040
Step 1470: loss = 2.47082
Step 1475: loss = 1.63288
Step 1480: loss = 1.47290
Step 1485: loss = 1.94989
Step 1490: loss = 1.96257
Step 1495: loss = 2.13441
Step 1500: loss = 1.81787
Step 1505: loss = 1.79826
Step 1510: loss = 1.63871
Step 1515: loss = 1.65714
Step 1520: loss = 1.62958
Step 1525: loss = 1.90308
Step 1530: loss = 1.65306
Step 1535: loss = 2.61798
Step 1540: loss = 2.82897
Step 1545: loss = 1.92774
Step 1550: loss = 2.58392
Step 1555: loss = 2.02988
Step 1560: loss = 2.34380
Step 1565: loss = 2.40046
Step 1570: loss = 1.69014
Step 1575: loss = 2.25571
Step 1580: loss = 2.66705
Step 1585: loss = 1.61272
Step 1590: loss = 2.42018
Step 1595: loss = 2.37550
Step 1600: loss = 1.76501
Step 1605: loss = 2.17600
Step 1610: loss = 1.98173
Step 1615: loss = 1.81324
Step 1620: loss = 1.90137
Step 1625: loss = 3.04907
Step 1630: loss = 1.66731
Step 1635: loss = 2.11445
Step 1640: loss = 1.46194
Step 1645: loss = 2.23586
Step 1650: loss = 2.29226
Step 1655: loss = 2.59274
Step 1660: loss = 2.25343
Step 1665: loss = 1.90070
Step 1670: loss = 1.99495
Step 1675: loss = 2.28615
Step 1680: loss = 2.06085
Step 1685: loss = 2.02053
Step 1690: loss = 1.94464
Step 1695: loss = 1.83462
Step 1700: loss = 2.16351
Step 1705: loss = 1.86336
Step 1710: loss = 2.09597
Step 1715: loss = 1.63720
Step 1720: loss = 1.66413
Step 1725: loss = 1.76815
Step 1730: loss = 2.92192
Step 1735: loss = 1.63386
Step 1740: loss = 1.73111
Step 1745: loss = 1.61236
Step 1750: loss = 1.83444
Step 1755: loss = 3.05491
Step 1760: loss = 1.81985
Step 1765: loss = 1.59579
Step 1770: loss = 1.65117
Step 1775: loss = 1.62475
Step 1780: loss = 1.81295
Step 1785: loss = 1.69538
Step 1790: loss = 1.74697
Step 1795: loss = 1.81546
Step 1800: loss = 1.85871
Step 1805: loss = 1.86294
Step 1810: loss = 1.90179
Step 1815: loss = 1.71013
Step 1820: loss = 1.52849
Step 1825: loss = 1.93693
Step 1830: loss = 1.55528
Step 1835: loss = 1.92192
Step 1840: loss = 1.54720
Step 1845: loss = 1.80156
Step 1850: loss = 1.57184
Step 1855: loss = 1.98273
Step 1860: loss = 1.85533
Step 1865: loss = 2.22005
Step 1870: loss = 1.67155
Step 1875: loss = 1.84830
Step 1880: loss = 1.97274
Step 1885: loss = 1.85812
Step 1890: loss = 2.61965
Step 1895: loss = 1.70078
Step 1900: loss = 1.74800
Step 1905: loss = 1.76506
Step 1910: loss = 1.66299
Step 1915: loss = 1.83034
Step 1920: loss = 1.92226
Step 1925: loss = 1.44300
Step 1930: loss = 2.16677
Step 1935: loss = 1.89205
Step 1940: loss = 2.29449
Step 1945: loss = 2.19455
Step 1950: loss = 1.78102
Step 1955: loss = 1.76988
Step 1960: loss = 1.71509
Step 1965: loss = 1.32899
Step 1970: loss = 2.59450
Step 1975: loss = 1.70189
Step 1980: loss = 1.91539
Step 1985: loss = 1.97996
Step 1990: loss = 1.67660
Step 1995: loss = 2.07512
Step 2000: loss = 1.62691
Training Data Eval:
  Num examples: 50000, Num correct: 19043, Precision @ 1: 0.3809
('Testing Data Eval: EPOCH->', 3)
  Num examples: 10000, Num correct: 3201, Precision @ 1: 0.3201
Step 2005: loss = 1.80374
Step 2010: loss = 2.27082
Step 2015: loss = 1.43565
Step 2020: loss = 1.66850
Step 2025: loss = 1.78806
Step 2030: loss = 1.68247
Step 2035: loss = 1.50194
Step 2040: loss = 1.83381
Step 2045: loss = 1.57226
Step 2050: loss = 1.92293
Step 2055: loss = 1.71215
Step 2060: loss = 1.80446
Step 2065: loss = 1.41544
Step 2070: loss = 2.17590
Step 2075: loss = 1.83466
Step 2080: loss = 1.68249
Step 2085: loss = 1.62191
Step 2090: loss = 1.69740
Step 2095: loss = 1.67877
Step 2100: loss = 1.38432
Step 2105: loss = 1.72908
Step 2110: loss = 1.68397
Step 2115: loss = 1.71316
Step 2120: loss = 1.90622
Step 2125: loss = 2.01982
Step 2130: loss = 2.01315
Step 2135: loss = 1.73073
Step 2140: loss = 1.48966
Step 2145: loss = 1.71774
Step 2150: loss = 1.92399
Step 2155: loss = 1.73266
Step 2160: loss = 1.61931
Step 2165: loss = 1.52948
Step 2170: loss = 1.51494
Step 2175: loss = 1.51539
Step 2180: loss = 1.56595
Step 2185: loss = 1.62949
Step 2190: loss = 1.85846
Step 2195: loss = 2.29281
Step 2200: loss = 1.51873
Step 2205: loss = 1.68809
Step 2210: loss = 1.60243
Step 2215: loss = 1.64634
Step 2220: loss = 1.41069
Step 2225: loss = 1.87641
Step 2230: loss = 1.51328
Step 2235: loss = 1.73888
Step 2240: loss = 1.50259
Step 2245: loss = 1.54683
Step 2250: loss = 1.83637
Step 2255: loss = 1.83954
Step 2260: loss = 1.70017
Step 2265: loss = 1.69872
Step 2270: loss = 1.30612
Step 2275: loss = 1.41631
Step 2280: loss = 1.64869
Step 2285: loss = 1.66994
Step 2290: loss = 1.62718
Step 2295: loss = 2.02354
Step 2300: loss = 1.72158
Step 2305: loss = 1.52828
Step 2310: loss = 1.64244
Step 2315: loss = 1.58188
Step 2320: loss = 1.79828
Step 2325: loss = 1.94665
Step 2330: loss = 1.95093
Step 2335: loss = 1.63004
Step 2340: loss = 1.52103
Step 2345: loss = 1.57586
Step 2350: loss = 1.78563
Step 2355: loss = 1.68495
Step 2360: loss = 1.55500
Step 2365: loss = 1.53235
Step 2370: loss = 1.48601
Step 2375: loss = 1.96079
Step 2380: loss = 1.74881
Step 2385: loss = 1.75635
Step 2390: loss = 1.58054
Step 2395: loss = 1.69488
Step 2400: loss = 1.57237
Step 2405: loss = 1.61793
Step 2410: loss = 1.80855
Step 2415: loss = 1.58976
Step 2420: loss = 1.72286
Step 2425: loss = 1.76627
Step 2430: loss = 1.42317
Step 2435: loss = 1.45750
Step 2440: loss = 1.85360
Step 2445: loss = 1.66958
Step 2450: loss = 1.61975
Step 2455: loss = 1.58333
Step 2460: loss = 1.91612
Step 2465: loss = 1.75792
Step 2470: loss = 1.57924
Step 2475: loss = 1.61701
Step 2480: loss = 1.65621
Step 2485: loss = 1.50597
Step 2490: loss = 1.52393
Step 2495: loss = 1.50000
Step 2500: loss = 1.89614
Step 2505: loss = 1.55169
Step 2510: loss = 1.62532
Step 2515: loss = 1.75146
Step 2520: loss = 1.54964
Step 2525: loss = 1.54561
Step 2530: loss = 1.59213
Step 2535: loss = 1.99993
Step 2540: loss = 1.63019
Step 2545: loss = 1.86524
Step 2550: loss = 1.61960
Step 2555: loss = 1.70341
Step 2560: loss = 1.55989
Step 2565: loss = 1.44612
Step 2570: loss = 1.48290
Step 2575: loss = 1.64547
Step 2580: loss = 1.78031
Step 2585: loss = 1.74592
Step 2590: loss = 1.77654
Step 2595: loss = 1.49228
Step 2600: loss = 1.61902
Step 2605: loss = 1.39525
Step 2610: loss = 1.57166
Step 2615: loss = 1.85273
Step 2620: loss = 1.56866
Step 2625: loss = 1.96123
Step 2630: loss = 1.41102
Step 2635: loss = 1.55179
Step 2640: loss = 1.50535
Step 2645: loss = 1.40546
Step 2650: loss = 1.52179
Step 2655: loss = 1.57136
Step 2660: loss = 1.65856
Step 2665: loss = 1.59904
Step 2670: loss = 1.67533
Step 2675: loss = 1.55289
Step 2680: loss = 1.89000
Step 2685: loss = 1.49283
Step 2690: loss = 1.62687
Step 2695: loss = 2.10547
Step 2700: loss = 1.49108
Step 2705: loss = 1.47454
Step 2710: loss = 1.56955
Step 2715: loss = 1.49481
Step 2720: loss = 1.59065
Step 2725: loss = 1.67902
Step 2730: loss = 1.55740
Step 2735: loss = 1.41979
Step 2740: loss = 2.17848
Step 2745: loss = 1.72009
Step 2750: loss = 1.60325
Step 2755: loss = 1.61174
Step 2760: loss = 1.49201
Step 2765: loss = 1.81584
Step 2770: loss = 1.67198
Step 2775: loss = 1.89573
Step 2780: loss = 1.44056
Step 2785: loss = 1.59073
Step 2790: loss = 1.71645
Step 2795: loss = 1.49125
Step 2800: loss = 1.54030
Step 2805: loss = 1.46952
Step 2810: loss = 1.56358
Step 2815: loss = 1.55614
Step 2820: loss = 1.60163
Step 2825: loss = 1.54606
Step 2830: loss = 1.35692
Step 2835: loss = 1.50033
Step 2840: loss = 1.53173
Step 2845: loss = 1.30167
Step 2850: loss = 1.47899
Step 2855: loss = 1.51240
Step 2860: loss = 1.59653
Step 2865: loss = 1.55538
Step 2870: loss = 1.20968
Step 2875: loss = 1.55725
Step 2880: loss = 1.67065
Step 2885: loss = 1.48737
Step 2890: loss = 1.73459
Step 2895: loss = 1.35859
Step 2900: loss = 1.38808
Step 2905: loss = 1.28073
Step 2910: loss = 1.45341
Step 2915: loss = 1.43276
Step 2920: loss = 1.63389
Step 2925: loss = 1.85899
Step 2930: loss = 1.71014
Step 2935: loss = 1.49753
Step 2940: loss = 1.42188
Step 2945: loss = 1.71069
Step 2950: loss = 1.52900
Step 2955: loss = 1.92937
Step 2960: loss = 1.43137
Step 2965: loss = 1.50131
Step 2970: loss = 1.62258
Step 2975: loss = 1.90719
Step 2980: loss = 1.49399
Step 2985: loss = 1.61350
Step 2990: loss = 1.73113
Step 2995: loss = 1.22082
Step 3000: loss = 1.42538
Training Data Eval:
  Num examples: 50000, Num correct: 22141, Precision @ 1: 0.4428
('Testing Data Eval: EPOCH->', 4)
  Num examples: 10000, Num correct: 3588, Precision @ 1: 0.3588
Step 3005: loss = 1.71539
Step 3010: loss = 1.63728
Step 3015: loss = 1.60492
Step 3020: loss = 1.41450
Step 3025: loss = 1.43515
Step 3030: loss = 1.93964
Step 3035: loss = 1.48250
Step 3040: loss = 1.47411
Step 3045: loss = 1.31264
Step 3050: loss = 1.27876
Step 3055: loss = 1.31290
Step 3060: loss = 1.49128
Step 3065: loss = 1.63889
Step 3070: loss = 1.51386
Step 3075: loss = 1.69538
Step 3080: loss = 1.34886
Step 3085: loss = 1.51099
Step 3090: loss = 1.63652
Step 3095: loss = 1.28368
Step 3100: loss = 1.66875
Step 3105: loss = 1.68888
Step 3110: loss = 1.51861
Step 3115: loss = 1.78601
Step 3120: loss = 2.08696
Step 3125: loss = 1.71136
Step 3130: loss = 1.57765
Step 3135: loss = 1.53799
Step 3140: loss = 1.60872
Step 3145: loss = 1.59007
Step 3150: loss = 1.64897
Step 3155: loss = 1.44417
Step 3160: loss = 1.65053
Step 3165: loss = 1.24208
Step 3170: loss = 1.58001
Step 3175: loss = 1.83816
Step 3180: loss = 1.23579
Step 3185: loss = 1.59660
Step 3190: loss = 1.61420
Step 3195: loss = 1.61590
Step 3200: loss = 1.27433
Step 3205: loss = 1.27629
Step 3210: loss = 1.49414
Step 3215: loss = 1.43806
Step 3220: loss = 1.27132
Step 3225: loss = 1.30778
Step 3230: loss = 1.49351
Step 3235: loss = 1.83172
Step 3240: loss = 1.53464
Step 3245: loss = 1.35352
Step 3250: loss = 1.55727
Step 3255: loss = 1.19057
Step 3260: loss = 1.43855
Step 3265: loss = 1.81485
Step 3270: loss = 1.65407
Step 3275: loss = 1.51856
Step 3280: loss = 1.47108
Step 3285: loss = 1.57227
Step 3290: loss = 1.62887
Step 3295: loss = 1.59022
Step 3300: loss = 1.52525
Step 3305: loss = 1.42939
Step 3310: loss = 1.46139
Step 3315: loss = 1.35364
Step 3320: loss = 1.36427
Step 3325: loss = 1.66072
Step 3330: loss = 1.39168
Step 3335: loss = 1.89255
Step 3340: loss = 1.42450
Step 3345: loss = 1.40992
Step 3350: loss = 1.42885
Step 3355: loss = 1.51415
Step 3360: loss = 1.29787
Step 3365: loss = 1.74347
Step 3370: loss = 1.51525
Step 3375: loss = 1.17763
Step 3380: loss = 1.56666
Step 3385: loss = 1.52869
Step 3390: loss = 1.57929
Step 3395: loss = 1.47772
Step 3400: loss = 1.37440
Step 3405: loss = 1.61927
Step 3410: loss = 1.37756
Step 3415: loss = 1.45021
Step 3420: loss = 1.61534
Step 3425: loss = 1.31310
Step 3430: loss = 1.69182
Step 3435: loss = 1.32168
Step 3440: loss = 1.42731
Step 3445: loss = 1.48013
Step 3450: loss = 1.54990
Step 3455: loss = 1.39926
Step 3460: loss = 1.20369
Step 3465: loss = 1.45253
Step 3470: loss = 1.41130
Step 3475: loss = 1.38431
Step 3480: loss = 1.57066
Step 3485: loss = 1.21691
Step 3490: loss = 1.57916
Step 3495: loss = 1.46540
Step 3500: loss = 1.61796
Step 3505: loss = 1.46594
Step 3510: loss = 1.35332
Step 3515: loss = 1.34398
Step 3520: loss = 1.43240
Step 3525: loss = 1.26160
Step 3530: loss = 1.47615
Step 3535: loss = 1.33452
Step 3540: loss = 1.29874
Step 3545: loss = 1.44178
Step 3550: loss = 1.71164
Step 3555: loss = 1.27415
Step 3560: loss = 1.54210
Step 3565: loss = 1.42884
Step 3570: loss = 1.33252
Step 3575: loss = 1.44037
Step 3580: loss = 1.72310
Step 3585: loss = 1.21669
Step 3590: loss = 1.31858
Step 3595: loss = 1.45370
Step 3600: loss = 1.51865
Step 3605: loss = 1.53173
Step 3610: loss = 1.36685
Step 3615: loss = 1.49482
Step 3620: loss = 1.44604
Step 3625: loss = 1.57322
Step 3630: loss = 1.67557
Step 3635: loss = 1.50103
Step 3640: loss = 1.53308
Step 3645: loss = 1.49457
Step 3650: loss = 1.35672
Step 3655: loss = 1.47088
Step 3660: loss = 1.52311
Step 3665: loss = 1.44455
Step 3670: loss = 1.60336
Step 3675: loss = 1.58910
Step 3680: loss = 1.45972
Step 3685: loss = 1.44742
Step 3690: loss = 1.61893
Step 3695: loss = 1.52325
Step 3700: loss = 1.53369
Step 3705: loss = 1.39496
Step 3710: loss = 1.50199
Step 3715: loss = 1.11639
Step 3720: loss = 1.18269
Step 3725: loss = 1.58842
Step 3730: loss = 1.45548
Step 3735: loss = 1.41721
Step 3740: loss = 1.43450
Step 3745: loss = 1.61497
Step 3750: loss = 1.37342
Step 3755: loss = 1.59921
Step 3760: loss = 1.35206
Step 3765: loss = 1.38225
Step 3770: loss = 1.37541
Step 3775: loss = 1.67086
Step 3780: loss = 1.70215
Step 3785: loss = 1.52606
Step 3790: loss = 1.64606
Step 3795: loss = 1.46886
Step 3800: loss = 1.29337
Step 3805: loss = 1.52440
Step 3810: loss = 1.94480
Step 3815: loss = 1.45081
Step 3820: loss = 1.67043
Step 3825: loss = 1.30875
Step 3830: loss = 1.29841
Step 3835: loss = 1.40816
Step 3840: loss = 1.41756
Step 3845: loss = 1.39258
Step 3850: loss = 1.77851
Step 3855: loss = 1.65954
Step 3860: loss = 1.47106
Step 3865: loss = 1.41466
Step 3870: loss = 1.62399
Step 3875: loss = 1.43347
Step 3880: loss = 1.34437
Step 3885: loss = 1.56593
Step 3890: loss = 1.31727
Step 3895: loss = 1.53187
Step 3900: loss = 1.47375
Step 3905: loss = 1.57629
Step 3910: loss = 1.63735
Step 3915: loss = 1.42340
Step 3920: loss = 1.33598
Step 3925: loss = 1.88130
Step 3930: loss = 1.47594
Step 3935: loss = 1.52966
Step 3940: loss = 1.19439
Step 3945: loss = 1.47368
Step 3950: loss = 1.32662
Step 3955: loss = 1.17509
Step 3960: loss = 1.25253
Step 3965: loss = 1.40009
Step 3970: loss = 1.54742
Step 3975: loss = 1.42981
Step 3980: loss = 1.44315
Step 3985: loss = 1.37309
Step 3990: loss = 1.34352
Step 3995: loss = 1.45248
Step 4000: loss = 1.58913
Training Data Eval:
  Num examples: 50000, Num correct: 23944, Precision @ 1: 0.4789
('Testing Data Eval: EPOCH->', 5)
  Num examples: 10000, Num correct: 3908, Precision @ 1: 0.3908
Step 4005: loss = 1.26647
Step 4010: loss = 1.42210
Step 4015: loss = 1.34983
Step 4020: loss = 1.54888
Step 4025: loss = 1.17687
Step 4030: loss = 1.58384
Step 4035: loss = 1.46170
Step 4040: loss = 1.76648
Step 4045: loss = 1.63196
Step 4050: loss = 1.68109
Step 4055: loss = 1.32512
Step 4060: loss = 1.60469
Step 4065: loss = 1.55827
Step 4070: loss = 1.44424
Step 4075: loss = 1.64236
Step 4080: loss = 1.66416
Step 4085: loss = 1.36452
Step 4090: loss = 1.37837
Step 4095: loss = 1.37051
Step 4100: loss = 1.62368
Step 4105: loss = 1.51544
Step 4110: loss = 1.31779
Step 4115: loss = 1.67466
Step 4120: loss = 1.61907
Step 4125: loss = 1.27794
Step 4130: loss = 1.75478
Step 4135: loss = 1.50274
Step 4140: loss = 1.39834
Step 4145: loss = 1.27999
Step 4150: loss = 1.67685
Step 4155: loss = 1.43023
Step 4160: loss = 1.44881
Step 4165: loss = 1.39826
Step 4170: loss = 1.29620
Step 4175: loss = 1.30038
Step 4180: loss = 1.53047
Step 4185: loss = 1.27348
Step 4190: loss = 1.25880
Step 4195: loss = 1.23483
Step 4200: loss = 1.07705
Step 4205: loss = 1.19660
Step 4210: loss = 1.25939
Step 4215: loss = 1.27690
Step 4220: loss = 1.80906
Step 4225: loss = 1.37840
Step 4230: loss = 1.17686
Step 4235: loss = 1.64208
Step 4240: loss = 1.38912
Step 4245: loss = 1.60802
Step 4250: loss = 1.42992
Step 4255: loss = 1.34399
Step 4260: loss = 1.35025
Step 4265: loss = 1.57022
Step 4270: loss = 1.29246
Step 4275: loss = 1.36466
Step 4280: loss = 1.47150
Step 4285: loss = 1.92489
Step 4290: loss = 1.45434
Step 4295: loss = 1.32711
Step 4300: loss = 1.31989
Step 4305: loss = 1.37240
Step 4310: loss = 1.31888
Step 4315: loss = 1.47688
Step 4320: loss = 1.45688
Step 4325: loss = 1.33642
Step 4330: loss = 1.22568
Step 4335: loss = 1.25477
Step 4340: loss = 1.31523
Step 4345: loss = 1.44864
Step 4350: loss = 1.63751
Step 4355: loss = 1.38224
Step 4360: loss = 1.62992
Step 4365: loss = 1.47744
Step 4370: loss = 1.34803
Step 4375: loss = 1.48867
Step 4380: loss = 1.50751
Step 4385: loss = 1.31705
Step 4390: loss = 1.51181
Step 4395: loss = 1.29294
Step 4400: loss = 1.49320
Step 4405: loss = 1.27589
Step 4410: loss = 1.58607
Step 4415: loss = 1.45836
Step 4420: loss = 1.34774
Step 4425: loss = 1.28315
Step 4430: loss = 1.26691
Step 4435: loss = 1.27852
Step 4440: loss = 1.39465
Step 4445: loss = 1.45850
Step 4450: loss = 1.40343
Step 4455: loss = 1.48557
Step 4460: loss = 1.19002
Step 4465: loss = 1.16185
Step 4470: loss = 1.38436
Step 4475: loss = 1.46110
Step 4480: loss = 1.38669
Step 4485: loss = 1.83560
Step 4490: loss = 1.42535
Step 4495: loss = 1.50093
Step 4500: loss = 1.44176
Step 4505: loss = 1.29210
Step 4510: loss = 1.46490
Step 4515: loss = 1.25961
Step 4520: loss = 1.26926
Step 4525: loss = 1.34354
Step 4530: loss = 1.37413
Step 4535: loss = 1.23409
Step 4540: loss = 1.64155
Step 4545: loss = 1.50034
Step 4550: loss = 1.28879
Step 4555: loss = 1.06880
Step 4560: loss = 1.40678
Step 4565: loss = 1.50469
Step 4570: loss = 1.46058
Step 4575: loss = 1.42413
Step 4580: loss = 1.42034
Step 4585: loss = 1.60988
Step 4590: loss = 1.51563
Step 4595: loss = 1.39239
Step 4600: loss = 1.55478
Step 4605: loss = 1.35284
Step 4610: loss = 1.46935
Step 4615: loss = 1.68365
Step 4620: loss = 1.35418
Step 4625: loss = 1.48075
Step 4630: loss = 1.29731
Step 4635: loss = 1.55429
Step 4640: loss = 1.27339
Step 4645: loss = 1.30476
Step 4650: loss = 1.19687
Step 4655: loss = 1.35966
Step 4660: loss = 1.33593
Step 4665: loss = 1.47781
Step 4670: loss = 1.61374
Step 4675: loss = 1.30128
Step 4680: loss = 1.61265
Step 4685: loss = 1.64056
Step 4690: loss = 1.54890
Step 4695: loss = 1.19434
Step 4700: loss = 1.12167
Step 4705: loss = 1.36663
Step 4710: loss = 1.61914
Step 4715: loss = 1.56954
Step 4720: loss = 1.42977
Step 4725: loss = 1.44485
Step 4730: loss = 1.41790
Step 4735: loss = 1.60323
Step 4740: loss = 1.41781
Step 4745: loss = 1.48270
Step 4750: loss = 1.28537
Step 4755: loss = 1.54945
Step 4760: loss = 1.57215
Step 4765: loss = 1.24681
Step 4770: loss = 1.10125
Step 4775: loss = 1.51557
Step 4780: loss = 1.74492
Step 4785: loss = 1.25108
Step 4790: loss = 1.56084
Step 4795: loss = 1.23856
Step 4800: loss = 1.21265
Step 4805: loss = 1.62636
Step 4810: loss = 1.23728
Step 4815: loss = 1.27979
Step 4820: loss = 1.14348
Step 4825: loss = 1.14110
Step 4830: loss = 1.39284
Step 4835: loss = 1.38511
Step 4840: loss = 1.47253
Step 4845: loss = 1.13397
Step 4850: loss = 1.33348
Step 4855: loss = 1.30290
Step 4860: loss = 1.50971
Step 4865: loss = 1.39870
Step 4870: loss = 1.24826
Step 4875: loss = 1.19583
Step 4880: loss = 1.30696
Step 4885: loss = 1.26934
Step 4890: loss = 1.25754
Step 4895: loss = 1.48254
Step 4900: loss = 1.53709
Step 4905: loss = 1.56241
Step 4910: loss = 1.33922
Step 4915: loss = 1.40799
Step 4920: loss = 1.39547
Step 4925: loss = 1.60181
Step 4930: loss = 1.44707
Step 4935: loss = 1.22173
Step 4940: loss = 1.23932
Step 4945: loss = 1.29217
Step 4950: loss = 1.37659
Step 4955: loss = 1.31941
Step 4960: loss = 1.55641
Step 4965: loss = 1.57688
Step 4970: loss = 1.21852
Step 4975: loss = 1.28253
Step 4980: loss = 1.09683
Step 4985: loss = 1.32033
Step 4990: loss = 1.43074
Step 4995: loss = 1.28352
Step 5000: loss = 1.61319
Training Data Eval:
  Num examples: 50000, Num correct: 25872, Precision @ 1: 0.5174
('Testing Data Eval: EPOCH->', 6)
  Num examples: 10000, Num correct: 4177, Precision @ 1: 0.4177
Step 5005: loss = 1.23663
Step 5010: loss = 1.36804
Step 5015: loss = 1.41064
Step 5020: loss = 1.63711
Step 5025: loss = 1.13348
Step 5030: loss = 1.29152
Step 5035: loss = 1.56677
Step 5040: loss = 1.30112
Step 5045: loss = 1.26931
Step 5050: loss = 1.35710
Step 5055: loss = 1.69190
Step 5060: loss = 1.32827
Step 5065: loss = 1.25258
Step 5070: loss = 1.38346
Step 5075: loss = 1.30844
Step 5080: loss = 1.50538
Step 5085: loss = 1.06880
Step 5090: loss = 1.25812
Step 5095: loss = 1.43060
Step 5100: loss = 1.11368
Step 5105: loss = 1.33932
Step 5110: loss = 1.20434
Step 5115: loss = 1.38163
Step 5120: loss = 1.41133
Step 5125: loss = 1.42024
Step 5130: loss = 1.03537
Step 5135: loss = 1.64906
Step 5140: loss = 1.33809
Step 5145: loss = 1.36854
Step 5150: loss = 1.32199
Step 5155: loss = 1.42682
Step 5160: loss = 1.63504
Step 5165: loss = 1.55386
Step 5170: loss = 1.31607
Step 5175: loss = 1.62554
Step 5180: loss = 1.63164
Step 5185: loss = 1.17647
Step 5190: loss = 1.70069
Step 5195: loss = 1.29142
Step 5200: loss = 1.45756
Step 5205: loss = 1.28780
Step 5210: loss = 1.48648
Step 5215: loss = 1.06786
Step 5220: loss = 1.36969
Step 5225: loss = 1.71115
Step 5230: loss = 1.39872
Step 5235: loss = 1.41654
Step 5240: loss = 1.41267
Step 5245: loss = 1.15231
Step 5250: loss = 1.53071
Step 5255: loss = 1.42328
Step 5260: loss = 1.38075
Step 5265: loss = 1.44433
Step 5270: loss = 1.38242
Step 5275: loss = 1.35758
Step 5280: loss = 1.29909
Step 5285: loss = 1.12876
Step 5290: loss = 1.26205
Step 5295: loss = 1.10347
Step 5300: loss = 1.38070
Step 5305: loss = 1.42552
Step 5310: loss = 1.40768
Step 5315: loss = 1.23219
Step 5320: loss = 1.16620
Step 5325: loss = 1.36739
Step 5330: loss = 1.49215
Step 5335: loss = 1.15530
Step 5340: loss = 1.51754
Step 5345: loss = 1.28739
Step 5350: loss = 1.33610
Step 5355: loss = 1.30032
Step 5360: loss = 1.37611
Step 5365: loss = 1.35446
Step 5370: loss = 1.48444
Step 5375: loss = 1.34521
Step 5380: loss = 1.47824
Step 5385: loss = 1.44649
Step 5390: loss = 1.37229
Step 5395: loss = 1.41641
Step 5400: loss = 1.40433
Step 5405: loss = 1.54780
Step 5410: loss = 1.36820
Step 5415: loss = 1.23083
Step 5420: loss = 1.39335
Step 5425: loss = 1.52393
Step 5430: loss = 1.47236
Step 5435: loss = 1.13439
Step 5440: loss = 1.42173
Step 5445: loss = 1.69592
Step 5450: loss = 1.29651
Step 5455: loss = 1.45406
Step 5460: loss = 1.43600
Step 5465: loss = 1.07681
Step 5470: loss = 1.30225
Step 5475: loss = 1.53177
Step 5480: loss = 1.11700
Step 5485: loss = 1.35363
Step 5490: loss = 1.77651
Step 5495: loss = 1.22996
Step 5500: loss = 1.29337
Step 5505: loss = 1.67958
Step 5510: loss = 1.53916
Step 5515: loss = 1.41999
Step 5520: loss = 1.17924
Step 5525: loss = 1.21451
Step 5530: loss = 1.15543
Step 5535: loss = 1.70873
Step 5540: loss = 1.26181
Step 5545: loss = 1.36074
Step 5550: loss = 1.46962
Step 5555: loss = 1.36439
Step 5560: loss = 1.23201
Step 5565: loss = 1.17495
Step 5570: loss = 1.39124
Step 5575: loss = 1.36815
Step 5580: loss = 1.24598
Step 5585: loss = 1.11748
Step 5590: loss = 1.39679
Step 5595: loss = 1.44985
Step 5600: loss = 1.60950
Step 5605: loss = 1.33600
Step 5610: loss = 1.35362
Step 5615: loss = 1.47904
Step 5620: loss = 1.23151
Step 5625: loss = 1.20091
Step 5630: loss = 1.03486
Step 5635: loss = 1.49708
Step 5640: loss = 1.79169
Step 5645: loss = 1.41545
Step 5650: loss = 1.22517
Step 5655: loss = 1.49274
Step 5660: loss = 1.36378
Step 5665: loss = 1.30669
Step 5670: loss = 1.48106
Step 5675: loss = 1.29684
Step 5680: loss = 1.05624
Step 5685: loss = 1.30469
Step 5690: loss = 1.32260
Step 5695: loss = 1.32079
Step 5700: loss = 1.16025
Step 5705: loss = 1.40088
Step 5710: loss = 1.28364
Step 5715: loss = 1.45583
Step 5720: loss = 1.60633
Step 5725: loss = 1.40925
Step 5730: loss = 1.35553
Step 5735: loss = 1.34406
Step 5740: loss = 1.38302
Step 5745: loss = 1.14473
Step 5750: loss = 1.35091
Step 5755: loss = 1.24428
Step 5760: loss = 1.34510
Step 5765: loss = 1.32108
Step 5770: loss = 1.29797
Step 5775: loss = 1.67629
Step 5780: loss = 1.33497
Step 5785: loss = 1.28829
Step 5790: loss = 1.70424
Step 5795: loss = 1.20089
Step 5800: loss = 1.43559
Step 5805: loss = 1.39167
Step 5810: loss = 1.42680
Step 5815: loss = 1.15587
Step 5820: loss = 1.18642
Step 5825: loss = 1.21932
Step 5830: loss = 1.46467
Step 5835: loss = 1.16368
Step 5840: loss = 1.29508
Step 5845: loss = 1.23931
Step 5850: loss = 1.20640
Step 5855: loss = 1.48512
Step 5860: loss = 1.50245
Step 5865: loss = 1.22694
Step 5870: loss = 1.58660
Step 5875: loss = 1.42642
Step 5880: loss = 1.58466
Step 5885: loss = 1.22655
Step 5890: loss = 1.46293
Step 5895: loss = 1.53025
Step 5900: loss = 1.40170
Step 5905: loss = 1.23980
Step 5910: loss = 1.44443
Step 5915: loss = 1.27916
Step 5920: loss = 1.17546
Step 5925: loss = 1.35091
Step 5930: loss = 1.22901
Step 5935: loss = 1.20505
Step 5940: loss = 1.27058
Step 5945: loss = 1.17959
Step 5950: loss = 1.50256
Step 5955: loss = 1.17644
Step 5960: loss = 1.41713
Step 5965: loss = 1.26776
Step 5970: loss = 1.29203
Step 5975: loss = 1.23064
Step 5980: loss = 1.25397
Step 5985: loss = 1.26354
Step 5990: loss = 1.43064
Step 5995: loss = 1.15315
Step 6000: loss = 1.02209
Training Data Eval:
  Num examples: 50000, Num correct: 27120, Precision @ 1: 0.5424
('Testing Data Eval: EPOCH->', 7)
  Num examples: 10000, Num correct: 4500, Precision @ 1: 0.4500
Step 6005: loss = 0.98329
Step 6010: loss = 1.05602
Step 6015: loss = 1.42329
Step 6020: loss = 1.25051
Step 6025: loss = 1.33551
Step 6030: loss = 1.01335
Step 6035: loss = 1.34171
Step 6040: loss = 1.17944
Step 6045: loss = 1.36556
Step 6050: loss = 1.29504
Step 6055: loss = 1.12492
Step 6060: loss = 1.08480
Step 6065: loss = 1.69437
Step 6070: loss = 1.40137
Step 6075: loss = 1.28152
Step 6080: loss = 1.23746
Step 6085: loss = 1.16466
Step 6090: loss = 1.25629
Step 6095: loss = 1.20576
Step 6100: loss = 1.29880
Step 6105: loss = 1.37989
Step 6110: loss = 1.45014
Step 6115: loss = 1.53215
Step 6120: loss = 1.26271
Step 6125: loss = 1.17833
Step 6130: loss = 1.42902
Step 6135: loss = 1.49447
Step 6140: loss = 1.16339
Step 6145: loss = 1.49116
Step 6150: loss = 1.26068
Step 6155: loss = 1.23359
Step 6160: loss = 1.52645
Step 6165: loss = 1.60467
Step 6170: loss = 1.31355
Step 6175: loss = 1.47459
Step 6180: loss = 1.40332
Step 6185: loss = 1.42230
Step 6190: loss = 1.66686
Step 6195: loss = 1.29726
Step 6200: loss = 1.69164
Step 6205: loss = 1.15238
Step 6210: loss = 1.27233
Step 6215: loss = 1.32669
Step 6220: loss = 1.37566
Step 6225: loss = 1.32239
Step 6230: loss = 1.53908
Step 6235: loss = 1.23637
Step 6240: loss = 1.57885
Step 6245: loss = 1.25361
Step 6250: loss = 0.81936
Step 6255: loss = 1.41250
Step 6260: loss = 1.53970
Step 6265: loss = 1.36040
Step 6270: loss = 1.55038
Step 6275: loss = 1.22439
Step 6280: loss = 1.33553
Step 6285: loss = 1.20945
Step 6290: loss = 1.47242
Step 6295: loss = 1.20092
Step 6300: loss = 1.26406
Step 6305: loss = 1.36168
Step 6310: loss = 1.11966
Step 6315: loss = 1.17628
Step 6320: loss = 1.41689
Step 6325: loss = 1.25794
Step 6330: loss = 1.16317
Step 6335: loss = 1.17054
Step 6340: loss = 1.23080
Step 6345: loss = 1.44520
Step 6350: loss = 1.42662
Step 6355: loss = 1.31533
Step 6360: loss = 1.34036
Step 6365: loss = 1.29187
Step 6370: loss = 1.01663
Step 6375: loss = 1.44016
Step 6380: loss = 1.40644
Step 6385: loss = 1.38940
Step 6390: loss = 1.06868
Step 6395: loss = 1.13516
Step 6400: loss = 1.20236
Step 6405: loss = 1.03300
Step 6410: loss = 1.17087
Step 6415: loss = 0.93718
Step 6420: loss = 1.16639
Step 6425: loss = 1.02478
Step 6430: loss = 1.18812
Step 6435: loss = 1.22248
Step 6440: loss = 1.22461
Step 6445: loss = 1.44261
Step 6450: loss = 1.08806
Step 6455: loss = 1.31288
Step 6460: loss = 1.54980
Step 6465: loss = 0.94045
Step 6470: loss = 1.55649
Step 6475: loss = 1.59627
Step 6480: loss = 1.15489
Step 6485: loss = 1.21669
Step 6490: loss = 1.59421
Step 6495: loss = 1.39705
Step 6500: loss = 1.30936
Step 6505: loss = 1.10422
Step 6510: loss = 1.39836
Step 6515: loss = 1.22823
Step 6520: loss = 1.39019
Step 6525: loss = 0.88318
Step 6530: loss = 1.18005
Step 6535: loss = 1.44965
Step 6540: loss = 1.22849
Step 6545: loss = 1.37256
Step 6550: loss = 1.40952
Step 6555: loss = 1.63949
Step 6560: loss = 1.38435
Step 6565: loss = 1.51267
Step 6570: loss = 1.16943
Step 6575: loss = 1.03476
Step 6580: loss = 1.21213
Step 6585: loss = 1.20245
Step 6590: loss = 1.18338
Step 6595: loss = 1.39882
Step 6600: loss = 1.34761
Step 6605: loss = 1.62047
Step 6610: loss = 1.40552
Step 6615: loss = 1.13947
Step 6620: loss = 1.18275
Step 6625: loss = 1.19180
Step 6630: loss = 1.08244
Step 6635: loss = 1.24282
Step 6640: loss = 1.07890
Step 6645: loss = 1.36365
Step 6650: loss = 1.27041
Step 6655: loss = 1.09511
Step 6660: loss = 1.64084
Step 6665: loss = 1.17766
Step 6670: loss = 1.04162
Step 6675: loss = 1.42626
Step 6680: loss = 1.25361
Step 6685: loss = 1.34875
Step 6690: loss = 1.21835
Step 6695: loss = 1.40081
Step 6700: loss = 1.05015
Step 6705: loss = 1.31949
Step 6710: loss = 1.61860
Step 6715: loss = 1.26257
Step 6720: loss = 1.22571
Step 6725: loss = 1.33702
Step 6730: loss = 1.29259
Step 6735: loss = 0.94474
Step 6740: loss = 1.37897
Step 6745: loss = 1.04906
Step 6750: loss = 1.31247
Step 6755: loss = 1.27455
Step 6760: loss = 1.31962
Step 6765: loss = 1.30951
Step 6770: loss = 1.25435
Step 6775: loss = 1.43441
Step 6780: loss = 1.26210
Step 6785: loss = 1.25835
Step 6790: loss = 1.30989
Step 6795: loss = 1.55552
Step 6800: loss = 1.42265
Step 6805: loss = 1.40873
Step 6810: loss = 1.10905
Step 6815: loss = 1.09244
Step 6820: loss = 1.28910
Step 6825: loss = 1.16853
Step 6830: loss = 1.28466
Step 6835: loss = 1.25630
Step 6840: loss = 1.28970
Step 6845: loss = 1.49276
Step 6850: loss = 0.96097
Step 6855: loss = 1.34576
Step 6860: loss = 1.60136
Step 6865: loss = 1.41654
Step 6870: loss = 0.93550
Step 6875: loss = 1.51781
Step 6880: loss = 1.29128
Step 6885: loss = 1.00320
Step 6890: loss = 1.19136
Step 6895: loss = 1.17877
Step 6900: loss = 1.08770
Step 6905: loss = 1.11768
Step 6910: loss = 1.11844
Step 6915: loss = 1.50505
Step 6920: loss = 1.34084
Step 6925: loss = 1.34916
Step 6930: loss = 1.26341
Step 6935: loss = 1.46696
Step 6940: loss = 1.20655
Step 6945: loss = 1.10930
Step 6950: loss = 1.31994
Step 6955: loss = 1.31976
Step 6960: loss = 1.10175
Step 6965: loss = 1.49266
Step 6970: loss = 1.51303
Step 6975: loss = 1.53158
Step 6980: loss = 1.09716
Step 6985: loss = 1.47176
Step 6990: loss = 1.15330
Step 6995: loss = 1.36000
Step 7000: loss = 1.15367
Training Data Eval:
  Num examples: 50000, Num correct: 28337, Precision @ 1: 0.5667
('Testing Data Eval: EPOCH->', 8)
  Num examples: 10000, Num correct: 4779, Precision @ 1: 0.4779
Step 7005: loss = 1.05491
Step 7010: loss = 1.46955
Step 7015: loss = 1.40286
Step 7020: loss = 1.14081
Step 7025: loss = 1.31499
Step 7030: loss = 1.02637
Step 7035: loss = 1.06129
Step 7040: loss = 0.89528
Step 7045: loss = 0.93898
Step 7050: loss = 1.45363
Step 7055: loss = 1.11707
Step 7060: loss = 1.26360
Step 7065: loss = 1.56560
Step 7070: loss = 1.56390
Step 7075: loss = 1.14632
Step 7080: loss = 0.99782
Step 7085: loss = 1.33683
Step 7090: loss = 1.29315
Step 7095: loss = 1.42224
Step 7100: loss = 1.17463
Step 7105: loss = 1.14625
Step 7110: loss = 1.43722
Step 7115: loss = 1.00418
Step 7120: loss = 1.08434
Step 7125: loss = 1.22231
Step 7130: loss = 1.48933
Step 7135: loss = 1.31806
Step 7140: loss = 1.07168
Step 7145: loss = 1.27001
Step 7150: loss = 1.74254
Step 7155: loss = 1.26975
Step 7160: loss = 1.46583
Step 7165: loss = 1.08976
Step 7170: loss = 1.43940
Step 7175: loss = 1.41744
Step 7180: loss = 1.25613
Step 7185: loss = 0.99554
Step 7190: loss = 1.17217
Step 7195: loss = 1.05685
Step 7200: loss = 1.25828
Step 7205: loss = 1.48158
Step 7210: loss = 1.39053
Step 7215: loss = 1.53046
Step 7220: loss = 1.12282
Step 7225: loss = 1.36224
Step 7230: loss = 1.22699
Step 7235: loss = 1.17635
Step 7240: loss = 1.21669
Step 7245: loss = 1.29913
Step 7250: loss = 1.37540
Step 7255: loss = 1.42043
Step 7260: loss = 0.98501
Step 7265: loss = 1.13449
Step 7270: loss = 1.08126
Step 7275: loss = 1.15764
Step 7280: loss = 1.32877
Step 7285: loss = 1.53412
Step 7290: loss = 1.15761
Step 7295: loss = 1.28733
Step 7300: loss = 1.18372
Step 7305: loss = 1.18540
Step 7310: loss = 1.16750
Step 7315: loss = 1.10482
Step 7320: loss = 1.14835
Step 7325: loss = 1.21469
Step 7330: loss = 1.34603
Step 7335: loss = 1.07350
Step 7340: loss = 0.94121
Step 7345: loss = 1.25863
Step 7350: loss = 1.35669
Step 7355: loss = 1.22936
Step 7360: loss = 1.11397
Step 7365: loss = 1.26493
Step 7370: loss = 0.81999
Step 7375: loss = 1.90847
Step 7380: loss = 1.05932
Step 7385: loss = 1.18047
Step 7390: loss = 1.19415
Step 7395: loss = 1.37001
Step 7400: loss = 1.34268
Step 7405: loss = 1.15325
Step 7410: loss = 0.82329
Step 7415: loss = 1.08396
Step 7420: loss = 0.92715
Step 7425: loss = 0.97078
Step 7430: loss = 1.38246
Step 7435: loss = 0.98988
Step 7440: loss = 1.21229
Step 7445: loss = 1.34901
Step 7450: loss = 1.04232
Step 7455: loss = 1.06137
Step 7460: loss = 1.20600
Step 7465: loss = 1.45771
Step 7470: loss = 1.22179
Step 7475: loss = 1.39193
Step 7480: loss = 1.66022
Step 7485: loss = 1.18460
Step 7490: loss = 1.45247
Step 7495: loss = 1.27529
Step 7500: loss = 1.54553
Step 7505: loss = 1.18856
Step 7510: loss = 1.37436
Step 7515: loss = 0.91111
Step 7520: loss = 1.11100
Step 7525: loss = 1.13672
Step 7530: loss = 1.12904
Step 7535: loss = 1.36692
Step 7540: loss = 0.98111
Step 7545: loss = 0.98724
Step 7550: loss = 1.21224
Step 7555: loss = 1.24380
Step 7560: loss = 1.21162
Step 7565: loss = 1.26584
Step 7570: loss = 1.33888
Step 7575: loss = 1.22229
Step 7580: loss = 1.04265
Step 7585: loss = 1.40986
Step 7590: loss = 1.08930
Step 7595: loss = 1.26421
Step 7600: loss = 1.21736
Step 7605: loss = 1.31240
Step 7610: loss = 1.42043
Step 7615: loss = 1.24731
Step 7620: loss = 1.37488
Step 7625: loss = 1.12202
Step 7630: loss = 1.40334
Step 7635: loss = 1.18888
Step 7640: loss = 1.16898
Step 7645: loss = 1.21749
Step 7650: loss = 1.11636
Step 7655: loss = 1.22489
Step 7660: loss = 1.11600
Step 7665: loss = 1.40663
Step 7670: loss = 1.49569
Step 7675: loss = 1.32580
Step 7680: loss = 1.04350
Step 7685: loss = 1.36581
Step 7690: loss = 1.61420
Step 7695: loss = 1.21719
Step 7700: loss = 1.11691
Step 7705: loss = 1.32458
Step 7710: loss = 1.12079
Step 7715: loss = 1.11230
Step 7720: loss = 1.19277
Step 7725: loss = 0.99010
Step 7730: loss = 1.22622
Step 7735: loss = 1.43228
Step 7740: loss = 1.20197
Step 7745: loss = 1.20685
Step 7750: loss = 1.19069
Step 7755: loss = 1.03421
Step 7760: loss = 1.09565
Step 7765: loss = 1.07529
Step 7770: loss = 1.22858
Step 7775: loss = 1.12175
Step 7780: loss = 1.00334
Step 7785: loss = 1.13318
Step 7790: loss = 1.18893
Step 7795: loss = 1.11863
Step 7800: loss = 1.48595
Step 7805: loss = 0.99226
Step 7810: loss = 1.21372
Step 7815: loss = 0.98564
Step 7820: loss = 1.11760
Step 7825: loss = 1.48334
Step 7830: loss = 1.06064
Step 7835: loss = 1.28121
Step 7840: loss = 1.41904
Step 7845: loss = 1.22334
Step 7850: loss = 1.07773
Step 7855: loss = 1.42989
Step 7860: loss = 0.96576
Step 7865: loss = 1.03916
Step 7870: loss = 1.22354
Step 7875: loss = 1.10134
Step 7880: loss = 0.98697
Step 7885: loss = 1.22995
Step 7890: loss = 0.97166
Step 7895: loss = 1.11300
Step 7900: loss = 1.09704
Step 7905: loss = 1.24755
Step 7910: loss = 1.24301
Step 7915: loss = 0.79923
Step 7920: loss = 1.32030
Step 7925: loss = 1.41499
Step 7930: loss = 1.04676
Step 7935: loss = 1.22574
Step 7940: loss = 1.25552
Step 7945: loss = 1.14979
Step 7950: loss = 1.05098
Step 7955: loss = 1.24286
Step 7960: loss = 1.30488
Step 7965: loss = 1.21730
Step 7970: loss = 1.03711
Step 7975: loss = 1.14156
Step 7980: loss = 1.03386
Step 7985: loss = 1.37115
Step 7990: loss = 1.18988
Step 7995: loss = 1.38005
Step 8000: loss = 1.25901
Training Data Eval:
  Num examples: 50000, Num correct: 28886, Precision @ 1: 0.5777
('Testing Data Eval: EPOCH->', 9)
  Num examples: 10000, Num correct: 4826, Precision @ 1: 0.4826
Step 8005: loss = 1.27862
Step 8010: loss = 1.18771
Step 8015: loss = 1.08186
Step 8020: loss = 1.11649
Step 8025: loss = 1.41441
Step 8030: loss = 1.11185
Step 8035: loss = 1.25839
Step 8040: loss = 1.27569
Step 8045: loss = 1.41510
Step 8050: loss = 0.80314
Step 8055: loss = 1.19001
Step 8060: loss = 1.46832
Step 8065: loss = 1.08055
Step 8070: loss = 1.39277
Step 8075: loss = 1.24326
Step 8080: loss = 1.38453
Step 8085: loss = 0.84926
Step 8090: loss = 1.35895
Step 8095: loss = 1.20013
Step 8100: loss = 0.97412
Step 8105: loss = 1.12881
Step 8110: loss = 1.09801
Step 8115: loss = 1.22466
Step 8120: loss = 1.04767
Step 8125: loss = 1.20616
Step 8130: loss = 1.28390
Step 8135: loss = 1.46203
Step 8140: loss = 1.42075
Step 8145: loss = 1.31171
Step 8150: loss = 1.04281
Step 8155: loss = 1.14745
Step 8160: loss = 1.45461
Step 8165: loss = 1.28742
Step 8170: loss = 1.07647
Step 8175: loss = 1.29843
Step 8180: loss = 1.27070
Step 8185: loss = 1.25139
Step 8190: loss = 1.26249
Step 8195: loss = 1.31949
Step 8200: loss = 1.09697
Step 8205: loss = 1.08966
Step 8210: loss = 1.29182
Step 8215: loss = 1.07468
Step 8220: loss = 0.97778
Step 8225: loss = 1.34624
Step 8230: loss = 1.17808
Step 8235: loss = 1.39386
Step 8240: loss = 1.13905
Step 8245: loss = 1.06138
Step 8250: loss = 1.10499
Step 8255: loss = 1.08478
Step 8260: loss = 1.13997
Step 8265: loss = 1.32538
Step 8270: loss = 1.26601
Step 8275: loss = 1.18932
Step 8280: loss = 1.08656
Step 8285: loss = 1.08728
Step 8290: loss = 1.20546
Step 8295: loss = 1.13243
Step 8300: loss = 1.48277
Step 8305: loss = 1.08395
Step 8310: loss = 1.10487
Step 8315: loss = 1.16226
Step 8320: loss = 1.37255
Step 8325: loss = 1.29760
Step 8330: loss = 0.89852
Step 8335: loss = 1.45179
Step 8340: loss = 1.44997
Step 8345: loss = 1.23538
Step 8350: loss = 1.12307
Step 8355: loss = 1.03737
Step 8360: loss = 0.88607
Step 8365: loss = 1.11905
Step 8370: loss = 1.15616
Step 8375: loss = 1.27631
Step 8380: loss = 1.25844
Step 8385: loss = 1.09549
Step 8390: loss = 1.29141
Step 8395: loss = 0.81666
Step 8400: loss = 0.90739
Step 8405: loss = 1.40346
Step 8410: loss = 1.16184
Step 8415: loss = 1.01681
Step 8420: loss = 1.02031
Step 8425: loss = 1.06733
Step 8430: loss = 1.05413
Step 8435: loss = 1.22903
Step 8440: loss = 1.13270
Step 8445: loss = 1.26045
Step 8450: loss = 1.33735
Step 8455: loss = 1.33504
Step 8460: loss = 1.18326
Step 8465: loss = 0.98620
Step 8470: loss = 1.07806
Step 8475: loss = 1.40050
Step 8480: loss = 0.99995
Step 8485: loss = 1.25327
Step 8490: loss = 1.14758
Step 8495: loss = 1.28526
Step 8500: loss = 1.32688
Step 8505: loss = 0.91914
Step 8510: loss = 1.09272
Step 8515: loss = 1.03381
Step 8520: loss = 0.84862
Step 8525: loss = 1.22824
Step 8530: loss = 1.21658
Step 8535: loss = 1.31216
Step 8540: loss = 1.20593
Step 8545: loss = 1.23414
Step 8550: loss = 1.10096
Step 8555: loss = 1.10347
Step 8560: loss = 1.38154
Step 8565: loss = 1.27581
Step 8570: loss = 1.16272
Step 8575: loss = 1.30841
Step 8580: loss = 1.37146
Step 8585: loss = 1.28228
Step 8590: loss = 0.99231
Step 8595: loss = 1.19342
Step 8600: loss = 1.35018
Step 8605: loss = 1.14473
Step 8610: loss = 1.20626
Step 8615: loss = 1.08584
Step 8620: loss = 1.07691
Step 8625: loss = 1.25849
Step 8630: loss = 1.17023
Step 8635: loss = 1.13091
Step 8640: loss = 1.14602
Step 8645: loss = 1.39371
Step 8650: loss = 1.39303
Step 8655: loss = 1.13304
Step 8660: loss = 1.17046
Step 8665: loss = 1.31629
Step 8670: loss = 1.08100
Step 8675: loss = 1.20690
Step 8680: loss = 0.93264
Step 8685: loss = 0.91701
Step 8690: loss = 0.97729
Step 8695: loss = 1.22468
Step 8700: loss = 1.03078
Step 8705: loss = 1.40224
Step 8710: loss = 1.05480
Step 8715: loss = 1.35177
Step 8720: loss = 1.26095
Step 8725: loss = 1.41446
Step 8730: loss = 0.95670
Step 8735: loss = 1.31995
Step 8740: loss = 1.04168
Step 8745: loss = 1.05174
Step 8750: loss = 1.14286
Step 8755: loss = 0.94501
Step 8760: loss = 1.40517
Step 8765: loss = 1.18075
Step 8770: loss = 1.59223
Step 8775: loss = 1.18797
Step 8780: loss = 1.22341
Step 8785: loss = 1.26968
Step 8790: loss = 1.11780
Step 8795: loss = 1.29159
Step 8800: loss = 1.26550
Step 8805: loss = 1.43626
Step 8810: loss = 1.21973
Step 8815: loss = 1.23296
Step 8820: loss = 1.21238
Step 8825: loss = 1.01668
Step 8830: loss = 1.17916
Step 8835: loss = 1.13074
Step 8840: loss = 1.16122
Step 8845: loss = 0.83650
Step 8850: loss = 1.06204
Step 8855: loss = 1.32336
Step 8860: loss = 0.98951
Step 8865: loss = 0.73353
Step 8870: loss = 1.40707
Step 8875: loss = 1.17144
Step 8880: loss = 1.11499
Step 8885: loss = 1.17192
Step 8890: loss = 1.51953
Step 8895: loss = 0.94449
Step 8900: loss = 1.33442
Step 8905: loss = 1.04762
Step 8910: loss = 1.12537
Step 8915: loss = 1.41215
Step 8920: loss = 0.99604
Step 8925: loss = 1.01261
Step 8930: loss = 1.25311
Step 8935: loss = 1.07862
Step 8940: loss = 1.33242
Step 8945: loss = 1.37272
Step 8950: loss = 1.10373
Step 8955: loss = 1.22205
Step 8960: loss = 1.14985
Step 8965: loss = 0.99249
Step 8970: loss = 1.07559
Step 8975: loss = 0.97240
Step 8980: loss = 1.36616
Step 8985: loss = 1.15402
Step 8990: loss = 1.28163
Step 8995: loss = 1.14751
Step 9000: loss = 1.15663
Training Data Eval:
  Num examples: 50000, Num correct: 30290, Precision @ 1: 0.6058
('Testing Data Eval: EPOCH->', 10)
  Num examples: 10000, Num correct: 5144, Precision @ 1: 0.5144
Step 9005: loss = 1.18813
Step 9010: loss = 1.19274
Step 9015: loss = 1.21231
Step 9020: loss = 0.92782
Step 9025: loss = 1.08939
Step 9030: loss = 0.94107
Step 9035: loss = 1.17499
Step 9040: loss = 1.28174
Step 9045: loss = 1.24865
Step 9050: loss = 1.02623
Step 9055: loss = 1.18738
Step 9060: loss = 0.86093
Step 9065: loss = 1.06048
Step 9070: loss = 1.11879
Step 9075: loss = 1.24767
Step 9080: loss = 1.26213
Step 9085: loss = 1.15306
Step 9090: loss = 1.28682
Step 9095: loss = 1.11545
Step 9100: loss = 1.17761
Step 9105: loss = 1.31931
Step 9110: loss = 0.89474
Step 9115: loss = 1.28455
Step 9120: loss = 1.24030
Step 9125: loss = 1.02019
Step 9130: loss = 1.26710
Step 9135: loss = 1.30933
Step 9140: loss = 1.38207
Step 9145: loss = 1.24840
Step 9150: loss = 0.98486
Step 9155: loss = 1.17423
Step 9160: loss = 1.20993
Step 9165: loss = 0.91607
Step 9170: loss = 0.85321
Step 9175: loss = 1.06416
Step 9180: loss = 0.81691
Step 9185: loss = 1.11054
Step 9190: loss = 1.10832
Step 9195: loss = 0.94084
Step 9200: loss = 1.11492
Step 9205: loss = 1.26369
Step 9210: loss = 1.10600
Step 9215: loss = 1.47385
Step 9220: loss = 1.08432
Step 9225: loss = 0.97138
Step 9230: loss = 1.04352
Step 9235: loss = 1.08580
Step 9240: loss = 1.03276
Step 9245: loss = 1.32795
Step 9250: loss = 1.13259
Step 9255: loss = 0.97286
Step 9260: loss = 1.03305
Step 9265: loss = 0.88595
Step 9270: loss = 1.01940
Step 9275: loss = 0.94822
Step 9280: loss = 1.36547
Step 9285: loss = 1.23583
Step 9290: loss = 0.89625
Step 9295: loss = 1.13664
Step 9300: loss = 0.83368
Step 9305: loss = 1.29032
Step 9310: loss = 1.21439
Step 9315: loss = 1.28717
Step 9320: loss = 1.31057
Step 9325: loss = 1.16086
Step 9330: loss = 1.04339
Step 9335: loss = 0.97258
Step 9340: loss = 1.22198
Step 9345: loss = 1.04827
Step 9350: loss = 0.91614
Step 9355: loss = 0.98937
Step 9360: loss = 0.85450
Step 9365: loss = 0.91184
Step 9370: loss = 1.13347
Step 9375: loss = 1.01897
Step 9380: loss = 1.18453
Step 9385: loss = 1.43828
Step 9390: loss = 1.13414
Step 9395: loss = 1.30275
Step 9400: loss = 1.12571
Step 9405: loss = 1.06470
Step 9410: loss = 1.06863
Step 9415: loss = 1.08591
Step 9420: loss = 1.17098
Step 9425: loss = 1.16020
Step 9430: loss = 1.51298
Step 9435: loss = 1.03512
Step 9440: loss = 1.08965
Step 9445: loss = 1.35190
Step 9450: loss = 1.04286
Step 9455: loss = 1.13307
Step 9460: loss = 1.26138
Step 9465: loss = 1.01691
Step 9470: loss = 1.03600
Step 9475: loss = 1.25741
Step 9480: loss = 1.08236
Step 9485: loss = 1.09252
Step 9490: loss = 1.21820
Step 9495: loss = 1.08129
Step 9500: loss = 1.03096
Step 9505: loss = 0.97589
Step 9510: loss = 1.09387
Step 9515: loss = 0.86873
Step 9520: loss = 1.50409
Step 9525: loss = 1.15217
Step 9530: loss = 1.26549
Step 9535: loss = 1.14940
Step 9540: loss = 1.07834
Step 9545: loss = 1.24155
Step 9550: loss = 1.00853
Step 9555: loss = 1.29209
Step 9560: loss = 1.41598
Step 9565: loss = 1.18116
Step 9570: loss = 0.95320
Step 9575: loss = 1.16436
Step 9580: loss = 1.02159
Step 9585: loss = 1.39314
Step 9590: loss = 0.93032
Step 9595: loss = 1.21418
Step 9600: loss = 1.08110
Step 9605: loss = 1.21621
Step 9610: loss = 1.28358
Step 9615: loss = 1.32249
Step 9620: loss = 1.15575
Step 9625: loss = 1.29848
Step 9630: loss = 1.31865
Step 9635: loss = 0.91160
Step 9640: loss = 1.04489
Step 9645: loss = 1.44168
Step 9650: loss = 0.88909
Step 9655: loss = 0.96078
Step 9660: loss = 1.06074
Step 9665: loss = 1.00591
Step 9670: loss = 1.22543
Step 9675: loss = 1.33818
Step 9680: loss = 1.21594
Step 9685: loss = 1.05830
Step 9690: loss = 1.01395
Step 9695: loss = 1.10844
Step 9700: loss = 1.27805
Step 9705: loss = 0.93895
Step 9710: loss = 1.06262
Step 9715: loss = 1.08887
Step 9720: loss = 0.96715
Step 9725: loss = 1.06144
Step 9730: loss = 1.02238
Step 9735: loss = 1.25016
Step 9740: loss = 0.99318
Step 9745: loss = 1.27116
Step 9750: loss = 1.12469
Step 9755: loss = 1.17831
Step 9760: loss = 1.11422
Step 9765: loss = 0.89017
Step 9770: loss = 1.05837
Step 9775: loss = 0.93638
Step 9780: loss = 1.13425
Step 9785: loss = 0.82933
Step 9790: loss = 1.02520
Step 9795: loss = 1.15523
Step 9800: loss = 1.35953
Step 9805: loss = 1.03236
Step 9810: loss = 0.93684
Step 9815: loss = 1.11673
Step 9820: loss = 1.00146
Step 9825: loss = 1.38784
Step 9830: loss = 0.99775
Step 9835: loss = 1.12955
Step 9840: loss = 1.09915
Step 9845: loss = 0.97184
Step 9850: loss = 1.26663
Step 9855: loss = 1.06267
Step 9860: loss = 1.19343
Step 9865: loss = 0.97335
Step 9870: loss = 0.95102
Step 9875: loss = 0.91617
Step 9880: loss = 1.04195
Step 9885: loss = 1.13928
Step 9890: loss = 1.23463
Step 9895: loss = 0.66613
Step 9900: loss = 1.14790
Step 9905: loss = 0.92957
Step 9910: loss = 1.18593
Step 9915: loss = 0.85384
Step 9920: loss = 1.08369
Step 9925: loss = 1.08236
Step 9930: loss = 1.03299
Step 9935: loss = 0.97591
Step 9940: loss = 1.25468
Step 9945: loss = 1.13404
Step 9950: loss = 0.86406
Step 9955: loss = 1.56432
Step 9960: loss = 1.06380
Step 9965: loss = 0.89447
Step 9970: loss = 1.11949
Step 9975: loss = 1.06962
Step 9980: loss = 0.80053
Step 9985: loss = 1.09875
Step 9990: loss = 1.49821
Step 9995: loss = 1.04922
Step 10000: loss = 1.19171
Training Data Eval:
  Num examples: 50000, Num correct: 30965, Precision @ 1: 0.6193
('Testing Data Eval: EPOCH->', 11)
  Num examples: 10000, Num correct: 5328, Precision @ 1: 0.5328
Step 10005: loss = 0.96365
Step 10010: loss = 0.89929
Step 10015: loss = 0.98727
Step 10020: loss = 1.09736
Step 10025: loss = 1.10549
Step 10030: loss = 1.07249
Step 10035: loss = 1.30815
Step 10040: loss = 1.30616
Step 10045: loss = 1.44418
Step 10050: loss = 0.88425
Step 10055: loss = 0.96867
Step 10060: loss = 0.99589
Step 10065: loss = 0.86375
Step 10070: loss = 1.14502
Step 10075: loss = 0.94875
Step 10080: loss = 0.91436
Step 10085: loss = 1.07963
Step 10090: loss = 1.16251
Step 10095: loss = 0.79120
Step 10100: loss = 1.21748
Step 10105: loss = 1.14574
Step 10110: loss = 0.98958
Step 10115: loss = 1.17695
Step 10120: loss = 1.13202
Step 10125: loss = 1.01575
Step 10130: loss = 1.00652
Step 10135: loss = 0.85538
Step 10140: loss = 1.02907
Step 10145: loss = 0.79636
Step 10150: loss = 1.24363
Step 10155: loss = 0.94835
Step 10160: loss = 1.17142
Step 10165: loss = 0.93080
Step 10170: loss = 1.20084
Step 10175: loss = 1.23397
Step 10180: loss = 1.21770
Step 10185: loss = 0.99538
Step 10190: loss = 1.09847
Step 10195: loss = 1.09143
Step 10200: loss = 1.21033
Step 10205: loss = 1.06479
Step 10210: loss = 1.18605
Step 10215: loss = 1.24120
Step 10220: loss = 1.15118
Step 10225: loss = 1.16511
Step 10230: loss = 1.37298
Step 10235: loss = 0.89552
Step 10240: loss = 1.21462
Step 10245: loss = 1.34808
Step 10250: loss = 0.91936
Step 10255: loss = 1.14486
Step 10260: loss = 1.25612
Step 10265: loss = 0.96351
Step 10270: loss = 1.14505
Step 10275: loss = 1.01997
Step 10280: loss = 1.11880
Step 10285: loss = 0.96363
Step 10290: loss = 1.40100
Step 10295: loss = 1.25330
Step 10300: loss = 1.09878
Step 10305: loss = 1.17148
Step 10310: loss = 1.00330
Step 10315: loss = 1.18431
Step 10320: loss = 0.86228
Step 10325: loss = 0.86461
Step 10330: loss = 0.89023
Step 10335: loss = 1.10154
Step 10340: loss = 0.95143
Step 10345: loss = 1.04111
Step 10350: loss = 1.01512
Step 10355: loss = 0.77893
Step 10360: loss = 0.70516
Step 10365: loss = 1.10463
Step 10370: loss = 0.99621
Step 10375: loss = 0.90160
Step 10380: loss = 0.98003
Step 10385: loss = 0.96155
Step 10390: loss = 0.90598
Step 10395: loss = 1.16205
Step 10400: loss = 1.20972
Step 10405: loss = 0.90535
Step 10410: loss = 0.81589
Step 10415: loss = 1.04701
Step 10420: loss = 0.96923
Step 10425: loss = 1.04293
Step 10430: loss = 0.99357
Step 10435: loss = 0.87490
Step 10440: loss = 0.94632
Step 10445: loss = 0.80030
Step 10450: loss = 1.15788
Step 10455: loss = 1.40483
Step 10460: loss = 0.82309
Step 10465: loss = 1.30069
Step 10470: loss = 0.75472
Step 10475: loss = 0.87736
Step 10480: loss = 1.19784
Step 10485: loss = 0.98121
Step 10490: loss = 0.96953
Step 10495: loss = 1.08059
Step 10500: loss = 1.15599
Step 10505: loss = 0.94008
Step 10510: loss = 0.98631
Step 10515: loss = 1.11358
Step 10520: loss = 1.37017
Step 10525: loss = 1.09995
Step 10530: loss = 0.98718
Step 10535: loss = 1.02776
Step 10540: loss = 1.06925
Step 10545: loss = 1.14014
Step 10550: loss = 0.88002
Step 10555: loss = 1.11495
Step 10560: loss = 0.89036
Step 10565: loss = 1.42225
Step 10570: loss = 0.83638
Step 10575: loss = 0.83995
Step 10580: loss = 1.12369
Step 10585: loss = 1.03220
Step 10590: loss = 1.02899
Step 10595: loss = 0.99383
Step 10600: loss = 1.11942
Step 10605: loss = 1.18793
Step 10610: loss = 1.03121
Step 10615: loss = 1.13765
Step 10620: loss = 1.12675
Step 10625: loss = 1.01140
Step 10630: loss = 1.09772
Step 10635: loss = 0.93690
Step 10640: loss = 1.06287
Step 10645: loss = 1.25141
Step 10650: loss = 1.13484
Step 10655: loss = 1.16830
Step 10660: loss = 1.21229
Step 10665: loss = 1.03569
Step 10670: loss = 1.07441
Step 10675: loss = 1.06633
Step 10680: loss = 1.33278
Step 10685: loss = 1.06918
Step 10690: loss = 1.09860
Step 10695: loss = 0.85406
Step 10700: loss = 1.31788
Step 10705: loss = 0.86194
Step 10710: loss = 1.12634
Step 10715: loss = 0.82119
Step 10720: loss = 1.06038
Step 10725: loss = 1.10214
Step 10730: loss = 1.08863
Step 10735: loss = 0.93041
Step 10740: loss = 1.18925
Step 10745: loss = 0.83889
Step 10750: loss = 1.34602
Step 10755: loss = 1.15029
Step 10760: loss = 0.88468
Step 10765: loss = 1.08133
Step 10770: loss = 1.16882
Step 10775: loss = 1.10565
Step 10780: loss = 0.73854
Step 10785: loss = 0.93093
Step 10790: loss = 1.29383
Step 10795: loss = 1.08263
Step 10800: loss = 0.88499
Step 10805: loss = 0.91372
Step 10810: loss = 0.98767
Step 10815: loss = 1.07090
Step 10820: loss = 1.07097
Step 10825: loss = 1.26890
Step 10830: loss = 1.11143
Step 10835: loss = 1.17003
Step 10840: loss = 1.02791
Step 10845: loss = 1.03980
Step 10850: loss = 0.95797
Step 10855: loss = 1.07197
Step 10860: loss = 1.02448
Step 10865: loss = 1.26686
Step 10870: loss = 1.25103
Step 10875: loss = 1.05580
Step 10880: loss = 0.85048
Step 10885: loss = 0.96691
Step 10890: loss = 1.17795
Step 10895: loss = 0.73896
Step 10900: loss = 1.27489
Step 10905: loss = 1.13898
Step 10910: loss = 0.93240
Step 10915: loss = 1.16696
Step 10920: loss = 1.08714
Step 10925: loss = 1.25068
Step 10930: loss = 0.87877
Step 10935: loss = 1.18400
Step 10940: loss = 0.81294
Step 10945: loss = 1.21448
Step 10950: loss = 0.64868
Step 10955: loss = 0.94452
Step 10960: loss = 0.83124
Step 10965: loss = 0.80829
Step 10970: loss = 1.03124
Step 10975: loss = 1.43110
Step 10980: loss = 0.97639
Step 10985: loss = 0.78670
Step 10990: loss = 0.88204
Step 10995: loss = 1.09109
Step 11000: loss = 0.91965
Training Data Eval:
  Num examples: 50000, Num correct: 31387, Precision @ 1: 0.6277
('Testing Data Eval: EPOCH->', 12)
  Num examples: 10000, Num correct: 5383, Precision @ 1: 0.5383
Step 11005: loss = 1.28926
Step 11010: loss = 0.80859
Step 11015: loss = 0.99212
Step 11020: loss = 0.79161
Step 11025: loss = 1.08422
Step 11030: loss = 1.04715
Step 11035: loss = 1.00486
Step 11040: loss = 1.21295
Step 11045: loss = 0.98787
Step 11050: loss = 1.21295
Step 11055: loss = 1.01982
Step 11060: loss = 0.90158
Step 11065: loss = 1.03299
Step 11070: loss = 1.02891
Step 11075: loss = 0.88628
Step 11080: loss = 1.01803
Step 11085: loss = 1.19390
Step 11090: loss = 0.87677
Step 11095: loss = 1.04604
Step 11100: loss = 0.90430
Step 11105: loss = 1.18123
Step 11110: loss = 0.86864
Step 11115: loss = 0.68878
Step 11120: loss = 1.19944
Step 11125: loss = 0.90481
Step 11130: loss = 0.70047
Step 11135: loss = 1.04606
Step 11140: loss = 0.67169
Step 11145: loss = 1.29419
Step 11150: loss = 0.94675
Step 11155: loss = 0.76523
Step 11160: loss = 1.39874
Step 11165: loss = 1.20462
Step 11170: loss = 0.96981
Step 11175: loss = 0.92232
Step 11180: loss = 1.22244
Step 11185: loss = 1.13583
Step 11190: loss = 1.18864
Step 11195: loss = 1.14680
Step 11200: loss = 0.90661
Step 11205: loss = 0.79117
Step 11210: loss = 0.86707
Step 11215: loss = 1.08464
Step 11220: loss = 1.62119
Step 11225: loss = 0.91839
Step 11230: loss = 0.98521
Step 11235: loss = 0.96455
Step 11240: loss = 1.06683
Step 11245: loss = 1.08817
Step 11250: loss = 0.82550
Step 11255: loss = 1.12895
Step 11260: loss = 0.82896
Step 11265: loss = 1.20167
Step 11270: loss = 0.79479
Step 11275: loss = 1.08578
Step 11280: loss = 0.86284
Step 11285: loss = 1.35704
Step 11290: loss = 1.09086
Step 11295: loss = 1.03574
Step 11300: loss = 0.94979
Step 11305: loss = 0.97422
Step 11310: loss = 0.94907
Step 11315: loss = 0.94526
Step 11320: loss = 0.90032
Step 11325: loss = 0.83484
Step 11330: loss = 0.72263
Step 11335: loss = 1.06820
Step 11340: loss = 0.95849
Step 11345: loss = 0.86141
Step 11350: loss = 0.95745
Step 11355: loss = 0.96540
Step 11360: loss = 1.00709
Step 11365: loss = 0.86463
Step 11370: loss = 1.04231
Step 11375: loss = 0.82720
Step 11380: loss = 1.54811
Step 11385: loss = 1.34470
Step 11390: loss = 0.96335
Step 11395: loss = 0.92653
Step 11400: loss = 0.79141
Step 11405: loss = 0.76787
Step 11410: loss = 1.05330
Step 11415: loss = 0.83114
Step 11420: loss = 0.84461
Step 11425: loss = 1.23551
Step 11430: loss = 0.83786
Step 11435: loss = 1.24705
Step 11440: loss = 0.60951
Step 11445: loss = 0.87518
Step 11450: loss = 0.78931
Step 11455: loss = 0.91539
Step 11460: loss = 0.99871
Step 11465: loss = 1.34282
Step 11470: loss = 1.31012
Step 11475: loss = 0.82619
Step 11480: loss = 1.04525
Step 11485: loss = 1.05537
Step 11490: loss = 0.97369
Step 11495: loss = 0.94950
Step 11500: loss = 0.78132
Step 11505: loss = 1.07397
Step 11510: loss = 1.29560
Step 11515: loss = 0.91489
Step 11520: loss = 0.87152
Step 11525: loss = 0.98190
Step 11530: loss = 1.07703
Step 11535: loss = 1.08553
Step 11540: loss = 1.00393
Step 11545: loss = 0.97274
Step 11550: loss = 1.01844
Step 11555: loss = 0.89152
Step 11560: loss = 1.23051
Step 11565: loss = 0.94871
Step 11570: loss = 1.10192
Step 11575: loss = 0.78811
Step 11580: loss = 0.90293
Step 11585: loss = 0.91272
Step 11590: loss = 0.85288
Step 11595: loss = 0.98828
Step 11600: loss = 1.04335
Step 11605: loss = 1.00127
Step 11610: loss = 1.33780
Step 11615: loss = 0.90747
Step 11620: loss = 0.93587
Step 11625: loss = 0.87128
Step 11630: loss = 1.02884
Step 11635: loss = 1.09238
Step 11640: loss = 1.07686
Step 11645: loss = 1.00555
Step 11650: loss = 1.19717
Step 11655: loss = 0.93815
Step 11660: loss = 1.15521
Step 11665: loss = 1.28675
Step 11670: loss = 1.13776
Step 11675: loss = 1.21074
Step 11680: loss = 1.00409
Step 11685: loss = 0.87632
Step 11690: loss = 1.08508
Step 11695: loss = 0.86658
Step 11700: loss = 0.89541
Step 11705: loss = 1.11542
Step 11710: loss = 1.04401
Step 11715: loss = 0.67199
Step 11720: loss = 1.02764
Step 11725: loss = 1.11327
Step 11730: loss = 1.04192
Step 11735: loss = 0.93711
Step 11740: loss = 1.07689
Step 11745: loss = 1.11671
Step 11750: loss = 1.11342
Step 11755: loss = 0.93359
Step 11760: loss = 1.25797
Step 11765: loss = 1.10229
Step 11770: loss = 0.72156
Step 11775: loss = 1.26638
Step 11780: loss = 0.93685
Step 11785: loss = 0.92223
Step 11790: loss = 1.30921
Step 11795: loss = 0.75753
Step 11800: loss = 1.00920
Step 11805: loss = 0.81023
Step 11810: loss = 0.98556
Step 11815: loss = 0.81706
Step 11820: loss = 1.21256
Step 11825: loss = 0.82169
Step 11830: loss = 0.94508
Step 11835: loss = 0.95826
Step 11840: loss = 0.98266
Step 11845: loss = 0.83307
Step 11850: loss = 1.05608
Step 11855: loss = 0.87625
Step 11860: loss = 1.05835
Step 11865: loss = 0.88023
Step 11870: loss = 0.98503
Step 11875: loss = 0.91798
Step 11880: loss = 1.17947
Step 11885: loss = 1.10711
Step 11890: loss = 1.06137
Step 11895: loss = 1.16792
Step 11900: loss = 0.97474
Step 11905: loss = 0.75642
Step 11910: loss = 0.85937
Step 11915: loss = 0.97348
Step 11920: loss = 0.95388
Step 11925: loss = 0.97319
Step 11930: loss = 1.01889
Step 11935: loss = 0.86718
Step 11940: loss = 1.14255
Step 11945: loss = 1.19671
Step 11950: loss = 0.99801
Step 11955: loss = 0.77655
Step 11960: loss = 0.85986
Step 11965: loss = 0.95134
Step 11970: loss = 0.97691
Step 11975: loss = 1.33456
Step 11980: loss = 1.19062
Step 11985: loss = 0.71050
Step 11990: loss = 1.01970
Step 11995: loss = 1.34342
Step 12000: loss = 1.11757
Training Data Eval:
  Num examples: 50000, Num correct: 32717, Precision @ 1: 0.6543
('Testing Data Eval: EPOCH->', 13)
  Num examples: 10000, Num correct: 5430, Precision @ 1: 0.5430
Step 12005: loss = 0.82677
Step 12010: loss = 1.13010
Step 12015: loss = 0.78889
Step 12020: loss = 0.94935
Step 12025: loss = 1.08465
Step 12030: loss = 0.86531
Step 12035: loss = 0.83671
Step 12040: loss = 0.78404
Step 12045: loss = 1.08496
Step 12050: loss = 1.02229
Step 12055: loss = 0.69507
Step 12060: loss = 0.98761
Step 12065: loss = 0.80239
Step 12070: loss = 0.97392
Step 12075: loss = 1.17995
Step 12080: loss = 0.96970
Step 12085: loss = 0.82274
Step 12090: loss = 0.98010
Step 12095: loss = 0.98358
Step 12100: loss = 0.89714
Step 12105: loss = 0.75633
Step 12110: loss = 1.05161
Step 12115: loss = 1.32109
Step 12120: loss = 1.11571
Step 12125: loss = 0.93919
Step 12130: loss = 0.87546
Step 12135: loss = 1.10534
Step 12140: loss = 1.22046
Step 12145: loss = 0.82945
Step 12150: loss = 0.99251
Step 12155: loss = 0.83588
Step 12160: loss = 1.01403
Step 12165: loss = 0.93466
Step 12170: loss = 1.41920
Step 12175: loss = 1.08146
Step 12180: loss = 0.89208
Step 12185: loss = 0.86030
Step 12190: loss = 0.75252
Step 12195: loss = 1.08740
Step 12200: loss = 1.33420
Step 12205: loss = 1.09592
Step 12210: loss = 0.84711
Step 12215: loss = 0.93229
Step 12220: loss = 1.00298
Step 12225: loss = 1.04268
Step 12230: loss = 1.10715
Step 12235: loss = 0.62678
Step 12240: loss = 0.65408
Step 12245: loss = 1.47654
Step 12250: loss = 0.99464
Step 12255: loss = 1.17256
Step 12260: loss = 0.81147
Step 12265: loss = 1.45526
Step 12270: loss = 1.35945
Step 12275: loss = 1.02707
Step 12280: loss = 0.86842
Step 12285: loss = 0.78185
Step 12290: loss = 0.88476
Step 12295: loss = 0.96275
Step 12300: loss = 0.80270
Step 12305: loss = 0.85313
Step 12310: loss = 0.90088
Step 12315: loss = 0.89117
Step 12320: loss = 0.96263
Step 12325: loss = 0.96171
Step 12330: loss = 0.90719
Step 12335: loss = 0.75831
Step 12340: loss = 0.71270
Step 12345: loss = 0.99906
Step 12350: loss = 0.79507
Step 12355: loss = 1.00842
Step 12360: loss = 0.84954
Step 12365: loss = 0.88407
Step 12370: loss = 0.77068
Step 12375: loss = 0.61028
Step 12380: loss = 1.06288
Step 12385: loss = 0.88544
Step 12390: loss = 0.77384
Step 12395: loss = 0.98541
Step 12400: loss = 1.64112
Step 12405: loss = 1.13110
Step 12410: loss = 0.93089
Step 12415: loss = 0.93046
Step 12420: loss = 0.89029
Step 12425: loss = 0.88349
Step 12430: loss = 0.96188
Step 12435: loss = 0.84204
Step 12440: loss = 1.12981
Step 12445: loss = 1.13467
Step 12450: loss = 0.88909
Step 12455: loss = 0.77633
Step 12460: loss = 0.91536
Step 12465: loss = 0.98195
Step 12470: loss = 0.82946
Step 12475: loss = 0.75677
Step 12480: loss = 0.97181
Step 12485: loss = 1.13467
Step 12490: loss = 0.84097
Step 12495: loss = 0.88159
Step 12500: loss = 1.17791
Step 12505: loss = 0.85014
Step 12510: loss = 0.90578
Step 12515: loss = 1.14170
Step 12520: loss = 1.22940
Step 12525: loss = 0.83633
Step 12530: loss = 1.04021
Step 12535: loss = 1.10790
Step 12540: loss = 1.06824
Step 12545: loss = 0.76543
Step 12550: loss = 0.90521
Step 12555: loss = 1.00238
Step 12560: loss = 0.96790
Step 12565: loss = 0.84320
Step 12570: loss = 0.78160
Step 12575: loss = 0.74603
Step 12580: loss = 0.88288
Step 12585: loss = 1.04941
Step 12590: loss = 1.12656
Step 12595: loss = 1.25723
Step 12600: loss = 0.80498
Step 12605: loss = 0.86688
Step 12610: loss = 1.09328
Step 12615: loss = 0.86215
Step 12620: loss = 0.80403
Step 12625: loss = 0.65904
Step 12630: loss = 1.05379
Step 12635: loss = 0.96179
Step 12640: loss = 0.85081
Step 12645: loss = 0.71345
Step 12650: loss = 1.05251
Step 12655: loss = 0.92409
Step 12660: loss = 0.90491
Step 12665: loss = 0.91537
Step 12670: loss = 1.01617
Step 12675: loss = 1.30097
Step 12680: loss = 0.91435
Step 12685: loss = 1.03678
Step 12690: loss = 0.95906
Step 12695: loss = 0.78308
Step 12700: loss = 0.92926
Step 12705: loss = 1.16950
Step 12710: loss = 0.94932
Step 12715: loss = 0.71966
Step 12720: loss = 1.12352
Step 12725: loss = 0.87553
Step 12730: loss = 0.93149
Step 12735: loss = 0.83227
Step 12740: loss = 0.94035
Step 12745: loss = 0.90847
Step 12750: loss = 0.95708
Step 12755: loss = 1.13018
Step 12760: loss = 0.91679
Step 12765: loss = 1.17879
Step 12770: loss = 1.08752
Step 12775: loss = 0.97855
Step 12780: loss = 1.38546
Step 12785: loss = 0.75222
Step 12790: loss = 0.86397
Step 12795: loss = 1.32034
Step 12800: loss = 0.93265
Step 12805: loss = 1.13868
Step 12810: loss = 0.83759
Step 12815: loss = 0.74101
Step 12820: loss = 0.91780
Step 12825: loss = 1.00682
Step 12830: loss = 1.00313
Step 12835: loss = 1.08279
Step 12840: loss = 1.30449
Step 12845: loss = 0.87894
Step 12850: loss = 1.11234
Step 12855: loss = 1.06853
Step 12860: loss = 0.94426
Step 12865: loss = 1.05675
Step 12870: loss = 0.94274
Step 12875: loss = 0.84838
Step 12880: loss = 1.03735
Step 12885: loss = 0.82846
Step 12890: loss = 0.96684
Step 12895: loss = 0.78858
Step 12900: loss = 1.15974
Step 12905: loss = 0.91407
Step 12910: loss = 0.94999
Step 12915: loss = 1.06815
Step 12920: loss = 1.17983
Step 12925: loss = 0.99207
Step 12930: loss = 0.81846
Step 12935: loss = 1.14562
Step 12940: loss = 0.84915
Step 12945: loss = 0.89582
Step 12950: loss = 1.06459
Step 12955: loss = 0.80467
Step 12960: loss = 1.19119
Step 12965: loss = 1.17919
Step 12970: loss = 0.78767
Step 12975: loss = 0.82861
Step 12980: loss = 0.95342
Step 12985: loss = 0.64394
Step 12990: loss = 0.90420
Step 12995: loss = 0.76289
Step 13000: loss = 1.21959
Training Data Eval:
  Num examples: 50000, Num correct: 33295, Precision @ 1: 0.6659
('Testing Data Eval: EPOCH->', 14)
  Num examples: 10000, Num correct: 5595, Precision @ 1: 0.5595
Step 13005: loss = 0.72743
Step 13010: loss = 0.81359
Step 13015: loss = 0.81561
Step 13020: loss = 0.86479
Step 13025: loss = 0.99031
Step 13030: loss = 1.14361
Step 13035: loss = 1.22161
Step 13040: loss = 0.92941
Step 13045: loss = 0.65959
Step 13050: loss = 1.02738
Step 13055: loss = 0.94856
Step 13060: loss = 1.48090
Step 13065: loss = 0.87791
Step 13070: loss = 1.02312
Step 13075: loss = 1.01226
Step 13080: loss = 0.86825
Step 13085: loss = 0.76328
Step 13090: loss = 0.71225
Step 13095: loss = 1.24938
Step 13100: loss = 1.16706
Step 13105: loss = 0.92273
Step 13110: loss = 0.68376
Step 13115: loss = 1.20446
Step 13120: loss = 0.82169
Step 13125: loss = 0.77134
Step 13130: loss = 0.72881
Step 13135: loss = 0.79828
Step 13140: loss = 2.09646
Step 13145: loss = 1.15931
Step 13150: loss = 1.04863
Step 13155: loss = 0.90681
Step 13160: loss = 1.03137
Step 13165: loss = 1.02574
Step 13170: loss = 1.26668
Step 13175: loss = 1.02986
Step 13180: loss = 0.96704
Step 13185: loss = 0.99889
Step 13190: loss = 0.85889
Step 13195: loss = 0.77868
Step 13200: loss = 0.99882
Step 13205: loss = 0.88787
Step 13210: loss = 1.20768
Step 13215: loss = 0.90569
Step 13220: loss = 0.87454
Step 13225: loss = 1.07307
Step 13230: loss = 1.09948
Step 13235: loss = 0.84893
Step 13240: loss = 1.02577
Step 13245: loss = 0.86320
Step 13250: loss = 0.88565
Step 13255: loss = 0.91956
Step 13260: loss = 1.30727
Step 13265: loss = 0.98541
Step 13270: loss = 0.93498
Step 13275: loss = 0.83171
Step 13280: loss = 0.89808
Step 13285: loss = 0.96019
Step 13290: loss = 1.06709
Step 13295: loss = 1.08323
Step 13300: loss = 0.88868
Step 13305: loss = 0.84990
Step 13310: loss = 0.86572
Step 13315: loss = 0.95655
Step 13320: loss = 1.06111
Step 13325: loss = 0.92503
Step 13330: loss = 0.85464
Step 13335: loss = 0.97515
Step 13340: loss = 0.72896
Step 13345: loss = 1.14774
Step 13350: loss = 0.84333
Step 13355: loss = 0.62224
Step 13360: loss = 0.92185
Step 13365: loss = 0.95236
Step 13370: loss = 0.86445
Step 13375: loss = 0.92482
Step 13380: loss = 0.98011
Step 13385: loss = 0.63198
Step 13390: loss = 0.65556
Step 13395: loss = 0.83641
Step 13400: loss = 0.73751
Step 13405: loss = 0.88586
Step 13410: loss = 0.72678
Step 13415: loss = 1.11132
Step 13420: loss = 0.79105
Step 13425: loss = 0.96687
Step 13430: loss = 0.76452
Step 13435: loss = 0.80555
Step 13440: loss = 1.00510
Step 13445: loss = 1.14866
Step 13450: loss = 0.94205
Step 13455: loss = 1.17021
Step 13460: loss = 0.67839
Step 13465: loss = 0.94251
Step 13470: loss = 0.75911
Step 13475: loss = 1.08829
Step 13480: loss = 0.81035
Step 13485: loss = 0.88769
Step 13490: loss = 0.76755
Step 13495: loss = 0.85886
Step 13500: loss = 0.84970
Step 13505: loss = 1.14266
Step 13510: loss = 1.07745
Step 13515: loss = 1.17914
Step 13520: loss = 1.15799
Step 13525: loss = 1.23914
Step 13530: loss = 0.61534
Step 13535: loss = 0.70558
Step 13540: loss = 1.15315
Step 13545: loss = 1.06048
Step 13550: loss = 0.88782
Step 13555: loss = 0.96471
Step 13560: loss = 0.71000
Step 13565: loss = 0.99470
Step 13570: loss = 0.93357
Step 13575: loss = 1.21474
Step 13580: loss = 0.84345
Step 13585: loss = 0.80676
Step 13590: loss = 0.97275
Step 13595: loss = 0.95244
Step 13600: loss = 0.67170
Step 13605: loss = 0.70459
Step 13610: loss = 0.98053
Step 13615: loss = 0.76749
Step 13620: loss = 1.13853
Step 13625: loss = 0.99190
Step 13630: loss = 1.12148
Step 13635: loss = 0.80292
Step 13640: loss = 1.00792
Step 13645: loss = 0.78070
Step 13650: loss = 0.63755
Step 13655: loss = 1.00408
Step 13660: loss = 0.97675
Step 13665: loss = 1.09379
Step 13670: loss = 1.19304
Step 13675: loss = 0.71273
Step 13680: loss = 0.95816
Step 13685: loss = 0.81830
Step 13690: loss = 0.81301
Step 13695: loss = 0.89969
Step 13700: loss = 0.80939
Step 13705: loss = 0.84715
Step 13710: loss = 0.98617
Step 13715: loss = 0.97451
Step 13720: loss = 1.21359
Step 13725: loss = 1.28323
Step 13730: loss = 0.62519
Step 13735: loss = 0.94711
Step 13740: loss = 1.23782
Step 13745: loss = 1.20103
Step 13750: loss = 0.82861
Step 13755: loss = 1.29045
Step 13760: loss = 0.89268
Step 13765: loss = 0.99974
Step 13770: loss = 0.81013
Step 13775: loss = 0.79796
Step 13780: loss = 0.87987
Step 13785: loss = 0.69220
Step 13790: loss = 1.26267
Step 13795: loss = 1.12305
Step 13800: loss = 1.04763
Step 13805: loss = 0.80719
Step 13810: loss = 0.91405
Step 13815: loss = 0.98373
Step 13820: loss = 1.09006
Step 13825: loss = 1.11519
Step 13830: loss = 1.06154
Step 13835: loss = 0.88198
Step 13840: loss = 0.99683
Step 13845: loss = 0.90810
Step 13850: loss = 0.74656
Step 13855: loss = 0.98780
Step 13860: loss = 0.93044
Step 13865: loss = 0.85843
Step 13870: loss = 1.31197
Step 13875: loss = 1.17790
Step 13880: loss = 0.74471
Step 13885: loss = 0.82192
Step 13890: loss = 1.17700
Step 13895: loss = 0.80007
Step 13900: loss = 1.10373
Step 13905: loss = 1.10033
Step 13910: loss = 0.80727
Step 13915: loss = 0.74499
Step 13920: loss = 1.05085
Step 13925: loss = 0.80110
Step 13930: loss = 0.90076
Step 13935: loss = 1.14091
Step 13940: loss = 0.77905
Step 13945: loss = 0.77663
Step 13950: loss = 0.73302
Step 13955: loss = 1.20316
Step 13960: loss = 0.70296
Step 13965: loss = 0.59801
Step 13970: loss = 0.91761
Step 13975: loss = 0.85421
Step 13980: loss = 0.87995
Step 13985: loss = 0.93288
Step 13990: loss = 0.99886
Step 13995: loss = 0.97769
Step 14000: loss = 0.72740
Training Data Eval:
  Num examples: 50000, Num correct: 34246, Precision @ 1: 0.6849
('Testing Data Eval: EPOCH->', 15)
  Num examples: 10000, Num correct: 5730, Precision @ 1: 0.5730
Step 14005: loss = 0.82496
Step 14010: loss = 0.76331
Step 14015: loss = 0.71927
Step 14020: loss = 0.62913
Step 14025: loss = 0.84437
Step 14030: loss = 1.00693
Step 14035: loss = 0.71335
Step 14040: loss = 0.81835
Step 14045: loss = 0.96121
Step 14050: loss = 1.13911
Step 14055: loss = 0.75335
Step 14060: loss = 0.83636
Step 14065: loss = 0.81264
Step 14070: loss = 0.88729
Step 14075: loss = 0.65803
Step 14080: loss = 1.19919
Step 14085: loss = 0.84627
Step 14090: loss = 1.01557
Step 14095: loss = 0.67023
Step 14100: loss = 0.81315
Step 14105: loss = 0.77340
Step 14110: loss = 1.03625
Step 14115: loss = 0.88005
Step 14120: loss = 0.73955
Step 14125: loss = 0.96901
Step 14130: loss = 0.74555
Step 14135: loss = 1.03170
Step 14140: loss = 0.81119
Step 14145: loss = 0.73270
Step 14150: loss = 0.73673
Step 14155: loss = 0.94788
Step 14160: loss = 0.87017
Step 14165: loss = 0.73562
Step 14170: loss = 0.72501
Step 14175: loss = 0.85235
Step 14180: loss = 0.81507
Step 14185: loss = 0.90663
Step 14190: loss = 0.92450
Step 14195: loss = 0.83783
Step 14200: loss = 0.86590
Step 14205: loss = 0.74906
Step 14210: loss = 0.78056
Step 14215: loss = 0.93586
Step 14220: loss = 0.71105
Step 14225: loss = 0.79829
Step 14230: loss = 0.70184
Step 14235: loss = 0.71361
Step 14240: loss = 0.97573
Step 14245: loss = 0.73478
Step 14250: loss = 0.95050
Step 14255: loss = 0.80192
Step 14260: loss = 0.76229
Step 14265: loss = 0.89154
Step 14270: loss = 0.61118
Step 14275: loss = 0.87804
Step 14280: loss = 0.72349
Step 14285: loss = 0.81339
Step 14290: loss = 1.14748
Step 14295: loss = 1.00702
Step 14300: loss = 0.88807
Step 14305: loss = 1.24601
Step 14310: loss = 0.92805
Step 14315: loss = 0.92116
Step 14320: loss = 1.07482
Step 14325: loss = 0.89187
Step 14330: loss = 0.78729
Step 14335: loss = 0.96227
Step 14340: loss = 1.00047
Step 14345: loss = 0.91885
Step 14350: loss = 0.74427
Step 14355: loss = 0.81554
Step 14360: loss = 0.73934
Step 14365: loss = 1.00769
Step 14370: loss = 0.83631
Step 14375: loss = 0.80814
Step 14380: loss = 0.82004
Step 14385: loss = 0.88348
Step 14390: loss = 1.13490
Step 14395: loss = 0.97231
Step 14400: loss = 0.81720
Step 14405: loss = 0.84510
Step 14410: loss = 0.84142
Step 14415: loss = 0.64008
Step 14420: loss = 0.97875
Step 14425: loss = 1.07432
Step 14430: loss = 0.94002
Step 14435: loss = 0.72718
Step 14440: loss = 0.69788
Step 14445: loss = 0.84531
Step 14450: loss = 0.82777
Step 14455: loss = 1.08943
Step 14460: loss = 1.44148
Step 14465: loss = 1.06290
Step 14470: loss = 0.81210
Step 14475: loss = 0.84745
Step 14480: loss = 1.00446
Step 14485: loss = 0.67480
Step 14490: loss = 0.81524
Step 14495: loss = 0.82357
Step 14500: loss = 0.88702
Step 14505: loss = 1.01625
Step 14510: loss = 0.85877
Step 14515: loss = 0.75221
Step 14520: loss = 0.83331
Step 14525: loss = 0.86177
Step 14530: loss = 1.14664
Step 14535: loss = 0.77728
Step 14540: loss = 0.99894
Step 14545: loss = 0.92143
Step 14550: loss = 1.23361
Step 14555: loss = 1.00172
Step 14560: loss = 0.63577
Step 14565: loss = 0.70755
Step 14570: loss = 0.81169
Step 14575: loss = 0.88392
Step 14580: loss = 0.92710
Step 14585: loss = 0.75767
Step 14590: loss = 1.21636
Step 14595: loss = 1.01775
Step 14600: loss = 0.85572
Step 14605: loss = 1.04734
Step 14610: loss = 1.04183
Step 14615: loss = 0.92514
Step 14620: loss = 1.31616
Step 14625: loss = 0.92040
Step 14630: loss = 0.70765
Step 14635: loss = 0.74270
Step 14640: loss = 0.84712
Step 14645: loss = 0.75239
Step 14650: loss = 1.14952
Step 14655: loss = 0.97335
Step 14660: loss = 0.74246
Step 14665: loss = 1.00574
Step 14670: loss = 0.91707
Step 14675: loss = 1.10706
Step 14680: loss = 0.79080
Step 14685: loss = 1.06547
Step 14690: loss = 1.38880
Step 14695: loss = 1.02247
Step 14700: loss = 0.85641
Step 14705: loss = 0.84676
Step 14710: loss = 0.74565
Step 14715: loss = 0.94288
Step 14720: loss = 0.86901
Step 14725: loss = 0.97689
Step 14730: loss = 0.76098
Step 14735: loss = 1.25331
Step 14740: loss = 0.95508
Step 14745: loss = 0.75220
Step 14750: loss = 1.08487
Step 14755: loss = 0.98750
Step 14760: loss = 0.98486
Step 14765: loss = 0.71474
Step 14770: loss = 1.16353
Step 14775: loss = 0.96694
Step 14780: loss = 0.87226
Step 14785: loss = 0.88206
Step 14790: loss = 0.92775
Step 14795: loss = 1.10431
Step 14800: loss = 0.86102
Step 14805: loss = 0.70808
Step 14810: loss = 0.84882
Step 14815: loss = 1.22891
Step 14820: loss = 0.64440
Step 14825: loss = 0.88176
Step 14830: loss = 1.01273
Step 14835: loss = 0.80890
Step 14840: loss = 1.01998
Step 14845: loss = 1.18337
Step 14850: loss = 0.67395
Step 14855: loss = 1.02722
Step 14860: loss = 1.07114
Step 14865: loss = 0.67793
Step 14870: loss = 1.13462
Step 14875: loss = 1.16055
Step 14880: loss = 1.01372
Step 14885: loss = 0.74473
Step 14890: loss = 1.35899
Step 14895: loss = 0.95651
Step 14900: loss = 0.87043
Step 14905: loss = 0.82986
Step 14910: loss = 1.07807
Step 14915: loss = 0.84946
Step 14920: loss = 1.17559
Step 14925: loss = 1.09764
Step 14930: loss = 0.84444
Step 14935: loss = 0.80736
Step 14940: loss = 0.86993
Step 14945: loss = 0.80931
Step 14950: loss = 0.86211
Step 14955: loss = 0.97460
Step 14960: loss = 1.00337
Step 14965: loss = 0.86436
Step 14970: loss = 1.14001
Step 14975: loss = 0.80934
Step 14980: loss = 0.81940
Step 14985: loss = 1.22718
Step 14990: loss = 1.09029
Step 14995: loss = 0.87898
Step 15000: loss = 0.93315
Training Data Eval:
  Num examples: 50000, Num correct: 34840, Precision @ 1: 0.6968
('Testing Data Eval: EPOCH->', 16)
  Num examples: 10000, Num correct: 5897, Precision @ 1: 0.5897
Step 15005: loss = 0.99929
Step 15010: loss = 0.74548
Step 15015: loss = 1.02150
Step 15020: loss = 0.93939
Step 15025: loss = 0.99819
Step 15030: loss = 1.04599
Step 15035: loss = 0.76235
Step 15040: loss = 0.80151
Step 15045: loss = 1.07594
Step 15050: loss = 0.73706
Step 15055: loss = 1.06398
Step 15060: loss = 0.81532
Step 15065: loss = 0.70974
Step 15070: loss = 0.88673
Step 15075: loss = 0.88307
Step 15080: loss = 0.71397
Step 15085: loss = 0.87613
Step 15090: loss = 0.69164
Step 15095: loss = 0.79233
Step 15100: loss = 0.71767
Step 15105: loss = 0.89607
Step 15110: loss = 0.86962
Step 15115: loss = 0.81511
Step 15120: loss = 0.66188
Step 15125: loss = 0.71342
Step 15130: loss = 0.72249
Step 15135: loss = 1.09550
Step 15140: loss = 0.86944
Step 15145: loss = 0.77763
Step 15150: loss = 0.72526
Step 15155: loss = 1.23928
Step 15160: loss = 0.90328
Step 15165: loss = 0.47466
Step 15170: loss = 0.70057
Step 15175: loss = 0.85770
Step 15180: loss = 0.88094
Step 15185: loss = 0.73602
Step 15190: loss = 1.03825
Step 15195: loss = 0.71450
Step 15200: loss = 0.97296
Step 15205: loss = 0.98830
Step 15210: loss = 0.97606
Step 15215: loss = 0.93237
Step 15220: loss = 0.90643
Step 15225: loss = 1.10093
Step 15230: loss = 0.76014
Step 15235: loss = 0.76506
Step 15240: loss = 1.08871
Step 15245: loss = 0.99038
Step 15250: loss = 1.08948
Step 15255: loss = 1.01847
Step 15260: loss = 0.87202
Step 15265: loss = 1.18134
Step 15270: loss = 0.99482
Step 15275: loss = 0.87738
Step 15280: loss = 1.02395
Step 15285: loss = 1.04791
Step 15290: loss = 0.88582
Step 15295: loss = 1.08969
Step 15300: loss = 0.99453
Step 15305: loss = 0.87273
Step 15310: loss = 0.84384
Step 15315: loss = 1.08892
Step 15320: loss = 0.74776
Step 15325: loss = 0.97357
Step 15330: loss = 0.99587
Step 15335: loss = 0.89224
Step 15340: loss = 0.53923
Step 15345: loss = 0.86415
Step 15350: loss = 0.61056
Step 15355: loss = 1.05195
Step 15360: loss = 0.98475
Step 15365: loss = 1.01317
Step 15370: loss = 0.87189
Step 15375: loss = 0.78835
Step 15380: loss = 0.74518
Step 15385: loss = 0.85103
Step 15390: loss = 0.86830
Step 15395: loss = 0.74876
Step 15400: loss = 0.90642
Step 15405: loss = 0.83655
Step 15410: loss = 0.70560
Step 15415: loss = 1.03748
Step 15420: loss = 0.55357
Step 15425: loss = 0.84141
Step 15430: loss = 0.53698
Step 15435: loss = 0.96090
Step 15440: loss = 0.90321
Step 15445: loss = 0.60080
Step 15450: loss = 0.87775
Step 15455: loss = 1.07362
Step 15460: loss = 1.10222
Step 15465: loss = 0.96118
Step 15470: loss = 0.70925
Step 15475: loss = 0.94445
Step 15480: loss = 0.69241
Step 15485: loss = 0.54300
Step 15490: loss = 0.95067
Step 15495: loss = 1.02227
Step 15500: loss = 0.78852
Step 15505: loss = 0.79153
Step 15510: loss = 0.72769
Step 15515: loss = 0.69025
Step 15520: loss = 0.76279
Step 15525: loss = 0.76466
Step 15530: loss = 0.78113
Step 15535: loss = 1.02586
Step 15540: loss = 0.80323
Step 15545: loss = 0.77825
Step 15550: loss = 0.59307
Step 15555: loss = 0.84008
Step 15560: loss = 0.74423
Step 15565: loss = 0.53923
Step 15570: loss = 0.85136
Step 15575: loss = 0.92603
Step 15580: loss = 1.11154
Step 15585: loss = 1.30291
Step 15590: loss = 0.64807
Step 15595: loss = 0.76345
Step 15600: loss = 1.07735
Step 15605: loss = 0.69969
Step 15610: loss = 0.81563
Step 15615: loss = 1.11956
Step 15620: loss = 0.68828
Step 15625: loss = 0.98185
Step 15630: loss = 0.91731
Step 15635: loss = 0.98043
Step 15640: loss = 1.09618
Step 15645: loss = 0.95417
Step 15650: loss = 0.69155
Step 15655: loss = 0.75512
Step 15660: loss = 1.00710
Step 15665: loss = 0.68576
Step 15670: loss = 0.84962
Step 15675: loss = 0.66874
Step 15680: loss = 0.87267
Step 15685: loss = 0.83199
Step 15690: loss = 0.75743
Step 15695: loss = 0.77791
Step 15700: loss = 0.96542
Step 15705: loss = 0.91538
Step 15710: loss = 0.89015
Step 15715: loss = 0.88033
Step 15720: loss = 0.62620
Step 15725: loss = 1.05341
Step 15730: loss = 0.95940
Step 15735: loss = 0.68195
Step 15740: loss = 1.23055
Step 15745: loss = 0.66879
Step 15750: loss = 1.08394
Step 15755: loss = 0.69392
Step 15760: loss = 0.74849
Step 15765: loss = 0.73003
Step 15770: loss = 0.90335
Step 15775: loss = 0.67518
Step 15780: loss = 1.13622
Step 15785: loss = 0.80380
Step 15790: loss = 0.60899
Step 15795: loss = 0.76106
Step 15800: loss = 1.03752
Step 15805: loss = 0.77733
Step 15810: loss = 1.14572
Step 15815: loss = 0.97855
Step 15820: loss = 0.80989
Step 15825: loss = 0.86987
Step 15830: loss = 0.98609
Step 15835: loss = 0.96992
Step 15840: loss = 0.70817
Step 15845: loss = 0.70452
Step 15850: loss = 0.61958
Step 15855: loss = 0.69323
Step 15860: loss = 1.02059
Step 15865: loss = 0.87560
Step 15870: loss = 1.01570
Step 15875: loss = 0.85713
Step 15880: loss = 0.81139
Step 15885: loss = 1.05791
Step 15890: loss = 0.71540
Step 15895: loss = 1.12903
Step 15900: loss = 0.79092
Step 15905: loss = 0.97746
Step 15910: loss = 0.83324
Step 15915: loss = 0.91588
Step 15920: loss = 0.89229
Step 15925: loss = 1.06580
Step 15930: loss = 0.93436
Step 15935: loss = 0.95107
Step 15940: loss = 0.72927
Step 15945: loss = 1.19494
Step 15950: loss = 0.76577
Step 15955: loss = 0.86551
Step 15960: loss = 1.01732
Step 15965: loss = 0.76217
Step 15970: loss = 0.78819
Step 15975: loss = 0.78484
Step 15980: loss = 0.99400
Step 15985: loss = 1.08807
Step 15990: loss = 0.73178
Step 15995: loss = 0.60387
Step 16000: loss = 0.57701
Training Data Eval:
  Num examples: 50000, Num correct: 35621, Precision @ 1: 0.7124
('Testing Data Eval: EPOCH->', 17)
  Num examples: 10000, Num correct: 5862, Precision @ 1: 0.5862
Step 16005: loss = 0.49429
Step 16010: loss = 0.89582
Step 16015: loss = 0.95456
Step 16020: loss = 0.81238
Step 16025: loss = 0.77061
Step 16030: loss = 0.85392
Step 16035: loss = 0.62351
Step 16040: loss = 0.76618
Step 16045: loss = 0.89818
Step 16050: loss = 1.04544
Step 16055: loss = 0.93170
Step 16060: loss = 0.77609
Step 16065: loss = 0.80231
Step 16070: loss = 0.71570
Step 16075: loss = 0.90730
Step 16080: loss = 0.83789
Step 16085: loss = 0.97060
Step 16090: loss = 0.96727
Step 16095: loss = 0.74728
Step 16100: loss = 0.85170
Step 16105: loss = 0.82133
Step 16110: loss = 1.03358
Step 16115: loss = 1.06430
Step 16120: loss = 0.56444
Step 16125: loss = 0.90528
Step 16130: loss = 0.53175
Step 16135: loss = 0.70209
Step 16140: loss = 0.92903
Step 16145: loss = 0.79032
Step 16150: loss = 0.91969
Step 16155: loss = 0.58841
Step 16160: loss = 0.66394
Step 16165: loss = 0.81014
Step 16170: loss = 0.99206
Step 16175: loss = 1.08503
Step 16180: loss = 0.65215
Step 16185: loss = 1.01717
Step 16190: loss = 0.91702
Step 16195: loss = 0.62064
Step 16200: loss = 0.60360
Step 16205: loss = 0.80009
Step 16210: loss = 0.90905
Step 16215: loss = 0.92329
Step 16220: loss = 0.61059
Step 16225: loss = 0.77718
Step 16230: loss = 0.71084
Step 16235: loss = 0.84581
Step 16240: loss = 0.60509
Step 16245: loss = 0.56489
Step 16250: loss = 1.06467
Step 16255: loss = 1.03953
Step 16260: loss = 0.53900
Step 16265: loss = 0.87525
Step 16270: loss = 0.74408
Step 16275: loss = 0.89005
Step 16280: loss = 0.80917
Step 16285: loss = 0.85736
Step 16290: loss = 0.98327
Step 16295: loss = 0.84932
Step 16300: loss = 1.02307
Step 16305: loss = 0.79410
Step 16310: loss = 0.92235
Step 16315: loss = 0.74452
Step 16320: loss = 0.66333
Step 16325: loss = 1.27309
Step 16330: loss = 0.97558
Step 16335: loss = 0.80318
Step 16340: loss = 0.82769
Step 16345: loss = 0.89234
Step 16350: loss = 0.99717
Step 16355: loss = 0.91706
Step 16360: loss = 1.07375
Step 16365: loss = 0.86857
Step 16370: loss = 1.07303
Step 16375: loss = 0.80746
Step 16380: loss = 0.76096
Step 16385: loss = 0.84158
Step 16390: loss = 0.73155
Step 16395: loss = 0.72137
Step 16400: loss = 1.02560
Step 16405: loss = 0.94583
Step 16410: loss = 0.78751
Step 16415: loss = 0.74378
Step 16420: loss = 0.82072
Step 16425: loss = 1.01568
Step 16430: loss = 0.86720
Step 16435: loss = 0.79940
Step 16440: loss = 0.66403
Step 16445: loss = 0.80511
Step 16450: loss = 1.13973
Step 16455: loss = 0.60682
Step 16460: loss = 0.87702
Step 16465: loss = 0.72814
Step 16470: loss = 0.61451
Step 16475: loss = 0.99536
Step 16480: loss = 0.58900
Step 16485: loss = 0.78206
Step 16490: loss = 0.99507
Step 16495: loss = 0.63812
Step 16500: loss = 0.97561
Step 16505: loss = 0.92144
Step 16510: loss = 0.60368
Step 16515: loss = 0.89037
Step 16520: loss = 0.99066
Step 16525: loss = 0.54905
Step 16530: loss = 1.02251
Step 16535: loss = 0.89238
Step 16540: loss = 0.90953
Step 16545: loss = 1.08844
Step 16550: loss = 1.08660
Step 16555: loss = 0.99430
Step 16560: loss = 0.95169
Step 16565: loss = 1.00290
Step 16570: loss = 0.89145
Step 16575: loss = 0.90798
Step 16580: loss = 0.91558
Step 16585: loss = 1.06780
Step 16590: loss = 0.68916
Step 16595: loss = 0.74214
Step 16600: loss = 0.78593
Step 16605: loss = 0.87825
Step 16610: loss = 0.70526
Step 16615: loss = 0.55612
Step 16620: loss = 0.82764
Step 16625: loss = 0.86263
Step 16630: loss = 0.68587
Step 16635: loss = 0.89193
Step 16640: loss = 0.98469
Step 16645: loss = 0.73946
Step 16650: loss = 0.69697
Step 16655: loss = 0.63038
Step 16660: loss = 0.87004
Step 16665: loss = 1.07710
Step 16670: loss = 0.70969
Step 16675: loss = 0.56057
Step 16680: loss = 0.57781
Step 16685: loss = 0.64019
Step 16690: loss = 0.71677
Step 16695: loss = 0.97836
Step 16700: loss = 0.93011
Step 16705: loss = 0.82733
Step 16710: loss = 0.77616
Step 16715: loss = 0.99678
Step 16720: loss = 1.04649
Step 16725: loss = 0.69088
Step 16730: loss = 0.74959
Step 16735: loss = 0.83219
Step 16740: loss = 0.48064
Step 16745: loss = 0.86170
Step 16750: loss = 0.75466
Step 16755: loss = 0.86793
Step 16760: loss = 1.02378
Step 16765: loss = 0.80884
Step 16770: loss = 0.83939
Step 16775: loss = 0.93989
Step 16780: loss = 0.68662
Step 16785: loss = 0.79709
Step 16790: loss = 0.75332
Step 16795: loss = 0.85809
Step 16800: loss = 0.59771
Step 16805: loss = 0.79696
Step 16810: loss = 0.91968
Step 16815: loss = 1.02598
Step 16820: loss = 0.96405
Step 16825: loss = 0.82289
Step 16830: loss = 1.19711
Step 16835: loss = 0.68407
Step 16840: loss = 0.80775
Step 16845: loss = 0.83566
Step 16850: loss = 0.99118
Step 16855: loss = 1.01530
Step 16860: loss = 0.92351
Step 16865: loss = 0.89731
Step 16870: loss = 0.76910
Step 16875: loss = 0.97231
Step 16880: loss = 0.97847
Step 16885: loss = 0.86506
Step 16890: loss = 1.04365
Step 16895: loss = 0.76174
Step 16900: loss = 1.01480
Step 16905: loss = 0.87538
Step 16910: loss = 0.74141
Step 16915: loss = 0.89972
Step 16920: loss = 0.71035
Step 16925: loss = 0.57433
Step 16930: loss = 1.17967
Step 16935: loss = 0.94115
Step 16940: loss = 0.61251
Step 16945: loss = 0.88838
Step 16950: loss = 0.77070
Step 16955: loss = 0.75233
Step 16960: loss = 0.71420
Step 16965: loss = 1.03852
Step 16970: loss = 0.87439
Step 16975: loss = 0.88334
Step 16980: loss = 0.80528
Step 16985: loss = 0.84250
Step 16990: loss = 0.70694
Step 16995: loss = 0.87307
Step 17000: loss = 0.86408
Training Data Eval:
  Num examples: 50000, Num correct: 36314, Precision @ 1: 0.7263
('Testing Data Eval: EPOCH->', 18)
  Num examples: 10000, Num correct: 6091, Precision @ 1: 0.6091
Step 17005: loss = 0.58406
Step 17010: loss = 0.58723
Step 17015: loss = 0.75712
Step 17020: loss = 0.94727
Step 17025: loss = 0.60892
Step 17030: loss = 0.97257
Step 17035: loss = 0.76387
Step 17040: loss = 0.67680
Step 17045: loss = 0.84136
Step 17050: loss = 0.70782
Step 17055: loss = 0.86745
Step 17060: loss = 0.79258
Step 17065: loss = 1.09414
Step 17070: loss = 1.16324
Step 17075: loss = 0.91633
Step 17080: loss = 0.68976
Step 17085: loss = 0.67796
Step 17090: loss = 1.20212
Step 17095: loss = 0.89576
Step 17100: loss = 1.02880
Step 17105: loss = 0.65942
Step 17110: loss = 1.09264
Step 17115: loss = 0.76444
Step 17120: loss = 0.79291
Step 17125: loss = 0.80990
Step 17130: loss = 0.94556
Step 17135: loss = 0.92075
Step 17140: loss = 1.06781
Step 17145: loss = 0.79753
Step 17150: loss = 0.70870
Step 17155: loss = 0.59028
Step 17160: loss = 1.02581
Step 17165: loss = 0.77320
Step 17170: loss = 0.89581
Step 17175: loss = 0.75614
Step 17180: loss = 0.90871
Step 17185: loss = 0.94341
Step 17190: loss = 0.56457
Step 17195: loss = 0.91753
Step 17200: loss = 0.67852
Step 17205: loss = 0.74868
Step 17210: loss = 0.95833
Step 17215: loss = 0.90911
Step 17220: loss = 0.91621
Step 17225: loss = 1.04078
Step 17230: loss = 0.80333
Step 17235: loss = 0.66662
Step 17240: loss = 0.87446
Step 17245: loss = 0.61295
Step 17250: loss = 0.79673
Step 17255: loss = 0.82618
Step 17260: loss = 0.99938
Step 17265: loss = 0.84351
Step 17270: loss = 0.68870
Step 17275: loss = 0.77857
Step 17280: loss = 0.73489
Step 17285: loss = 0.54262
Step 17290: loss = 0.87901
Step 17295: loss = 0.84933
Step 17300: loss = 0.84127
Step 17305: loss = 0.91014
Step 17310: loss = 0.79623
Step 17315: loss = 0.94744
Step 17320: loss = 0.72270
Step 17325: loss = 0.86921
Step 17330: loss = 0.78499
Step 17335: loss = 0.67032
Step 17340: loss = 0.95861
Step 17345: loss = 0.89449
Step 17350: loss = 0.59576
Step 17355: loss = 0.85953
Step 17360: loss = 0.90455
Step 17365: loss = 0.80538
Step 17370: loss = 0.48531
Step 17375: loss = 0.96691
Step 17380: loss = 0.90549
Step 17385: loss = 0.91265
Step 17390: loss = 0.75014
Step 17395: loss = 0.90466
Step 17400: loss = 0.86888
Step 17405: loss = 0.65080
Step 17410: loss = 1.02049
Step 17415: loss = 0.80061
Step 17420: loss = 0.92170
Step 17425: loss = 1.03153
Step 17430: loss = 0.89511
Step 17435: loss = 0.88547
Step 17440: loss = 0.93251
Step 17445: loss = 0.71707
Step 17450: loss = 0.89509
Step 17455: loss = 0.72681
Step 17460: loss = 0.99573
Step 17465: loss = 0.90210
Step 17470: loss = 1.02594
Step 17475: loss = 0.68739
Step 17480: loss = 0.90247
Step 17485: loss = 0.74689
Step 17490: loss = 0.81255
Step 17495: loss = 0.76290
Step 17500: loss = 0.61797
Step 17505: loss = 0.61130
Step 17510: loss = 1.12214
Step 17515: loss = 0.87223
Step 17520: loss = 0.68188
Step 17525: loss = 0.92386
Step 17530: loss = 1.21288
Step 17535: loss = 0.72540
Step 17540: loss = 0.83191
Step 17545: loss = 0.73098
Step 17550: loss = 1.12053
Step 17555: loss = 0.97906
Step 17560: loss = 0.83794
Step 17565: loss = 0.98077
Step 17570: loss = 0.89088
Step 17575: loss = 0.77924
Step 17580: loss = 0.64482
Step 17585: loss = 0.85996
Step 17590: loss = 0.75868
Step 17595: loss = 0.82371
Step 17600: loss = 0.90118
Step 17605: loss = 0.73284
Step 17610: loss = 0.93165
Step 17615: loss = 0.68900
Step 17620: loss = 0.79660
Step 17625: loss = 0.94194
Step 17630: loss = 0.97051
Step 17635: loss = 0.63117
Step 17640: loss = 0.76252
Step 17645: loss = 0.57724
Step 17650: loss = 0.68082
Step 17655: loss = 0.97763
Step 17660: loss = 0.82302
Step 17665: loss = 0.58784
Step 17670: loss = 1.06954
Step 17675: loss = 1.01019
Step 17680: loss = 0.65481
Step 17685: loss = 0.64634
Step 17690: loss = 0.87301
Step 17695: loss = 0.90965
Step 17700: loss = 0.56748
Step 17705: loss = 0.86949
Step 17710: loss = 0.89215
Step 17715: loss = 0.89750
Step 17720: loss = 0.81107
Step 17725: loss = 0.75742
Step 17730: loss = 0.58565
Step 17735: loss = 0.97523
Step 17740: loss = 0.67015
Step 17745: loss = 0.78060
Step 17750: loss = 0.79722
Step 17755: loss = 0.63387
Step 17760: loss = 0.66825
Step 17765: loss = 0.92476
Step 17770: loss = 0.53293
Step 17775: loss = 0.55658
Step 17780: loss = 1.00405
Step 17785: loss = 0.77817
Step 17790: loss = 0.75046
Step 17795: loss = 0.95154
Step 17800: loss = 0.65360
Step 17805: loss = 0.69889
Step 17810: loss = 0.51847
Step 17815: loss = 0.81473
Step 17820: loss = 0.69773
Step 17825: loss = 0.63786
Step 17830: loss = 0.87650
Step 17835: loss = 0.89845
Step 17840: loss = 0.79750
Step 17845: loss = 0.65876
Step 17850: loss = 0.72504
Step 17855: loss = 0.89931
Step 17860: loss = 0.71330
Step 17865: loss = 0.69403
Step 17870: loss = 0.62862
Step 17875: loss = 0.60290
Step 17880: loss = 0.65421
Step 17885: loss = 0.97364
Step 17890: loss = 0.70674
Step 17895: loss = 0.68355
Step 17900: loss = 0.53860
Step 17905: loss = 0.75400
Step 17910: loss = 0.85114
Step 17915: loss = 0.61762
Step 17920: loss = 0.68520
Step 17925: loss = 0.97075
Step 17930: loss = 0.94595
Step 17935: loss = 0.77732
Step 17940: loss = 0.52495
Step 17945: loss = 1.01599
Step 17950: loss = 1.05639
Step 17955: loss = 0.59209
Step 17960: loss = 0.97945
Step 17965: loss = 1.01191
Step 17970: loss = 0.84884
Step 17975: loss = 0.83962
Step 17980: loss = 0.64536
Step 17985: loss = 0.84216
Step 17990: loss = 0.68868
Step 17995: loss = 0.59488
Step 18000: loss = 0.88408
Training Data Eval:
  Num examples: 50000, Num correct: 36782, Precision @ 1: 0.7356
('Testing Data Eval: EPOCH->', 19)
  Num examples: 10000, Num correct: 6015, Precision @ 1: 0.6015
Step 18005: loss = 0.65860
Step 18010: loss = 0.81346
Step 18015: loss = 0.72988
Step 18020: loss = 0.53601
Step 18025: loss = 0.74719
Step 18030: loss = 0.80410
Step 18035: loss = 0.70228
Step 18040: loss = 0.61813
Step 18045: loss = 0.93529
Step 18050: loss = 0.74788
Step 18055: loss = 0.69741
Step 18060: loss = 0.84459
Step 18065: loss = 0.79390
Step 18070: loss = 1.11447
Step 18075: loss = 0.53447
Step 18080: loss = 0.62372
Step 18085: loss = 0.69949
Step 18090: loss = 0.99711
Step 18095: loss = 0.84629
Step 18100: loss = 0.51868
Step 18105: loss = 0.93062
Step 18110: loss = 0.86490
Step 18115: loss = 1.02170
Step 18120: loss = 0.77937
Step 18125: loss = 0.84063
Step 18130: loss = 0.76267
Step 18135: loss = 0.61128
Step 18140: loss = 0.97458
Step 18145: loss = 0.57947
Step 18150: loss = 0.83743
Step 18155: loss = 0.88422
Step 18160: loss = 0.97181
Step 18165: loss = 0.76427
Step 18170: loss = 0.77892
Step 18175: loss = 0.65649
Step 18180: loss = 0.65089
Step 18185: loss = 0.82021
Step 18190: loss = 0.61296
Step 18195: loss = 1.09160
Step 18200: loss = 0.78745
Step 18205: loss = 0.75963
Step 18210: loss = 1.07222
Step 18215: loss = 0.74437
Step 18220: loss = 0.69934
Step 18225: loss = 0.93664
Step 18230: loss = 0.92428
Step 18235: loss = 0.52133
Step 18240: loss = 0.88528
Step 18245: loss = 0.66333
Step 18250: loss = 0.56994
Step 18255: loss = 0.63874
Step 18260: loss = 0.75798
Step 18265: loss = 0.81579
Step 18270: loss = 0.60674
Step 18275: loss = 0.90174
Step 18280: loss = 0.72356
Step 18285: loss = 1.07162
Step 18290: loss = 0.65831
Step 18295: loss = 0.79803
Step 18300: loss = 0.60461
Step 18305: loss = 0.66841
Step 18310: loss = 0.62416
Step 18315: loss = 0.83030
Step 18320: loss = 0.77092
Step 18325: loss = 0.83066
Step 18330: loss = 0.99967
Step 18335: loss = 0.73322
Step 18340: loss = 0.83987
Step 18345: loss = 0.64721
Step 18350: loss = 0.66016
Step 18355: loss = 0.80249
Step 18360: loss = 1.02927
Step 18365: loss = 0.90633
Step 18370: loss = 0.84001
Step 18375: loss = 0.97927
Step 18380: loss = 0.85317
Step 18385: loss = 0.66680
Step 18390: loss = 0.63997
Step 18395: loss = 1.11453
Step 18400: loss = 0.71272
Step 18405: loss = 0.80589
Step 18410: loss = 0.64486
Step 18415: loss = 0.99231
Step 18420: loss = 0.72465
Step 18425: loss = 0.90301
Step 18430: loss = 1.02165
Step 18435: loss = 1.14565
Step 18440: loss = 0.75795
Step 18445: loss = 0.76761
Step 18450: loss = 0.55212
Step 18455: loss = 0.68968
Step 18460: loss = 0.92975
Step 18465: loss = 0.73433
Step 18470: loss = 0.82809
Step 18475: loss = 0.69793
Step 18480: loss = 0.63794
Step 18485: loss = 1.00103
Step 18490: loss = 0.61462
Step 18495: loss = 1.20052
Step 18500: loss = 0.79914
Step 18505: loss = 0.71502
Step 18510: loss = 0.89101
Step 18515: loss = 0.69617
Step 18520: loss = 0.69847
Step 18525: loss = 0.82112
Step 18530: loss = 0.99094
Step 18535: loss = 0.72638
Step 18540: loss = 1.09826
Step 18545: loss = 0.76956
Step 18550: loss = 0.69432
Step 18555: loss = 0.82631
Step 18560: loss = 0.79749
Step 18565: loss = 0.64523
Step 18570: loss = 0.82500
Step 18575: loss = 0.85269
Step 18580: loss = 0.47770
Step 18585: loss = 0.87044
Step 18590: loss = 0.78161
Step 18595: loss = 0.66862
Step 18600: loss = 0.91285
Step 18605: loss = 1.17459
Step 18610: loss = 0.59969
Step 18615: loss = 0.81573
Step 18620: loss = 0.89088
Step 18625: loss = 0.86707
Step 18630: loss = 0.90491
Step 18635: loss = 0.61286
Step 18640: loss = 0.97562
Step 18645: loss = 0.90431
Step 18650: loss = 0.79168
Step 18655: loss = 0.89154
Step 18660: loss = 0.77908
Step 18665: loss = 0.69887
Step 18670: loss = 0.75643
Step 18675: loss = 0.79917
Step 18680: loss = 0.89082
Step 18685: loss = 0.82410
Step 18690: loss = 0.51550
Step 18695: loss = 0.81652
Step 18700: loss = 0.88941
Step 18705: loss = 0.77672
Step 18710: loss = 1.03077
Step 18715: loss = 1.04053
Step 18720: loss = 1.10565
Step 18725: loss = 0.83930
Step 18730: loss = 0.80298
Step 18735: loss = 0.94419
Step 18740: loss = 0.93374
Step 18745: loss = 0.64268
Step 18750: loss = 0.80530
Step 18755: loss = 0.51236
Step 18760: loss = 0.62911
Step 18765: loss = 0.67247
Step 18770: loss = 0.70336
Step 18775: loss = 0.58493
Step 18780: loss = 0.74746
Step 18785: loss = 0.71747
Step 18790: loss = 0.99598
Step 18795: loss = 0.92920
Step 18800: loss = 0.84792
Step 18805: loss = 0.64021
Step 18810: loss = 0.87688
Step 18815: loss = 0.72976
Step 18820: loss = 0.90680
Step 18825: loss = 0.73838
Step 18830: loss = 0.94799
Step 18835: loss = 0.87266
Step 18840: loss = 0.76914
Step 18845: loss = 0.90952
Step 18850: loss = 0.54526
Step 18855: loss = 0.47606
Step 18860: loss = 0.74660
Step 18865: loss = 0.79277
Step 18870: loss = 0.82063
Step 18875: loss = 0.74273
Step 18880: loss = 0.59746
Step 18885: loss = 0.67166
Step 18890: loss = 0.70686
Step 18895: loss = 0.90883
Step 18900: loss = 0.84437
Step 18905: loss = 0.82535
Step 18910: loss = 0.71539
Step 18915: loss = 0.66936
Step 18920: loss = 0.44189
Step 18925: loss = 0.72750
Step 18930: loss = 0.79090
Step 18935: loss = 0.66625
Step 18940: loss = 1.04463
Step 18945: loss = 0.75447
Step 18950: loss = 0.85508
Step 18955: loss = 0.95349
Step 18960: loss = 0.66507
Step 18965: loss = 0.49015
Step 18970: loss = 0.87413
Step 18975: loss = 0.82178
Step 18980: loss = 0.87527
Step 18985: loss = 0.72627
Step 18990: loss = 0.60678
Step 18995: loss = 0.72719
Step 19000: loss = 1.19535
Training Data Eval:
  Num examples: 50000, Num correct: 36755, Precision @ 1: 0.7351
('Testing Data Eval: EPOCH->', 20)
  Num examples: 10000, Num correct: 6062, Precision @ 1: 0.6062
Step 19005: loss = 0.52875
Step 19010: loss = 0.90900
Step 19015: loss = 0.59936
Step 19020: loss = 1.01855
Step 19025: loss = 0.59757
Step 19030: loss = 0.69771
Step 19035: loss = 0.69915
Step 19040: loss = 0.96743
Step 19045: loss = 0.65514
Step 19050: loss = 0.79280
Step 19055: loss = 1.13564
Step 19060: loss = 0.68957
Step 19065: loss = 0.70790
Step 19070: loss = 0.54290
Step 19075: loss = 0.90726
Step 19080: loss = 0.58026
Step 19085: loss = 0.67908
Step 19090: loss = 1.10105
Step 19095: loss = 0.72014
Step 19100: loss = 0.62174
Step 19105: loss = 0.87251
Step 19110: loss = 0.54684
Step 19115: loss = 0.73820
Step 19120: loss = 0.70178
Step 19125: loss = 0.79457
Step 19130: loss = 0.60634
Step 19135: loss = 0.54991
Step 19140: loss = 0.62457
Step 19145: loss = 0.71748
Step 19150: loss = 0.74051
Step 19155: loss = 0.76992
Step 19160: loss = 0.75158
Step 19165: loss = 0.69372
Step 19170: loss = 0.98706
Step 19175: loss = 0.82083
Step 19180: loss = 0.83083
Step 19185: loss = 0.92358
Step 19190: loss = 0.57854
Step 19195: loss = 0.38384
Step 19200: loss = 0.67924
Step 19205: loss = 0.75214
Step 19210: loss = 0.58753
Step 19215: loss = 0.41944
Step 19220: loss = 0.65800
Step 19225: loss = 0.88481
Step 19230: loss = 0.99516
Step 19235: loss = 0.96176
Step 19240: loss = 0.79167
Step 19245: loss = 1.03247
Step 19250: loss = 0.79063
Step 19255: loss = 0.76816
Step 19260: loss = 0.77254
Step 19265: loss = 0.73698
Step 19270: loss = 0.75733
Step 19275: loss = 0.71230
Step 19280: loss = 0.69047
Step 19285: loss = 0.79132
Step 19290: loss = 0.87270
Step 19295: loss = 0.76011
Step 19300: loss = 0.93323
Step 19305: loss = 0.77144
Step 19310: loss = 0.87214
Step 19315: loss = 0.65736
Step 19320: loss = 0.70541
Step 19325: loss = 0.72796
Step 19330: loss = 0.74620
Step 19335: loss = 0.62699
Step 19340: loss = 0.56214
Step 19345: loss = 0.59602
Step 19350: loss = 0.59773
Step 19355: loss = 0.55895
Step 19360: loss = 0.80840
Step 19365: loss = 0.94884
Step 19370: loss = 0.79767
Step 19375: loss = 0.70540
Step 19380: loss = 0.66096
Step 19385: loss = 0.74122
Step 19390: loss = 0.73243
Step 19395: loss = 0.59142
Step 19400: loss = 0.80399
Step 19405: loss = 0.59910
Step 19410: loss = 0.82768
Step 19415: loss = 0.88175
Step 19420: loss = 0.63590
Step 19425: loss = 0.91109
Step 19430: loss = 0.71764
Step 19435: loss = 0.80226
Step 19440: loss = 0.70952
Step 19445: loss = 1.02871
Step 19450: loss = 0.81488
Step 19455: loss = 0.67584
Step 19460: loss = 0.79035
Step 19465: loss = 0.79035
Step 19470: loss = 0.68991
Step 19475: loss = 0.57374
Step 19480: loss = 0.55884
Step 19485: loss = 0.92303
Step 19490: loss = 0.56403
Step 19495: loss = 0.69388
Step 19500: loss = 0.58270
Step 19505: loss = 0.81068
Step 19510: loss = 0.58080
Step 19515: loss = 0.90199
Step 19520: loss = 0.70173
Step 19525: loss = 0.68887
Step 19530: loss = 0.57997
Step 19535: loss = 0.77029
Step 19540: loss = 0.42920
Step 19545: loss = 0.67096
Step 19550: loss = 0.61441
Step 19555: loss = 0.48839
Step 19560: loss = 0.80580
Step 19565: loss = 1.06860
Step 19570: loss = 0.50200
Step 19575: loss = 0.81777
Step 19580: loss = 0.72677
Step 19585: loss = 1.05347
Step 19590: loss = 0.69456
Step 19595: loss = 0.52551
Step 19600: loss = 0.78899
Step 19605: loss = 0.84227
Step 19610: loss = 0.71118
Step 19615: loss = 0.75899
Step 19620: loss = 0.40838
Step 19625: loss = 0.58114
Step 19630: loss = 0.65949
Step 19635: loss = 0.96258
Step 19640: loss = 0.75230
Step 19645: loss = 0.71684
Step 19650: loss = 0.60394
Step 19655: loss = 0.81182
Step 19660: loss = 0.59954
Step 19665: loss = 1.04039
Step 19670: loss = 0.74120
Step 19675: loss = 0.72522
Step 19680: loss = 0.79492
Step 19685: loss = 0.79811
Step 19690: loss = 0.74079
Step 19695: loss = 0.51398
Step 19700: loss = 0.96464
Step 19705: loss = 0.83861
Step 19710: loss = 0.64492
Step 19715: loss = 0.66898
Step 19720: loss = 0.80743
Step 19725: loss = 0.77534
Step 19730: loss = 0.73693
Step 19735: loss = 0.92395
Step 19740: loss = 0.64927
Step 19745: loss = 0.68749
Step 19750: loss = 0.75110
Step 19755: loss = 0.48254
Step 19760: loss = 0.40884
Step 19765: loss = 0.96125
Step 19770: loss = 0.87616
Step 19775: loss = 0.80669
Step 19780: loss = 0.85416
Step 19785: loss = 0.67138
Step 19790: loss = 0.49032
Step 19795: loss = 0.45696
Step 19800: loss = 0.77857
Step 19805: loss = 0.64963
Step 19810: loss = 0.75269
Step 19815: loss = 0.77522
Step 19820: loss = 0.94931
Step 19825: loss = 0.67333
Step 19830: loss = 0.73091
Step 19835: loss = 0.76039
Step 19840: loss = 0.86747
Step 19845: loss = 0.75008
Step 19850: loss = 0.51922
Step 19855: loss = 0.85911
Step 19860: loss = 0.63013
Step 19865: loss = 0.66994
Step 19870: loss = 0.81010
Step 19875: loss = 0.66584
Step 19880: loss = 0.72078
Step 19885: loss = 0.78773
Step 19890: loss = 0.61853
Step 19895: loss = 0.78145
Step 19900: loss = 0.75780
Step 19905: loss = 0.98456
Step 19910: loss = 0.75149
Step 19915: loss = 1.03207
Step 19920: loss = 0.81044
Step 19925: loss = 0.56874
Step 19930: loss = 0.72449
Step 19935: loss = 0.82752
Step 19940: loss = 0.80637
Step 19945: loss = 0.64682
Step 19950: loss = 1.04828
Step 19955: loss = 0.85546
Step 19960: loss = 0.70619
Step 19965: loss = 0.66297
Step 19970: loss = 0.74689
Step 19975: loss = 0.85102
Step 19980: loss = 0.70133
Step 19985: loss = 0.65379
Step 19990: loss = 0.63658
Step 19995: loss = 0.57841
Step 20000: loss = 0.92147
Training Data Eval:
  Num examples: 50000, Num correct: 37632, Precision @ 1: 0.7526
('Testing Data Eval: EPOCH->', 21)
  Num examples: 10000, Num correct: 6160, Precision @ 1: 0.6160
Step 20005: loss = 0.72043
Step 20010: loss = 0.75749
Step 20015: loss = 0.65358
Step 20020: loss = 0.52647
Step 20025: loss = 0.62721
Step 20030: loss = 0.77469
Step 20035: loss = 0.68300
Step 20040: loss = 0.64738
Step 20045: loss = 0.52212
Step 20050: loss = 0.56907
Step 20055: loss = 0.77079
Step 20060: loss = 0.48129
Step 20065: loss = 0.52446
Step 20070: loss = 0.80645
Step 20075: loss = 0.64723
Step 20080: loss = 1.15591
Step 20085: loss = 0.92185
Step 20090: loss = 0.56963
Step 20095: loss = 0.88790
Step 20100: loss = 0.66588
Step 20105: loss = 0.72745
Step 20110: loss = 0.83179
Step 20115: loss = 0.80710
Step 20120: loss = 0.64630
Step 20125: loss = 0.70499
Step 20130: loss = 0.93037
Step 20135: loss = 0.78835
Step 20140: loss = 0.83319
Step 20145: loss = 0.48021
Step 20150: loss = 0.54944
Step 20155: loss = 0.43314
Step 20160: loss = 0.69338
Step 20165: loss = 0.94314
Step 20170: loss = 0.96642
Step 20175: loss = 0.72087
Step 20180: loss = 0.82228
Step 20185: loss = 0.64682
Step 20190: loss = 0.82474
Step 20195: loss = 0.58741
Step 20200: loss = 0.60242
Step 20205: loss = 0.67376
Step 20210: loss = 0.63943
Step 20215: loss = 0.78019
Step 20220: loss = 0.55379
Step 20225: loss = 0.61668
Step 20230: loss = 1.05177
Step 20235: loss = 0.58691
Step 20240: loss = 1.02483
Step 20245: loss = 0.73845
Step 20250: loss = 0.86491
Step 20255: loss = 0.71437
Step 20260: loss = 0.57349
Step 20265: loss = 0.78666
Step 20270: loss = 1.01855
Step 20275: loss = 0.83433
Step 20280: loss = 0.60376
Step 20285: loss = 0.63107
Step 20290: loss = 0.50163
Step 20295: loss = 0.52718
Step 20300: loss = 0.55204
Step 20305: loss = 0.62850
Step 20310: loss = 0.75702
Step 20315: loss = 0.66038
Step 20320: loss = 0.84882
Step 20325: loss = 1.05869
Step 20330: loss = 1.21132
Step 20335: loss = 0.67919
Step 20340: loss = 0.61285
Step 20345: loss = 0.73611
Step 20350: loss = 0.91328
Step 20355: loss = 0.74105
Step 20360: loss = 0.71794
Step 20365: loss = 0.87812
Step 20370: loss = 0.68304
Step 20375: loss = 0.69160
Step 20380: loss = 0.71551
Step 20385: loss = 0.60864
Step 20390: loss = 0.57641
Step 20395: loss = 0.62310
Step 20400: loss = 0.69458
Step 20405: loss = 0.78156
Step 20410: loss = 0.67242
Step 20415: loss = 0.65413
Step 20420: loss = 0.67635
Step 20425: loss = 0.70238
Step 20430: loss = 0.99613
Step 20435: loss = 0.98081
Step 20440: loss = 0.46333
Step 20445: loss = 0.68282
Step 20450: loss = 0.52673
Step 20455: loss = 0.70210
Step 20460: loss = 0.55227
Step 20465: loss = 0.49146
Step 20470: loss = 0.96354
Step 20475: loss = 0.57050
Step 20480: loss = 0.93929
Step 20485: loss = 0.44874
Step 20490: loss = 0.64520
Step 20495: loss = 0.75497
Step 20500: loss = 0.90880
Step 20505: loss = 0.77419
Step 20510: loss = 0.65189
Step 20515: loss = 0.78945
Step 20520: loss = 0.63915
Step 20525: loss = 0.77194
Step 20530: loss = 0.71222
Step 20535: loss = 1.22599
Step 20540: loss = 0.66543
Step 20545: loss = 0.79816
Step 20550: loss = 0.94517
Step 20555: loss = 0.63392
Step 20560: loss = 0.80621
Step 20565: loss = 0.66223
Step 20570: loss = 0.88991
Step 20575: loss = 0.45895
Step 20580: loss = 0.67636
Step 20585: loss = 0.75055
Step 20590: loss = 0.69441
Step 20595: loss = 0.85328
Step 20600: loss = 0.61731
Step 20605: loss = 0.44752
Step 20610: loss = 0.83856
Step 20615: loss = 0.69847
Step 20620: loss = 0.73572
Step 20625: loss = 0.63056
Step 20630: loss = 0.42762
Step 20635: loss = 0.66063
Step 20640: loss = 0.59932
Step 20645: loss = 1.14262
Step 20650: loss = 0.85417
Step 20655: loss = 0.65266
Step 20660: loss = 0.51987
Step 20665: loss = 0.76352
Step 20670: loss = 0.74966
Step 20675: loss = 0.55891
Step 20680: loss = 0.77465
Step 20685: loss = 0.74622
Step 20690: loss = 0.82420
Step 20695: loss = 0.60029
Step 20700: loss = 0.43109
Step 20705: loss = 0.50497
Step 20710: loss = 1.00234
Step 20715: loss = 0.96000
Step 20720: loss = 0.33944
Step 20725: loss = 0.71463
Step 20730: loss = 0.80432
Step 20735: loss = 0.42533
Step 20740: loss = 0.53228
Step 20745: loss = 0.66190
Step 20750: loss = 0.88070
Step 20755: loss = 0.69601
Step 20760: loss = 0.67463
Step 20765: loss = 0.67920
Step 20770: loss = 0.57814
Step 20775: loss = 0.68637
Step 20780: loss = 0.58279
Step 20785: loss = 0.84996
Step 20790: loss = 0.88205
Step 20795: loss = 0.74939
Step 20800: loss = 0.62654
Step 20805: loss = 0.89419
Step 20810: loss = 0.78798
Step 20815: loss = 0.62122
Step 20820: loss = 0.74716
Step 20825: loss = 0.85935
Step 20830: loss = 0.91827
Step 20835: loss = 0.90678
Step 20840: loss = 0.90442
Step 20845: loss = 0.74589
Step 20850: loss = 0.61805
Step 20855: loss = 0.67829
Step 20860: loss = 0.78570
Step 20865: loss = 0.90478
Step 20870: loss = 0.75215
Step 20875: loss = 0.59622
Step 20880: loss = 0.61376
Step 20885: loss = 0.76594
Step 20890: loss = 0.58726
Step 20895: loss = 0.46061
Step 20900: loss = 0.68713
Step 20905: loss = 0.97596
Step 20910: loss = 0.95558
Step 20915: loss = 0.64070
Step 20920: loss = 0.58537
Step 20925: loss = 0.64253
Step 20930: loss = 0.87350
Step 20935: loss = 0.63219
Step 20940: loss = 0.87800
Step 20945: loss = 0.68562
Step 20950: loss = 0.44870
Step 20955: loss = 0.79160
Step 20960: loss = 0.68767
Step 20965: loss = 0.49996
Step 20970: loss = 0.71009
Step 20975: loss = 0.54955
Step 20980: loss = 0.73135
Step 20985: loss = 0.70929
Step 20990: loss = 0.90746
Step 20995: loss = 0.55690
Step 21000: loss = 0.55343
Training Data Eval:
  Num examples: 50000, Num correct: 38471, Precision @ 1: 0.7694
('Testing Data Eval: EPOCH->', 22)
  Num examples: 10000, Num correct: 6192, Precision @ 1: 0.6192
Step 21005: loss = 0.77682
Step 21010: loss = 0.65774
Step 21015: loss = 0.46868
Step 21020: loss = 0.47905
Step 21025: loss = 0.75153
Step 21030: loss = 1.03650
Step 21035: loss = 0.71525
Step 21040: loss = 0.79004
Step 21045: loss = 0.60763
Step 21050: loss = 0.41308
Step 21055: loss = 0.84924
Step 21060: loss = 0.57913
Step 21065: loss = 0.73646
Step 21070: loss = 0.83146
Step 21075: loss = 0.55514
Step 21080: loss = 0.62883
Step 21085: loss = 0.61628
Step 21090: loss = 0.68347
Step 21095: loss = 0.59015
Step 21100: loss = 0.61336
Step 21105: loss = 0.58992
Step 21110: loss = 1.07237
Step 21115: loss = 0.80017
Step 21120: loss = 0.87582
Step 21125: loss = 0.63460
Step 21130: loss = 0.61280
Step 21135: loss = 0.52810
Step 21140: loss = 0.50535
Step 21145: loss = 0.65187
Step 21150: loss = 0.67170
Step 21155: loss = 0.81250
Step 21160: loss = 0.71726
Step 21165: loss = 0.47608
Step 21170: loss = 0.94636
Step 21175: loss = 0.48028
Step 21180: loss = 1.11909
Step 21185: loss = 0.79825
Step 21190: loss = 0.75195
Step 21195: loss = 0.71520
Step 21200: loss = 0.52103
Step 21205: loss = 0.40293
Step 21210: loss = 0.66512
Step 21215: loss = 0.55157
Step 21220: loss = 0.68387
Step 21225: loss = 0.61867
Step 21230: loss = 0.92057
Step 21235: loss = 0.76322
Step 21240: loss = 0.90827
Step 21245: loss = 0.78567
Step 21250: loss = 0.76745
Step 21255: loss = 0.64625
Step 21260: loss = 0.76703
Step 21265: loss = 0.73551
Step 21270: loss = 0.73854
Step 21275: loss = 0.77059
Step 21280: loss = 0.72265
Step 21285: loss = 0.45199
Step 21290: loss = 0.64525
Step 21295: loss = 0.94128
Step 21300: loss = 0.64794
Step 21305: loss = 0.92541
Step 21310: loss = 1.10089
Step 21315: loss = 0.69457
Step 21320: loss = 0.66198
Step 21325: loss = 0.71221
Step 21330: loss = 0.76151
Step 21335: loss = 0.77839
Step 21340: loss = 0.62119
Step 21345: loss = 0.86018
Step 21350: loss = 0.58555
Step 21355: loss = 0.59338
Step 21360: loss = 0.63745
Step 21365: loss = 0.70002
Step 21370: loss = 1.01065
Step 21375: loss = 0.55300
Step 21380: loss = 0.86805
Step 21385: loss = 0.88471
Step 21390: loss = 0.91348
Step 21395: loss = 0.72171
Step 21400: loss = 0.58865
Step 21405: loss = 0.58411
Step 21410: loss = 0.53425
Step 21415: loss = 0.73765
Step 21420: loss = 0.99768
Step 21425: loss = 0.98849
Step 21430: loss = 0.50262
Step 21435: loss = 0.79847
Step 21440: loss = 0.78901
Step 21445: loss = 0.46162
Step 21450: loss = 0.74648
Step 21455: loss = 0.98769
Step 21460: loss = 0.95605
Step 21465: loss = 0.56714
Step 21470: loss = 0.57354
Step 21475: loss = 0.53655
Step 21480: loss = 0.66510
Step 21485: loss = 0.84604
Step 21490: loss = 0.82567
Step 21495: loss = 0.70545
Step 21500: loss = 0.74869
Step 21505: loss = 0.80135
Step 21510: loss = 0.77192
Step 21515: loss = 0.69005
Step 21520: loss = 0.62331
Step 21525: loss = 0.85603
Step 21530: loss = 0.71193
Step 21535: loss = 0.70884
Step 21540: loss = 0.69552
Step 21545: loss = 0.68670
Step 21550: loss = 0.68872
Step 21555: loss = 0.68253
Step 21560: loss = 0.88869
Step 21565: loss = 0.60607
Step 21570: loss = 0.54545
Step 21575: loss = 0.52063
Step 21580: loss = 0.70444
Step 21585: loss = 0.66039
Step 21590: loss = 0.54746
Step 21595: loss = 0.67331
Step 21600: loss = 0.57089
Step 21605: loss = 0.67595
Step 21610: loss = 0.65865
Step 21615: loss = 0.59422
Step 21620: loss = 0.66045
Step 21625: loss = 0.74188
Step 21630: loss = 0.79369
Step 21635: loss = 0.74279
Step 21640: loss = 0.52717
Step 21645: loss = 0.76394
Step 21650: loss = 0.93115
Step 21655: loss = 0.72453
Step 21660: loss = 0.62499
Step 21665: loss = 0.50505
Step 21670: loss = 0.36948
Step 21675: loss = 1.04461
Step 21680: loss = 0.68359
Step 21685: loss = 0.54781
Step 21690: loss = 0.65781
Step 21695: loss = 0.93583
Step 21700: loss = 0.66429
Step 21705: loss = 1.02104
Step 21710: loss = 0.74521
Step 21715: loss = 0.67699
Step 21720: loss = 0.70189
Step 21725: loss = 0.66456
Step 21730: loss = 0.56117
Step 21735: loss = 0.54810
Step 21740: loss = 0.63485
Step 21745: loss = 0.79625
Step 21750: loss = 0.48570
Step 21755: loss = 0.69106
Step 21760: loss = 0.79938
Step 21765: loss = 0.60793
Step 21770: loss = 0.59197
Step 21775: loss = 0.55751
Step 21780: loss = 0.48351
Step 21785: loss = 0.93079
Step 21790: loss = 0.95444
Step 21795: loss = 0.60066
Step 21800: loss = 0.76147
Step 21805: loss = 0.69993
Step 21810: loss = 0.63172
Step 21815: loss = 0.48163
Step 21820: loss = 0.72566
Step 21825: loss = 0.81192
Step 21830: loss = 0.55827
Step 21835: loss = 0.59412
Step 21840: loss = 0.70167
Step 21845: loss = 0.56594
Step 21850: loss = 0.65637
Step 21855: loss = 0.72869
Step 21860: loss = 0.58819
Step 21865: loss = 0.79122
Step 21870: loss = 0.76936
Step 21875: loss = 0.49419
Step 21880: loss = 0.62362
Step 21885: loss = 0.82794
Step 21890: loss = 0.93421
Step 21895: loss = 0.74120
Step 21900: loss = 0.49966
Step 21905: loss = 0.61454
Step 21910: loss = 0.71840
Step 21915: loss = 0.64680
Step 21920: loss = 0.73692
Step 21925: loss = 0.70499
Step 21930: loss = 0.63454
Step 21935: loss = 0.69816
Step 21940: loss = 0.63876
Step 21945: loss = 0.71708
Step 21950: loss = 0.70596
Step 21955: loss = 0.65558
Step 21960: loss = 0.89248
Step 21965: loss = 0.71601
Step 21970: loss = 0.72544
Step 21975: loss = 0.75334
Step 21980: loss = 0.64965
Step 21985: loss = 0.81342
Step 21990: loss = 0.94848
Step 21995: loss = 0.86102
Step 22000: loss = 0.66466
Training Data Eval:
  Num examples: 50000, Num correct: 38815, Precision @ 1: 0.7763
('Testing Data Eval: EPOCH->', 23)
  Num examples: 10000, Num correct: 6327, Precision @ 1: 0.6327
Step 22005: loss = 0.63596
Step 22010: loss = 0.49301
Step 22015: loss = 0.31280
Step 22020: loss = 0.67977
Step 22025: loss = 0.71399
Step 22030: loss = 0.57964
Step 22035: loss = 0.47228
Step 22040: loss = 0.77483
Step 22045: loss = 0.88946
Step 22050: loss = 0.64933
Step 22055: loss = 0.67269
Step 22060: loss = 0.48392
Step 22065: loss = 0.41804
Step 22070: loss = 1.00871
Step 22075: loss = 0.49832
Step 22080: loss = 0.59376
Step 22085: loss = 0.46179
Step 22090: loss = 0.83536
Step 22095: loss = 0.74789
Step 22100: loss = 0.58328
Step 22105: loss = 0.43344
Step 22110: loss = 0.75067
Step 22115: loss = 0.79420
Step 22120: loss = 0.49063
Step 22125: loss = 0.73731
Step 22130: loss = 0.53210
Step 22135: loss = 0.64631
Step 22140: loss = 0.81212
Step 22145: loss = 0.70457
Step 22150: loss = 0.66359
Step 22155: loss = 0.73536
Step 22160: loss = 0.72848
Step 22165: loss = 0.56852
Step 22170: loss = 0.60897
Step 22175: loss = 0.53600
Step 22180: loss = 0.63023
Step 22185: loss = 0.40282
Step 22190: loss = 0.73601
Step 22195: loss = 0.95212
Step 22200: loss = 0.58408
Step 22205: loss = 0.67675
Step 22210: loss = 0.86214
Step 22215: loss = 0.86143
Step 22220: loss = 0.64165
Step 22225: loss = 0.54877
Step 22230: loss = 0.66964
Step 22235: loss = 0.64182
Step 22240: loss = 0.67188
Step 22245: loss = 0.78796
Step 22250: loss = 0.64082
Step 22255: loss = 0.55969
Step 22260: loss = 0.76329
Step 22265: loss = 0.74011
Step 22270: loss = 0.52588
Step 22275: loss = 0.79751
Step 22280: loss = 0.50156
Step 22285: loss = 0.55990
Step 22290: loss = 0.87832
Step 22295: loss = 0.41930
Step 22300: loss = 0.78091
Step 22305: loss = 0.49670
Step 22310: loss = 0.60912
Step 22315: loss = 0.85138
Step 22320: loss = 0.49455
Step 22325: loss = 0.68621
Step 22330: loss = 0.60355
Step 22335: loss = 0.89367
Step 22340: loss = 0.43716
Step 22345: loss = 0.77816
Step 22350: loss = 0.65915
Step 22355: loss = 0.90852
Step 22360: loss = 0.65209
Step 22365: loss = 0.65266
Step 22370: loss = 0.47457
Step 22375: loss = 1.00591
Step 22380: loss = 0.51340
Step 22385: loss = 0.92196
Step 22390: loss = 0.65543
Step 22395: loss = 0.93770
Step 22400: loss = 0.63355
Step 22405: loss = 0.52029
Step 22410: loss = 0.82960
Step 22415: loss = 0.55107
Step 22420: loss = 0.93467
Step 22425: loss = 0.78757
Step 22430: loss = 0.46346
Step 22435: loss = 0.88927
Step 22440: loss = 0.70375
Step 22445: loss = 0.65634
Step 22450: loss = 0.55249
Step 22455: loss = 0.67906
Step 22460: loss = 0.57586
Step 22465: loss = 0.75540
Step 22470: loss = 0.68597
Step 22475: loss = 1.04270
Step 22480: loss = 0.60942
Step 22485: loss = 0.98349
Step 22490: loss = 0.71765
Step 22495: loss = 0.91853
Step 22500: loss = 0.67276
Step 22505: loss = 0.60103
Step 22510: loss = 0.77168
Step 22515: loss = 0.52124
Step 22520: loss = 0.56696
Step 22525: loss = 0.85706
Step 22530: loss = 0.80419
Step 22535: loss = 0.48326
Step 22540: loss = 0.56901
Step 22545: loss = 0.80561
Step 22550: loss = 0.82851
Step 22555: loss = 0.86566
Step 22560: loss = 0.71808
Step 22565: loss = 0.40199
Step 22570: loss = 0.70243
Step 22575: loss = 0.68975
Step 22580: loss = 0.60614
Step 22585: loss = 0.70825
Step 22590: loss = 0.67836
Step 22595: loss = 0.51670
Step 22600: loss = 0.63378
Step 22605: loss = 0.66522
Step 22610: loss = 0.44174
Step 22615: loss = 0.50231
Step 22620: loss = 0.38118
Step 22625: loss = 0.58159
Step 22630: loss = 0.62895
Step 22635: loss = 0.67248
Step 22640: loss = 0.38665
Step 22645: loss = 0.83828
Step 22650: loss = 0.55833
Step 22655: loss = 1.05549
Step 22660: loss = 0.56897
Step 22665: loss = 0.65292
Step 22670: loss = 0.89319
Step 22675: loss = 0.81800
Step 22680: loss = 0.67711
Step 22685: loss = 0.80400
Step 22690: loss = 0.73879
Step 22695: loss = 0.80382
Step 22700: loss = 0.55983
Step 22705: loss = 0.86060
Step 22710: loss = 0.67783
Step 22715: loss = 0.60700
Step 22720: loss = 0.91094
Step 22725: loss = 0.73842
Step 22730: loss = 0.60935
Step 22735: loss = 0.63565
Step 22740: loss = 0.86548
Step 22745: loss = 0.69773
Step 22750: loss = 0.76160
Step 22755: loss = 0.92582
Step 22760: loss = 0.35315
Step 22765: loss = 0.78444
Step 22770: loss = 0.86800
Step 22775: loss = 0.68540
Step 22780: loss = 0.56022
Step 22785: loss = 0.56697
Step 22790: loss = 1.17823
Step 22795: loss = 0.75094
Step 22800: loss = 0.63189
Step 22805: loss = 0.58106
Step 22810: loss = 0.44416
Step 22815: loss = 0.65141
Step 22820: loss = 0.64646
Step 22825: loss = 0.96854
Step 22830: loss = 0.59067
Step 22835: loss = 0.35888
Step 22840: loss = 0.84483
Step 22845: loss = 0.70977
Step 22850: loss = 1.02524
Step 22855: loss = 0.66641
Step 22860: loss = 0.47026
Step 22865: loss = 0.46743
Step 22870: loss = 0.70706
Step 22875: loss = 0.87351
Step 22880: loss = 0.83099
Step 22885: loss = 0.86730
Step 22890: loss = 0.56442
Step 22895: loss = 0.56885
Step 22900: loss = 0.65769
Step 22905: loss = 0.73488
Step 22910: loss = 0.52508
Step 22915: loss = 0.59509
Step 22920: loss = 0.55186
Step 22925: loss = 0.81076
Step 22930: loss = 0.83277
Step 22935: loss = 0.70121
Step 22940: loss = 0.69017
Step 22945: loss = 0.53200
Step 22950: loss = 0.42466
Step 22955: loss = 0.87477
Step 22960: loss = 0.81698
Step 22965: loss = 0.64408
Step 22970: loss = 0.57398
Step 22975: loss = 0.52035
Step 22980: loss = 0.87272
Step 22985: loss = 0.55500
Step 22990: loss = 0.53599
Step 22995: loss = 1.15003
Step 23000: loss = 0.47448
Training Data Eval:
  Num examples: 50000, Num correct: 38978, Precision @ 1: 0.7796
('Testing Data Eval: EPOCH->', 24)
  Num examples: 10000, Num correct: 6317, Precision @ 1: 0.6317
Step 23005: loss = 0.56322
Step 23010: loss = 0.84446
Step 23015: loss = 0.67971
Step 23020: loss = 0.48533
Step 23025: loss = 0.77805
Step 23030: loss = 0.43371
Step 23035: loss = 0.81845
Step 23040: loss = 0.70165
Step 23045: loss = 0.67285
Step 23050: loss = 0.62159
Step 23055: loss = 0.72078
Step 23060: loss = 0.50051
Step 23065: loss = 0.68973
Step 23070: loss = 0.85824
Step 23075: loss = 0.75545
Step 23080: loss = 0.65021
Step 23085: loss = 0.46593
Step 23090: loss = 0.45846
Step 23095: loss = 0.51380
Step 23100: loss = 0.65697
Step 23105: loss = 0.66203
Step 23110: loss = 0.44868
Step 23115: loss = 0.81899
Step 23120: loss = 0.62139
Step 23125: loss = 0.46045
Step 23130: loss = 0.56941
Step 23135: loss = 0.75325
Step 23140: loss = 0.79046
Step 23145: loss = 0.51822
Step 23150: loss = 0.56699
Step 23155: loss = 0.80639
Step 23160: loss = 0.68854
Step 23165: loss = 0.69484
Step 23170: loss = 0.69467
Step 23175: loss = 0.55061
Step 23180: loss = 0.60358
Step 23185: loss = 0.71432
Step 23190: loss = 0.52408
Step 23195: loss = 0.52446
Step 23200: loss = 0.65806
Step 23205: loss = 0.53176
Step 23210: loss = 0.90918
Step 23215: loss = 0.60149
Step 23220: loss = 0.57540
Step 23225: loss = 0.71173
Step 23230: loss = 0.49248
Step 23235: loss = 0.78903
Step 23240: loss = 0.63569
Step 23245: loss = 0.81441
Step 23250: loss = 0.68519
Step 23255: loss = 0.64160
Step 23260: loss = 0.70265
Step 23265: loss = 0.73526
Step 23270: loss = 0.56651
Step 23275: loss = 0.77019
Step 23280: loss = 0.65680
Step 23285: loss = 0.55943
Step 23290: loss = 0.72033
Step 23295: loss = 0.54540
Step 23300: loss = 0.83317
Step 23305: loss = 0.45546
Step 23310: loss = 0.94000
Step 23315: loss = 0.52334
Step 23320: loss = 0.89619
Step 23325: loss = 0.62738
Step 23330: loss = 0.66549
Step 23335: loss = 0.56794
Step 23340: loss = 0.62384
Step 23345: loss = 0.74631
Step 23350: loss = 0.69348
Step 23355: loss = 0.49628
Step 23360: loss = 0.57004
Step 23365: loss = 0.73318
Step 23370: loss = 0.59225
Step 23375: loss = 0.64541
Step 23380: loss = 0.76414
Step 23385: loss = 0.66927
Step 23390: loss = 0.58710
Step 23395: loss = 0.73605
Step 23400: loss = 0.59242
Step 23405: loss = 0.94526
Step 23410: loss = 0.52001
Step 23415: loss = 0.57456
Step 23420: loss = 0.65431
Step 23425: loss = 0.55196
Step 23430: loss = 0.40128
Step 23435: loss = 0.56014
Step 23440: loss = 0.49949
Step 23445: loss = 0.60726
Step 23450: loss = 0.67978
Step 23455: loss = 0.62130
Step 23460: loss = 0.67322
Step 23465: loss = 0.48574
Step 23470: loss = 0.65794
Step 23475: loss = 0.61719
Step 23480: loss = 0.63680
Step 23485: loss = 0.58263
Step 23490: loss = 0.66158
Step 23495: loss = 0.70065
Step 23500: loss = 0.42248
Step 23505: loss = 0.65995
Step 23510: loss = 0.67470
Step 23515: loss = 0.69578
Step 23520: loss = 0.50903
Step 23525: loss = 0.65931
Step 23530: loss = 0.56580
Step 23535: loss = 0.77130
Step 23540: loss = 0.63445
Step 23545: loss = 0.89122
Step 23550: loss = 0.67377
Step 23555: loss = 0.48308
Step 23560: loss = 0.62439
Step 23565: loss = 0.52999
Step 23570: loss = 0.82489
Step 23575: loss = 0.55630
Step 23580: loss = 0.70295
Step 23585: loss = 0.91110
Step 23590: loss = 0.74795
Step 23595: loss = 0.65227
Step 23600: loss = 0.60497
Step 23605: loss = 0.49793
Step 23610: loss = 0.72179
Step 23615: loss = 0.43419
Step 23620: loss = 0.74002
Step 23625: loss = 0.50531
Step 23630: loss = 0.52178
Step 23635: loss = 0.67104
Step 23640: loss = 0.78944
Step 23645: loss = 0.62796
Step 23650: loss = 0.64929
Step 23655: loss = 0.45598
Step 23660: loss = 0.86209
Step 23665: loss = 0.39973
Step 23670: loss = 0.75496
Step 23675: loss = 0.59466
Step 23680: loss = 0.60364
Step 23685: loss = 0.63438
Step 23690: loss = 0.65173
Step 23695: loss = 0.76215
Step 23700: loss = 0.81341
Step 23705: loss = 0.74485
Step 23710: loss = 0.87613
Step 23715: loss = 0.55120
Step 23720: loss = 0.63113
Step 23725: loss = 0.77047
Step 23730: loss = 0.90879
Step 23735: loss = 0.29993
Step 23740: loss = 0.57898
Step 23745: loss = 0.57202
Step 23750: loss = 0.83914
Step 23755: loss = 0.64551
Step 23760: loss = 0.41303
Step 23765: loss = 0.60098
Step 23770: loss = 0.53741
Step 23775: loss = 0.61139
Step 23780: loss = 0.47261
Step 23785: loss = 0.50316
Step 23790: loss = 0.71558
Step 23795: loss = 0.58867
Step 23800: loss = 0.62607
Step 23805: loss = 0.80895
Step 23810: loss = 0.64752
Step 23815: loss = 0.82470
Step 23820: loss = 0.64155
Step 23825: loss = 0.83937
Step 23830: loss = 0.72013
Step 23835: loss = 0.83475
Step 23840: loss = 0.67197
Step 23845: loss = 0.58060
Step 23850: loss = 0.35279
Step 23855: loss = 0.62765
Step 23860: loss = 0.47954
Step 23865: loss = 0.89973
Step 23870: loss = 0.90885
Step 23875: loss = 0.48121
Step 23880: loss = 0.45647
Step 23885: loss = 0.70091
Step 23890: loss = 0.37192
Step 23895: loss = 1.01435
Step 23900: loss = 0.44197
Step 23905: loss = 0.75041
Step 23910: loss = 0.72276
Step 23915: loss = 0.53135
Step 23920: loss = 0.62992
Step 23925: loss = 0.76593
Step 23930: loss = 0.58981
Step 23935: loss = 0.39486
Step 23940: loss = 0.83338
Step 23945: loss = 0.79855
Step 23950: loss = 0.63422
Step 23955: loss = 0.52687
Step 23960: loss = 0.45596
Step 23965: loss = 0.43887
Step 23970: loss = 0.56608
Step 23975: loss = 0.50238
Step 23980: loss = 0.65909
Step 23985: loss = 0.36589
Step 23990: loss = 0.59634
Step 23995: loss = 0.79219
Step 24000: loss = 0.79868
Training Data Eval:
  Num examples: 50000, Num correct: 39607, Precision @ 1: 0.7921
('Testing Data Eval: EPOCH->', 25)
  Num examples: 10000, Num correct: 6375, Precision @ 1: 0.6375
Step 24005: loss = 0.73496
Step 24010: loss = 0.72399
Step 24015: loss = 0.29892
Step 24020: loss = 0.78051
Step 24025: loss = 0.80077
Step 24030: loss = 0.54673
Step 24035: loss = 0.72117
Step 24040: loss = 0.79442
Step 24045: loss = 0.36632
Step 24050: loss = 0.63513
Step 24055: loss = 0.44631
Step 24060: loss = 0.44847
Step 24065: loss = 0.65442
Step 24070: loss = 0.47800
Step 24075: loss = 0.57005
Step 24080: loss = 0.74598
Step 24085: loss = 0.45568
Step 24090: loss = 0.76201
Step 24095: loss = 0.57973
Step 24100: loss = 0.53203
Step 24105: loss = 0.65982
Step 24110: loss = 0.72667
Step 24115: loss = 0.64654
Step 24120: loss = 0.70725
Step 24125: loss = 0.60457
Step 24130: loss = 0.45962
Step 24135: loss = 0.56210
Step 24140: loss = 0.55471
Step 24145: loss = 0.69553
Step 24150: loss = 0.42618
Step 24155: loss = 0.62803
Step 24160: loss = 0.58085
Step 24165: loss = 0.55892
Step 24170: loss = 0.64312
Step 24175: loss = 0.81947
Step 24180: loss = 0.55216
Step 24185: loss = 0.59993
Step 24190: loss = 0.47793
Step 24195: loss = 0.61808
Step 24200: loss = 0.56623
Step 24205: loss = 0.51487
Step 24210: loss = 0.54025
Step 24215: loss = 0.58726
Step 24220: loss = 0.66830
Step 24225: loss = 0.38281
Step 24230: loss = 0.61845
Step 24235: loss = 0.65087
Step 24240: loss = 0.56641
Step 24245: loss = 0.55337
Step 24250: loss = 0.50030
Step 24255: loss = 0.75015
Step 24260: loss = 0.57117
Step 24265: loss = 0.67945
Step 24270: loss = 0.56463
Step 24275: loss = 0.59861
Step 24280: loss = 0.50375
Step 24285: loss = 0.65482
Step 24290: loss = 0.65160
Step 24295: loss = 0.47839
Step 24300: loss = 0.72108
Step 24305: loss = 0.50787
Step 24310: loss = 0.82297
Step 24315: loss = 0.66362
Step 24320: loss = 0.55292
Step 24325: loss = 0.64677
Step 24330: loss = 0.65732
Step 24335: loss = 0.49479
Step 24340: loss = 0.63458
Step 24345: loss = 0.68777
Step 24350: loss = 0.74282
Step 24355: loss = 0.72555
Step 24360: loss = 0.49229
Step 24365: loss = 0.61330
Step 24370: loss = 0.71295
Step 24375: loss = 0.55368
Step 24380: loss = 0.58225
Step 24385: loss = 0.44544
Step 24390: loss = 0.49966
Step 24395: loss = 0.73471
Step 24400: loss = 1.00781
Step 24405: loss = 0.61334
Step 24410: loss = 0.81307
Step 24415: loss = 0.48547
Step 24420: loss = 0.90884
Step 24425: loss = 0.66935
Step 24430: loss = 0.53415
Step 24435: loss = 0.47439
Step 24440: loss = 0.49065
Step 24445: loss = 0.54928
Step 24450: loss = 0.75877
Step 24455: loss = 0.48207
Step 24460: loss = 0.89697
Step 24465: loss = 0.52761
Step 24470: loss = 0.71213
Step 24475: loss = 0.67960
Step 24480: loss = 0.69857
Step 24485: loss = 0.46319
Step 24490: loss = 0.69836
Step 24495: loss = 0.69806
Step 24500: loss = 0.67839
Step 24505: loss = 0.70367
Step 24510: loss = 0.51660
Step 24515: loss = 0.56561
Step 24520: loss = 0.69620
Step 24525: loss = 0.76821
Step 24530: loss = 0.67029
Step 24535: loss = 0.51212
Step 24540: loss = 0.68304
Step 24545: loss = 0.61037
Step 24550: loss = 0.62066
Step 24555: loss = 0.63858
Step 24560: loss = 0.63600
Step 24565: loss = 0.93509
Step 24570: loss = 0.35075
Step 24575: loss = 0.50966
Step 24580: loss = 0.46552
Step 24585: loss = 0.48256
Step 24590: loss = 0.66519
Step 24595: loss = 0.76797
Step 24600: loss = 0.47812
Step 24605: loss = 0.63734
Step 24610: loss = 0.54766
Step 24615: loss = 0.71897
Step 24620: loss = 0.81146
Step 24625: loss = 0.56498
Step 24630: loss = 0.68722
Step 24635: loss = 0.62859
Step 24640: loss = 0.47692
Step 24645: loss = 0.52717
Step 24650: loss = 0.54353
Step 24655: loss = 0.63488
Step 24660: loss = 0.88815
Step 24665: loss = 0.61894
Step 24670: loss = 0.50968
Step 24675: loss = 0.70042
Step 24680: loss = 0.43935
Step 24685: loss = 0.67036
Step 24690: loss = 0.91904
Step 24695: loss = 1.11224
Step 24700: loss = 1.05414
Step 24705: loss = 0.91642
Step 24710: loss = 0.71506
Step 24715: loss = 0.68881
Step 24720: loss = 0.92213
Step 24725: loss = 0.38524
Step 24730: loss = 0.56980
Step 24735: loss = 0.39284
Step 24740: loss = 0.58124
Step 24745: loss = 0.59499
Step 24750: loss = 0.65877
Step 24755: loss = 0.73047
Step 24760: loss = 0.56509
Step 24765: loss = 0.84794
Step 24770: loss = 0.71326
Step 24775: loss = 0.49853
Step 24780: loss = 0.50051
Step 24785: loss = 0.73359
Step 24790: loss = 0.60749
Step 24795: loss = 0.56506
Step 24800: loss = 0.62613
Step 24805: loss = 0.57652
Step 24810: loss = 0.49289
Step 24815: loss = 0.85585
Step 24820: loss = 0.61796
Step 24825: loss = 0.61072
Step 24830: loss = 0.61888
Step 24835: loss = 0.60090
Step 24840: loss = 0.69997
Step 24845: loss = 0.86451
Step 24850: loss = 0.57049
Step 24855: loss = 0.78755
Step 24860: loss = 0.74770
Step 24865: loss = 0.65289
Step 24870: loss = 0.73365
Step 24875: loss = 0.62122
Step 24880: loss = 0.56808
Step 24885: loss = 0.65745
Step 24890: loss = 0.80035
Step 24895: loss = 0.52120
Step 24900: loss = 0.60927
Step 24905: loss = 0.60568
Step 24910: loss = 0.85822
Step 24915: loss = 0.70412
Step 24920: loss = 0.99247
Step 24925: loss = 0.74293
Step 24930: loss = 0.58924
Step 24935: loss = 0.59805
Step 24940: loss = 0.59217
Step 24945: loss = 0.52784
Step 24950: loss = 0.57607
Step 24955: loss = 0.73719
Step 24960: loss = 0.82997
Step 24965: loss = 0.65661
Step 24970: loss = 0.45091
Step 24975: loss = 0.74773
Step 24980: loss = 0.55503
Step 24985: loss = 0.63291
Step 24990: loss = 0.61079
Step 24995: loss = 0.43799
Step 25000: loss = 0.96256
Training Data Eval:
  Num examples: 50000, Num correct: 39831, Precision @ 1: 0.7966
('Testing Data Eval: EPOCH->', 26)
  Num examples: 10000, Num correct: 6263, Precision @ 1: 0.6263
Step 25005: loss = 0.56937
Step 25010: loss = 0.64075
Step 25015: loss = 0.38327
Step 25020: loss = 0.74636
Step 25025: loss = 0.65922
Step 25030: loss = 0.63637
Step 25035: loss = 0.46392
Step 25040: loss = 0.53880
Step 25045: loss = 0.40812
Step 25050: loss = 0.47421
Step 25055: loss = 0.52987
Step 25060: loss = 0.46502
Step 25065: loss = 0.70518
Step 25070: loss = 0.57344
Step 25075: loss = 0.52608
Step 25080: loss = 0.56558
Step 25085: loss = 0.45837
Step 25090: loss = 0.71092
Step 25095: loss = 0.61394
Step 25100: loss = 0.39057
Step 25105: loss = 0.66211
Step 25110: loss = 0.62640
Step 25115: loss = 0.59341
Step 25120: loss = 0.64749
Step 25125: loss = 0.56532
Step 25130: loss = 0.76162
Step 25135: loss = 0.61403
Step 25140: loss = 0.95682
Step 25145: loss = 0.65877
Step 25150: loss = 0.69048
Step 25155: loss = 0.51639
Step 25160: loss = 0.31435
Step 25165: loss = 0.40179
Step 25170: loss = 0.65312
Step 25175: loss = 0.46681
Step 25180: loss = 0.75050
Step 25185: loss = 0.66357
Step 25190: loss = 0.42737
Step 25195: loss = 0.57657
Step 25200: loss = 0.70728
Step 25205: loss = 0.43659
Step 25210: loss = 0.72604
Step 25215: loss = 0.98295
Step 25220: loss = 0.57589
Step 25225: loss = 0.50673
Step 25230: loss = 0.72667
Step 25235: loss = 0.79290
Step 25240: loss = 0.84548
Step 25245: loss = 0.50608
Step 25250: loss = 0.59577
Step 25255: loss = 0.41152
Step 25260: loss = 0.51205
Step 25265: loss = 0.69039
Step 25270: loss = 0.49350
Step 25275: loss = 0.92833
Step 25280: loss = 0.59901
Step 25285: loss = 0.72617
Step 25290: loss = 0.76963
Step 25295: loss = 0.79056
Step 25300: loss = 0.61347
Step 25305: loss = 1.03326
Step 25310: loss = 0.59791
Step 25315: loss = 0.90224
Step 25320: loss = 0.60438
Step 25325: loss = 0.52541
Step 25330: loss = 0.53981
Step 25335: loss = 0.59736
Step 25340: loss = 0.41083
Step 25345: loss = 0.43701
Step 25350: loss = 0.68083
Step 25355: loss = 0.72546
Step 25360: loss = 0.49252
Step 25365: loss = 0.48548
Step 25370: loss = 0.45821
Step 25375: loss = 0.49584
Step 25380: loss = 0.51595
Step 25385: loss = 0.67304
Step 25390: loss = 0.85401
Step 25395: loss = 0.42627
Step 25400: loss = 0.58947
Step 25405: loss = 0.59662
Step 25410: loss = 0.44149
Step 25415: loss = 0.57619
Step 25420: loss = 0.53935
Step 25425: loss = 0.57558
Step 25430: loss = 0.78178
Step 25435: loss = 0.73003
Step 25440: loss = 0.79581
Step 25445: loss = 0.53740
Step 25450: loss = 0.50792
Step 25455: loss = 0.38685
Step 25460: loss = 0.52635
Step 25465: loss = 0.57959
Step 25470: loss = 0.46407
Step 25475: loss = 0.48236
Step 25480: loss = 0.51723
Step 25485: loss = 0.81867
Step 25490: loss = 0.69737
Step 25495: loss = 0.60600
Step 25500: loss = 0.42227
Step 25505: loss = 0.62631
Step 25510: loss = 0.56961
Step 25515: loss = 0.70446
Step 25520: loss = 0.69740
Step 25525: loss = 0.37188
Step 25530: loss = 0.69113
Step 25535: loss = 0.47683
Step 25540: loss = 0.68383
Step 25545: loss = 0.64962
Step 25550: loss = 0.41207
Step 25555: loss = 0.68745
Step 25560: loss = 0.63938
Step 25565: loss = 0.61501
Step 25570: loss = 0.52718
Step 25575: loss = 0.65557
Step 25580: loss = 0.56409
Step 25585: loss = 0.41361
Step 25590: loss = 0.70542
Step 25595: loss = 0.63627
Step 25600: loss = 0.94890
Step 25605: loss = 0.53181
Step 25610: loss = 0.48195
Step 25615: loss = 0.68168
Step 25620: loss = 0.60939
Step 25625: loss = 0.43907
Step 25630: loss = 0.51962
Step 25635: loss = 0.49601
Step 25640: loss = 0.45017
Step 25645: loss = 0.74662
Step 25650: loss = 0.51562
Step 25655: loss = 0.62785
Step 25660: loss = 0.56975
Step 25665: loss = 0.78084
Step 25670: loss = 0.33912
Step 25675: loss = 0.92525
Step 25680: loss = 0.45697
Step 25685: loss = 0.52908
Step 25690: loss = 0.45873
Step 25695: loss = 0.62948
Step 25700: loss = 0.71218
Step 25705: loss = 0.67046
Step 25710: loss = 0.41210
Step 25715: loss = 0.40534
Step 25720: loss = 0.58406
Step 25725: loss = 0.50624
Step 25730: loss = 0.46077
Step 25735: loss = 0.65211
Step 25740: loss = 0.60358
Step 25745: loss = 0.74919
Step 25750: loss = 0.93572
Step 25755: loss = 0.54955
Step 25760: loss = 0.71822
Step 25765: loss = 0.53718
Step 25770: loss = 0.56628
Step 25775: loss = 0.57535
Step 25780: loss = 0.74094
Step 25785: loss = 0.39606
Step 25790: loss = 0.51230
Step 25795: loss = 0.41243
Step 25800: loss = 0.41973
Step 25805: loss = 0.49676
Step 25810: loss = 0.41176
Step 25815: loss = 0.46827
Step 25820: loss = 0.59867
Step 25825: loss = 0.77550
Step 25830: loss = 0.64004
Step 25835: loss = 0.77581
Step 25840: loss = 0.44447
Step 25845: loss = 0.83917
Step 25850: loss = 0.80383
Step 25855: loss = 0.57130
Step 25860: loss = 0.47716
Step 25865: loss = 0.38912
Step 25870: loss = 0.49467
Step 25875: loss = 0.47140
Step 25880: loss = 0.35149
Step 25885: loss = 0.65213
Step 25890: loss = 0.38915
Step 25895: loss = 0.63665
Step 25900: loss = 0.67281
Step 25905: loss = 0.58873
Step 25910: loss = 0.84823
Step 25915: loss = 0.35130
Step 25920: loss = 0.68500
Step 25925: loss = 0.69426
Step 25930: loss = 0.39401
Step 25935: loss = 0.70531
Step 25940: loss = 0.56796
Step 25945: loss = 0.80353
Step 25950: loss = 0.58636
Step 25955: loss = 0.65524
Step 25960: loss = 0.75584
Step 25965: loss = 0.59625
Step 25970: loss = 0.49331
Step 25975: loss = 0.50589
Step 25980: loss = 0.38299
Step 25985: loss = 0.73020
Step 25990: loss = 0.61046
Step 25995: loss = 0.49038
Step 26000: loss = 0.40601
Training Data Eval:
  Num examples: 50000, Num correct: 39910, Precision @ 1: 0.7982
('Testing Data Eval: EPOCH->', 27)
  Num examples: 10000, Num correct: 6266, Precision @ 1: 0.6266
Step 26005: loss = 0.53195
Step 26010: loss = 0.70815
Step 26015: loss = 0.56489
Step 26020: loss = 0.72567
Step 26025: loss = 0.46943
Step 26030: loss = 0.49418
Step 26035: loss = 0.46175
Step 26040: loss = 0.45553
Step 26045: loss = 0.59344
Step 26050: loss = 0.78775
Step 26055: loss = 0.40611
Step 26060: loss = 0.33025
Step 26065: loss = 0.58664
Step 26070: loss = 0.47109
Step 26075: loss = 0.69801
Step 26080: loss = 0.85892
Step 26085: loss = 0.43526
Step 26090: loss = 0.69991
Step 26095: loss = 0.68928
Step 26100: loss = 0.64908
Step 26105: loss = 0.53135
Step 26110: loss = 0.49999
Step 26115: loss = 0.53561
Step 26120: loss = 0.33760
Step 26125: loss = 0.48136
Step 26130: loss = 0.43707
Step 26135: loss = 0.37574
Step 26140: loss = 0.63048
Step 26145: loss = 0.46633
Step 26150: loss = 0.52136
Step 26155: loss = 0.43332
Step 26160: loss = 0.60318
Step 26165: loss = 0.44784
Step 26170: loss = 0.56779
Step 26175: loss = 0.55698
Step 26180: loss = 0.57111
Step 26185: loss = 0.59137
Step 26190: loss = 0.59001
Step 26195: loss = 0.46373
Step 26200: loss = 0.48508
Step 26205: loss = 0.64509
Step 26210: loss = 0.60834
Step 26215: loss = 0.61246
Step 26220: loss = 0.83508
Step 26225: loss = 0.54703
Step 26230: loss = 0.67130
Step 26235: loss = 0.45186
Step 26240: loss = 0.56217
Step 26245: loss = 0.70011
Step 26250: loss = 0.53527
Step 26255: loss = 0.60799
Step 26260: loss = 0.44316
Step 26265: loss = 0.53929
Step 26270: loss = 0.47842
Step 26275: loss = 0.35419
Step 26280: loss = 0.58359
Step 26285: loss = 0.52031
Step 26290: loss = 0.75110
Step 26295: loss = 0.71582
Step 26300: loss = 0.51100
Step 26305: loss = 0.60976
Step 26310: loss = 0.91073
Step 26315: loss = 0.43603
Step 26320: loss = 0.82496
Step 26325: loss = 0.59835
Step 26330: loss = 0.68178
Step 26335: loss = 0.52955
Step 26340: loss = 1.02876
Step 26345: loss = 0.58631
Step 26350: loss = 0.64767
Step 26355: loss = 0.69173
Step 26360: loss = 0.64557
Step 26365: loss = 0.40520
Step 26370: loss = 0.37142
Step 26375: loss = 0.59492
Step 26380: loss = 0.34089
Step 26385: loss = 0.58713
Step 26390: loss = 0.43900
Step 26395: loss = 0.52659
Step 26400: loss = 0.88822
Step 26405: loss = 0.26745
Step 26410: loss = 0.57318
Step 26415: loss = 0.84455
Step 26420: loss = 0.30855
Step 26425: loss = 0.42613
Step 26430: loss = 0.48309
Step 26435: loss = 0.64003
Step 26440: loss = 0.48851
Step 26445: loss = 0.56985
Step 26450: loss = 0.74204
Step 26455: loss = 0.68172
Step 26460: loss = 0.30881
Step 26465: loss = 0.55335
Step 26470: loss = 0.88942
Step 26475: loss = 0.63084
Step 26480: loss = 0.44390
Step 26485: loss = 0.37480
Step 26490: loss = 0.63527
Step 26495: loss = 0.59005
Step 26500: loss = 0.53979
Step 26505: loss = 0.83360
Step 26510: loss = 0.52176
Step 26515: loss = 0.82290
Step 26520: loss = 0.67051
Step 26525: loss = 0.59788
Step 26530: loss = 0.88358
Step 26535: loss = 0.59492
Step 26540: loss = 0.52763
Step 26545: loss = 0.32477
Step 26550: loss = 0.71007
Step 26555: loss = 0.86719
Step 26560: loss = 0.40481
Step 26565: loss = 0.70574
Step 26570: loss = 0.69638
Step 26575: loss = 0.64015
Step 26580: loss = 0.44840
Step 26585: loss = 0.71763
Step 26590: loss = 0.56194
Step 26595: loss = 0.49653
Step 26600: loss = 0.61697
Step 26605: loss = 0.57404
Step 26610: loss = 0.53675
Step 26615: loss = 0.42151
Step 26620: loss = 0.55135
Step 26625: loss = 0.47424
Step 26630: loss = 0.77377
Step 26635: loss = 0.69467
Step 26640: loss = 0.70055
Step 26645: loss = 0.51549
Step 26650: loss = 0.64649
Step 26655: loss = 0.70265
Step 26660: loss = 0.61555
Step 26665: loss = 0.48514
Step 26670: loss = 0.52134
Step 26675: loss = 0.47455
Step 26680: loss = 0.74287
Step 26685: loss = 0.66813
Step 26690: loss = 0.75359
Step 26695: loss = 0.52388
Step 26700: loss = 0.68466
Step 26705: loss = 0.63361
Step 26710: loss = 0.58247
Step 26715: loss = 0.71190
Step 26720: loss = 0.52067
Step 26725: loss = 0.52454
Step 26730: loss = 0.32752
Step 26735: loss = 0.67144
Step 26740: loss = 0.48431
Step 26745: loss = 0.45036
Step 26750: loss = 0.49688
Step 26755: loss = 0.63207
Step 26760: loss = 0.39577
Step 26765: loss = 0.60975
Step 26770: loss = 0.70128
Step 26775: loss = 0.50544
Step 26780: loss = 0.51187
Step 26785: loss = 0.44711
Step 26790: loss = 0.32112
Step 26795: loss = 0.36539
Step 26800: loss = 0.59893
Step 26805: loss = 0.74428
Step 26810: loss = 0.36448
Step 26815: loss = 0.47024
Step 26820: loss = 0.52340
Step 26825: loss = 0.52702
Step 26830: loss = 0.68258
Step 26835: loss = 0.60963
Step 26840: loss = 0.46275
Step 26845: loss = 0.59843
Step 26850: loss = 0.63718
Step 26855: loss = 0.76694
Step 26860: loss = 0.76669
Step 26865: loss = 0.66924
Step 26870: loss = 0.55865
Step 26875: loss = 0.65497
Step 26880: loss = 0.60464
Step 26885: loss = 0.58855
Step 26890: loss = 0.29799
Step 26895: loss = 0.63715
Step 26900: loss = 0.70614
Step 26905: loss = 0.56601
Step 26910: loss = 0.60432
Step 26915: loss = 0.42657
Step 26920: loss = 0.57840
Step 26925: loss = 0.44129
Step 26930: loss = 0.46824
Step 26935: loss = 0.43513
Step 26940: loss = 0.87402
Step 26945: loss = 0.65328
Step 26950: loss = 0.48013
Step 26955: loss = 0.52309
Step 26960: loss = 0.66950
Step 26965: loss = 0.59237
Step 26970: loss = 0.74724
Step 26975: loss = 0.62031
Step 26980: loss = 0.43645
Step 26985: loss = 0.65230
Step 26990: loss = 0.54278
Step 26995: loss = 0.56261
Step 27000: loss = 0.37851
Training Data Eval:
  Num examples: 50000, Num correct: 40518, Precision @ 1: 0.8104
('Testing Data Eval: EPOCH->', 28)
  Num examples: 10000, Num correct: 6324, Precision @ 1: 0.6324
Step 27005: loss = 0.65999
Step 27010: loss = 0.33644
Step 27015: loss = 0.40556
Step 27020: loss = 0.50868
Step 27025: loss = 0.58451
Step 27030: loss = 0.40029
Step 27035: loss = 0.68800
Step 27040: loss = 0.58432
Step 27045: loss = 0.64719
Step 27050: loss = 0.56574
Step 27055: loss = 0.56523
Step 27060: loss = 0.72916
Step 27065: loss = 0.35280
Step 27070: loss = 0.69007
Step 27075: loss = 0.40601
Step 27080: loss = 0.60569
Step 27085: loss = 0.66866
Step 27090: loss = 0.49928
Step 27095: loss = 0.41816
Step 27100: loss = 0.75863
Step 27105: loss = 0.58092
Step 27110: loss = 0.53729
Step 27115: loss = 0.38035
Step 27120: loss = 0.32109
Step 27125: loss = 0.50426
Step 27130: loss = 0.27021
Step 27135: loss = 0.36927
Step 27140: loss = 0.44749
Step 27145: loss = 0.57491
Step 27150: loss = 0.59339
Step 27155: loss = 0.69082
Step 27160: loss = 0.45263
Step 27165: loss = 0.39052
Step 27170: loss = 0.47494
Step 27175: loss = 0.50309
Step 27180: loss = 0.50869
Step 27185: loss = 0.52084
Step 27190: loss = 0.53777
Step 27195: loss = 0.65181
Step 27200: loss = 0.52345
Step 27205: loss = 0.74634
Step 27210: loss = 0.62031
Step 27215: loss = 0.49379
Step 27220: loss = 0.84257
Step 27225: loss = 0.56909
Step 27230: loss = 0.62296
Step 27235: loss = 0.66443
Step 27240: loss = 0.48271
Step 27245: loss = 0.44232
Step 27250: loss = 0.46229
Step 27255: loss = 0.62532
Step 27260: loss = 0.42042
Step 27265: loss = 0.40780
Step 27270: loss = 0.57018
Step 27275: loss = 0.43916
Step 27280: loss = 0.34372
Step 27285: loss = 0.72407
Step 27290: loss = 0.41388
Step 27295: loss = 0.71789
Step 27300: loss = 0.33382
Step 27305: loss = 0.58170
Step 27310: loss = 0.57541
Step 27315: loss = 0.51197
Step 27320: loss = 0.73949
Step 27325: loss = 0.59068
Step 27330: loss = 0.58915
Step 27335: loss = 0.53703
Step 27340: loss = 0.50351
Step 27345: loss = 0.54082
Step 27350: loss = 0.48003
Step 27355: loss = 0.67376
Step 27360: loss = 0.70262
Step 27365: loss = 0.71392
Step 27370: loss = 0.41651
Step 27375: loss = 0.48547
Step 27380: loss = 0.64867
Step 27385: loss = 0.54608
Step 27390: loss = 0.72601
Step 27395: loss = 0.54030
Step 27400: loss = 0.52855
Step 27405: loss = 0.40070
Step 27410: loss = 0.39842
Step 27415: loss = 0.33472
Step 27420: loss = 0.57470
Step 27425: loss = 0.67059
Step 27430: loss = 0.52831
Step 27435: loss = 0.45521
Step 27440: loss = 0.53605
Step 27445: loss = 0.48877
Step 27450: loss = 0.54456
Step 27455: loss = 0.63364
Step 27460: loss = 0.59966
Step 27465: loss = 0.32376
Step 27470: loss = 0.87014
Step 27475: loss = 0.49701
Step 27480: loss = 0.68644
Step 27485: loss = 0.42962
Step 27490: loss = 0.59400
Step 27495: loss = 0.70393
Step 27500: loss = 0.87153
Step 27505: loss = 0.66903
Step 27510: loss = 0.43093
Step 27515: loss = 0.52122
Step 27520: loss = 0.27163
Step 27525: loss = 0.41331
Step 27530: loss = 0.64298
Step 27535: loss = 0.69322
Step 27540: loss = 0.63039
Step 27545: loss = 0.46039
Step 27550: loss = 0.61466
Step 27555: loss = 0.74867
Step 27560: loss = 0.86622
Step 27565: loss = 0.56378
Step 27570: loss = 0.44113
Step 27575: loss = 0.45828
Step 27580: loss = 0.63546
Step 27585: loss = 0.52108
Step 27590: loss = 0.52942
Step 27595: loss = 0.42837
Step 27600: loss = 0.68759
Step 27605: loss = 0.36317
Step 27610: loss = 0.56623
Step 27615: loss = 0.56548
Step 27620: loss = 0.38275
Step 27625: loss = 0.49253
Step 27630: loss = 0.31131
Step 27635: loss = 0.60436
Step 27640: loss = 0.59228
Step 27645: loss = 0.50469
Step 27650: loss = 0.34920
Step 27655: loss = 0.46824
Step 27660: loss = 0.52911
Step 27665: loss = 0.94870
Step 27670: loss = 0.72121
Step 27675: loss = 0.65287
Step 27680: loss = 0.71098
Step 27685: loss = 0.85070
Step 27690: loss = 0.84466
Step 27695: loss = 0.57023
Step 27700: loss = 1.10358
Step 27705: loss = 0.79222
Step 27710: loss = 0.50301
Step 27715: loss = 0.73742
Step 27720: loss = 1.16573
Step 27725: loss = 0.44947
Step 27730: loss = 0.56217
Step 27735: loss = 0.38915
Step 27740: loss = 0.35147
Step 27745: loss = 0.55384
Step 27750: loss = 0.75807
Step 27755: loss = 0.35334
Step 27760: loss = 0.61340
Step 27765: loss = 0.39086
Step 27770: loss = 0.57482
Step 27775: loss = 0.39331
Step 27780: loss = 0.67452
Step 27785: loss = 0.44104
Step 27790: loss = 0.52877
Step 27795: loss = 0.52223
Step 27800: loss = 0.71804
Step 27805: loss = 0.60497
Step 27810: loss = 0.55606
Step 27815: loss = 0.63837
Step 27820: loss = 0.55728
Step 27825: loss = 0.46164
Step 27830: loss = 0.58347
Step 27835: loss = 0.32037
Step 27840: loss = 0.40688
Step 27845: loss = 0.51723
Step 27850: loss = 0.45404
Step 27855: loss = 0.65520
Step 27860: loss = 0.62791
Step 27865: loss = 0.44751
Step 27870: loss = 0.70314
Step 27875: loss = 0.60883
Step 27880: loss = 0.84987
Step 27885: loss = 0.73833
Step 27890: loss = 0.69560
Step 27895: loss = 0.64050
Step 27900: loss = 0.53676
Step 27905: loss = 0.91870
Step 27910: loss = 0.79322
Step 27915: loss = 0.56395
Step 27920: loss = 0.53034
Step 27925: loss = 0.50084
Step 27930: loss = 0.63220
Step 27935: loss = 0.80656
Step 27940: loss = 0.87349
Step 27945: loss = 0.44997
Step 27950: loss = 0.47549
Step 27955: loss = 0.55795
Step 27960: loss = 0.54626
Step 27965: loss = 0.88725
Step 27970: loss = 0.46119
Step 27975: loss = 0.56462
Step 27980: loss = 0.58381
Step 27985: loss = 0.60303
Step 27990: loss = 0.53882
Step 27995: loss = 0.42972
Step 28000: loss = 0.24032
Training Data Eval:
  Num examples: 50000, Num correct: 40652, Precision @ 1: 0.8130
('Testing Data Eval: EPOCH->', 29)
  Num examples: 10000, Num correct: 6370, Precision @ 1: 0.6370
Step 28005: loss = 0.46236
Step 28010: loss = 0.55240
Step 28015: loss = 0.56135
Step 28020: loss = 0.93250
Step 28025: loss = 0.53501
Step 28030: loss = 0.42251
Step 28035: loss = 0.49955
Step 28040: loss = 0.37177
Step 28045: loss = 0.34584
Step 28050: loss = 0.31435
Step 28055: loss = 0.45463
Step 28060: loss = 0.38560
Step 28065: loss = 0.49451
Step 28070: loss = 0.61545
Step 28075: loss = 0.71687
Step 28080: loss = 0.44313
Step 28085: loss = 0.64624
Step 28090: loss = 0.41119
Step 28095: loss = 0.77550
Step 28100: loss = 0.51176
Step 28105: loss = 0.40263
Step 28110: loss = 0.52383
Step 28115: loss = 0.49841
Step 28120: loss = 0.79341
Step 28125: loss = 0.55555
Step 28130: loss = 0.48615
Step 28135: loss = 0.54685
Step 28140: loss = 0.52397
Step 28145: loss = 0.61364
Step 28150: loss = 0.35727
Step 28155: loss = 0.45890
Step 28160: loss = 0.80563
Step 28165: loss = 0.54745
Step 28170: loss = 0.40034
Step 28175: loss = 0.65633
Step 28180: loss = 0.64809
Step 28185: loss = 0.38902
Step 28190: loss = 0.29992
Step 28195: loss = 0.40234
Step 28200: loss = 0.53784
Step 28205: loss = 0.53411
Step 28210: loss = 0.39919
Step 28215: loss = 0.66635
Step 28220: loss = 0.46743
Step 28225: loss = 0.59813
Step 28230: loss = 0.68740
Step 28235: loss = 0.35114
Step 28240: loss = 0.43471
Step 28245: loss = 0.70385
Step 28250: loss = 0.53210
Step 28255: loss = 0.67525
Step 28260: loss = 0.51112
Step 28265: loss = 0.70137
Step 28270: loss = 0.23187
Step 28275: loss = 0.70208
Step 28280: loss = 0.78926
Step 28285: loss = 0.76899
Step 28290: loss = 0.68972
Step 28295: loss = 0.48517
Step 28300: loss = 0.71964
Step 28305: loss = 0.37662
Step 28310: loss = 0.58328
Step 28315: loss = 0.48423
Step 28320: loss = 0.98741
Step 28325: loss = 0.99506
Step 28330: loss = 0.51069
Step 28335: loss = 0.38528
Step 28340: loss = 0.45345
Step 28345: loss = 0.68923
Step 28350: loss = 0.65580
Step 28355: loss = 0.56526
Step 28360: loss = 0.58385
Step 28365: loss = 0.39771
Step 28370: loss = 0.62762
Step 28375: loss = 0.62283
Step 28380: loss = 0.70578
Step 28385: loss = 0.40197
Step 28390: loss = 0.64566
Step 28395: loss = 0.32715
Step 28400: loss = 0.61724
Step 28405: loss = 0.55324
Step 28410: loss = 0.54600
Step 28415: loss = 0.45384
Step 28420: loss = 0.58267
Step 28425: loss = 0.58689
Step 28430: loss = 0.70907
Step 28435: loss = 0.57926
Step 28440: loss = 0.48516
Step 28445: loss = 0.35795
Step 28450: loss = 0.89983
Step 28455: loss = 0.34685
Step 28460: loss = 0.50136
Step 28465: loss = 0.68956
Step 28470: loss = 0.34928
Step 28475: loss = 0.50519
Step 28480: loss = 0.63617
Step 28485: loss = 0.64930
Step 28490: loss = 0.44486
Step 28495: loss = 0.58627
Step 28500: loss = 0.57532
Step 28505: loss = 0.65016
Step 28510: loss = 0.62348
Step 28515: loss = 0.34446
Step 28520: loss = 0.60349
Step 28525: loss = 0.53913
Step 28530: loss = 0.55960
Step 28535: loss = 0.52981
Step 28540: loss = 0.55730
Step 28545: loss = 0.39664
Step 28550: loss = 0.99965
Step 28555: loss = 0.64721
Step 28560: loss = 0.42105
Step 28565: loss = 0.51656
Step 28570: loss = 0.46160
Step 28575: loss = 0.56848
Step 28580: loss = 0.53578
Step 28585: loss = 0.58106
Step 28590: loss = 0.54505
Step 28595: loss = 0.86746
Step 28600: loss = 0.69189
Step 28605: loss = 0.60851
Step 28610: loss = 0.54721
Step 28615: loss = 0.40605
Step 28620: loss = 0.68846
Step 28625: loss = 0.29440
Step 28630: loss = 0.31654
Step 28635: loss = 0.74796
Step 28640: loss = 0.60328
Step 28645: loss = 0.86055
Step 28650: loss = 0.55843
Step 28655: loss = 0.37613
Step 28660: loss = 0.46977
Step 28665: loss = 0.28696
Step 28670: loss = 0.65015
Step 28675: loss = 0.60320
Step 28680: loss = 0.56311
Step 28685: loss = 0.55232
Step 28690: loss = 0.60043
Step 28695: loss = 0.58251
Step 28700: loss = 0.51042
Step 28705: loss = 0.60631
Step 28710: loss = 0.50163
Step 28715: loss = 0.53664
Step 28720: loss = 0.51888
Step 28725: loss = 0.56485
Step 28730: loss = 0.40691
Step 28735: loss = 0.69975
Step 28740: loss = 0.51214
Step 28745: loss = 0.69578
Step 28750: loss = 0.56933
Step 28755: loss = 0.55587
Step 28760: loss = 0.47529
Step 28765: loss = 0.49842
Step 28770: loss = 0.75147
Step 28775: loss = 0.74722
Step 28780: loss = 0.26438
Step 28785: loss = 0.48656
Step 28790: loss = 0.64826
Step 28795: loss = 0.55133
Step 28800: loss = 0.51677
Step 28805: loss = 0.58464
Step 28810: loss = 0.56736
Step 28815: loss = 0.47584
Step 28820: loss = 0.46167
Step 28825: loss = 0.59623
Step 28830: loss = 0.53267
Step 28835: loss = 0.47178
Step 28840: loss = 0.41919
Step 28845: loss = 0.58546
Step 28850: loss = 0.42291
Step 28855: loss = 0.90465
Step 28860: loss = 0.54421
Step 28865: loss = 0.59173
Step 28870: loss = 0.74974
Step 28875: loss = 0.57333
Step 28880: loss = 0.45887
Step 28885: loss = 0.44888
Step 28890: loss = 0.94952
Step 28895: loss = 0.74130
Step 28900: loss = 0.57943
Step 28905: loss = 0.49238
Step 28910: loss = 0.39839
Step 28915: loss = 0.73325
Step 28920: loss = 0.73853
Step 28925: loss = 0.65723
Step 28930: loss = 0.67286
Step 28935: loss = 0.51269
Step 28940: loss = 0.42707
Step 28945: loss = 0.83850
Step 28950: loss = 0.64938
Step 28955: loss = 0.48105
Step 28960: loss = 0.58535
Step 28965: loss = 0.54383
Step 28970: loss = 0.64392
Step 28975: loss = 0.48771
Step 28980: loss = 0.40596
Step 28985: loss = 0.46514
Step 28990: loss = 0.50929
Step 28995: loss = 1.03148
Step 29000: loss = 0.70212
Training Data Eval:
  Num examples: 50000, Num correct: 40995, Precision @ 1: 0.8199
('Testing Data Eval: EPOCH->', 30)
  Num examples: 10000, Num correct: 6394, Precision @ 1: 0.6394
Step 29005: loss = 0.57529
Step 29010: loss = 0.54635
Step 29015: loss = 0.36648
Step 29020: loss = 0.40356
Step 29025: loss = 0.56812
Step 29030: loss = 0.46615
Step 29035: loss = 0.78441
Step 29040: loss = 0.45442
Step 29045: loss = 0.34379
Step 29050: loss = 0.44549
Step 29055: loss = 0.55152
Step 29060: loss = 0.45526
Step 29065: loss = 0.46534
Step 29070: loss = 0.34144
Step 29075: loss = 0.41270
Step 29080: loss = 0.59597
Step 29085: loss = 0.38214
Step 29090: loss = 0.66003
Step 29095: loss = 0.58592
Step 29100: loss = 0.55929
Step 29105: loss = 0.55702
Step 29110: loss = 0.61462
Step 29115: loss = 0.47386
Step 29120: loss = 0.47314
Step 29125: loss = 0.53020
Step 29130: loss = 0.37822
Step 29135: loss = 0.40628
Step 29140: loss = 0.30822
Step 29145: loss = 0.47892
Step 29150: loss = 1.01445
Step 29155: loss = 0.49934
Step 29160: loss = 0.57555
Step 29165: loss = 0.68345
Step 29170: loss = 0.91158
Step 29175: loss = 0.54400
Step 29180: loss = 0.82375
Step 29185: loss = 0.47111
Step 29190: loss = 0.62558
Step 29195: loss = 0.43894
Step 29200: loss = 0.35336
Step 29205: loss = 0.70750
Step 29210: loss = 0.66327
Step 29215: loss = 0.31114
Step 29220: loss = 0.62015
Step 29225: loss = 0.37127
Step 29230: loss = 0.43571
Step 29235: loss = 0.43170
Step 29240: loss = 0.60191
Step 29245: loss = 0.58463
Step 29250: loss = 0.79014
Step 29255: loss = 0.56728
Step 29260: loss = 0.27564
Step 29265: loss = 0.22815
Step 29270: loss = 0.27977
Step 29275: loss = 0.33681
Step 29280: loss = 0.33862
Step 29285: loss = 0.47017
Step 29290: loss = 0.35399
Step 29295: loss = 0.43568
Step 29300: loss = 0.55325
Step 29305: loss = 0.34030
Step 29310: loss = 0.50814
Step 29315: loss = 0.31612
Step 29320: loss = 0.42924
Step 29325: loss = 0.34357
Step 29330: loss = 0.72708
Step 29335: loss = 0.56728
Step 29340: loss = 0.56386
Step 29345: loss = 0.42333
Step 29350: loss = 0.65288
Step 29355: loss = 0.80482
Step 29360: loss = 0.68444
Step 29365: loss = 0.58709
Step 29370: loss = 0.55900
Step 29375: loss = 0.93385
Step 29380: loss = 0.63310
Step 29385: loss = 0.50725
Step 29390: loss = 0.26068
Step 29395: loss = 0.79528
Step 29400: loss = 0.79696
Step 29405: loss = 0.64647
Step 29410: loss = 0.58339
Step 29415: loss = 0.46567
Step 29420: loss = 0.47832
Step 29425: loss = 0.31032
Step 29430: loss = 0.69067
Step 29435: loss = 0.51796
Step 29440: loss = 0.47787
Step 29445: loss = 0.66346
Step 29450: loss = 0.41195
Step 29455: loss = 0.70408
Step 29460: loss = 0.43459
Step 29465: loss = 0.57198
Step 29470: loss = 0.49360
Step 29475: loss = 0.52246
Step 29480: loss = 0.45271
Step 29485: loss = 0.66386
Step 29490: loss = 0.50899
Step 29495: loss = 0.51734
Step 29500: loss = 0.61827
Step 29505: loss = 0.51718
Step 29510: loss = 0.63847
Step 29515: loss = 0.54216
Step 29520: loss = 0.39001
Step 29525: loss = 0.54459
Step 29530: loss = 0.55036
Step 29535: loss = 0.61056
Step 29540: loss = 0.61397
Step 29545: loss = 0.47411
Step 29550: loss = 0.64562
Step 29555: loss = 0.60493
Step 29560: loss = 0.54337
Step 29565: loss = 0.51287
Step 29570: loss = 0.65070
Step 29575: loss = 0.34119
Step 29580: loss = 0.41459
Step 29585: loss = 0.47128
Step 29590: loss = 0.66012
Step 29595: loss = 0.52160
Step 29600: loss = 0.39369
Step 29605: loss = 0.42702
Step 29610: loss = 0.39582
Step 29615: loss = 0.58186
Step 29620: loss = 0.55227
Step 29625: loss = 0.48047
Step 29630: loss = 0.39549
Step 29635: loss = 0.51708
Step 29640: loss = 0.38238
Step 29645: loss = 0.45849
Step 29650: loss = 0.51529
Step 29655: loss = 0.55214
Step 29660: loss = 0.70345
Step 29665: loss = 0.66752
Step 29670: loss = 0.56139
Step 29675: loss = 0.31948
Step 29680: loss = 0.69210
Step 29685: loss = 0.46627
Step 29690: loss = 0.49730
Step 29695: loss = 0.71090
Step 29700: loss = 0.57110
Step 29705: loss = 0.61668
Step 29710: loss = 0.41499
Step 29715: loss = 0.86224
Step 29720: loss = 0.51953
Step 29725: loss = 0.71772
Step 29730: loss = 0.42627
Step 29735: loss = 0.68436
Step 29740: loss = 0.47272
Step 29745: loss = 0.56228
Step 29750: loss = 0.39657
Step 29755: loss = 0.57465
Step 29760: loss = 0.79083
Step 29765: loss = 0.20960
Step 29770: loss = 0.72737
Step 29775: loss = 0.38910
Step 29780: loss = 0.50992
Step 29785: loss = 0.66121
Step 29790: loss = 0.53828
Step 29795: loss = 0.51826
Step 29800: loss = 0.74196
Step 29805: loss = 0.70177
Step 29810: loss = 0.66662
Step 29815: loss = 0.48466
Step 29820: loss = 0.48913
Step 29825: loss = 0.42091
Step 29830: loss = 0.55289
Step 29835: loss = 0.47585
Step 29840: loss = 0.53265
Step 29845: loss = 0.31083
Step 29850: loss = 0.43083
Step 29855: loss = 0.78088
Step 29860: loss = 0.50481
Step 29865: loss = 0.52493
Step 29870: loss = 0.72821
Step 29875: loss = 0.38943
Step 29880: loss = 0.51669
Step 29885: loss = 0.62696
Step 29890: loss = 0.44644
Step 29895: loss = 0.33460
Step 29900: loss = 0.39187
Step 29905: loss = 0.38980
Step 29910: loss = 0.36385
Step 29915: loss = 0.62447
Step 29920: loss = 0.53129
Step 29925: loss = 0.62217
Step 29930: loss = 0.41249
Step 29935: loss = 0.55485
Step 29940: loss = 0.62340
Step 29945: loss = 0.40456
Step 29950: loss = 0.72152
Step 29955: loss = 0.55293
Step 29960: loss = 0.74733
Step 29965: loss = 0.59197
Step 29970: loss = 0.50603
Step 29975: loss = 0.59221
Step 29980: loss = 0.32008
Step 29985: loss = 0.61403
Step 29990: loss = 0.53927
Step 29995: loss = 0.83742
Step 30000: loss = 0.28282
Training Data Eval:
  Num examples: 50000, Num correct: 41215, Precision @ 1: 0.8243
('Testing Data Eval: EPOCH->', 31)
  Num examples: 10000, Num correct: 6376, Precision @ 1: 0.6376
Step 30005: loss = 0.39047
Step 30010: loss = 0.50482
Step 30015: loss = 0.37368
Step 30020: loss = 0.49415
Step 30025: loss = 0.63160
Step 30030: loss = 0.47813
Step 30035: loss = 0.80937
Step 30040: loss = 0.71762
Step 30045: loss = 0.56009
Step 30050: loss = 0.33988
Step 30055: loss = 0.44915
Step 30060: loss = 0.44740
Step 30065: loss = 0.39610
Step 30070: loss = 0.77533
Step 30075: loss = 0.48681
Step 30080: loss = 0.55287
Step 30085: loss = 0.67012
Step 30090: loss = 0.54574
Step 30095: loss = 0.67437
Step 30100: loss = 0.52174
Step 30105: loss = 0.30742
Step 30110: loss = 0.27304
Step 30115: loss = 0.71942
Step 30120: loss = 0.48474
Step 30125: loss = 0.59125
Step 30130: loss = 0.42117
Step 30135: loss = 0.47489
Step 30140: loss = 0.49236
Step 30145: loss = 0.45061
Step 30150: loss = 0.54067
Step 30155: loss = 0.58888
Step 30160: loss = 0.67743
Step 30165: loss = 0.37622
Step 30170: loss = 0.19490
Step 30175: loss = 0.49494
Step 30180: loss = 0.36276
Step 30185: loss = 0.67017
Step 30190: loss = 0.48653
Step 30195: loss = 0.33609
Step 30200: loss = 0.54197
Step 30205: loss = 0.36915
Step 30210: loss = 0.65143
Step 30215: loss = 0.36539
Step 30220: loss = 0.46895
Step 30225: loss = 0.73082
Step 30230: loss = 0.43680
Step 30235: loss = 0.51027
Step 30240: loss = 0.59260
Step 30245: loss = 0.46360
Step 30250: loss = 0.45831
Step 30255: loss = 0.58031
Step 30260: loss = 0.45339
Step 30265: loss = 0.75656
Step 30270: loss = 0.19304
Step 30275: loss = 0.69135
Step 30280: loss = 0.49254
Step 30285: loss = 0.49225
Step 30290: loss = 0.79689
Step 30295: loss = 0.35142
Step 30300: loss = 0.57185
Step 30305: loss = 0.63061
Step 30310: loss = 0.78707
Step 30315: loss = 0.41732
Step 30320: loss = 0.54345
Step 30325: loss = 0.25756
Step 30330: loss = 0.53325
Step 30335: loss = 0.45594
Step 30340: loss = 0.97219
Step 30345: loss = 0.33988
Step 30350: loss = 0.42691
Step 30355: loss = 0.71375
Step 30360: loss = 0.74046
Step 30365: loss = 0.40943
Step 30370: loss = 0.65219
Step 30375: loss = 0.27352
Step 30380: loss = 0.57980
Step 30385: loss = 0.38463
Step 30390: loss = 0.43307
Step 30395: loss = 0.45125
Step 30400: loss = 0.45983
Step 30405: loss = 0.38970
Step 30410: loss = 0.34377
Step 30415: loss = 0.42367
Step 30420: loss = 0.52100
Step 30425: loss = 0.50604
Step 30430: loss = 0.36793
Step 30435: loss = 0.48132
Step 30440: loss = 0.38821
Step 30445: loss = 0.52039
Step 30450: loss = 0.44178
Step 30455: loss = 0.55365
Step 30460: loss = 0.69139
Step 30465: loss = 0.66461
Step 30470: loss = 0.46632
Step 30475: loss = 0.65406
Step 30480: loss = 0.42118
Step 30485: loss = 0.59837
Step 30490: loss = 0.65235
Step 30495: loss = 0.43161
Step 30500: loss = 0.41097
Step 30505: loss = 0.33554
Step 30510: loss = 0.51672
Step 30515: loss = 0.60490
Step 30520: loss = 0.69889
Step 30525: loss = 0.61039
Step 30530: loss = 0.53718
Step 30535: loss = 0.59596
Step 30540: loss = 0.53793
Step 30545: loss = 0.55508
Step 30550: loss = 0.51622
Step 30555: loss = 0.99640
Step 30560: loss = 0.39016
Step 30565: loss = 0.53714
Step 30570: loss = 0.91854
Step 30575: loss = 0.23314
Step 30580: loss = 0.39466
Step 30585: loss = 0.65530
Step 30590: loss = 0.41931
Step 30595: loss = 0.59518
Step 30600: loss = 0.50924
Step 30605: loss = 0.46470
Step 30610: loss = 0.77643
Step 30615: loss = 0.26200
Step 30620: loss = 0.58076
Step 30625: loss = 1.08180
Step 30630: loss = 0.42296
Step 30635: loss = 0.58529
Step 30640: loss = 0.68054
Step 30645: loss = 0.46130
Step 30650: loss = 0.64191
Step 30655: loss = 0.63250
Step 30660: loss = 0.48555
Step 30665: loss = 0.51911
Step 30670: loss = 0.32009
Step 30675: loss = 0.41591
Step 30680: loss = 0.47409
Step 30685: loss = 0.49532
Step 30690: loss = 0.85059
Step 30695: loss = 0.54436
Step 30700: loss = 0.38904
Step 30705: loss = 0.34996
Step 30710: loss = 0.47624
Step 30715: loss = 0.63620
Step 30720: loss = 0.69315
Step 30725: loss = 0.47792
Step 30730: loss = 0.54104
Step 30735: loss = 0.42187
Step 30740: loss = 0.30260
Step 30745: loss = 0.51370
Step 30750: loss = 0.42520
Step 30755: loss = 0.35408
Step 30760: loss = 0.40863
Step 30765: loss = 0.33955
Step 30770: loss = 0.62790
Step 30775: loss = 0.64804
Step 30780: loss = 0.64406
Step 30785: loss = 0.68258
Step 30790: loss = 0.40181
Step 30795: loss = 0.43659
Step 30800: loss = 0.46455
Step 30805: loss = 0.32262
Step 30810: loss = 0.85241
Step 30815: loss = 0.56561
Step 30820: loss = 0.66507
Step 30825: loss = 0.49721
Step 30830: loss = 0.27549
Step 30835: loss = 0.61457
Step 30840: loss = 0.46466
Step 30845: loss = 0.57919
Step 30850: loss = 0.54105
Step 30855: loss = 0.54209
Step 30860: loss = 0.46168
Step 30865: loss = 0.49754
Step 30870: loss = 0.42703
Step 30875: loss = 0.36836
Step 30880: loss = 0.57733
Step 30885: loss = 0.44666
Step 30890: loss = 0.31354
Step 30895: loss = 0.33091
Step 30900: loss = 0.57829
Step 30905: loss = 0.49960
Step 30910: loss = 0.55155
Step 30915: loss = 0.58500
Step 30920: loss = 0.54712
Step 30925: loss = 0.39606
Step 30930: loss = 0.54969
Step 30935: loss = 0.55157
Step 30940: loss = 0.51280
Step 30945: loss = 0.45611
Step 30950: loss = 0.42754
Step 30955: loss = 0.63227
Step 30960: loss = 0.37521
Step 30965: loss = 0.44370
Step 30970: loss = 0.35548
Step 30975: loss = 0.45191
Step 30980: loss = 0.35735
Step 30985: loss = 0.26706
Step 30990: loss = 0.38403
Step 30995: loss = 0.39699
Step 31000: loss = 0.65240
Training Data Eval:
  Num examples: 50000, Num correct: 41618, Precision @ 1: 0.8324
('Testing Data Eval: EPOCH->', 32)
  Num examples: 10000, Num correct: 6370, Precision @ 1: 0.6370
Step 31005: loss = 0.45122
Step 31010: loss = 0.34662
Step 31015: loss = 0.41500
Step 31020: loss = 0.40395
Step 31025: loss = 0.28352
Step 31030: loss = 0.44126
Step 31035: loss = 0.71452
Step 31040: loss = 0.42152
Step 31045: loss = 0.76092
Step 31050: loss = 0.45424
Step 31055: loss = 0.46466
Step 31060: loss = 0.44609
Step 31065: loss = 0.61675
Step 31070: loss = 0.76798
Step 31075: loss = 0.65657
Step 31080: loss = 0.43251
Step 31085: loss = 0.62909
Step 31090: loss = 0.29937
Step 31095: loss = 0.35554
Step 31100: loss = 0.58659
Step 31105: loss = 0.25860
Step 31110: loss = 0.41395
Step 31115: loss = 0.41922
Step 31120: loss = 0.65227
Step 31125: loss = 0.51100
Step 31130: loss = 0.70803
Step 31135: loss = 0.43844
Step 31140: loss = 0.48026
Step 31145: loss = 0.53472
Step 31150: loss = 0.53922
Step 31155: loss = 0.57186
Step 31160: loss = 0.59834
Step 31165: loss = 0.31356
Step 31170: loss = 0.30598
Step 31175: loss = 0.50186
Step 31180: loss = 0.45731
Step 31185: loss = 0.44336
Step 31190: loss = 0.48012
Step 31195: loss = 0.48085
Step 31200: loss = 0.41232
Step 31205: loss = 0.43016
Step 31210: loss = 0.32728
Step 31215: loss = 0.34331
Step 31220: loss = 0.68089
Step 31225: loss = 0.26502
Step 31230: loss = 0.37389
Step 31235: loss = 0.40479
Step 31240: loss = 0.48839
Step 31245: loss = 0.47553
Step 31250: loss = 0.34275
Step 31255: loss = 0.62903
Step 31260: loss = 0.63000
Step 31265: loss = 0.53633
Step 31270: loss = 0.61199
Step 31275: loss = 0.67659
Step 31280: loss = 0.45370
Step 31285: loss = 0.50081
Step 31290: loss = 0.66591
Step 31295: loss = 0.51838
Step 31300: loss = 0.61495
Step 31305: loss = 0.38149
Step 31310: loss = 0.31644
Step 31315: loss = 0.34395
Step 31320: loss = 0.71048
Step 31325: loss = 0.42445
Step 31330: loss = 0.65740
Step 31335: loss = 0.36366
Step 31340: loss = 0.48381
Step 31345: loss = 0.36878
Step 31350: loss = 0.62231
Step 31355: loss = 0.72385
Step 31360: loss = 0.42421
Step 31365: loss = 0.34038
Step 31370: loss = 0.60741
Step 31375: loss = 0.54582
Step 31380: loss = 0.42196
Step 31385: loss = 0.59162
Step 31390: loss = 0.39398
Step 31395: loss = 0.45794
Step 31400: loss = 0.49742
Step 31405: loss = 0.42578
Step 31410: loss = 0.61133
Step 31415: loss = 0.40613
Step 31420: loss = 0.43452
Step 31425: loss = 0.73389
Step 31430: loss = 0.45357
Step 31435: loss = 0.41862
Step 31440: loss = 0.57584
Step 31445: loss = 0.69227
Step 31450: loss = 0.68863
Step 31455: loss = 0.44714
Step 31460: loss = 0.36615
Step 31465: loss = 0.56930
Step 31470: loss = 0.42394
Step 31475: loss = 0.25092
Step 31480: loss = 0.36849
Step 31485: loss = 0.19877
Step 31490: loss = 0.49730
Step 31495: loss = 0.41472
Step 31500: loss = 0.36016
Step 31505: loss = 0.47119
Step 31510: loss = 0.41684
Step 31515: loss = 0.53664
Step 31520: loss = 0.67331
Step 31525: loss = 0.39477
Step 31530: loss = 0.63610
Step 31535: loss = 0.43768
Step 31540: loss = 0.47761
Step 31545: loss = 0.77691
Step 31550: loss = 0.54848
Step 31555: loss = 0.35522
Step 31560: loss = 0.69418
Step 31565: loss = 0.50869
Step 31570: loss = 0.41738
Step 31575: loss = 0.44409
Step 31580: loss = 0.50608
Step 31585: loss = 0.48558
Step 31590: loss = 0.44749
Step 31595: loss = 0.46207
Step 31600: loss = 0.46352
Step 31605: loss = 0.44133
Step 31610: loss = 0.39227
Step 31615: loss = 0.77902
Step 31620: loss = 0.59231
Step 31625: loss = 0.41526
Step 31630: loss = 0.51694
Step 31635: loss = 0.52285
Step 31640: loss = 0.62505
Step 31645: loss = 0.48777
Step 31650: loss = 0.62321
Step 31655: loss = 0.59964
Step 31660: loss = 0.40198
Step 31665: loss = 0.41869
Step 31670: loss = 0.39714
Step 31675: loss = 0.43636
Step 31680: loss = 0.64801
Step 31685: loss = 0.29595
Step 31690: loss = 0.36799
Step 31695: loss = 0.39912
Step 31700: loss = 0.72581
Step 31705: loss = 0.81971
Step 31710: loss = 0.42654
Step 31715: loss = 0.45277
Step 31720: loss = 0.31136
Step 31725: loss = 0.48180
Step 31730: loss = 0.68675
Step 31735: loss = 0.55867
Step 31740: loss = 0.67420
Step 31745: loss = 0.67761
Step 31750: loss = 0.41002
Step 31755: loss = 0.72162
Step 31760: loss = 0.54350
Step 31765: loss = 0.36110
Step 31770: loss = 0.42760
Step 31775: loss = 0.67162
Step 31780: loss = 0.36610
Step 31785: loss = 0.38826
Step 31790: loss = 0.73115
Step 31795: loss = 0.57146
Step 31800: loss = 0.51598
Step 31805: loss = 0.71023
Step 31810: loss = 0.28716
Step 31815: loss = 0.49195
Step 31820: loss = 0.44329
Step 31825: loss = 0.17079
Step 31830: loss = 0.58291
Step 31835: loss = 0.44147
Step 31840: loss = 0.48461
Step 31845: loss = 0.58733
Step 31850: loss = 0.40617
Step 31855: loss = 0.51069
Step 31860: loss = 0.65583
Step 31865: loss = 0.48444
Step 31870: loss = 0.49741
Step 31875: loss = 0.31051
Step 31880: loss = 0.56565
Step 31885: loss = 0.42232
Step 31890: loss = 0.61635
Step 31895: loss = 0.52919
Step 31900: loss = 0.39369
Step 31905: loss = 0.26318
Step 31910: loss = 0.63274
Step 31915: loss = 0.49855
Step 31920: loss = 1.03033
Step 31925: loss = 0.73740
Step 31930: loss = 0.33123
Step 31935: loss = 0.67720
Step 31940: loss = 0.40936
Step 31945: loss = 0.58558
Step 31950: loss = 0.67853
Step 31955: loss = 0.36131
Step 31960: loss = 0.54460
Step 31965: loss = 0.22779
Step 31970: loss = 0.55756
Step 31975: loss = 0.46081
Step 31980: loss = 0.55242
Step 31985: loss = 0.51681
Step 31990: loss = 0.63812
Step 31995: loss = 0.43698
Step 32000: loss = 0.57266
Training Data Eval:
  Num examples: 50000, Num correct: 42032, Precision @ 1: 0.8406
('Testing Data Eval: EPOCH->', 33)
  Num examples: 10000, Num correct: 6398, Precision @ 1: 0.6398
Step 32005: loss = 0.56083
Step 32010: loss = 0.66288
Step 32015: loss = 0.44059
Step 32020: loss = 0.33372
Step 32025: loss = 0.45378
Step 32030: loss = 0.54515
Step 32035: loss = 0.40516
Step 32040: loss = 0.23167
Step 32045: loss = 0.53116
Step 32050: loss = 0.27531
Step 32055: loss = 0.58048
Step 32060: loss = 0.58970
Step 32065: loss = 0.31935
Step 32070: loss = 0.45776
Step 32075: loss = 0.44321
Step 32080: loss = 0.72853
Step 32085: loss = 0.59248
Step 32090: loss = 0.31505
Step 32095: loss = 0.56599
Step 32100: loss = 0.40022
Step 32105: loss = 0.58616
Step 32110: loss = 0.48512
Step 32115: loss = 0.68710
Step 32120: loss = 0.52563
Step 32125: loss = 0.45502
Step 32130: loss = 0.49027
Step 32135: loss = 0.46236
Step 32140: loss = 0.41051
Step 32145: loss = 0.53072
Step 32150: loss = 0.48721
Step 32155: loss = 0.40155
Step 32160: loss = 0.31161
Step 32165: loss = 0.56733
Step 32170: loss = 0.50903
Step 32175: loss = 0.56290
Step 32180: loss = 0.65992
Step 32185: loss = 0.48119
Step 32190: loss = 0.41777
Step 32195: loss = 0.49495
Step 32200: loss = 0.33387
Step 32205: loss = 0.60731
Step 32210: loss = 0.37378
Step 32215: loss = 0.57691
Step 32220: loss = 0.81778
Step 32225: loss = 0.54802
Step 32230: loss = 0.52094
Step 32235: loss = 0.73557
Step 32240: loss = 0.74282
Step 32245: loss = 0.65354
Step 32250: loss = 0.33081
Step 32255: loss = 0.63284
Step 32260: loss = 0.74425
Step 32265: loss = 0.42521
Step 32270: loss = 0.57571
Step 32275: loss = 0.51629
Step 32280: loss = 0.38942
Step 32285: loss = 0.64306
Step 32290: loss = 0.53465
Step 32295: loss = 0.51408
Step 32300: loss = 0.35917
Step 32305: loss = 0.43767
Step 32310: loss = 0.42689
Step 32315: loss = 0.52730
Step 32320: loss = 0.53067
Step 32325: loss = 0.80499
Step 32330: loss = 0.44977
Step 32335: loss = 0.63945
Step 32340: loss = 0.47958
Step 32345: loss = 0.39745
Step 32350: loss = 0.51229
Step 32355: loss = 0.66088
Step 32360: loss = 0.38848
Step 32365: loss = 0.33259
Step 32370: loss = 0.46964
Step 32375: loss = 0.44664
Step 32380: loss = 0.48376
Step 32385: loss = 0.38758
Step 32390: loss = 0.38210
Step 32395: loss = 0.42884
Step 32400: loss = 0.49392
Step 32405: loss = 0.37932
Step 32410: loss = 0.68095
Step 32415: loss = 0.47810
Step 32420: loss = 0.53755
Step 32425: loss = 0.73052
Step 32430: loss = 0.36580
Step 32435: loss = 0.39791
Step 32440: loss = 0.27928
Step 32445: loss = 0.55996
Step 32450: loss = 0.33854
Step 32455: loss = 0.75018
Step 32460: loss = 0.35808
Step 32465: loss = 0.44162
Step 32470: loss = 0.62668
Step 32475: loss = 0.41904
Step 32480: loss = 0.51328
Step 32485: loss = 0.56572
Step 32490: loss = 0.63432
Step 32495: loss = 0.39186
Step 32500: loss = 0.41229
Step 32505: loss = 0.62980
Step 32510: loss = 0.38358
Step 32515: loss = 0.50948
Step 32520: loss = 0.60843
Step 32525: loss = 0.54051
Step 32530: loss = 0.54809
Step 32535: loss = 0.71192
Step 32540: loss = 0.39938
Step 32545: loss = 0.68604
Step 32550: loss = 0.79015
Step 32555: loss = 0.36441
Step 32560: loss = 0.53505
Step 32565: loss = 0.39278
Step 32570: loss = 0.66946
Step 32575: loss = 0.53294
Step 32580: loss = 0.25923
Step 32585: loss = 0.33945
Step 32590: loss = 0.51197
Step 32595: loss = 0.42036
Step 32600: loss = 0.39885
Step 32605: loss = 0.59096
Step 32610: loss = 0.69705
Step 32615: loss = 0.45422
Step 32620: loss = 0.64805
Step 32625: loss = 0.78795
Step 32630: loss = 0.35533
Step 32635: loss = 0.57197
Step 32640: loss = 0.59611
Step 32645: loss = 0.64702
Step 32650: loss = 0.56817
Step 32655: loss = 0.49465
Step 32660: loss = 0.52507
Step 32665: loss = 0.49263
Step 32670: loss = 1.06227
Step 32675: loss = 0.57814
Step 32680: loss = 0.47580
Step 32685: loss = 0.59337
Step 32690: loss = 0.51757
Step 32695: loss = 0.55354
Step 32700: loss = 0.54418
Step 32705: loss = 0.53242
Step 32710: loss = 0.43081
Step 32715: loss = 0.62645
Step 32720: loss = 0.33183
Step 32725: loss = 0.59643
Step 32730: loss = 0.43157
Step 32735: loss = 0.49081
Step 32740: loss = 0.55673
Step 32745: loss = 0.17152
Step 32750: loss = 0.57389
Step 32755: loss = 0.52425
Step 32760: loss = 0.40225
Step 32765: loss = 0.42062
Step 32770: loss = 0.38588
Step 32775: loss = 0.51207
Step 32780: loss = 0.64239
Step 32785: loss = 0.52158
Step 32790: loss = 0.37905
Step 32795: loss = 0.84765
Step 32800: loss = 0.52636
Step 32805: loss = 0.61486
Step 32810: loss = 0.49250
Step 32815: loss = 0.40544
Step 32820: loss = 0.40896
Step 32825: loss = 0.46210
Step 32830: loss = 0.63186
Step 32835: loss = 0.41413
Step 32840: loss = 0.59923
Step 32845: loss = 0.49421
Step 32850: loss = 0.56343
Step 32855: loss = 0.39451
Step 32860: loss = 0.27221
Step 32865: loss = 0.59130
Step 32870: loss = 0.75746
Step 32875: loss = 0.22420
Step 32880: loss = 0.32898
Step 32885: loss = 0.59554
Step 32890: loss = 0.75619
Step 32895: loss = 0.53542
Step 32900: loss = 0.43261
Step 32905: loss = 0.42348
Step 32910: loss = 0.63084
Step 32915: loss = 0.57861
Step 32920: loss = 0.42356
Step 32925: loss = 0.44130
Step 32930: loss = 0.48981
Step 32935: loss = 0.47903
Step 32940: loss = 0.43107
Step 32945: loss = 0.51398
Step 32950: loss = 0.35063
Step 32955: loss = 0.63741
Step 32960: loss = 0.42829
Step 32965: loss = 0.35854
Step 32970: loss = 0.38463
Step 32975: loss = 0.54911
Step 32980: loss = 0.56977
Step 32985: loss = 0.40419
Step 32990: loss = 0.32081
Step 32995: loss = 0.29313
Step 33000: loss = 0.31303
Training Data Eval:
  Num examples: 50000, Num correct: 42172, Precision @ 1: 0.8434
('Testing Data Eval: EPOCH->', 34)
  Num examples: 10000, Num correct: 6436, Precision @ 1: 0.6436
Step 33005: loss = 0.44380
Step 33010: loss = 0.44006
Step 33015: loss = 0.36819
Step 33020: loss = 0.27000
Step 33025: loss = 0.50500
Step 33030: loss = 0.65140
Step 33035: loss = 0.34261
Step 33040: loss = 0.26490
Step 33045: loss = 0.40415
Step 33050: loss = 0.48200
Step 33055: loss = 0.59239
Step 33060: loss = 0.61618
Step 33065: loss = 0.53607
Step 33070: loss = 0.60210
Step 33075: loss = 0.53878
Step 33080: loss = 0.22689
Step 33085: loss = 0.26412
Step 33090: loss = 0.41032
Step 33095: loss = 0.35859
Step 33100: loss = 0.36106
Step 33105: loss = 0.72781
Step 33110: loss = 0.24486
Step 33115: loss = 0.32291
Step 33120: loss = 0.45766
Step 33125: loss = 0.68360
Step 33130: loss = 0.35029
Step 33135: loss = 0.53258
Step 33140: loss = 0.57255
Step 33145: loss = 0.56040
Step 33150: loss = 0.50855
Step 33155: loss = 0.54232
Step 33160: loss = 0.46062
Step 33165: loss = 0.48713
Step 33170: loss = 0.38613
Step 33175: loss = 0.34904
Step 33180: loss = 0.47508
Step 33185: loss = 0.77240
Step 33190: loss = 0.54396
Step 33195: loss = 0.73555
Step 33200: loss = 0.42624
Step 33205: loss = 0.37557
Step 33210: loss = 0.74281
Step 33215: loss = 0.67100
Step 33220: loss = 0.59585
Step 33225: loss = 0.34213
Step 33230: loss = 0.65534
Step 33235: loss = 0.35821
Step 33240: loss = 0.36060
Step 33245: loss = 0.28845
Step 33250: loss = 0.56560
Step 33255: loss = 0.50931
Step 33260: loss = 0.49096
Step 33265: loss = 0.34497
Step 33270: loss = 0.38596
Step 33275: loss = 0.44924
Step 33280: loss = 0.77992
Step 33285: loss = 0.64093
Step 33290: loss = 0.56637
Step 33295: loss = 0.50740
Step 33300: loss = 0.46200
Step 33305: loss = 0.28433
Step 33310: loss = 0.24520
Step 33315: loss = 0.53519
Step 33320: loss = 0.34792
Step 33325: loss = 0.34760
Step 33330: loss = 0.23975
Step 33335: loss = 0.40670
Step 33340: loss = 0.71237
Step 33345: loss = 0.39557
Step 33350: loss = 0.47570
Step 33355: loss = 0.25566
Step 33360: loss = 0.56946
Step 33365: loss = 0.71533
Step 33370: loss = 0.68367
Step 33375: loss = 0.72497
Step 33380: loss = 0.58307
Step 33385: loss = 0.34737
Step 33390: loss = 0.60821
Step 33395: loss = 0.30128
Step 33400: loss = 0.44455
Step 33405: loss = 0.29609
Step 33410: loss = 0.49624
Step 33415: loss = 0.60315
Step 33420: loss = 0.53858
Step 33425: loss = 0.30341
Step 33430: loss = 0.40580
Step 33435: loss = 0.40683
Step 33440: loss = 0.34700
Step 33445: loss = 0.40118
Step 33450: loss = 0.38785
Step 33455: loss = 0.27790
Step 33460: loss = 0.34836
Step 33465: loss = 0.71688
Step 33470: loss = 0.44140
Step 33475: loss = 0.39624
Step 33480: loss = 0.32956
Step 33485: loss = 0.53368
Step 33490: loss = 0.61076
Step 33495: loss = 0.54822
Step 33500: loss = 0.28926
Step 33505: loss = 0.55892
Step 33510: loss = 0.40010
Step 33515: loss = 0.30855
Step 33520: loss = 0.79465
Step 33525: loss = 0.44206
Step 33530: loss = 0.55636
Step 33535: loss = 0.47562
Step 33540: loss = 0.44663
Step 33545: loss = 0.60352
Step 33550: loss = 0.42797
Step 33555: loss = 0.60006
Step 33560: loss = 0.45792
Step 33565: loss = 0.43135
Step 33570: loss = 0.42142
Step 33575: loss = 0.30825
Step 33580: loss = 0.29648
Step 33585: loss = 0.31304
Step 33590: loss = 0.44355
Step 33595: loss = 0.49043
Step 33600: loss = 0.39071
Step 33605: loss = 0.45504
Step 33610: loss = 0.55151
Step 33615: loss = 0.49043
Step 33620: loss = 0.27223
Step 33625: loss = 0.58085
Step 33630: loss = 0.59118
Step 33635: loss = 0.55595
Step 33640: loss = 0.34388
Step 33645: loss = 0.54834
Step 33650: loss = 0.49805
Step 33655: loss = 0.54820
Step 33660: loss = 0.40331
Step 33665: loss = 0.42612
Step 33670: loss = 0.54789
Step 33675: loss = 0.49969
Step 33680: loss = 0.49996
Step 33685: loss = 0.30161
Step 33690: loss = 0.33733
Step 33695: loss = 0.68150
Step 33700: loss = 0.31477
Step 33705: loss = 0.33051
Step 33710: loss = 0.45434
Step 33715: loss = 0.44325
Step 33720: loss = 0.64252
Step 33725: loss = 0.59241
Step 33730: loss = 0.31832
Step 33735: loss = 0.39387
Step 33740: loss = 0.32227
Step 33745: loss = 0.43719
Step 33750: loss = 0.74256
Step 33755: loss = 0.65206
Step 33760: loss = 0.88340
Step 33765: loss = 0.29011
Step 33770: loss = 0.30658
Step 33775: loss = 0.32337
Step 33780: loss = 0.44689
Step 33785: loss = 0.78777
Step 33790: loss = 0.40913
Step 33795: loss = 0.43080
Step 33800: loss = 0.40423
Step 33805: loss = 0.63401
Step 33810: loss = 0.63044
Step 33815: loss = 0.70640
Step 33820: loss = 0.36169
Step 33825: loss = 0.67075
Step 33830: loss = 0.59359
Step 33835: loss = 0.44865
Step 33840: loss = 0.45212
Step 33845: loss = 0.42380
Step 33850: loss = 0.72602
Step 33855: loss = 0.41975
Step 33860: loss = 0.37080
Step 33865: loss = 0.63455
Step 33870: loss = 0.41475
Step 33875: loss = 0.42280
Step 33880: loss = 0.44206
Step 33885: loss = 0.32564
Step 33890: loss = 0.46215
Step 33895: loss = 0.43804
Step 33900: loss = 0.57031
Step 33905: loss = 0.29033
Step 33910: loss = 0.61536
Step 33915: loss = 0.59336
Step 33920: loss = 0.37904
Step 33925: loss = 0.48020
Step 33930: loss = 0.48476
Step 33935: loss = 0.43653
Step 33940: loss = 0.55203
Step 33945: loss = 0.19632
Step 33950: loss = 0.38449
Step 33955: loss = 0.49052
Step 33960: loss = 0.57461
Step 33965: loss = 0.55345
Step 33970: loss = 0.32507
Step 33975: loss = 0.22941
Step 33980: loss = 0.49305
Step 33985: loss = 0.20430
Step 33990: loss = 0.43635
Step 33995: loss = 0.47456
Step 34000: loss = 0.39878
Training Data Eval:
  Num examples: 50000, Num correct: 42357, Precision @ 1: 0.8471
('Testing Data Eval: EPOCH->', 35)
  Num examples: 10000, Num correct: 6337, Precision @ 1: 0.6337
Step 34005: loss = 0.52307
Step 34010: loss = 0.46796
Step 34015: loss = 0.56486
Step 34020: loss = 0.24212
Step 34025: loss = 0.53452
Step 34030: loss = 0.41120
Step 34035: loss = 0.35247
Step 34040: loss = 0.32551
Step 34045: loss = 0.31542
Step 34050: loss = 0.32475
Step 34055: loss = 0.48597
Step 34060: loss = 0.47456
Step 34065: loss = 0.34444
Step 34070: loss = 0.50454
Step 34075: loss = 0.35541
Step 34080: loss = 0.58784
Step 34085: loss = 0.53315
Step 34090: loss = 0.67906
Step 34095: loss = 0.49424
Step 34100: loss = 0.62824
Step 34105: loss = 0.41411
Step 34110: loss = 0.56287
Step 34115: loss = 0.50162
Step 34120: loss = 0.65551
Step 34125: loss = 0.56686
Step 34130: loss = 0.41575
Step 34135: loss = 0.46164
Step 34140: loss = 0.40981
Step 34145: loss = 0.38967
Step 34150: loss = 0.22653
Step 34155: loss = 0.28993
Step 34160: loss = 0.55498
Step 34165: loss = 0.30313
Step 34170: loss = 0.34541
Step 34175: loss = 0.58024
Step 34180: loss = 0.45356
Step 34185: loss = 0.55260
Step 34190: loss = 0.54374
Step 34195: loss = 0.42955
Step 34200: loss = 0.90281
Step 34205: loss = 0.45615
Step 34210: loss = 0.47760
Step 34215: loss = 0.47819
Step 34220: loss = 0.39340
Step 34225: loss = 0.48476
Step 34230: loss = 0.60396
Step 34235: loss = 0.57663
Step 34240: loss = 0.24968
Step 34245: loss = 0.36349
Step 34250: loss = 0.39522
Step 34255: loss = 0.46185
Step 34260: loss = 0.60992
Step 34265: loss = 0.71575
Step 34270: loss = 0.66281
Step 34275: loss = 0.29063
Step 34280: loss = 0.36431
Step 34285: loss = 0.43251
Step 34290: loss = 0.43148
Step 34295: loss = 0.44570
Step 34300: loss = 0.49928
Step 34305: loss = 0.47120
Step 34310: loss = 0.32120
Step 34315: loss = 0.56261
Step 34320: loss = 0.31453
Step 34325: loss = 0.40453
Step 34330: loss = 0.39925
Step 34335: loss = 0.44332
Step 34340: loss = 0.37674
Step 34345: loss = 0.35163
Step 34350: loss = 0.34603
Step 34355: loss = 0.32314
Step 34360: loss = 0.38816
Step 34365: loss = 0.50802
Step 34370: loss = 0.29517
Step 34375: loss = 0.36899
Step 34380: loss = 0.40645
Step 34385: loss = 0.37346
Step 34390: loss = 0.37074
Step 34395: loss = 0.63432
Step 34400: loss = 0.46492
Step 34405: loss = 0.55259
Step 34410: loss = 0.56839
Step 34415: loss = 0.67511
Step 34420: loss = 0.52657
Step 34425: loss = 0.35624
Step 34430: loss = 0.28069
Step 34435: loss = 0.55975
Step 34440: loss = 0.41169
Step 34445: loss = 0.44884
Step 34450: loss = 0.40312
Step 34455: loss = 0.39395
Step 34460: loss = 0.34981
Step 34465: loss = 0.57659
Step 34470: loss = 0.43422
Step 34475: loss = 0.43330
Step 34480: loss = 0.41306
Step 34485: loss = 0.63941
Step 34490: loss = 0.32328
Step 34495: loss = 0.40441
Step 34500: loss = 0.29727
Step 34505: loss = 0.42021
Step 34510: loss = 0.62506
Step 34515: loss = 0.57462
Step 34520: loss = 0.70032
Step 34525: loss = 0.48608
Step 34530: loss = 0.27736
Step 34535: loss = 0.60086
Step 34540: loss = 0.25127
Step 34545: loss = 0.43685
Step 34550: loss = 0.34941
Step 34555: loss = 0.24615
Step 34560: loss = 0.72215
Step 34565: loss = 0.51342
Step 34570: loss = 0.62444
Step 34575: loss = 0.43721
Step 34580: loss = 0.40282
Step 34585: loss = 0.49178
Step 34590: loss = 0.75534
Step 34595: loss = 0.37605
Step 34600: loss = 0.39538
Step 34605: loss = 0.57463
Step 34610: loss = 0.48045
Step 34615: loss = 0.67889
Step 34620: loss = 0.84146
Step 34625: loss = 0.38655
Step 34630: loss = 0.34222
Step 34635: loss = 0.31745
Step 34640: loss = 0.51832
Step 34645: loss = 0.44870
Step 34650: loss = 0.47530
Step 34655: loss = 0.50715
Step 34660: loss = 0.71821
Step 34665: loss = 0.32117
Step 34670: loss = 0.61511
Step 34675: loss = 0.46900
Step 34680: loss = 0.35035
Step 34685: loss = 0.64820
Step 34690: loss = 0.47036
Step 34695: loss = 0.69260
Step 34700: loss = 0.52767
Step 34705: loss = 0.47024
Step 34710: loss = 0.38631
Step 34715: loss = 0.51086
Step 34720: loss = 0.63860
Step 34725: loss = 0.36836
Step 34730: loss = 0.48187
Step 34735: loss = 0.50271
Step 34740: loss = 0.37437
Step 34745: loss = 0.25323
Step 34750: loss = 0.36816
Step 34755: loss = 0.27909
Step 34760: loss = 0.60726
Step 34765: loss = 0.51409
Step 34770: loss = 0.47365
Step 34775: loss = 0.67459
Step 34780: loss = 0.53452
Step 34785: loss = 0.69278
Step 34790: loss = 0.42256
Step 34795: loss = 0.61892
Step 34800: loss = 0.24496
Step 34805: loss = 0.62405
Step 34810: loss = 0.35877
Step 34815: loss = 0.38852
Step 34820: loss = 0.25828
Step 34825: loss = 0.32629
Step 34830: loss = 0.68446
Step 34835: loss = 0.59318
Step 34840: loss = 0.57773
Step 34845: loss = 0.42308
Step 34850: loss = 0.51982
Step 34855: loss = 0.65225
Step 34860: loss = 0.33937
Step 34865: loss = 0.30003
Step 34870: loss = 0.39685
Step 34875: loss = 0.50730
Step 34880: loss = 0.37789
Step 34885: loss = 0.38319
Step 34890: loss = 0.52461
Step 34895: loss = 0.42294
Step 34900: loss = 0.48366
Step 34905: loss = 0.53587
Step 34910: loss = 0.39312
Step 34915: loss = 0.33313
Step 34920: loss = 0.46210
Step 34925: loss = 0.45014
Step 34930: loss = 0.63172
Step 34935: loss = 0.48018
Step 34940: loss = 0.36152
Step 34945: loss = 0.43588
Step 34950: loss = 0.58703
Step 34955: loss = 0.53076
Step 34960: loss = 0.48730
Step 34965: loss = 0.25756
Step 34970: loss = 0.29861
Step 34975: loss = 0.40621
Step 34980: loss = 0.61092
Step 34985: loss = 0.61000
Step 34990: loss = 0.30412
Step 34995: loss = 0.41871
Step 35000: loss = 0.34889
Training Data Eval:
  Num examples: 50000, Num correct: 42098, Precision @ 1: 0.8420
('Testing Data Eval: EPOCH->', 36)
  Num examples: 10000, Num correct: 6353, Precision @ 1: 0.6353
Step 35005: loss = 0.45533
Step 35010: loss = 0.26776
Step 35015: loss = 0.43644
Step 35020: loss = 0.33457
Step 35025: loss = 0.54923
Step 35030: loss = 0.38124
Step 35035: loss = 0.41139
Step 35040: loss = 0.48545
Step 35045: loss = 0.63838
Step 35050: loss = 0.35929
Step 35055: loss = 0.81699
Step 35060: loss = 0.66595
Step 35065: loss = 0.46480
Step 35070: loss = 0.52124
Step 35075: loss = 0.41141
Step 35080: loss = 0.39312
Step 35085: loss = 0.33373
Step 35090: loss = 0.43699
Step 35095: loss = 0.48883
Step 35100: loss = 0.38357
Step 35105: loss = 0.34043
Step 35110: loss = 0.49425
Step 35115: loss = 0.33770
Step 35120: loss = 0.62004
Step 35125: loss = 0.39901
Step 35130: loss = 0.29393
Step 35135: loss = 0.57092
Step 35140: loss = 0.68581
Step 35145: loss = 0.44639
Step 35150: loss = 0.27333
Step 35155: loss = 0.67187
Step 35160: loss = 0.31517
Step 35165: loss = 0.26011
Step 35170: loss = 0.50378
Step 35175: loss = 0.18526
Step 35180: loss = 0.31872
Step 35185: loss = 0.38117
Step 35190: loss = 0.59872
Step 35195: loss = 0.30979
Step 35200: loss = 0.34934
Step 35205: loss = 0.68352
Step 35210: loss = 0.54820
Step 35215: loss = 0.42827
Step 35220: loss = 0.59393
Step 35225: loss = 0.42018
Step 35230: loss = 0.39726
Step 35235: loss = 0.43066
Step 35240: loss = 0.71771
Step 35245: loss = 0.62318
Step 35250: loss = 0.42128
Step 35255: loss = 0.40202
Step 35260: loss = 0.21752
Step 35265: loss = 0.58460
Step 35270: loss = 0.50303
Step 35275: loss = 0.33711
Step 35280: loss = 0.74142
Step 35285: loss = 0.74195
Step 35290: loss = 0.51424
Step 35295: loss = 0.58993
Step 35300: loss = 0.53694
Step 35305: loss = 0.41615
Step 35310: loss = 0.64606
Step 35315: loss = 0.24227
Step 35320: loss = 0.72390
Step 35325: loss = 0.30838
Step 35330: loss = 0.37567
Step 35335: loss = 0.36837
Step 35340: loss = 0.30734
Step 35345: loss = 0.52896
Step 35350: loss = 0.27734
Step 35355: loss = 0.37873
Step 35360: loss = 0.55495
Step 35365: loss = 0.79184
Step 35370: loss = 0.41623
Step 35375: loss = 0.40148
Step 35380: loss = 0.27062
Step 35385: loss = 0.44239
Step 35390: loss = 0.64403
Step 35395: loss = 0.37701
Step 35400: loss = 0.35684
Step 35405: loss = 0.49390
Step 35410: loss = 0.27804
Step 35415: loss = 0.50348
Step 35420: loss = 0.32930
Step 35425: loss = 0.47808
Step 35430: loss = 0.20166
Step 35435: loss = 0.43764
Step 35440: loss = 0.62312
Step 35445: loss = 0.56253
Step 35450: loss = 0.39947
Step 35455: loss = 0.53413
Step 35460: loss = 0.38312
Step 35465: loss = 0.38831
Step 35470: loss = 0.48804
Step 35475: loss = 0.23961
Step 35480: loss = 0.41487
Step 35485: loss = 0.41049
Step 35490: loss = 0.47718
Step 35495: loss = 0.60330
Step 35500: loss = 0.57209
Step 35505: loss = 0.41078
Step 35510: loss = 0.46839
Step 35515: loss = 0.37093
Step 35520: loss = 0.53023
Step 35525: loss = 0.37523
Step 35530: loss = 0.17974
Step 35535: loss = 0.36252
Step 35540: loss = 0.44161
Step 35545: loss = 0.39859
Step 35550: loss = 0.30754
Step 35555: loss = 0.33328
Step 35560: loss = 0.43374
Step 35565: loss = 0.28287
Step 35570: loss = 0.45607
Step 35575: loss = 0.35979
Step 35580: loss = 0.44880
Step 35585: loss = 0.40628
Step 35590: loss = 0.35121
Step 35595: loss = 0.55089
Step 35600: loss = 0.40866
Step 35605: loss = 0.47457
Step 35610: loss = 0.42815
Step 35615: loss = 0.35834
Step 35620: loss = 0.42891
Step 35625: loss = 0.67036
Step 35630: loss = 0.21990
Step 35635: loss = 0.62409
Step 35640: loss = 0.47088
Step 35645: loss = 0.60695
Step 35650: loss = 0.35284
Step 35655: loss = 0.47369
Step 35660: loss = 0.54341
Step 35665: loss = 0.24526
Step 35670: loss = 0.59140
Step 35675: loss = 0.38921
Step 35680: loss = 0.44158
Step 35685: loss = 0.16720
Step 35690: loss = 0.36245
Step 35695: loss = 0.41505
Step 35700: loss = 0.41447
Step 35705: loss = 0.44220
Step 35710: loss = 0.68112
Step 35715: loss = 0.40913
Step 35720: loss = 0.38177
Step 35725: loss = 0.40218
Step 35730: loss = 0.61142
Step 35735: loss = 0.59181
Step 35740: loss = 0.46044
Step 35745: loss = 0.64578
Step 35750: loss = 0.51278
Step 35755: loss = 0.56057
Step 35760: loss = 0.36876
Step 35765: loss = 0.52563
Step 35770: loss = 0.66829
Step 35775: loss = 0.53808
Step 35780: loss = 0.35343
Step 35785: loss = 0.38607
Step 35790: loss = 0.28199
Step 35795: loss = 0.39254
Step 35800: loss = 0.55959
Step 35805: loss = 0.32392
Step 35810: loss = 0.40051
Step 35815: loss = 0.38282
Step 35820: loss = 0.46871
Step 35825: loss = 0.36721
Step 35830: loss = 0.62596
Step 35835: loss = 0.33409
Step 35840: loss = 0.45328
Step 35845: loss = 0.47473
Step 35850: loss = 0.47484
Step 35855: loss = 0.49714
Step 35860: loss = 0.42987
Step 35865: loss = 0.53804
Step 35870: loss = 1.02092
Step 35875: loss = 0.28171
Step 35880: loss = 0.26423
Step 35885: loss = 0.31874
Step 35890: loss = 0.36017
Step 35895: loss = 0.26201
Step 35900: loss = 0.68626
Step 35905: loss = 0.54848
Step 35910: loss = 0.40220
Step 35915: loss = 0.36377
Step 35920: loss = 0.28368
Step 35925: loss = 0.44160
Step 35930: loss = 0.38112
Step 35935: loss = 0.35590
Step 35940: loss = 0.43121
Step 35945: loss = 0.45837
Step 35950: loss = 0.24552
Step 35955: loss = 0.60803
Step 35960: loss = 0.19064
Step 35965: loss = 0.46114
Step 35970: loss = 0.52192
Step 35975: loss = 0.43523
Step 35980: loss = 0.32618
Step 35985: loss = 0.57036
Step 35990: loss = 0.65108
Step 35995: loss = 0.33819
Step 36000: loss = 0.73985
Training Data Eval:
  Num examples: 50000, Num correct: 42804, Precision @ 1: 0.8561
('Testing Data Eval: EPOCH->', 37)
  Num examples: 10000, Num correct: 6398, Precision @ 1: 0.6398
Step 36005: loss = 0.36364
Step 36010: loss = 0.31882
Step 36015: loss = 0.40726
Step 36020: loss = 0.38676
Step 36025: loss = 0.35167
Step 36030: loss = 0.57372
Step 36035: loss = 0.40301
Step 36040: loss = 0.25987
Step 36045: loss = 0.33262
Step 36050: loss = 0.37340
Step 36055: loss = 0.52304
Step 36060: loss = 0.29783
Step 36065: loss = 0.50939
Step 36070: loss = 0.41490
Step 36075: loss = 0.65967
Step 36080: loss = 0.49973
Step 36085: loss = 0.38546
Step 36090: loss = 0.34274
Step 36095: loss = 0.25285
Step 36100: loss = 0.24736
Step 36105: loss = 0.57412
Step 36110: loss = 0.47412
Step 36115: loss = 0.29735
Step 36120: loss = 0.24942
Step 36125: loss = 0.26935
Step 36130: loss = 0.22928
Step 36135: loss = 0.48987
Step 36140: loss = 0.61649
Step 36145: loss = 0.48085
Step 36150: loss = 0.48865
Step 36155: loss = 0.21217
Step 36160: loss = 0.48746
Step 36165: loss = 0.42167
Step 36170: loss = 0.34691
Step 36175: loss = 0.59074
Step 36180: loss = 0.30231
Step 36185: loss = 0.35889
Step 36190: loss = 0.23996
Step 36195: loss = 0.46671
Step 36200: loss = 0.46678
Step 36205: loss = 0.42296
Step 36210: loss = 0.39488
Step 36215: loss = 0.66748
Step 36220: loss = 0.44927
Step 36225: loss = 0.34855
Step 36230: loss = 0.43405
Step 36235: loss = 0.40823
Step 36240: loss = 0.21212
Step 36245: loss = 0.49536
Step 36250: loss = 0.35678
Step 36255: loss = 0.34286
Step 36260: loss = 0.51781
Step 36265: loss = 0.58093
Step 36270: loss = 0.30726
Step 36275: loss = 0.36962
Step 36280: loss = 0.36486
Step 36285: loss = 0.45362
Step 36290: loss = 0.53519
Step 36295: loss = 0.69755
Step 36300: loss = 0.51744
Step 36305: loss = 0.49243
Step 36310: loss = 0.80416
Step 36315: loss = 0.49571
Step 36320: loss = 0.45025
Step 36325: loss = 0.51503
Step 36330: loss = 0.38483
Step 36335: loss = 0.54839
Step 36340: loss = 0.60939
Step 36345: loss = 0.46906
Step 36350: loss = 0.52082
Step 36355: loss = 0.37263
Step 36360: loss = 0.49501
Step 36365: loss = 0.34367
Step 36370: loss = 0.22720
Step 36375: loss = 0.70411
Step 36380: loss = 0.57926
Step 36385: loss = 0.30921
Step 36390: loss = 0.42098
Step 36395: loss = 0.58365
Step 36400: loss = 0.53514
Step 36405: loss = 0.44301
Step 36410: loss = 0.52870
Step 36415: loss = 0.44694
Step 36420: loss = 0.39312
Step 36425: loss = 0.62711
Step 36430: loss = 0.41069
Step 36435: loss = 0.80073
Step 36440: loss = 0.55514
Step 36445: loss = 0.47828
Step 36450: loss = 0.45852
Step 36455: loss = 0.33260
Step 36460: loss = 0.34814
Step 36465: loss = 0.44247
Step 36470: loss = 0.36929
Step 36475: loss = 0.61687
Step 36480: loss = 0.38310
Step 36485: loss = 0.55637
Step 36490: loss = 0.38579
Step 36495: loss = 0.37694
Step 36500: loss = 0.45962
Step 36505: loss = 0.52756
Step 36510: loss = 0.55555
Step 36515: loss = 0.27931
Step 36520: loss = 0.43871
Step 36525: loss = 0.33151
Step 36530: loss = 0.57194
Step 36535: loss = 0.39383
Step 36540: loss = 0.28167
Step 36545: loss = 0.33696
Step 36550: loss = 0.29642
Step 36555: loss = 0.37825
Step 36560: loss = 0.34789
Step 36565: loss = 0.51266
Step 36570: loss = 0.44746
Step 36575: loss = 0.44806
Step 36580: loss = 0.43860
Step 36585: loss = 0.48329
Step 36590: loss = 0.44305
Step 36595: loss = 0.56671
Step 36600: loss = 0.44376
Step 36605: loss = 0.33422
Step 36610: loss = 0.32730
Step 36615: loss = 0.43837
Step 36620: loss = 0.39630
Step 36625: loss = 0.25744
Step 36630: loss = 0.38165
Step 36635: loss = 0.25648
Step 36640: loss = 0.52508
Step 36645: loss = 0.25400
Step 36650: loss = 0.31925
Step 36655: loss = 0.51179
Step 36660: loss = 0.17715
Step 36665: loss = 0.45750
Step 36670: loss = 0.42435
Step 36675: loss = 0.36408
Step 36680: loss = 0.35808
Step 36685: loss = 0.73474
Step 36690: loss = 0.20134
Step 36695: loss = 0.36782
Step 36700: loss = 0.46644
Step 36705: loss = 0.36738
Step 36710: loss = 0.50674
Step 36715: loss = 0.45307
Step 36720: loss = 0.22908
Step 36725: loss = 0.29995
Step 36730: loss = 0.54001
Step 36735: loss = 0.25749
Step 36740: loss = 0.71787
Step 36745: loss = 0.35826
Step 36750: loss = 0.31629
Step 36755: loss = 0.45647
Step 36760: loss = 0.43271
Step 36765: loss = 0.48367
Step 36770: loss = 0.46435
Step 36775: loss = 0.35575
Step 36780: loss = 0.50305
Step 36785: loss = 0.28862
Step 36790: loss = 0.47132
Step 36795: loss = 0.31730
Step 36800: loss = 0.61583
Step 36805: loss = 0.43886
Step 36810: loss = 0.35631
Step 36815: loss = 0.32274
Step 36820: loss = 0.36816
Step 36825: loss = 0.47754
Step 36830: loss = 0.59840
Step 36835: loss = 0.41724
Step 36840: loss = 0.54313
Step 36845: loss = 0.38674
Step 36850: loss = 0.59109
Step 36855: loss = 0.41443
Step 36860: loss = 0.43542
Step 36865: loss = 0.60543
Step 36870: loss = 0.54472
Step 36875: loss = 0.34336
Step 36880: loss = 0.48094
Step 36885: loss = 0.41019
Step 36890: loss = 0.44257
Step 36895: loss = 0.40365
Step 36900: loss = 0.34872
Step 36905: loss = 0.29813
Step 36910: loss = 0.66019
Step 36915: loss = 0.51424
Step 36920: loss = 0.43073
Step 36925: loss = 0.24215
Step 36930: loss = 0.59393
Step 36935: loss = 0.35065
Step 36940: loss = 0.33200
Step 36945: loss = 0.23345
Step 36950: loss = 0.40543
Step 36955: loss = 0.53995
Step 36960: loss = 0.38538
Step 36965: loss = 0.42451
Step 36970: loss = 0.34185
Step 36975: loss = 0.41727
Step 36980: loss = 0.73846
Step 36985: loss = 0.49659
Step 36990: loss = 0.40411
Step 36995: loss = 0.47903
Step 37000: loss = 0.64076
Training Data Eval:
  Num examples: 50000, Num correct: 42825, Precision @ 1: 0.8565
('Testing Data Eval: EPOCH->', 38)
  Num examples: 10000, Num correct: 6312, Precision @ 1: 0.6312
Step 37005: loss = 0.47136
Step 37010: loss = 0.34177
Step 37015: loss = 0.28304
Step 37020: loss = 0.35325
Step 37025: loss = 0.36554
Step 37030: loss = 0.40044
Step 37035: loss = 0.26857
Step 37040: loss = 0.30191
Step 37045: loss = 0.41889
Step 37050: loss = 0.35890
Step 37055: loss = 0.44629
Step 37060: loss = 0.28682
Step 37065: loss = 0.42953
Step 37070: loss = 0.36694
Step 37075: loss = 0.38626
Step 37080: loss = 0.30459
Step 37085: loss = 0.36874
Step 37090: loss = 0.40967
Step 37095: loss = 0.33309
Step 37100: loss = 0.31562
Step 37105: loss = 0.33747
Step 37110: loss = 0.37975
Step 37115: loss = 0.26539
Step 37120: loss = 0.33601
Step 37125: loss = 0.43605
Step 37130: loss = 0.56187
Step 37135: loss = 0.39429
Step 37140: loss = 0.16860
Step 37145: loss = 0.33962
Step 37150: loss = 0.33478
Step 37155: loss = 0.77069
Step 37160: loss = 0.48860
Step 37165: loss = 0.45649
Step 37170: loss = 0.59351
Step 37175: loss = 0.40969
Step 37180: loss = 0.64376
Step 37185: loss = 0.44554
Step 37190: loss = 0.62305
Step 37195: loss = 0.71834
Step 37200: loss = 0.34861
Step 37205: loss = 0.31582
Step 37210: loss = 0.48392
Step 37215: loss = 0.34729
Step 37220: loss = 0.45062
Step 37225: loss = 0.42026
Step 37230: loss = 0.47522
Step 37235: loss = 0.30873
Step 37240: loss = 0.49448
Step 37245: loss = 0.33985
Step 37250: loss = 0.36262
Step 37255: loss = 0.47100
Step 37260: loss = 0.27487
Step 37265: loss = 0.36490
Step 37270: loss = 0.58110
Step 37275: loss = 0.29261
Step 37280: loss = 0.25875
Step 37285: loss = 0.61009
Step 37290: loss = 0.43400
Step 37295: loss = 0.51936
Step 37300: loss = 0.44610
Step 37305: loss = 0.37508
Step 37310: loss = 0.55725
Step 37315: loss = 0.53711
Step 37320: loss = 0.36204
Step 37325: loss = 0.30669
Step 37330: loss = 0.32492
Step 37335: loss = 0.40036
Step 37340: loss = 0.59924
Step 37345: loss = 0.63892
Step 37350: loss = 0.34189
Step 37355: loss = 0.46286
Step 37360: loss = 0.45121
Step 37365: loss = 0.47859
Step 37370: loss = 0.40567
Step 37375: loss = 0.52652
Step 37380: loss = 0.36968
Step 37385: loss = 0.36871
Step 37390: loss = 0.40756
Step 37395: loss = 0.92326
Step 37400: loss = 0.72244
Step 37405: loss = 0.34120
Step 37410: loss = 0.26554
Step 37415: loss = 0.40388
Step 37420: loss = 0.38906
Step 37425: loss = 0.34793
Step 37430: loss = 0.38024
Step 37435: loss = 0.66362
Step 37440: loss = 0.53159
Step 37445: loss = 0.56596
Step 37450: loss = 0.58822
Step 37455: loss = 0.32222
Step 37460: loss = 0.55412
Step 37465: loss = 0.30831
Step 37470: loss = 0.51632
Step 37475: loss = 0.35965
Step 37480: loss = 0.28295
Step 37485: loss = 0.38683
Step 37490: loss = 0.34832
Step 37495: loss = 0.25855
Step 37500: loss = 0.46819
Step 37505: loss = 0.25432
Step 37510: loss = 0.51578
Step 37515: loss = 0.60753
Step 37520: loss = 0.36160
Step 37525: loss = 0.65461
Step 37530: loss = 0.24923
Step 37535: loss = 0.28420
Step 37540: loss = 0.18575
Step 37545: loss = 0.32072
Step 37550: loss = 0.39103
Step 37555: loss = 0.32640
Step 37560: loss = 0.75113
Step 37565: loss = 0.39959
Step 37570: loss = 0.63794
Step 37575: loss = 0.26335
Step 37580: loss = 0.30419
Step 37585: loss = 0.27025
Step 37590: loss = 0.67523
Step 37595: loss = 0.29236
Step 37600: loss = 0.56989
Step 37605: loss = 0.56317
Step 37610: loss = 0.48466
Step 37615: loss = 0.49097
Step 37620: loss = 0.33251
Step 37625: loss = 0.38503
Step 37630: loss = 0.27586
Step 37635: loss = 0.38735
Step 37640: loss = 0.43453
Step 37645: loss = 0.31726
Step 37650: loss = 0.24724
Step 37655: loss = 0.53255
Step 37660: loss = 0.31263
Step 37665: loss = 0.66897
Step 37670: loss = 0.28090
Step 37675: loss = 0.41053
Step 37680: loss = 0.53049
Step 37685: loss = 0.40353
Step 37690: loss = 0.40313
Step 37695: loss = 0.27861
Step 37700: loss = 0.43514
Step 37705: loss = 0.38397
Step 37710: loss = 0.45681
Step 37715: loss = 0.45767
Step 37720: loss = 0.57315
Step 37725: loss = 0.18173
Step 37730: loss = 0.27619
Step 37735: loss = 0.40514
Step 37740: loss = 0.20736
Step 37745: loss = 0.44753
Step 37750: loss = 0.64515
Step 37755: loss = 0.57825
Step 37760: loss = 0.41352
Step 37765: loss = 0.50670
Step 37770: loss = 0.43185
Step 37775: loss = 0.40643
Step 37780: loss = 0.45236
Step 37785: loss = 0.52289
Step 37790: loss = 0.26847
Step 37795: loss = 0.60055
Step 37800: loss = 0.30735
Step 37805: loss = 0.83922
Step 37810: loss = 0.40988
Step 37815: loss = 0.42605
Step 37820: loss = 0.57156
Step 37825: loss = 0.39573
Step 37830: loss = 0.24484
Step 37835: loss = 0.55318
Step 37840: loss = 0.40254
Step 37845: loss = 0.43731
Step 37850: loss = 0.38000
Step 37855: loss = 0.37607
Step 37860: loss = 0.42617
Step 37865: loss = 0.31100
Step 37870: loss = 0.59006
Step 37875: loss = 0.24423
Step 37880: loss = 0.53205
Step 37885: loss = 0.35356
Step 37890: loss = 0.67498
Step 37895: loss = 0.40057
Step 37900: loss = 0.44375
Step 37905: loss = 0.42712
Step 37910: loss = 0.39756
Step 37915: loss = 0.40627
Step 37920: loss = 0.50178
Step 37925: loss = 0.41044
Step 37930: loss = 0.45130
Step 37935: loss = 0.68892
Step 37940: loss = 0.54045
Step 37945: loss = 0.55202
Step 37950: loss = 0.64085
Step 37955: loss = 0.37741
Step 37960: loss = 0.29297
Step 37965: loss = 0.46427
Step 37970: loss = 0.64500
Step 37975: loss = 0.50143
Step 37980: loss = 0.45496
Step 37985: loss = 0.41100
Step 37990: loss = 0.32504
Step 37995: loss = 0.23735
Step 38000: loss = 0.25626
Training Data Eval:
  Num examples: 50000, Num correct: 43150, Precision @ 1: 0.8630
('Testing Data Eval: EPOCH->', 39)
  Num examples: 10000, Num correct: 6445, Precision @ 1: 0.6445
Step 38005: loss = 0.35757
Step 38010: loss = 0.42753
Step 38015: loss = 0.60548
Step 38020: loss = 0.58281
Step 38025: loss = 0.37776
Step 38030: loss = 0.46085
Step 38035: loss = 0.27431
Step 38040: loss = 0.46378
Step 38045: loss = 0.42960
Step 38050: loss = 0.26886
Step 38055: loss = 0.40291
Step 38060: loss = 0.55241
Step 38065: loss = 0.35483
Step 38070: loss = 0.24562
Step 38075: loss = 0.41240
Step 38080: loss = 0.51959
Step 38085: loss = 0.39312
Step 38090: loss = 0.56800
Step 38095: loss = 0.29845
Step 38100: loss = 0.31907
Step 38105: loss = 0.67503
Step 38110: loss = 0.51802
Step 38115: loss = 0.44508
Step 38120: loss = 0.61163
Step 38125: loss = 0.49226
Step 38130: loss = 0.40180
Step 38135: loss = 0.66513
Step 38140: loss = 0.20724
Step 38145: loss = 0.28732
Step 38150: loss = 0.26891
Step 38155: loss = 0.36295
Step 38160: loss = 0.40026
Step 38165: loss = 0.40035
Step 38170: loss = 0.19804
Step 38175: loss = 0.37700
Step 38180: loss = 0.43641
Step 38185: loss = 0.45106
Step 38190: loss = 0.48991
Step 38195: loss = 0.37353
Step 38200: loss = 0.35692
Step 38205: loss = 0.16941
Step 38210: loss = 0.32469
Step 38215: loss = 0.48526
Step 38220: loss = 0.38543
Step 38225: loss = 0.33710
Step 38230: loss = 0.45547
Step 38235: loss = 0.38175
Step 38240: loss = 0.65436
Step 38245: loss = 0.39155
Step 38250: loss = 0.50505
Step 38255: loss = 0.49297
Step 38260: loss = 0.48414
Step 38265: loss = 0.33706
Step 38270: loss = 0.38692
Step 38275: loss = 0.38793
Step 38280: loss = 0.38161
Step 38285: loss = 0.51193
Step 38290: loss = 0.32041
Step 38295: loss = 0.38807
Step 38300: loss = 0.60778
Step 38305: loss = 0.33687
Step 38310: loss = 0.31848
Step 38315: loss = 0.29272
Step 38320: loss = 0.51557
Step 38325: loss = 0.63839
Step 38330: loss = 0.38448
Step 38335: loss = 0.29709
Step 38340: loss = 0.48386
Step 38345: loss = 0.53279
Step 38350: loss = 0.56640
Step 38355: loss = 0.25831
Step 38360: loss = 0.49842
Step 38365: loss = 0.44414
Step 38370: loss = 0.45172
Step 38375: loss = 0.39045
Step 38380: loss = 0.45676
Step 38385: loss = 0.35146
Step 38390: loss = 0.31525
Step 38395: loss = 0.27313
Step 38400: loss = 0.45165
Step 38405: loss = 0.45115
Step 38410: loss = 0.38337
Step 38415: loss = 0.14222
Step 38420: loss = 0.92909
Step 38425: loss = 0.40171
Step 38430: loss = 0.55605
Step 38435: loss = 0.36715
Step 38440: loss = 0.70151
Step 38445: loss = 0.34070
Step 38450: loss = 0.24838
Step 38455: loss = 0.51600
Step 38460: loss = 0.33543
Step 38465: loss = 0.48310
Step 38470: loss = 0.28050
Step 38475: loss = 0.36084
Step 38480: loss = 0.47452
Step 38485: loss = 0.84410
Step 38490: loss = 0.39549
Step 38495: loss = 0.42518
Step 38500: loss = 0.50218
Step 38505: loss = 0.57157
Step 38510: loss = 0.21666
Step 38515: loss = 0.29259
Step 38520: loss = 0.30064
Step 38525: loss = 0.30751
Step 38530: loss = 0.46671
Step 38535: loss = 0.67965
Step 38540: loss = 0.21601
Step 38545: loss = 0.38572
Step 38550: loss = 0.44141
Step 38555: loss = 0.46837
Step 38560: loss = 0.47523
Step 38565: loss = 0.37975
Step 38570: loss = 0.34801
Step 38575: loss = 0.57395
Step 38580: loss = 0.27578
Step 38585: loss = 0.37506
Step 38590: loss = 0.32034
Step 38595: loss = 0.37412
Step 38600: loss = 0.37833
Step 38605: loss = 0.18731
Step 38610: loss = 0.21037
Step 38615: loss = 0.38138
Step 38620: loss = 0.44302
Step 38625: loss = 0.51339
Step 38630: loss = 0.44083
Step 38635: loss = 0.48476
Step 38640: loss = 0.38392
Step 38645: loss = 0.44348
Step 38650: loss = 0.42427
Step 38655: loss = 0.39095
Step 38660: loss = 0.48571
Step 38665: loss = 0.50028
Step 38670: loss = 0.26141
Step 38675: loss = 0.33522
Step 38680: loss = 0.37831
Step 38685: loss = 0.53169
Step 38690: loss = 0.28021
Step 38695: loss = 0.25593
Step 38700: loss = 0.42014
Step 38705: loss = 0.34077
Step 38710: loss = 0.36372
Step 38715: loss = 0.40981
Step 38720: loss = 0.53401
Step 38725: loss = 0.50530
Step 38730: loss = 0.26894
Step 38735: loss = 0.25495
Step 38740: loss = 0.34706
Step 38745: loss = 0.20911
Step 38750: loss = 0.38788
Step 38755: loss = 0.42943
Step 38760: loss = 0.53167
Step 38765: loss = 0.29784
Step 38770: loss = 0.33031
Step 38775: loss = 0.61135
Step 38780: loss = 0.29214
Step 38785: loss = 0.37537
Step 38790: loss = 0.26496
Step 38795: loss = 0.36452
Step 38800: loss = 0.29590
Step 38805: loss = 0.43602
Step 38810: loss = 0.52970
Step 38815: loss = 0.56337
Step 38820: loss = 0.45982
Step 38825: loss = 0.51860
Step 38830: loss = 0.44192
Step 38835: loss = 0.48066
Step 38840: loss = 0.45297
Step 38845: loss = 0.39964
Step 38850: loss = 0.25409
Step 38855: loss = 0.38739
Step 38860: loss = 0.58471
Step 38865: loss = 0.40389
Step 38870: loss = 0.47392
Step 38875: loss = 0.28279
Step 38880: loss = 0.50677
Step 38885: loss = 0.58825
Step 38890: loss = 0.38804
Step 38895: loss = 0.61661
Step 38900: loss = 0.54650
Step 38905: loss = 0.22476
Step 38910: loss = 0.42287
Step 38915: loss = 0.35351
Step 38920: loss = 0.41933
Step 38925: loss = 0.69798
Step 38930: loss = 0.23606
Step 38935: loss = 0.77162
Step 38940: loss = 0.29858
Step 38945: loss = 0.59715
Step 38950: loss = 0.69835
Step 38955: loss = 0.36176
Step 38960: loss = 0.41318
Step 38965: loss = 0.29114
Step 38970: loss = 0.30189
Step 38975: loss = 0.29018
Step 38980: loss = 0.50004
Step 38985: loss = 0.45474
Step 38990: loss = 0.56763
Step 38995: loss = 0.29448
Step 39000: loss = 0.33094
Training Data Eval:
  Num examples: 50000, Num correct: 43463, Precision @ 1: 0.8693
('Testing Data Eval: EPOCH->', 40)
  Num examples: 10000, Num correct: 6436, Precision @ 1: 0.6436
Step 39005: loss = 0.41209
Step 39010: loss = 0.24001
Step 39015: loss = 0.21555
Step 39020: loss = 0.34302
Step 39025: loss = 0.43138
Step 39030: loss = 0.24695
Step 39035: loss = 0.40110
Step 39040: loss = 0.27036
Step 39045: loss = 0.40579
Step 39050: loss = 0.52257
Step 39055: loss = 0.77417
Step 39060: loss = 0.45746
Step 39065: loss = 0.27536
Step 39070: loss = 0.51552
Step 39075: loss = 0.38488
Step 39080: loss = 0.24747
Step 39085: loss = 0.36133
Step 39090: loss = 0.20861
Step 39095: loss = 0.48499
Step 39100: loss = 0.29390
Step 39105: loss = 0.25120
Step 39110: loss = 0.39780
Step 39115: loss = 0.22640
Step 39120: loss = 0.44611
Step 39125: loss = 0.17987
Step 39130: loss = 0.43921
Step 39135: loss = 0.57375
Step 39140: loss = 0.47253
Step 39145: loss = 0.28025
Step 39150: loss = 0.22559
Step 39155: loss = 0.40271
Step 39160: loss = 0.45081
Step 39165: loss = 0.27834
Step 39170: loss = 0.47811
Step 39175: loss = 0.23033
Step 39180: loss = 0.39866
Step 39185: loss = 0.45433
Step 39190: loss = 0.33036
Step 39195: loss = 0.33838
Step 39200: loss = 0.23852
Step 39205: loss = 0.57344
Step 39210: loss = 0.32789
Step 39215: loss = 0.34069
Step 39220: loss = 0.41967
Step 39225: loss = 0.22372
Step 39230: loss = 0.46373
Step 39235: loss = 0.41765
Step 39240: loss = 0.33464
Step 39245: loss = 0.47655
Step 39250: loss = 0.46612
Step 39255: loss = 0.31551
Step 39260: loss = 0.26356
Step 39265: loss = 0.75580
Step 39270: loss = 0.39741
Step 39275: loss = 0.45261
Step 39280: loss = 0.33128
Step 39285: loss = 0.44578
Step 39290: loss = 0.44168
Step 39295: loss = 0.60871
Step 39300: loss = 0.34020
Step 39305: loss = 0.34030
Step 39310: loss = 0.45585
Step 39315: loss = 0.27365
Step 39320: loss = 0.21349
Step 39325: loss = 0.32358
Step 39330: loss = 0.85775
Step 39335: loss = 0.19969
Step 39340: loss = 0.45951
Step 39345: loss = 0.45534
Step 39350: loss = 0.49464
Step 39355: loss = 0.35582
Step 39360: loss = 0.48914
Step 39365: loss = 0.28520
Step 39370: loss = 0.58712
Step 39375: loss = 0.25653
Step 39380: loss = 0.37706
Step 39385: loss = 0.68311
Step 39390: loss = 0.27182
Step 39395: loss = 0.69335
Step 39400: loss = 0.40265
Step 39405: loss = 0.35286
Step 39410: loss = 0.62433
Step 39415: loss = 0.63211
Step 39420: loss = 0.20609
Step 39425: loss = 0.27560
Step 39430: loss = 0.32068
Step 39435: loss = 0.32000
Step 39440: loss = 0.54987
Step 39445: loss = 0.28254
Step 39450: loss = 0.31096
Step 39455: loss = 0.28768
Step 39460: loss = 0.23561
Step 39465: loss = 0.62983
Step 39470: loss = 0.37636
Step 39475: loss = 0.31731
Step 39480: loss = 0.47374
Step 39485: loss = 0.33020
Step 39490: loss = 0.25551
Step 39495: loss = 0.50216
Step 39500: loss = 0.47819
Step 39505: loss = 0.46325
Step 39510: loss = 0.20387
Step 39515: loss = 0.34486
Step 39520: loss = 0.45914
Step 39525: loss = 0.19499
Step 39530: loss = 0.34100
Step 39535: loss = 0.32036
Step 39540: loss = 0.36494
Step 39545: loss = 0.56130
Step 39550: loss = 0.35643
Step 39555: loss = 0.71050
Step 39560: loss = 0.32478
Step 39565: loss = 0.27771
Step 39570: loss = 0.29777
Step 39575: loss = 0.58718
Step 39580: loss = 0.46759
Step 39585: loss = 0.54635
Step 39590: loss = 0.22455
Step 39595: loss = 0.54669
Step 39600: loss = 0.40208
Step 39605: loss = 0.32514
Step 39610: loss = 0.42367
Step 39615: loss = 0.37889
Step 39620: loss = 0.40365
Step 39625: loss = 0.43498
Step 39630: loss = 0.36727
Step 39635: loss = 0.29750
Step 39640: loss = 0.61893
Step 39645: loss = 0.25924
Step 39650: loss = 0.45465
Step 39655: loss = 0.20109
Step 39660: loss = 0.44504
Step 39665: loss = 0.45694
Step 39670: loss = 0.36028
Step 39675: loss = 0.26023
Step 39680: loss = 0.54342
Step 39685: loss = 0.41034
Step 39690: loss = 0.57120
Step 39695: loss = 0.34206
Step 39700: loss = 0.64212
Step 39705: loss = 0.45058
Step 39710: loss = 0.37246
Step 39715: loss = 0.55042
Step 39720: loss = 0.47338
Step 39725: loss = 0.27061
Step 39730: loss = 0.46789
Step 39735: loss = 0.39924
Step 39740: loss = 0.45202
Step 39745: loss = 0.37215
Step 39750: loss = 0.33403
Step 39755: loss = 0.19428
Step 39760: loss = 0.42687
Step 39765: loss = 0.29647
Step 39770: loss = 0.42399
Step 39775: loss = 0.72778
Step 39780: loss = 0.70651
Step 39785: loss = 0.64428
Step 39790: loss = 0.35766
Step 39795: loss = 0.22985
Step 39800: loss = 0.39663
Step 39805: loss = 0.20858
Step 39810: loss = 0.64821
Step 39815: loss = 0.37345
Step 39820: loss = 0.47251
Step 39825: loss = 0.36761
Step 39830: loss = 0.59698
Step 39835: loss = 0.23371
Step 39840: loss = 0.37783
Step 39845: loss = 0.39995
Step 39850: loss = 0.28559
Step 39855: loss = 0.21972
Step 39860: loss = 0.28130
Step 39865: loss = 0.49262
Step 39870: loss = 0.59282
Step 39875: loss = 0.32505
Step 39880: loss = 0.42431
Step 39885: loss = 0.45337
Step 39890: loss = 0.50365
Step 39895: loss = 1.07375
Step 39900: loss = 0.59579
Step 39905: loss = 0.42567
Step 39910: loss = 0.50553
Step 39915: loss = 0.40874
Step 39920: loss = 0.45935
Step 39925: loss = 0.25610
Step 39930: loss = 0.43648
Step 39935: loss = 0.58353
Step 39940: loss = 0.31241
Step 39945: loss = 0.32193
Step 39950: loss = 0.36923
Step 39955: loss = 0.43044
Step 39960: loss = 0.51672
Step 39965: loss = 0.55096
Step 39970: loss = 0.27388
Step 39975: loss = 0.24800
Step 39980: loss = 0.46086
Step 39985: loss = 0.49350
Step 39990: loss = 0.56607
Step 39995: loss = 0.61703
Step 40000: loss = 0.41988
Training Data Eval:
  Num examples: 50000, Num correct: 43205, Precision @ 1: 0.8641
('Testing Data Eval: EPOCH->', 41)
  Num examples: 10000, Num correct: 6372, Precision @ 1: 0.6372
Step 40005: loss = 0.43754
Step 40010: loss = 0.35745
Step 40015: loss = 0.22431
Step 40020: loss = 0.27319
Step 40025: loss = 0.26578
Step 40030: loss = 0.40055
Step 40035: loss = 0.32011
Step 40040: loss = 0.57999
Step 40045: loss = 0.43550
Step 40050: loss = 0.48829
Step 40055: loss = 0.44627
Step 40060: loss = 0.22602
Step 40065: loss = 0.49725
Step 40070: loss = 0.27648
Step 40075: loss = 0.50640
Step 40080: loss = 0.37935
Step 40085: loss = 0.43303
Step 40090: loss = 0.28871
Step 40095: loss = 0.47154
Step 40100: loss = 0.31429
Step 40105: loss = 0.56764
Step 40110: loss = 0.30819
Step 40115: loss = 0.40728
Step 40120: loss = 0.54900
Step 40125: loss = 0.24423
Step 40130: loss = 0.30112
Step 40135: loss = 0.32023
Step 40140: loss = 0.43917
Step 40145: loss = 0.23795
Step 40150: loss = 0.31882
Step 40155: loss = 0.39019
Step 40160: loss = 0.36937
Step 40165: loss = 0.49990
Step 40170: loss = 0.30892
Step 40175: loss = 0.42829
Step 40180: loss = 0.35542
Step 40185: loss = 0.35105
Step 40190: loss = 0.33671
Step 40195: loss = 0.35839
Step 40200: loss = 0.40900
Step 40205: loss = 0.29179
Step 40210: loss = 0.48975
Step 40215: loss = 0.58485
Step 40220: loss = 0.38238
Step 40225: loss = 0.30758
Step 40230: loss = 0.25524
Step 40235: loss = 0.31736
Step 40240: loss = 0.43077
Step 40245: loss = 0.30712
Step 40250: loss = 0.58884
Step 40255: loss = 0.25447
Step 40260: loss = 0.46890
Step 40265: loss = 0.33734
Step 40270: loss = 0.48071
Step 40275: loss = 0.42215
Step 40280: loss = 0.31310
Step 40285: loss = 0.51405
Step 40290: loss = 0.38759
Step 40295: loss = 0.27944
Step 40300: loss = 0.62187
Step 40305: loss = 0.27329
Step 40310: loss = 0.22579
Step 40315: loss = 0.26943
Step 40320: loss = 0.30363
Step 40325: loss = 0.41083
Step 40330: loss = 0.34685
Step 40335: loss = 0.32564
Step 40340: loss = 0.32014
Step 40345: loss = 0.34292
Step 40350: loss = 0.30637
Step 40355: loss = 0.37227
Step 40360: loss = 0.56183
Step 40365: loss = 0.28020
Step 40370: loss = 0.24946
Step 40375: loss = 0.45916
Step 40380: loss = 0.40002
Step 40385: loss = 0.28404
Step 40390: loss = 0.31715
Step 40395: loss = 0.29534
Step 40400: loss = 0.24805
Step 40405: loss = 0.51050
Step 40410: loss = 0.47859
Step 40415: loss = 0.48366
Step 40420: loss = 0.37822
Step 40425: loss = 0.43197
Step 40430: loss = 0.55533
Step 40435: loss = 0.30105
Step 40440: loss = 0.41246
Step 40445: loss = 0.34264
Step 40450: loss = 0.53046
Step 40455: loss = 0.38532
Step 40460: loss = 0.40218
Step 40465: loss = 0.33342
Step 40470: loss = 0.44870
Step 40475: loss = 0.42408
Step 40480: loss = 0.16233
Step 40485: loss = 0.37193
Step 40490: loss = 0.31383
Step 40495: loss = 0.57804
Step 40500: loss = 0.39032
Step 40505: loss = 0.56204
Step 40510: loss = 0.42884
Step 40515: loss = 0.43968
Step 40520: loss = 0.48839
Step 40525: loss = 0.33215
Step 40530: loss = 0.52574
Step 40535: loss = 0.22079
Step 40540: loss = 0.34514
Step 40545: loss = 0.39726
Step 40550: loss = 0.23805
Step 40555: loss = 0.39042
Step 40560: loss = 0.45021
Step 40565: loss = 0.28652
Step 40570: loss = 0.39602
Step 40575: loss = 0.39474
Step 40580: loss = 0.37260
Step 40585: loss = 0.35795
Step 40590: loss = 0.40965
Step 40595: loss = 0.32770
Step 40600: loss = 0.50811
Step 40605: loss = 0.47456
Step 40610: loss = 0.36479
Step 40615: loss = 0.30097
Step 40620: loss = 0.47828
Step 40625: loss = 0.48014
Step 40630: loss = 0.28594
Step 40635: loss = 0.57321
Step 40640: loss = 0.55987
Step 40645: loss = 0.32355
Step 40650: loss = 0.53122
Step 40655: loss = 0.29466
Step 40660: loss = 0.32272
Step 40665: loss = 0.52005
Step 40670: loss = 0.65395
Step 40675: loss = 0.38559
Step 40680: loss = 0.48889
Step 40685: loss = 0.34327
Step 40690: loss = 0.34589
Step 40695: loss = 0.21125
Step 40700: loss = 0.43180
Step 40705: loss = 0.33160
Step 40710: loss = 0.45728
Step 40715: loss = 0.66311
Step 40720: loss = 0.58167
Step 40725: loss = 0.35368
Step 40730: loss = 0.28273
Step 40735: loss = 0.40980
Step 40740: loss = 0.65514
Step 40745: loss = 0.25967
Step 40750: loss = 0.57232
Step 40755: loss = 0.38343
Step 40760: loss = 0.44637
Step 40765: loss = 0.38534
Step 40770: loss = 0.38094
Step 40775: loss = 0.45680
Step 40780: loss = 0.36134
Step 40785: loss = 0.34672
Step 40790: loss = 0.27754
Step 40795: loss = 0.36975
Step 40800: loss = 0.33290
Step 40805: loss = 0.37455
Step 40810: loss = 0.36036
Step 40815: loss = 0.61993
Step 40820: loss = 0.31433
Step 40825: loss = 0.47748
Step 40830: loss = 0.42288
Step 40835: loss = 0.34389
Step 40840: loss = 0.33226
Step 40845: loss = 0.69075
Step 40850: loss = 0.47186
Step 40855: loss = 0.30366
Step 40860: loss = 0.23325
Step 40865: loss = 0.40819
Step 40870: loss = 0.29510
Step 40875: loss = 0.37798
Step 40880: loss = 0.55884
Step 40885: loss = 0.42660
Step 40890: loss = 0.38541
Step 40895: loss = 0.90114
Step 40900: loss = 0.45471
Step 40905: loss = 0.26464
Step 40910: loss = 0.16474
Step 40915: loss = 0.35061
Step 40920: loss = 0.42032
Step 40925: loss = 0.34922
Step 40930: loss = 0.33335
Step 40935: loss = 0.23498
Step 40940: loss = 0.57228
Step 40945: loss = 0.42498
Step 40950: loss = 0.84468
Step 40955: loss = 0.33516
Step 40960: loss = 0.33824
Step 40965: loss = 0.35764
Step 40970: loss = 0.32521
Step 40975: loss = 0.43482
Step 40980: loss = 0.28416
Step 40985: loss = 0.32057
Step 40990: loss = 0.33608
Step 40995: loss = 0.54465
Step 41000: loss = 0.43344
Training Data Eval:
  Num examples: 50000, Num correct: 43389, Precision @ 1: 0.8678
('Testing Data Eval: EPOCH->', 42)
  Num examples: 10000, Num correct: 6361, Precision @ 1: 0.6361
Step 41005: loss = 0.41475
Step 41010: loss = 0.12634
Step 41015: loss = 0.36124
Step 41020: loss = 0.32229
Step 41025: loss = 0.41183
Step 41030: loss = 0.21396
Step 41035: loss = 0.10307
Step 41040: loss = 0.28099
Step 41045: loss = 0.49200
Step 41050: loss = 0.49522
Step 41055: loss = 0.55943
Step 41060: loss = 0.68973
Step 41065: loss = 0.35987
Step 41070: loss = 0.39145
Step 41075: loss = 0.43926
Step 41080: loss = 0.31603
Step 41085: loss = 0.17884
Step 41090: loss = 0.44295
Step 41095: loss = 0.32806
Step 41100: loss = 0.30558
Step 41105: loss = 0.29775
Step 41110: loss = 0.21791
Step 41115: loss = 0.40104
Step 41120: loss = 0.43436
Step 41125: loss = 0.33384
Step 41130: loss = 0.28506
Step 41135: loss = 0.46046
Step 41140: loss = 0.21637
Step 41145: loss = 0.39348
Step 41150: loss = 0.20597
Step 41155: loss = 0.43822
Step 41160: loss = 0.26523
Step 41165: loss = 0.41528
Step 41170: loss = 0.41386
Step 41175: loss = 0.32738
Step 41180: loss = 0.49635
Step 41185: loss = 0.22837
Step 41190: loss = 0.46483
Step 41195: loss = 0.21027
Step 41200: loss = 0.45625
Step 41205: loss = 0.64478
Step 41210: loss = 0.48058
Step 41215: loss = 0.36726
Step 41220: loss = 0.39337
Step 41225: loss = 0.31302
Step 41230: loss = 0.25697
Step 41235: loss = 0.38437
Step 41240: loss = 0.35747
Step 41245: loss = 0.31082
Step 41250: loss = 0.35015
Step 41255: loss = 0.40849
Step 41260: loss = 0.28730
Step 41265: loss = 0.27609
Step 41270: loss = 0.17242
Step 41275: loss = 0.24025
Step 41280: loss = 0.29482
Step 41285: loss = 0.34035
Step 41290: loss = 0.18678
Step 41295: loss = 0.42491
Step 41300: loss = 0.34114
Step 41305: loss = 0.24329
Step 41310: loss = 0.48375
Step 41315: loss = 0.41476
Step 41320: loss = 0.34736
Step 41325: loss = 0.41022
Step 41330: loss = 0.36921
Step 41335: loss = 0.54093
Step 41340: loss = 0.49323
Step 41345: loss = 0.43238
Step 41350: loss = 0.49930
Step 41355: loss = 0.30758
Step 41360: loss = 0.36883
Step 41365: loss = 0.15095
Step 41370: loss = 0.19728
Step 41375: loss = 0.28132
Step 41380: loss = 0.37546
Step 41385: loss = 0.41585
Step 41390: loss = 0.39618
Step 41395: loss = 0.29085
Step 41400: loss = 0.33354
Step 41405: loss = 0.34089
Step 41410: loss = 0.27452
Step 41415: loss = 0.44602
Step 41420: loss = 0.37682
Step 41425: loss = 0.41022
Step 41430: loss = 0.25367
Step 41435: loss = 0.42636
Step 41440: loss = 0.32447
Step 41445: loss = 0.71934
Step 41450: loss = 0.54940
Step 41455: loss = 0.30820
Step 41460: loss = 0.52457
Step 41465: loss = 0.46865
Step 41470: loss = 0.49295
Step 41475: loss = 0.33722
Step 41480: loss = 0.40417
Step 41485: loss = 0.84578
Step 41490: loss = 0.33714
Step 41495: loss = 0.52503
Step 41500: loss = 0.36685
Step 41505: loss = 0.43231
Step 41510: loss = 0.39416
Step 41515: loss = 0.37043
Step 41520: loss = 0.33009
Step 41525: loss = 0.38157
Step 41530: loss = 0.22745
Step 41535: loss = 0.15045
Step 41540: loss = 0.31862
Step 41545: loss = 0.76380
Step 41550: loss = 0.33688
Step 41555: loss = 0.75639
Step 41560: loss = 0.41700
Step 41565: loss = 0.47465
Step 41570: loss = 0.33892
Step 41575: loss = 0.58163
Step 41580: loss = 0.35660
Step 41585: loss = 0.34489
Step 41590: loss = 0.38145
Step 41595: loss = 0.61628
Step 41600: loss = 0.27752
Step 41605: loss = 0.41570
Step 41610: loss = 0.36575
Step 41615: loss = 0.44423
Step 41620: loss = 0.34696
Step 41625: loss = 0.21985
Step 41630: loss = 0.35100
Step 41635: loss = 0.45324
Step 41640: loss = 0.38788
Step 41645: loss = 0.20727
Step 41650: loss = 0.39404
Step 41655: loss = 0.34999
Step 41660: loss = 0.56759
Step 41665: loss = 0.73820
Step 41670: loss = 0.48763
Step 41675: loss = 0.43593
Step 41680: loss = 0.49462
Step 41685: loss = 0.61122
Step 41690: loss = 0.55660
Step 41695: loss = 0.34721
Step 41700: loss = 0.36124
Step 41705: loss = 0.56220
Step 41710: loss = 0.23565
Step 41715: loss = 0.25899
Step 41720: loss = 0.50761
Step 41725: loss = 0.39465
Step 41730: loss = 0.23461
Step 41735: loss = 0.61335
Step 41740: loss = 0.62372
Step 41745: loss = 0.27590
Step 41750: loss = 0.44295
Step 41755: loss = 0.37038
Step 41760: loss = 0.25479
Step 41765: loss = 0.24539
Step 41770: loss = 0.20809
Step 41775: loss = 0.26207
Step 41780: loss = 0.43066
Step 41785: loss = 0.45691
Step 41790: loss = 0.33011
Step 41795: loss = 0.45394
Step 41800: loss = 0.49472
Step 41805: loss = 0.40260
Step 41810: loss = 0.36812
Step 41815: loss = 0.20998
Step 41820: loss = 0.15275
Step 41825: loss = 0.53863
Step 41830: loss = 0.32918
Step 41835: loss = 0.33712
Step 41840: loss = 0.15753
Step 41845: loss = 0.28179
Step 41850: loss = 0.25867
Step 41855: loss = 0.46640
Step 41860: loss = 0.48842
Step 41865: loss = 0.39592
Step 41870: loss = 0.32901
Step 41875: loss = 0.46974
Step 41880: loss = 0.26848
Step 41885: loss = 0.54413
Step 41890: loss = 0.29475
Step 41895: loss = 0.18968
Step 41900: loss = 0.68139
Step 41905: loss = 0.30435
Step 41910: loss = 0.61495
Step 41915: loss = 0.20049
Step 41920: loss = 0.38501
Step 41925: loss = 0.25020
Step 41930: loss = 0.31951
Step 41935: loss = 0.20597
Step 41940: loss = 0.40748
Step 41945: loss = 0.15955
Step 41950: loss = 0.27566
Step 41955: loss = 0.19223
Step 41960: loss = 0.20303
Step 41965: loss = 0.20248
Step 41970: loss = 0.50712
Step 41975: loss = 0.34325
Step 41980: loss = 0.32651
Step 41985: loss = 0.34644
Step 41990: loss = 0.38303
Step 41995: loss = 0.37764
Step 42000: loss = 0.72179
Training Data Eval:
  Num examples: 50000, Num correct: 43690, Precision @ 1: 0.8738
('Testing Data Eval: EPOCH->', 43)
  Num examples: 10000, Num correct: 6374, Precision @ 1: 0.6374
Step 42005: loss = 0.23039
Step 42010: loss = 0.20709
Step 42015: loss = 0.30372
Step 42020: loss = 0.30857
Step 42025: loss = 0.53012
Step 42030: loss = 0.43718
Step 42035: loss = 0.20751
Step 42040: loss = 0.52346
Step 42045: loss = 0.27678
Step 42050: loss = 0.47466
Step 42055: loss = 0.36899
Step 42060: loss = 0.46694
Step 42065: loss = 0.27761
Step 42070: loss = 0.32995
Step 42075: loss = 0.19297
Step 42080: loss = 0.41984
Step 42085: loss = 0.22299
Step 42090: loss = 0.49978
Step 42095: loss = 0.43719
Step 42100: loss = 0.51801
Step 42105: loss = 0.37593
Step 42110: loss = 0.26475
Step 42115: loss = 0.41352
Step 42120: loss = 0.29687
Step 42125: loss = 0.23100
Step 42130: loss = 0.17693
Step 42135: loss = 0.37148
Step 42140: loss = 0.53997
Step 42145: loss = 0.47284
Step 42150: loss = 0.34403
Step 42155: loss = 0.40168
Step 42160: loss = 0.27736
Step 42165: loss = 0.50561
Step 42170: loss = 0.40433
Step 42175: loss = 0.53673
Step 42180: loss = 0.55278
Step 42185: loss = 0.31158
Step 42190: loss = 0.34171
Step 42195: loss = 0.40350
Step 42200: loss = 0.33887
Step 42205: loss = 0.22851
Step 42210: loss = 0.66444
Step 42215: loss = 0.36562
Step 42220: loss = 0.23321
Step 42225: loss = 0.40770
Step 42230: loss = 0.23737
Step 42235: loss = 0.38243
Step 42240: loss = 0.34332
Step 42245: loss = 0.40750
Step 42250: loss = 0.35088
Step 42255: loss = 0.25397
Step 42260: loss = 0.24112
Step 42265: loss = 0.22379
Step 42270: loss = 0.41344
Step 42275: loss = 0.27544
Step 42280: loss = 0.30195
Step 42285: loss = 0.34985
Step 42290: loss = 0.21782
Step 42295: loss = 0.33442
Step 42300: loss = 0.25449
Step 42305: loss = 0.27539
Step 42310: loss = 0.44382
Step 42315: loss = 0.34700
Step 42320: loss = 0.22299
Step 42325: loss = 0.26368
Step 42330: loss = 0.30865
Step 42335: loss = 0.23389
Step 42340: loss = 0.32200
Step 42345: loss = 0.61104
Step 42350: loss = 0.56462
Step 42355: loss = 0.33197
Step 42360: loss = 0.42588
Step 42365: loss = 0.53530
Step 42370: loss = 0.45500
Step 42375: loss = 0.40836
Step 42380: loss = 0.44800
Step 42385: loss = 0.40620
Step 42390: loss = 0.24710
Step 42395: loss = 0.41010
Step 42400: loss = 0.21972
Step 42405: loss = 0.40381
Step 42410: loss = 0.41687
Step 42415: loss = 0.33402
Step 42420: loss = 0.43136
Step 42425: loss = 0.48669
Step 42430: loss = 0.46960
Step 42435: loss = 0.39941
Step 42440: loss = 0.36286
Step 42445: loss = 0.38916
Step 42450: loss = 0.27215
Step 42455: loss = 0.46876
Step 42460: loss = 0.36971
Step 42465: loss = 0.59385
Step 42470: loss = 0.61533
Step 42475: loss = 0.23901
Step 42480: loss = 0.34983
Step 42485: loss = 0.42441
Step 42490: loss = 0.41537
Step 42495: loss = 0.19899
Step 42500: loss = 0.58406
Step 42505: loss = 0.35228
Step 42510: loss = 0.32028
Step 42515: loss = 0.52850
Step 42520: loss = 0.44452
Step 42525: loss = 0.29715
Step 42530: loss = 0.39704
Step 42535: loss = 0.33130
Step 42540: loss = 0.32456
Step 42545: loss = 0.39539
Step 42550: loss = 0.43552
Step 42555: loss = 0.44753
Step 42560: loss = 0.25601
Step 42565: loss = 0.32193
Step 42570: loss = 0.29384
Step 42575: loss = 0.21475
Step 42580: loss = 0.33186
Step 42585: loss = 0.34293
Step 42590: loss = 0.68589
Step 42595: loss = 0.49539
Step 42600: loss = 0.30249
Step 42605: loss = 0.36847
Step 42610: loss = 0.46813
Step 42615: loss = 0.47310
Step 42620: loss = 0.66608
Step 42625: loss = 0.29953
Step 42630: loss = 0.38163
Step 42635: loss = 0.24916
Step 42640: loss = 0.28321
Step 42645: loss = 0.36177
Step 42650: loss = 0.55168
Step 42655: loss = 0.28637
Step 42660: loss = 0.44361
Step 42665: loss = 0.47056
Step 42670: loss = 0.33818
Step 42675: loss = 0.26848
Step 42680: loss = 0.34480
Step 42685: loss = 0.23584
Step 42690: loss = 0.45092
Step 42695: loss = 0.67884
Step 42700: loss = 0.33993
Step 42705: loss = 0.42713
Step 42710: loss = 0.17946
Step 42715: loss = 0.43071
Step 42720: loss = 0.33335
Step 42725: loss = 0.50222
Step 42730: loss = 0.25640
Step 42735: loss = 0.32135
Step 42740: loss = 0.37344
Step 42745: loss = 0.27945
Step 42750: loss = 0.44297
Step 42755: loss = 0.32558
Step 42760: loss = 0.43680
Step 42765: loss = 0.28166
Step 42770: loss = 0.66178
Step 42775: loss = 0.38973
Step 42780: loss = 0.39789
Step 42785: loss = 0.40907
Step 42790: loss = 0.46788
Step 42795: loss = 0.36055
Step 42800: loss = 0.40960
Step 42805: loss = 0.38720
Step 42810: loss = 0.50147
Step 42815: loss = 0.44875
Step 42820: loss = 0.33466
Step 42825: loss = 0.47389
Step 42830: loss = 0.46468
Step 42835: loss = 0.32693
Step 42840: loss = 0.41385
Step 42845: loss = 0.26507
Step 42850: loss = 0.46935
Step 42855: loss = 0.50495
Step 42860: loss = 0.26176
Step 42865: loss = 0.28374
Step 42870: loss = 0.28796
Step 42875: loss = 0.35543
Step 42880: loss = 0.51616
Step 42885: loss = 0.32646
Step 42890: loss = 0.29803
Step 42895: loss = 0.41658
Step 42900: loss = 0.40276
Step 42905: loss = 0.32692
Step 42910: loss = 0.16178
Step 42915: loss = 0.38921
Step 42920: loss = 0.45422
Step 42925: loss = 0.19979
Step 42930: loss = 0.38239
Step 42935: loss = 0.37665
Step 42940: loss = 0.53155
Step 42945: loss = 0.23039
Step 42950: loss = 0.46096
Step 42955: loss = 0.22481
Step 42960: loss = 0.54233
Step 42965: loss = 0.39728
Step 42970: loss = 0.42575
Step 42975: loss = 0.54278
Step 42980: loss = 0.39476
Step 42985: loss = 0.20609
Step 42990: loss = 0.39389
Step 42995: loss = 0.33213
Step 43000: loss = 0.50504
Training Data Eval:
  Num examples: 50000, Num correct: 44207, Precision @ 1: 0.8841
('Testing Data Eval: EPOCH->', 44)
  Num examples: 10000, Num correct: 6497, Precision @ 1: 0.6497
Step 43005: loss = 0.21192
Step 43010: loss = 0.28546
Step 43015: loss = 0.38177
Step 43020: loss = 0.23807
Step 43025: loss = 0.37049
Step 43030: loss = 0.50392
Step 43035: loss = 0.23597
Step 43040: loss = 0.35085
Step 43045: loss = 0.32124
Step 43050: loss = 0.29674
Step 43055: loss = 0.33818
Step 43060: loss = 0.33455
Step 43065: loss = 0.25788
Step 43070: loss = 0.38877
Step 43075: loss = 0.41276
Step 43080: loss = 0.44378
Step 43085: loss = 0.37790
Step 43090: loss = 0.38367
Step 43095: loss = 0.57323
Step 43100: loss = 0.32350
Step 43105: loss = 0.36299
Step 43110: loss = 0.12565
Step 43115: loss = 0.60314
Step 43120: loss = 0.34085
Step 43125: loss = 0.36073
Step 43130: loss = 0.51173
Step 43135: loss = 0.53492
Step 43140: loss = 0.21714
Step 43145: loss = 0.32326
Step 43150: loss = 0.17168
Step 43155: loss = 0.41399
Step 43160: loss = 0.54910
Step 43165: loss = 0.23343
Step 43170: loss = 0.51182
Step 43175: loss = 0.25776
Step 43180: loss = 0.21885
Step 43185: loss = 0.35727
Step 43190: loss = 0.40217
Step 43195: loss = 0.47334
Step 43200: loss = 0.23713
Step 43205: loss = 0.25268
Step 43210: loss = 0.43283
Step 43215: loss = 0.35034
Step 43220: loss = 0.30390
Step 43225: loss = 0.54077
Step 43230: loss = 0.21114
Step 43235: loss = 0.55537
Step 43240: loss = 0.31102
Step 43245: loss = 0.73975
Step 43250: loss = 0.22873
Step 43255: loss = 0.34687
Step 43260: loss = 0.39821
Step 43265: loss = 0.29529
Step 43270: loss = 0.54036
Step 43275: loss = 0.44952
Step 43280: loss = 0.40795
Step 43285: loss = 0.29882
Step 43290: loss = 0.44369
Step 43295: loss = 0.12810
Step 43300: loss = 0.19978
Step 43305: loss = 0.29185
Step 43310: loss = 0.60295
Step 43315: loss = 0.20890
Step 43320: loss = 0.31864
Step 43325: loss = 0.49291
Step 43330: loss = 0.38938
Step 43335: loss = 0.39721
Step 43340: loss = 0.56951
Step 43345: loss = 0.22093
Step 43350: loss = 0.32504
Step 43355: loss = 0.34776
Step 43360: loss = 0.15340
Step 43365: loss = 0.34820
Step 43370: loss = 0.34212
Step 43375: loss = 0.49858
Step 43380: loss = 0.29396
Step 43385: loss = 0.47812
Step 43390: loss = 0.40113
Step 43395: loss = 0.46884
Step 43400: loss = 0.58725
Step 43405: loss = 0.38630
Step 43410: loss = 0.23670
Step 43415: loss = 0.44475
Step 43420: loss = 0.33845
Step 43425: loss = 0.39816
Step 43430: loss = 0.46374
Step 43435: loss = 0.34616
Step 43440: loss = 0.19150
Step 43445: loss = 0.12338
Step 43450: loss = 0.43159
Step 43455: loss = 0.24963
Step 43460: loss = 0.58030
Step 43465: loss = 0.47055
Step 43470: loss = 0.56521
Step 43475: loss = 0.66049
Step 43480: loss = 0.39555
Step 43485: loss = 0.74847
Step 43490: loss = 0.16215
Step 43495: loss = 0.40159
Step 43500: loss = 0.46159
Step 43505: loss = 0.47939
Step 43510: loss = 0.25252
Step 43515: loss = 0.59587
Step 43520: loss = 0.30974
Step 43525: loss = 0.36087
Step 43530: loss = 0.46652
Step 43535: loss = 0.54484
Step 43540: loss = 0.40106
Step 43545: loss = 0.45961
Step 43550: loss = 0.36131
Step 43555: loss = 0.33262
Step 43560: loss = 0.32720
Step 43565: loss = 0.24895
Step 43570: loss = 0.40266
Step 43575: loss = 0.28042
Step 43580: loss = 0.40221
Step 43585: loss = 0.31775
Step 43590: loss = 0.40063
Step 43595: loss = 0.81568
Step 43600: loss = 0.45892
Step 43605: loss = 0.24357
Step 43610: loss = 0.53053
Step 43615: loss = 0.18956
Step 43620: loss = 0.32837
Step 43625: loss = 0.36352
Step 43630: loss = 0.33626
Step 43635: loss = 0.48081
Step 43640: loss = 0.24272
Step 43645: loss = 0.28011
Step 43650: loss = 0.36234
Step 43655: loss = 0.35767
Step 43660: loss = 0.61028
Step 43665: loss = 0.54864
Step 43670: loss = 0.25838
Step 43675: loss = 0.24830
Step 43680: loss = 0.19001
Step 43685: loss = 0.21125
Step 43690: loss = 0.35903
Step 43695: loss = 0.41021
Step 43700: loss = 0.33692
Step 43705: loss = 0.47650
Step 43710: loss = 0.44408
Step 43715: loss = 0.36823
Step 43720: loss = 0.23205
Step 43725: loss = 0.16017
Step 43730: loss = 0.33619
Step 43735: loss = 0.52602
Step 43740: loss = 0.40019
Step 43745: loss = 0.62269
Step 43750: loss = 0.31298
Step 43755: loss = 0.49470
Step 43760: loss = 0.30198
Step 43765: loss = 0.23877
Step 43770: loss = 0.63694
Step 43775: loss = 0.36990
Step 43780: loss = 0.44360
Step 43785: loss = 0.52575
Step 43790: loss = 0.33511
Step 43795: loss = 0.41165
Step 43800: loss = 0.35171
Step 43805: loss = 0.47378
Step 43810: loss = 0.42259
Step 43815: loss = 0.36479
Step 43820: loss = 0.25503
Step 43825: loss = 0.34291
Step 43830: loss = 0.56132
Step 43835: loss = 0.33667
Step 43840: loss = 0.29752
Step 43845: loss = 0.38947
Step 43850: loss = 0.29894
Step 43855: loss = 0.30740
Step 43860: loss = 0.33186
Step 43865: loss = 0.32398
Step 43870: loss = 0.35221
Step 43875: loss = 0.36701
Step 43880: loss = 0.58683
Step 43885: loss = 0.37712
Step 43890: loss = 0.29210
Step 43895: loss = 0.39222
Step 43900: loss = 0.39944
Step 43905: loss = 0.33837
Step 43910: loss = 0.27262
Step 43915: loss = 0.20136
Step 43920: loss = 0.15257
Step 43925: loss = 0.43141
Step 43930: loss = 0.49135
Step 43935: loss = 0.31390
Step 43940: loss = 0.24813
Step 43945: loss = 0.27595
Step 43950: loss = 0.38713
Step 43955: loss = 0.40799
Step 43960: loss = 0.34312
Step 43965: loss = 0.36483
Step 43970: loss = 0.23264
Step 43975: loss = 0.50328
Step 43980: loss = 0.32504
Step 43985: loss = 0.24868
Step 43990: loss = 0.24867
Step 43995: loss = 0.33076
Step 44000: loss = 0.63754
Training Data Eval:
  Num examples: 50000, Num correct: 44104, Precision @ 1: 0.8821
('Testing Data Eval: EPOCH->', 45)
  Num examples: 10000, Num correct: 6348, Precision @ 1: 0.6348
Step 44005: loss = 0.31104
Step 44010: loss = 0.20722
Step 44015: loss = 0.30296
Step 44020: loss = 0.19336
Step 44025: loss = 0.15598
Step 44030: loss = 0.28993
Step 44035: loss = 0.42468
Step 44040: loss = 0.31023
Step 44045: loss = 0.30454
Step 44050: loss = 0.35029
Step 44055: loss = 0.35983
Step 44060: loss = 0.26115
Step 44065: loss = 0.20416
Step 44070: loss = 0.31816
Step 44075: loss = 0.18629
Step 44080: loss = 0.46594
Step 44085: loss = 0.54452
Step 44090: loss = 0.28510
Step 44095: loss = 0.45844
Step 44100: loss = 0.32957
Step 44105: loss = 0.30912
Step 44110: loss = 0.32668
Step 44115: loss = 0.15710
Step 44120: loss = 0.41540
Step 44125: loss = 0.40223
Step 44130: loss = 0.29737
Step 44135: loss = 0.21480
Step 44140: loss = 0.33363
Step 44145: loss = 0.26814
Step 44150: loss = 0.27647
Step 44155: loss = 0.38001
Step 44160: loss = 0.44768
Step 44165: loss = 0.49253
Step 44170: loss = 0.23085
Step 44175: loss = 0.36062
Step 44180: loss = 0.36744
Step 44185: loss = 0.40251
Step 44190: loss = 0.68982
Step 44195: loss = 0.29222
Step 44200: loss = 0.40044
Step 44205: loss = 0.33846
Step 44210: loss = 0.28653
Step 44215: loss = 0.40984
Step 44220: loss = 0.22536
Step 44225: loss = 0.29254
Step 44230: loss = 0.52271
Step 44235: loss = 0.38771
Step 44240: loss = 0.32774
Step 44245: loss = 0.45921
Step 44250: loss = 0.44419
Step 44255: loss = 0.22989
Step 44260: loss = 0.39669
Step 44265: loss = 0.75853
Step 44270: loss = 0.53923
Step 44275: loss = 0.44001
Step 44280: loss = 0.42464
Step 44285: loss = 0.23161
Step 44290: loss = 0.37845
Step 44295: loss = 0.33331
Step 44300: loss = 0.40632
Step 44305: loss = 0.64253
Step 44310: loss = 0.56417
Step 44315: loss = 0.35491
Step 44320: loss = 0.58240
Step 44325: loss = 0.59669
Step 44330: loss = 0.14527
Step 44335: loss = 0.34813
Step 44340: loss = 0.29552
Step 44345: loss = 0.19216
Step 44350: loss = 0.37810
Step 44355: loss = 0.52723
Step 44360: loss = 0.45483
Step 44365: loss = 0.56285
Step 44370: loss = 0.30598
Step 44375: loss = 0.23969
Step 44380: loss = 0.23707
Step 44385: loss = 0.27006
Step 44390: loss = 0.16224
Step 44395: loss = 0.22558
Step 44400: loss = 0.32170
Step 44405: loss = 0.28409
Step 44410: loss = 0.41906
Step 44415: loss = 0.23237
Step 44420: loss = 0.15557
Step 44425: loss = 0.29275
Step 44430: loss = 0.47720
Step 44435: loss = 0.60523
Step 44440: loss = 0.40245
Step 44445: loss = 0.31503
Step 44450: loss = 0.26846
Step 44455: loss = 0.42302
Step 44460: loss = 0.34134
Step 44465: loss = 0.27608
Step 44470: loss = 0.32213
Step 44475: loss = 0.23453
Step 44480: loss = 0.37169
Step 44485: loss = 0.43143
Step 44490: loss = 0.36434
Step 44495: loss = 0.31003
Step 44500: loss = 0.41285
Step 44505: loss = 0.28533
Step 44510: loss = 0.35387
Step 44515: loss = 0.75219
Step 44520: loss = 0.58349
Step 44525: loss = 0.26229
Step 44530: loss = 0.27374
Step 44535: loss = 0.38538
Step 44540: loss = 0.34795
Step 44545: loss = 0.17751
Step 44550: loss = 0.30564
Step 44555: loss = 0.42909
Step 44560: loss = 0.53627
Step 44565: loss = 0.37268
Step 44570: loss = 0.06641
Step 44575: loss = 0.41009
Step 44580: loss = 0.46241
Step 44585: loss = 0.40794
Step 44590: loss = 0.21549
Step 44595: loss = 0.24225
Step 44600: loss = 0.37350
Step 44605: loss = 0.32575
Step 44610: loss = 0.37285
Step 44615: loss = 0.25725
Step 44620: loss = 0.19917
Step 44625: loss = 0.28865
Step 44630: loss = 0.46780
Step 44635: loss = 0.42956
Step 44640: loss = 0.42206
Step 44645: loss = 0.30562
Step 44650: loss = 0.24295
Step 44655: loss = 0.22299
Step 44660: loss = 0.43866
Step 44665: loss = 0.37147
Step 44670: loss = 0.52038
Step 44675: loss = 0.23121
Step 44680: loss = 0.48374
Step 44685: loss = 0.36187
Step 44690: loss = 0.32725
Step 44695: loss = 0.41868
Step 44700: loss = 0.32375
Step 44705: loss = 0.54119
Step 44710: loss = 0.30717
Step 44715: loss = 0.46082
Step 44720: loss = 0.50931
Step 44725: loss = 0.38234
Step 44730: loss = 0.31178
Step 44735: loss = 0.27837
Step 44740: loss = 0.38712
Step 44745: loss = 0.59203
Step 44750: loss = 0.33024
Step 44755: loss = 0.35144
Step 44760: loss = 0.49785
Step 44765: loss = 0.43162
Step 44770: loss = 0.30341
Step 44775: loss = 0.48930
Step 44780: loss = 0.47258
Step 44785: loss = 0.29519
Step 44790: loss = 0.26988
Step 44795: loss = 0.39678
Step 44800: loss = 0.42673
Step 44805: loss = 0.36751
Step 44810: loss = 0.28222
Step 44815: loss = 0.25125
Step 44820: loss = 0.33468
Step 44825: loss = 0.36097
Step 44830: loss = 0.29013
Step 44835: loss = 0.27180
Step 44840: loss = 0.59379
Step 44845: loss = 0.70200
Step 44850: loss = 0.43660
Step 44855: loss = 0.67649
Step 44860: loss = 0.40855
Step 44865: loss = 0.23280
Step 44870: loss = 0.42122
Step 44875: loss = 0.44900
Step 44880: loss = 0.30137
Step 44885: loss = 0.32994
Step 44890: loss = 0.47068
Step 44895: loss = 0.30990
Step 44900: loss = 0.37176
Step 44905: loss = 0.42587
Step 44910: loss = 0.33503
Step 44915: loss = 0.46594
Step 44920: loss = 0.52008
Step 44925: loss = 0.33713
Step 44930: loss = 0.28039
Step 44935: loss = 0.65067
Step 44940: loss = 0.17083
Step 44945: loss = 0.40469
Step 44950: loss = 0.33097
Step 44955: loss = 0.39938
Step 44960: loss = 0.24096
Step 44965: loss = 0.36750
Step 44970: loss = 0.41901
Step 44975: loss = 0.20211
Step 44980: loss = 0.65927
Step 44985: loss = 0.48121
Step 44990: loss = 0.28083
Step 44995: loss = 0.43468
Step 45000: loss = 0.31186
Training Data Eval:
  Num examples: 50000, Num correct: 43999, Precision @ 1: 0.8800
('Testing Data Eval: EPOCH->', 46)
  Num examples: 10000, Num correct: 6400, Precision @ 1: 0.6400
Step 45005: loss = 0.18991
Step 45010: loss = 0.29605
Step 45015: loss = 0.27867
Step 45020: loss = 0.32666
Step 45025: loss = 0.25686
Step 45030: loss = 0.45494
Step 45035: loss = 0.30104
Step 45040: loss = 0.32261
Step 45045: loss = 0.32874
Step 45050: loss = 0.21702
Step 45055: loss = 0.43090
Step 45060: loss = 0.41763
Step 45065: loss = 0.35377
Step 45070: loss = 0.67373
Step 45075: loss = 0.12420
Step 45080: loss = 0.40280
Step 45085: loss = 0.13841
Step 45090: loss = 0.19406
Step 45095: loss = 0.30767
Step 45100: loss = 0.35853
Step 45105: loss = 0.37729
Step 45110: loss = 0.11525
Step 45115: loss = 0.34648
Step 45120: loss = 0.25546
Step 45125: loss = 0.34144
Step 45130: loss = 0.24800
Step 45135: loss = 0.28782
Step 45140: loss = 0.31057
Step 45145: loss = 0.28315
Step 45150: loss = 0.26492
Step 45155: loss = 0.25636
Step 45160: loss = 0.19707
Step 45165: loss = 0.32586
Step 45170: loss = 0.15371
Step 45175: loss = 0.30649
Step 45180: loss = 0.37447
Step 45185: loss = 0.23964
Step 45190: loss = 0.74778
Step 45195: loss = 0.50703
Step 45200: loss = 0.57807
Step 45205: loss = 0.58804
Step 45210: loss = 0.32978
Step 45215: loss = 0.26023
Step 45220: loss = 0.27515
Step 45225: loss = 0.32783
Step 45230: loss = 0.25284
Step 45235: loss = 0.15948
Step 45240: loss = 0.36137
Step 45245: loss = 0.22055
Step 45250: loss = 0.30702
Step 45255: loss = 0.18936
Step 45260: loss = 0.45716
Step 45265: loss = 0.46381
Step 45270: loss = 0.14336
Step 45275: loss = 0.32245
Step 45280: loss = 0.30292
Step 45285: loss = 0.22247
Step 45290: loss = 0.28374
Step 45295: loss = 0.31725
Step 45300: loss = 0.22285
Step 45305: loss = 0.19340
Step 45310: loss = 0.27124
Step 45315: loss = 0.25662
Step 45320: loss = 0.26849
Step 45325: loss = 0.29349
Step 45330: loss = 0.18458
Step 45335: loss = 0.36630
Step 45340: loss = 0.49136
Step 45345: loss = 0.39323
Step 45350: loss = 0.38348
Step 45355: loss = 0.29758
Step 45360: loss = 0.24668
Step 45365: loss = 0.28179
Step 45370: loss = 0.20698
Step 45375: loss = 0.37657
Step 45380: loss = 0.22879
Step 45385: loss = 0.48254
Step 45390: loss = 0.41699
Step 45395: loss = 0.25813
Step 45400: loss = 0.72576
Step 45405: loss = 0.24639
Step 45410: loss = 0.36383
Step 45415: loss = 0.30498
Step 45420: loss = 0.44128
Step 45425: loss = 0.24442
Step 45430: loss = 0.73196
Step 45435: loss = 0.50210
Step 45440: loss = 0.40017
Step 45445: loss = 0.45179
Step 45450: loss = 0.29833
Step 45455: loss = 0.48289
Step 45460: loss = 0.13318
Step 45465: loss = 0.50019
Step 45470: loss = 0.29094
Step 45475: loss = 0.35360
Step 45480: loss = 0.36288
Step 45485: loss = 0.23843
Step 45490: loss = 0.42274
Step 45495: loss = 0.37821
Step 45500: loss = 0.43206
Step 45505: loss = 0.21195
Step 45510: loss = 0.23540
Step 45515: loss = 0.34782
Step 45520: loss = 0.29550
Step 45525: loss = 0.63526
Step 45530: loss = 0.41539
Step 45535: loss = 0.38421
Step 45540: loss = 0.20665
Step 45545: loss = 0.41307
Step 45550: loss = 0.71514
Step 45555: loss = 0.61104
Step 45560: loss = 0.40499
Step 45565: loss = 0.19740
Step 45570: loss = 0.23447
Step 45575: loss = 0.41534
Step 45580: loss = 0.25715
Step 45585: loss = 0.32354
Step 45590: loss = 0.28921
Step 45595: loss = 0.56552
Step 45600: loss = 0.46687
Step 45605: loss = 0.29792
Step 45610: loss = 0.23061
Step 45615: loss = 0.40769
Step 45620: loss = 0.33107
Step 45625: loss = 0.52781
Step 45630: loss = 0.44647
Step 45635: loss = 0.79376
Step 45640: loss = 0.26010
Step 45645: loss = 0.32441
Step 45650: loss = 0.47432
Step 45655: loss = 0.30163
Step 45660: loss = 0.37500
Step 45665: loss = 0.36634
Step 45670: loss = 0.29992
Step 45675: loss = 0.28112
Step 45680: loss = 0.29802
Step 45685: loss = 0.53054
Step 45690: loss = 0.30653
Step 45695: loss = 0.45993
Step 45700: loss = 0.28215
Step 45705: loss = 0.44377
Step 45710: loss = 0.41078
Step 45715: loss = 0.27172
Step 45720: loss = 0.28782
Step 45725: loss = 0.42690
Step 45730: loss = 0.35027
Step 45735: loss = 0.15098
Step 45740: loss = 0.29824
Step 45745: loss = 0.55138
Step 45750: loss = 0.29312
Step 45755: loss = 0.38222
Step 45760: loss = 0.26848
Step 45765: loss = 0.31202
Step 45770: loss = 0.31688
Step 45775: loss = 0.22566
Step 45780: loss = 0.35451
Step 45785: loss = 0.36710
Step 45790: loss = 0.14871
Step 45795: loss = 0.33780
Step 45800: loss = 0.51565
Step 45805: loss = 0.20065
Step 45810: loss = 0.42257
Step 45815: loss = 0.29593
Step 45820: loss = 0.47268
Step 45825: loss = 0.44834
Step 45830: loss = 0.24798
Step 45835: loss = 0.36877
Step 45840: loss = 0.47017
Step 45845: loss = 0.35798
Step 45850: loss = 0.52595
Step 45855: loss = 0.35196
Step 45860: loss = 0.37723
Step 45865: loss = 0.21417
Step 45870: loss = 0.30894
Step 45875: loss = 0.29798
Step 45880: loss = 0.32633
Step 45885: loss = 0.27459
Step 45890: loss = 0.62132
Step 45895: loss = 0.34863
Step 45900: loss = 0.25362
Step 45905: loss = 0.46900
Step 45910: loss = 0.42879
Step 45915: loss = 0.76293
Step 45920: loss = 0.26020
Step 45925: loss = 0.24564
Step 45930: loss = 0.28522
Step 45935: loss = 0.22923
Step 45940: loss = 0.46195
Step 45945: loss = 0.52077
Step 45950: loss = 0.44494
Step 45955: loss = 0.31746
Step 45960: loss = 0.32433
Step 45965: loss = 0.70889
Step 45970: loss = 0.31660
Step 45975: loss = 0.52706
Step 45980: loss = 0.39067
Step 45985: loss = 0.11035
Step 45990: loss = 0.39572
Step 45995: loss = 0.39485
Step 46000: loss = 0.34877
Training Data Eval:
  Num examples: 50000, Num correct: 43081, Precision @ 1: 0.8616
('Testing Data Eval: EPOCH->', 47)
  Num examples: 10000, Num correct: 6339, Precision @ 1: 0.6339
Step 46005: loss = 0.18745
Step 46010: loss = 0.45852
Step 46015: loss = 0.31724
Step 46020: loss = 0.23904
Step 46025: loss = 0.39868
Step 46030: loss = 0.32015
Step 46035: loss = 0.26656
Step 46040: loss = 0.32432
Step 46045: loss = 0.42026
Step 46050: loss = 0.41362
Step 46055: loss = 0.20480
Step 46060: loss = 0.23173
Step 46065: loss = 0.22051
Step 46070: loss = 0.36352
Step 46075: loss = 0.23853
Step 46080: loss = 0.36981
Step 46085: loss = 0.25238
Step 46090: loss = 0.27275
Step 46095: loss = 0.39158
Step 46100: loss = 0.54527
Step 46105: loss = 0.38793
Step 46110: loss = 0.38391
Step 46115: loss = 0.45772
Step 46120: loss = 0.42527
Step 46125: loss = 0.59339
Step 46130: loss = 0.17596
Step 46135: loss = 0.57119
Step 46140: loss = 0.19841
Step 46145: loss = 0.25898
Step 46150: loss = 0.29395
Step 46155: loss = 0.28840
Step 46160: loss = 0.34332
Step 46165: loss = 0.53357
Step 46170: loss = 0.19326
Step 46175: loss = 0.30555
Step 46180: loss = 0.68743
Step 46185: loss = 0.38986
Step 46190: loss = 0.25210
Step 46195: loss = 0.22610
Step 46200: loss = 0.50247
Step 46205: loss = 0.25048
Step 46210: loss = 0.28463
Step 46215: loss = 0.44775
Step 46220: loss = 0.11951
Step 46225: loss = 0.23792
Step 46230: loss = 0.23784
Step 46235: loss = 0.47003
Step 46240: loss = 0.54008
Step 46245: loss = 0.31509
Step 46250: loss = 0.18165
Step 46255: loss = 0.19709
Step 46260: loss = 0.55140
Step 46265: loss = 0.40538
Step 46270: loss = 0.35161
Step 46275: loss = 0.38610
Step 46280: loss = 0.34946
Step 46285: loss = 0.53444
Step 46290: loss = 0.32898
Step 46295: loss = 0.29854
Step 46300: loss = 0.40248
Step 46305: loss = 0.38534
Step 46310: loss = 0.35159
Step 46315: loss = 0.36982
Step 46320: loss = 0.51011
Step 46325: loss = 0.47251
Step 46330: loss = 0.24987
Step 46335: loss = 0.25873
Step 46340: loss = 0.41434
Step 46345: loss = 0.42584
Step 46350: loss = 0.44018
Step 46355: loss = 0.34999
Step 46360: loss = 0.17542
Step 46365: loss = 0.39069
Step 46370: loss = 0.12222
Step 46375: loss = 0.33418
Step 46380: loss = 0.35430
Step 46385: loss = 0.29396
Step 46390: loss = 0.68835
Step 46395: loss = 0.35202
Step 46400: loss = 0.22667
Step 46405: loss = 0.26726
Step 46410: loss = 0.21401
Step 46415: loss = 0.18326
Step 46420: loss = 0.50925
Step 46425: loss = 0.34935
Step 46430: loss = 0.50298
Step 46435: loss = 0.19586
Step 46440: loss = 0.15788
Step 46445: loss = 0.38499
Step 46450: loss = 0.31360
Step 46455: loss = 0.18369
Step 46460: loss = 0.23389
Step 46465: loss = 0.27947
Step 46470: loss = 0.29970
Step 46475: loss = 0.63131
Step 46480: loss = 0.31315
Step 46485: loss = 0.39358
Step 46490: loss = 0.34107
Step 46495: loss = 0.27849
Step 46500: loss = 0.34110
Step 46505: loss = 0.45973
Step 46510: loss = 0.25410
Step 46515: loss = 0.47080
Step 46520: loss = 0.55361
Step 46525: loss = 0.25650
Step 46530: loss = 0.35113
Step 46535: loss = 0.39328
Step 46540: loss = 0.21419
Step 46545: loss = 0.26375
Step 46550: loss = 0.34372
Step 46555: loss = 0.43989
Step 46560: loss = 0.46563
Step 46565: loss = 0.31886
Step 46570: loss = 0.28781
Step 46575: loss = 0.61551
Step 46580: loss = 0.32846
Step 46585: loss = 0.36841
Step 46590: loss = 0.58258
Step 46595: loss = 0.28337
Step 46600: loss = 0.27208
Step 46605: loss = 0.43069
Step 46610: loss = 0.40185
Step 46615: loss = 0.20516
Step 46620: loss = 0.37969
Step 46625: loss = 0.51155
Step 46630: loss = 0.18184
Step 46635: loss = 0.24567
Step 46640: loss = 0.29929
Step 46645: loss = 0.38369
Step 46650: loss = 0.29559
Step 46655: loss = 0.25585
Step 46660: loss = 0.55917
Step 46665: loss = 0.22198
Step 46670: loss = 0.41512
Step 46675: loss = 0.70614
Step 46680: loss = 0.46928
Step 46685: loss = 0.26402
Step 46690: loss = 0.25938
Step 46695: loss = 0.18957
Step 46700: loss = 0.71499
Step 46705: loss = 0.22145
Step 46710: loss = 0.38297
Step 46715: loss = 0.39719
Step 46720: loss = 0.40133
Step 46725: loss = 0.53032
Step 46730: loss = 0.28740
Step 46735: loss = 0.39548
Step 46740: loss = 0.36438
Step 46745: loss = 0.20676
Step 46750: loss = 0.32808
Step 46755: loss = 0.12552
Step 46760: loss = 0.40427
Step 46765: loss = 0.39859
Step 46770: loss = 0.22553
Step 46775: loss = 0.38502
Step 46780: loss = 0.35377
Step 46785: loss = 0.39221
Step 46790: loss = 0.29814
Step 46795: loss = 0.37137
Step 46800: loss = 0.37690
Step 46805: loss = 0.34651
Step 46810: loss = 0.50426
Step 46815: loss = 0.24170
Step 46820: loss = 0.48181
Step 46825: loss = 0.44553
Step 46830: loss = 0.29326
Step 46835: loss = 0.24175
Step 46840: loss = 0.37871
Step 46845: loss = 0.47872
Step 46850: loss = 0.81109
Step 46855: loss = 0.49626
Step 46860: loss = 0.55962
Step 46865: loss = 0.16449
Step 46870: loss = 0.39871
Step 46875: loss = 0.46751
Step 46880: loss = 0.24892
Step 46885: loss = 0.37201
Step 46890: loss = 0.31487
Step 46895: loss = 0.39319
Step 46900: loss = 0.31199
Step 46905: loss = 0.57688
Step 46910: loss = 0.34414
Step 46915: loss = 0.88732
Step 46920: loss = 0.35355
Step 46925: loss = 0.26522
Step 46930: loss = 0.31275
Step 46935: loss = 0.40509
Step 46940: loss = 0.21756
Step 46945: loss = 0.33538
Step 46950: loss = 0.53200
Step 46955: loss = 0.47972
Step 46960: loss = 0.30644
Step 46965: loss = 0.40879
Step 46970: loss = 0.21100
Step 46975: loss = 0.28958
Step 46980: loss = 0.52186
Step 46985: loss = 0.41240
Step 46990: loss = 0.20956
Step 46995: loss = 0.42491
Step 47000: loss = 0.39673
Training Data Eval:
  Num examples: 50000, Num correct: 44270, Precision @ 1: 0.8854
('Testing Data Eval: EPOCH->', 48)
  Num examples: 10000, Num correct: 6500, Precision @ 1: 0.6500
Step 47005: loss = 0.32474
Step 47010: loss = 0.26217
Step 47015: loss = 0.61063
Step 47020: loss = 0.19842
Step 47025: loss = 0.47907
Step 47030: loss = 0.50738
Step 47035: loss = 0.18332
Step 47040: loss = 0.47110
Step 47045: loss = 0.26966
Step 47050: loss = 0.15020
Step 47055: loss = 0.41709
Step 47060: loss = 0.43913
Step 47065: loss = 0.09226
Step 47070: loss = 0.31512
Step 47075: loss = 0.27857
Step 47080: loss = 0.10517
Step 47085: loss = 0.15251
Step 47090: loss = 0.55096
Step 47095: loss = 0.37907
Step 47100: loss = 0.51463
Step 47105: loss = 0.15470
Step 47110: loss = 0.42981
Step 47115: loss = 0.40184
Step 47120: loss = 0.42425
Step 47125: loss = 0.32087
Step 47130: loss = 0.40000
Step 47135: loss = 0.28109
Step 47140: loss = 0.24835
Step 47145: loss = 0.41639
Step 47150: loss = 0.48590
Step 47155: loss = 0.40473
Step 47160: loss = 0.24677
Step 47165: loss = 0.19147
Step 47170: loss = 0.30662
Step 47175: loss = 0.11316
Step 47180: loss = 0.21024
Step 47185: loss = 0.50110
Step 47190: loss = 0.37019
Step 47195: loss = 0.36821
Step 47200: loss = 0.42977
Step 47205: loss = 0.35524
Step 47210: loss = 0.44514
Step 47215: loss = 0.34048
Step 47220: loss = 0.49385
Step 47225: loss = 0.21530
Step 47230: loss = 0.24917
Step 47235: loss = 0.44410
Step 47240: loss = 0.21743
Step 47245: loss = 0.23814
Step 47250: loss = 0.42721
Step 47255: loss = 0.30966
Step 47260: loss = 0.19458
Step 47265: loss = 0.43349
Step 47270: loss = 0.26124
Step 47275: loss = 0.23306
Step 47280: loss = 0.52640
Step 47285: loss = 0.38444
Step 47290: loss = 0.30252
Step 47295: loss = 0.25629
Step 47300: loss = 0.55881
Step 47305: loss = 0.72518
Step 47310: loss = 0.52211
Step 47315: loss = 0.21642
Step 47320: loss = 0.34744
Step 47325: loss = 0.28634
Step 47330: loss = 0.22010
Step 47335: loss = 0.26594
Step 47340: loss = 0.14111
Step 47345: loss = 0.36936
Step 47350: loss = 0.28989
Step 47355: loss = 0.45074
Step 47360: loss = 0.40581
Step 47365: loss = 0.16934
Step 47370: loss = 0.56091
Step 47375: loss = 0.48573
Step 47380: loss = 0.28615
Step 47385: loss = 0.25642
Step 47390: loss = 0.30276
Step 47395: loss = 0.37601
Step 47400: loss = 0.52358
Step 47405: loss = 0.13497
Step 47410: loss = 0.23801
Step 47415: loss = 0.43795
Step 47420: loss = 0.49536
Step 47425: loss = 0.38386
Step 47430: loss = 0.18639
Step 47435: loss = 0.49239
Step 47440: loss = 0.36330
Step 47445: loss = 0.22153
Step 47450: loss = 0.22808
Step 47455: loss = 0.26244
Step 47460: loss = 0.21082
Step 47465: loss = 0.49649
Step 47470: loss = 0.37616
Step 47475: loss = 0.61857
Step 47480: loss = 0.27765
Step 47485: loss = 0.20145
Step 47490: loss = 0.25115
Step 47495: loss = 0.34242
Step 47500: loss = 0.25892
Step 47505: loss = 0.20464
Step 47510: loss = 0.21399
Step 47515: loss = 0.35440
Step 47520: loss = 0.42889
Step 47525: loss = 0.30172
Step 47530: loss = 0.26711
Step 47535: loss = 0.28995
Step 47540: loss = 0.31194
Step 47545: loss = 0.29949
Step 47550: loss = 0.35018
Step 47555: loss = 0.26823
Step 47560: loss = 0.37594
Step 47565: loss = 0.35367
Step 47570: loss = 0.31768
Step 47575: loss = 0.30529
Step 47580: loss = 0.28458
Step 47585: loss = 0.11949
Step 47590: loss = 0.28102
Step 47595: loss = 0.21803
Step 47600: loss = 0.35782
Step 47605: loss = 0.22913
Step 47610: loss = 0.28836
Step 47615: loss = 0.20463
Step 47620: loss = 0.19126
Step 47625: loss = 0.27129
Step 47630: loss = 0.23742
Step 47635: loss = 0.26297
Step 47640: loss = 0.35566
Step 47645: loss = 0.60404
Step 47650: loss = 0.45218
Step 47655: loss = 0.40702
Step 47660: loss = 0.36729
Step 47665: loss = 0.20375
Step 47670: loss = 0.35762
Step 47675: loss = 0.27504
Step 47680: loss = 0.27669
Step 47685: loss = 0.40397
Step 47690: loss = 0.35938
Step 47695: loss = 0.22059
Step 47700: loss = 0.23404
Step 47705: loss = 0.32318
Step 47710: loss = 0.32368
Step 47715: loss = 0.25875
Step 47720: loss = 0.33834
Step 47725: loss = 0.28507
Step 47730: loss = 0.36794
Step 47735: loss = 0.39219
Step 47740: loss = 0.36931
Step 47745: loss = 0.24573
Step 47750: loss = 0.12555
Step 47755: loss = 0.20009
Step 47760: loss = 0.33277
Step 47765: loss = 0.15812
Step 47770: loss = 0.43398
Step 47775: loss = 0.56011
Step 47780: loss = 0.20990
Step 47785: loss = 0.17348
Step 47790: loss = 0.28254
Step 47795: loss = 0.53341
Step 47800: loss = 0.41721
Step 47805: loss = 0.35258
Step 47810: loss = 0.23147
Step 47815: loss = 0.39107
Step 47820: loss = 0.26734
Step 47825: loss = 0.28727
Step 47830: loss = 0.46692
Step 47835: loss = 0.46372
Step 47840: loss = 0.38385
Step 47845: loss = 0.21564
Step 47850: loss = 0.70221
Step 47855: loss = 0.23095
Step 47860: loss = 0.42408
Step 47865: loss = 0.46275
Step 47870: loss = 0.22770
Step 47875: loss = 0.36201
Step 47880: loss = 0.34003
Step 47885: loss = 0.70496
Step 47890: loss = 0.40585
Step 47895: loss = 0.65987
Step 47900: loss = 0.36128
Step 47905: loss = 0.52756
Step 47910: loss = 0.42581
Step 47915: loss = 0.32215
Step 47920: loss = 0.35117
Step 47925: loss = 0.31616
Step 47930: loss = 0.47262
Step 47935: loss = 0.25341
Step 47940: loss = 0.23260
Step 47945: loss = 0.58161
Step 47950: loss = 0.47387
Step 47955: loss = 0.28763
Step 47960: loss = 0.39148
Step 47965: loss = 0.26470
Step 47970: loss = 0.48232
Step 47975: loss = 0.32174
Step 47980: loss = 0.50839
Step 47985: loss = 0.25358
Step 47990: loss = 0.31626
Step 47995: loss = 0.27681
Step 48000: loss = 0.34332
Training Data Eval:
  Num examples: 50000, Num correct: 44492, Precision @ 1: 0.8898
('Testing Data Eval: EPOCH->', 49)
  Num examples: 10000, Num correct: 6418, Precision @ 1: 0.6418
Step 48005: loss = 0.15971
Step 48010: loss = 0.45645
Step 48015: loss = 0.66480
Step 48020: loss = 0.16883
Step 48025: loss = 0.33544
Step 48030: loss = 0.21986
Step 48035: loss = 0.24935
Step 48040: loss = 0.30653
Step 48045: loss = 0.24307
Step 48050: loss = 0.34709
Step 48055: loss = 0.24034
Step 48060: loss = 0.17617
Step 48065: loss = 0.11796
Step 48070: loss = 0.12528
Step 48075: loss = 0.21706
Step 48080: loss = 0.35238
Step 48085: loss = 0.10039
Step 48090: loss = 0.30765
Step 48095: loss = 0.39897
Step 48100: loss = 0.36564
Step 48105: loss = 0.46430
Step 48110: loss = 0.35022
Step 48115: loss = 0.29879
Step 48120: loss = 0.21279
Step 48125: loss = 0.33749
Step 48130: loss = 0.33460
Step 48135: loss = 0.33470
Step 48140: loss = 0.47863
Step 48145: loss = 0.18674
Step 48150: loss = 0.24126
Step 48155: loss = 0.36804
Step 48160: loss = 0.35940
Step 48165: loss = 0.30571
Step 48170: loss = 0.60898
Step 48175: loss = 0.35143
Step 48180: loss = 0.24093
Step 48185: loss = 0.48701
Step 48190: loss = 0.14294
Step 48195: loss = 0.25494
Step 48200: loss = 0.51554
Step 48205: loss = 0.43917
Step 48210: loss = 0.20034
Step 48215: loss = 0.25552
Step 48220: loss = 0.27629
Step 48225: loss = 0.42559
Step 48230: loss = 0.51194
Step 48235: loss = 0.45347
Step 48240: loss = 0.26292
Step 48245: loss = 0.30757
Step 48250: loss = 0.32843
Step 48255: loss = 0.26496
Step 48260: loss = 0.23795
Step 48265: loss = 0.28796
Step 48270: loss = 0.33842
Step 48275: loss = 0.48204
Step 48280: loss = 0.32332
Step 48285: loss = 0.28538
Step 48290: loss = 0.31347
Step 48295: loss = 0.51534
Step 48300: loss = 0.56727
Step 48305: loss = 0.41445
Step 48310: loss = 0.46157
Step 48315: loss = 0.23356
Step 48320: loss = 0.37122
Step 48325: loss = 0.44315
Step 48330: loss = 0.46245
Step 48335: loss = 0.41971
Step 48340: loss = 0.50258
Step 48345: loss = 0.45029
Step 48350: loss = 0.23735
Step 48355: loss = 0.22843
Step 48360: loss = 0.40342
Step 48365: loss = 0.39915
Step 48370: loss = 0.35499
Step 48375: loss = 0.43259
Step 48380: loss = 0.47142
Step 48385: loss = 0.42136
Step 48390: loss = 0.78760
Step 48395: loss = 0.18100
Step 48400: loss = 0.29218
Step 48405: loss = 0.21265
Step 48410: loss = 0.39812
Step 48415: loss = 0.28194
Step 48420: loss = 0.37361
Step 48425: loss = 0.37743
Step 48430: loss = 0.32352
Step 48435: loss = 0.27215
Step 48440: loss = 0.43146
Step 48445: loss = 0.29768
Step 48450: loss = 0.20981
Step 48455: loss = 0.33153
Step 48460: loss = 0.39578
Step 48465: loss = 0.27354
Step 48470: loss = 0.29193
Step 48475: loss = 0.21614
Step 48480: loss = 0.33420
Step 48485: loss = 0.40470
Step 48490: loss = 0.30552
Step 48495: loss = 0.21301
Step 48500: loss = 0.27776
Step 48505: loss = 0.56056
Step 48510: loss = 0.14381
Step 48515: loss = 0.37179
Step 48520: loss = 0.37204
Step 48525: loss = 0.24062
Step 48530: loss = 0.49065
Step 48535: loss = 0.23983
Step 48540: loss = 0.39542
Step 48545: loss = 0.17892
Step 48550: loss = 0.37913
Step 48555: loss = 0.27249
Step 48560: loss = 0.39616
Step 48565: loss = 0.24263
Step 48570: loss = 0.36750
Step 48575: loss = 0.45698
Step 48580: loss = 0.36847
Step 48585: loss = 0.31645
Step 48590: loss = 0.64954
Step 48595: loss = 0.13224
Step 48600: loss = 0.73949
Step 48605: loss = 0.41557
Step 48610: loss = 0.23075
Step 48615: loss = 0.38752
Step 48620: loss = 0.27183
Step 48625: loss = 0.30778
Step 48630: loss = 0.19468
Step 48635: loss = 0.45593
Step 48640: loss = 0.22481
Step 48645: loss = 0.45933
Step 48650: loss = 0.38230
Step 48655: loss = 0.14568
Step 48660: loss = 0.29248
Step 48665: loss = 0.49140
Step 48670: loss = 0.25461
Step 48675: loss = 0.33989
Step 48680: loss = 0.16511
Step 48685: loss = 0.44713
Step 48690: loss = 0.20576
Step 48695: loss = 0.33761
Step 48700: loss = 0.28451
Step 48705: loss = 0.39688
Step 48710: loss = 0.35848
Step 48715: loss = 0.24800
Step 48720: loss = 0.47896
Step 48725: loss = 0.45861
Step 48730: loss = 0.21990
Step 48735: loss = 0.32584
Step 48740: loss = 0.22553
Step 48745: loss = 0.22118
Step 48750: loss = 0.28226
Step 48755: loss = 0.41592
Step 48760: loss = 0.41467
Step 48765: loss = 0.41592
Step 48770: loss = 0.56519
Step 48775: loss = 0.50906
Step 48780: loss = 0.70385
Step 48785: loss = 0.33852
Step 48790: loss = 0.45709
Step 48795: loss = 0.58464
Step 48800: loss = 0.39085
Step 48805: loss = 0.47183
Step 48810: loss = 0.53543
Step 48815: loss = 0.41476
Step 48820: loss = 0.20343
Step 48825: loss = 0.33497
Step 48830: loss = 0.20891
Step 48835: loss = 0.50244
Step 48840: loss = 0.32764
Step 48845: loss = 0.29327
Step 48850: loss = 0.35033
Step 48855: loss = 0.28837
Step 48860: loss = 0.30185
Step 48865: loss = 0.30558
Step 48870: loss = 0.42051
Step 48875: loss = 0.28619
Step 48880: loss = 0.28055
Step 48885: loss = 0.37330
Step 48890: loss = 0.30831
Step 48895: loss = 0.17512
Step 48900: loss = 0.50235
Step 48905: loss = 0.48528
Step 48910: loss = 0.27612
Step 48915: loss = 0.29765
Step 48920: loss = 0.36554
Step 48925: loss = 0.31630
Step 48930: loss = 0.38312
Step 48935: loss = 0.34396
Step 48940: loss = 0.40358
Step 48945: loss = 0.51661
Step 48950: loss = 0.39678
Step 48955: loss = 0.36773
Step 48960: loss = 0.44141
Step 48965: loss = 0.23588
Step 48970: loss = 0.57594
Step 48975: loss = 0.32026
Step 48980: loss = 0.19422
Step 48985: loss = 0.14994
Step 48990: loss = 0.24633
Step 48995: loss = 0.36599
Step 49000: loss = 0.31888
Training Data Eval:
  Num examples: 50000, Num correct: 44644, Precision @ 1: 0.8929
('Testing Data Eval: EPOCH->', 50)
  Num examples: 10000, Num correct: 6561, Precision @ 1: 0.6561
Step 49005: loss = 0.31914
Step 49010: loss = 0.20339
Step 49015: loss = 0.34452
Step 49020: loss = 0.40791
Step 49025: loss = 0.30318
Step 49030: loss = 0.42979
Step 49035: loss = 0.26206
Step 49040: loss = 0.27895
Step 49045: loss = 0.27187
Step 49050: loss = 0.32040
Step 49055: loss = 0.23573
Step 49060: loss = 0.21787
Step 49065: loss = 0.48794
Step 49070: loss = 0.32504
Step 49075: loss = 0.34301
Step 49080: loss = 0.66099
Step 49085: loss = 0.26236
Step 49090: loss = 0.28702
Step 49095: loss = 0.30063
Step 49100: loss = 0.36351
Step 49105: loss = 0.29664
Step 49110: loss = 0.21133
Step 49115: loss = 0.20567
Step 49120: loss = 0.44788
Step 49125: loss = 0.41836
Step 49130: loss = 0.28222
Step 49135: loss = 0.29212
Step 49140: loss = 0.33261
Step 49145: loss = 0.47392
Step 49150: loss = 0.46717
Step 49155: loss = 0.56346
Step 49160: loss = 0.16156
Step 49165: loss = 0.28268
Step 49170: loss = 0.47711
Step 49175: loss = 0.26276
Step 49180: loss = 0.26834
Step 49185: loss = 0.38924
Step 49190: loss = 0.46690
Step 49195: loss = 0.57618
Step 49200: loss = 0.13049
Step 49205: loss = 0.18694
Step 49210: loss = 0.61986
Step 49215: loss = 0.24796
Step 49220: loss = 0.33823
Step 49225: loss = 0.63685
Step 49230: loss = 0.46510
Step 49235: loss = 0.30941
Step 49240: loss = 0.45231
Step 49245: loss = 0.43469
Step 49250: loss = 0.30626
Step 49255: loss = 0.34659
Step 49260: loss = 0.21358
Step 49265: loss = 0.43003
Step 49270: loss = 0.30211
Step 49275: loss = 0.22387
Step 49280: loss = 0.35731
Step 49285: loss = 0.37273
Step 49290: loss = 0.30208
Step 49295: loss = 0.39773
Step 49300: loss = 0.31926
Step 49305: loss = 0.64858
Step 49310: loss = 0.26549
Step 49315: loss = 0.30753
Step 49320: loss = 0.26761
Step 49325: loss = 0.26728
Step 49330: loss = 0.35912
Step 49335: loss = 0.31775
Step 49340: loss = 0.40156
Step 49345: loss = 0.38656
Step 49350: loss = 0.45658
Step 49355: loss = 0.75559
Step 49360: loss = 0.18675
Step 49365: loss = 0.41157
Step 49370: loss = 0.71099
Step 49375: loss = 0.20302
Step 49380: loss = 0.29728
Step 49385: loss = 0.32219
Step 49390: loss = 0.34041
Step 49395: loss = 0.29979
Step 49400: loss = 0.36874
Step 49405: loss = 0.23862
Step 49410: loss = 0.31657
Step 49415: loss = 0.32160
Step 49420: loss = 0.40401
Step 49425: loss = 0.74364
Step 49430: loss = 0.20829
Step 49435: loss = 0.44997
Step 49440: loss = 0.20862
Step 49445: loss = 0.36311
Step 49450: loss = 0.51571
Step 49455: loss = 0.35177
Step 49460: loss = 0.43578
Step 49465: loss = 0.42054
Step 49470: loss = 0.55119
Step 49475: loss = 0.29556
Step 49480: loss = 0.41731
Step 49485: loss = 0.43566
Step 49490: loss = 0.27393
Step 49495: loss = 0.24502
Step 49500: loss = 0.42784
Step 49505: loss = 0.36274
Step 49510: loss = 0.27859
Step 49515: loss = 0.32988
Step 49520: loss = 0.41196
Step 49525: loss = 0.27057
Step 49530: loss = 0.27631
Step 49535: loss = 0.37882
Step 49540: loss = 0.14271
Step 49545: loss = 0.42832
Step 49550: loss = 0.47505
Step 49555: loss = 0.38043
Step 49560: loss = 0.38203
Step 49565: loss = 0.34034
Step 49570: loss = 0.44813
Step 49575: loss = 0.39817
Step 49580: loss = 0.53900
Step 49585: loss = 0.50232
Step 49590: loss = 0.43736
Step 49595: loss = 0.16135
Step 49600: loss = 0.27865
Step 49605: loss = 0.33801
Step 49610: loss = 0.33427
Step 49615: loss = 0.18143
Step 49620: loss = 0.15859
Step 49625: loss = 0.55913
Step 49630: loss = 0.31358
Step 49635: loss = 0.40047
Step 49640: loss = 0.30633
Step 49645: loss = 0.41453
Step 49650: loss = 0.47134
Step 49655: loss = 0.50470
Step 49660: loss = 0.23432
Step 49665: loss = 0.18821
Step 49670: loss = 0.27872
Step 49675: loss = 0.25034
Step 49680: loss = 0.47026
Step 49685: loss = 0.43422
Step 49690: loss = 0.35551
Step 49695: loss = 0.42097
Step 49700: loss = 0.22796
Step 49705: loss = 0.21578
Step 49710: loss = 0.28389
Step 49715: loss = 0.28581
Step 49720: loss = 0.43443
Step 49725: loss = 0.56566
Step 49730: loss = 0.31918
Step 49735: loss = 0.37922
Step 49740: loss = 0.34023
Step 49745: loss = 0.28563
Step 49750: loss = 0.14474
Step 49755: loss = 0.19516
Step 49760: loss = 0.47973
Step 49765: loss = 0.27918
Step 49770: loss = 0.33060
Step 49775: loss = 0.16811
Step 49780: loss = 0.48319
Step 49785: loss = 0.25665
Step 49790: loss = 0.32238
Step 49795: loss = 0.22841
Step 49800: loss = 0.36416
Step 49805: loss = 0.41965
Step 49810: loss = 0.39958
Step 49815: loss = 0.32780
Step 49820: loss = 0.48556
Step 49825: loss = 0.22777
Step 49830: loss = 0.41002
Step 49835: loss = 0.43852
Step 49840: loss = 0.35336
Step 49845: loss = 0.27021
Step 49850: loss = 0.28894
Step 49855: loss = 0.23714
Step 49860: loss = 0.73455
Step 49865: loss = 0.31280
Step 49870: loss = 0.30010
Step 49875: loss = 0.40030
Step 49880: loss = 0.25799
Step 49885: loss = 0.38600
Step 49890: loss = 0.27682
Step 49895: loss = 0.22923
Step 49900: loss = 0.27818
Step 49905: loss = 0.34943
Step 49910: loss = 0.62988
Step 49915: loss = 0.28258
Step 49920: loss = 0.36996
Step 49925: loss = 0.25058
Step 49930: loss = 0.38673
Step 49935: loss = 0.21944
Step 49940: loss = 0.31599
Step 49945: loss = 0.35674
Step 49950: loss = 0.34148
Step 49955: loss = 0.46711
Step 49960: loss = 0.33345
Step 49965: loss = 0.40856
Step 49970: loss = 0.29344
Step 49975: loss = 0.28028
Step 49980: loss = 0.21738
Step 49985: loss = 0.41877
Step 49990: loss = 0.21950
Step 49995: loss = 0.33208
Step 50000: loss = 0.34238
Training Data Eval:
  Num examples: 50000, Num correct: 44433, Precision @ 1: 0.8887
('Testing Data Eval: EPOCH->', 51)
  Num examples: 10000, Num correct: 6378, Precision @ 1: 0.6378
Step 50005: loss = 0.16421
Step 50010: loss = 0.13332
Step 50015: loss = 0.19977
Step 50020: loss = 0.16351
Step 50025: loss = 0.30712
Step 50030: loss = 0.21251
Step 50035: loss = 0.22810
Step 50040: loss = 0.35450
Step 50045: loss = 0.19988
Step 50050: loss = 0.40773
Step 50055: loss = 0.34223
Step 50060: loss = 0.26305
Step 50065: loss = 0.57632
Step 50070: loss = 0.18384
Step 50075: loss = 0.55209
Step 50080: loss = 0.35539
Step 50085: loss = 0.32669
Step 50090: loss = 0.29522
Step 50095: loss = 0.15961
Step 50100: loss = 0.46573
Step 50105: loss = 0.24122
Step 50110: loss = 0.38143
Step 50115: loss = 0.31873
Step 50120: loss = 0.38878
Step 50125: loss = 0.12370
Step 50130: loss = 0.28820
Step 50135: loss = 0.13409
Step 50140: loss = 0.28429
Step 50145: loss = 0.17939
Step 50150: loss = 0.26731
Step 50155: loss = 0.47642
Step 50160: loss = 0.48998
Step 50165: loss = 0.26723
Step 50170: loss = 0.35284
Step 50175: loss = 0.40157
Step 50180: loss = 0.56492
Step 50185: loss = 0.14840
Step 50190: loss = 0.48833
Step 50195: loss = 0.17012
Step 50200: loss = 0.19425
Step 50205: loss = 0.21221
Step 50210: loss = 0.33458
Step 50215: loss = 0.27066
Step 50220: loss = 0.23550
Step 50225: loss = 0.33838
Step 50230: loss = 0.38753
Step 50235: loss = 0.21543
Step 50240: loss = 0.18161
Step 50245: loss = 0.45669
Step 50250: loss = 0.39365
Step 50255: loss = 0.38449
Step 50260: loss = 0.53135
Step 50265: loss = 0.35061
Step 50270: loss = 0.12872
Step 50275: loss = 0.22049
Step 50280: loss = 0.57845
Step 50285: loss = 0.20863
Step 50290: loss = 0.40424
Step 50295: loss = 0.28736
Step 50300: loss = 0.36014
Step 50305: loss = 0.28377
Step 50310: loss = 0.45023
Step 50315: loss = 0.35351
Step 50320: loss = 0.21125
Step 50325: loss = 0.23104
Step 50330: loss = 0.36487
Step 50335: loss = 0.40674
Step 50340: loss = 0.41299
Step 50345: loss = 0.40783
Step 50350: loss = 0.11445
Step 50355: loss = 0.35856
Step 50360: loss = 0.60379
Step 50365: loss = 0.34173
Step 50370: loss = 0.23137
Step 50375: loss = 0.40435
Step 50380: loss = 0.26241
Step 50385: loss = 0.27220
Step 50390: loss = 0.32842
Step 50395: loss = 0.18926
Step 50400: loss = 0.37295
Step 50405: loss = 0.51776
Step 50410: loss = 0.26852
Step 50415: loss = 0.22439
Step 50420: loss = 0.46387
Step 50425: loss = 0.50281
Step 50430: loss = 0.54000
Step 50435: loss = 0.21043
Step 50440: loss = 0.24976
Step 50445: loss = 0.34142
Step 50450: loss = 0.29877
Step 50455: loss = 0.40946
Step 50460: loss = 0.29763
Step 50465: loss = 0.20698
Step 50470: loss = 0.45965
Step 50475: loss = 0.11760
Step 50480: loss = 0.44595
Step 50485: loss = 0.26252
Step 50490: loss = 0.12297
Step 50495: loss = 0.29795
Step 50500: loss = 0.27553
Step 50505: loss = 0.26684
Step 50510: loss = 0.28413
Step 50515: loss = 0.23054
Step 50520: loss = 0.21197
Step 50525: loss = 0.32430
Step 50530: loss = 0.32474
Step 50535: loss = 0.12475
Step 50540: loss = 0.35709
Step 50545: loss = 0.53543
Step 50550: loss = 0.29877
Step 50555: loss = 0.22385
Step 50560: loss = 0.17001
Step 50565: loss = 0.16330
Step 50570: loss = 0.25920
Step 50575: loss = 0.37006
Step 50580: loss = 0.27627
Step 50585: loss = 0.44326
Step 50590: loss = 0.31671
Step 50595: loss = 0.36609
Step 50600: loss = 0.29978
Step 50605: loss = 0.42751
Step 50610: loss = 0.50345
Step 50615: loss = 0.50771
Step 50620: loss = 0.30399
Step 50625: loss = 0.43279
Step 50630: loss = 0.30554
Step 50635: loss = 0.35255
Step 50640: loss = 0.71473
Step 50645: loss = 0.32729
Step 50650: loss = 0.37372
Step 50655: loss = 0.26272
Step 50660: loss = 0.38095
Step 50665: loss = 0.37853
Step 50670: loss = 0.17154
Step 50675: loss = 0.36855
Step 50680: loss = 0.40930
Step 50685: loss = 0.32416
Step 50690: loss = 0.72450
Step 50695: loss = 0.23759
Step 50700: loss = 0.30628
Step 50705: loss = 0.35260
Step 50710: loss = 0.22535
Step 50715: loss = 0.32147
Step 50720: loss = 0.30442
Step 50725: loss = 0.20776
Step 50730: loss = 0.27607
Step 50735: loss = 0.35430
Step 50740: loss = 0.21419
Step 50745: loss = 0.22543
Step 50750: loss = 0.23324
Step 50755: loss = 0.26792
Step 50760: loss = 0.21322
Step 50765: loss = 0.28954
Step 50770: loss = 0.64626
Step 50775: loss = 0.16074
Step 50780: loss = 0.29772
Step 50785: loss = 0.37624
Step 50790: loss = 0.40397
Step 50795: loss = 0.33818
Step 50800: loss = 0.28970
Step 50805: loss = 0.45187
Step 50810: loss = 0.20593
Step 50815: loss = 0.32233
Step 50820: loss = 0.87631
Step 50825: loss = 0.34279
Step 50830: loss = 0.21100
Step 50835: loss = 0.46944
Step 50840: loss = 0.25018
Step 50845: loss = 0.22499
Step 50850: loss = 0.23596
Step 50855: loss = 0.31582
Step 50860: loss = 0.35607
Step 50865: loss = 0.30535
Step 50870: loss = 0.34730
Step 50875: loss = 0.30344
Step 50880: loss = 0.26230
Step 50885: loss = 0.45074
Step 50890: loss = 0.36672
Step 50895: loss = 0.21331
Step 50900: loss = 0.49527
Step 50905: loss = 0.57994
Step 50910: loss = 0.25332
Step 50915: loss = 0.27324
Step 50920: loss = 0.31854
Step 50925: loss = 0.56889
Step 50930: loss = 0.50417
Step 50935: loss = 0.54983
Step 50940: loss = 0.32313
Step 50945: loss = 0.22212
Step 50950: loss = 0.14299
Step 50955: loss = 0.30598
Step 50960: loss = 0.25602
Step 50965: loss = 0.49633
Step 50970: loss = 0.27020
Step 50975: loss = 0.36794
Step 50980: loss = 0.16497
Step 50985: loss = 0.14621
Step 50990: loss = 0.22719
Step 50995: loss = 0.43627
Step 51000: loss = 0.61488
Training Data Eval:
  Num examples: 50000, Num correct: 44807, Precision @ 1: 0.8961
('Testing Data Eval: EPOCH->', 52)
  Num examples: 10000, Num correct: 6435, Precision @ 1: 0.6435
Step 51005: loss = 0.28792
Step 51010: loss = 0.20629
Step 51015: loss = 0.26549
Step 51020: loss = 0.41872
Step 51025: loss = 0.33358
Step 51030: loss = 0.34547
Step 51035: loss = 0.26020
Step 51040: loss = 0.22479
Step 51045: loss = 0.21517
Step 51050: loss = 0.44087
Step 51055: loss = 0.24195
Step 51060: loss = 0.20750
Step 51065: loss = 0.17998
Step 51070: loss = 0.26623
Step 51075: loss = 0.27513
Step 51080: loss = 0.36047
Step 51085: loss = 0.29946
Step 51090: loss = 0.22633
Step 51095: loss = 0.28793
Step 51100: loss = 0.33618
Step 51105: loss = 0.17862
Step 51110: loss = 0.49382
Step 51115: loss = 0.46067
Step 51120: loss = 0.41533
Step 51125: loss = 0.20127
Step 51130: loss = 0.25560
Step 51135: loss = 0.12781
Step 51140: loss = 0.27721
Step 51145: loss = 0.40380
Step 51150: loss = 0.19443
Step 51155: loss = 0.31330
Step 51160: loss = 0.49684
Step 51165: loss = 0.30010
Step 51170: loss = 0.30150
Step 51175: loss = 0.15041
Step 51180: loss = 0.28036
Step 51185: loss = 0.31992
Step 51190: loss = 0.25985
Step 51195: loss = 0.56969
Step 51200: loss = 0.20269
Step 51205: loss = 0.34027
Step 51210: loss = 0.40446
Step 51215: loss = 0.41681
Step 51220: loss = 0.12220
Step 51225: loss = 0.41253
Step 51230: loss = 0.30711
Step 51235: loss = 0.38117
Step 51240: loss = 0.25806
Step 51245: loss = 0.19640
Step 51250: loss = 0.16993
Step 51255: loss = 0.25144
Step 51260: loss = 0.17893
Step 51265: loss = 0.25763
Step 51270: loss = 0.57607
Step 51275: loss = 0.16000
Step 51280: loss = 0.41150
Step 51285: loss = 0.41903
Step 51290: loss = 0.41802
Step 51295: loss = 0.17023
Step 51300: loss = 0.24901
Step 51305: loss = 0.53525
Step 51310: loss = 0.30192
Step 51315: loss = 0.53347
Step 51320: loss = 0.29053
Step 51325: loss = 0.26613
Step 51330: loss = 0.28208
Step 51335: loss = 0.50310
Step 51340: loss = 0.19837
Step 51345: loss = 0.37906
Step 51350: loss = 0.21306
Step 51355: loss = 0.27209
Step 51360: loss = 0.39457
Step 51365: loss = 0.27854
Step 51370: loss = 0.19240
Step 51375: loss = 0.27527
Step 51380: loss = 0.22654
Step 51385: loss = 0.27885
Step 51390: loss = 0.34030
Step 51395: loss = 0.16338
Step 51400: loss = 0.21151
Step 51405: loss = 0.24765
Step 51410: loss = 0.20096
Step 51415: loss = 0.39682
Step 51420: loss = 0.27265
Step 51425: loss = 0.38658
Step 51430: loss = 0.23710
Step 51435: loss = 0.27251
Step 51440: loss = 0.27801
Step 51445: loss = 0.23844
Step 51450: loss = 0.22641
Step 51455: loss = 0.41249
Step 51460: loss = 0.23891
Step 51465: loss = 0.19964
Step 51470: loss = 0.32881
Step 51475: loss = 0.21477
Step 51480: loss = 0.25820
Step 51485: loss = 0.40450
Step 51490: loss = 0.39378
Step 51495: loss = 0.13997
Step 51500: loss = 0.52461
Step 51505: loss = 0.16796
Step 51510: loss = 0.16966
Step 51515: loss = 0.27655
Step 51520: loss = 0.28373
Step 51525: loss = 0.17371
Step 51530: loss = 0.11667
Step 51535: loss = 0.27992
Step 51540: loss = 0.36089
Step 51545: loss = 0.26290
Step 51550: loss = 0.58888
Step 51555: loss = 0.26168
Step 51560: loss = 0.38778
Step 51565: loss = 0.36254
Step 51570: loss = 0.38980
Step 51575: loss = 0.25497
Step 51580: loss = 0.31100
Step 51585: loss = 0.30647
Step 51590: loss = 0.34837
Step 51595: loss = 0.32986
Step 51600: loss = 0.49411
Step 51605: loss = 0.35587
Step 51610: loss = 0.15964
Step 51615: loss = 0.34029
Step 51620: loss = 0.39285
Step 51625: loss = 0.24739
Step 51630: loss = 0.53058
Step 51635: loss = 0.40215
Step 51640: loss = 0.39809
Step 51645: loss = 0.35923
Step 51650: loss = 0.36228
Step 51655: loss = 0.58604
Step 51660: loss = 0.25092
Step 51665: loss = 0.39370
Step 51670: loss = 0.34000
Step 51675: loss = 0.46492
Step 51680: loss = 0.41434
Step 51685: loss = 0.34428
Step 51690: loss = 0.61693
Step 51695: loss = 0.50132
Step 51700: loss = 0.24451
Step 51705: loss = 0.26995
Step 51710: loss = 0.36097
Step 51715: loss = 0.55345
Step 51720: loss = 0.20438
Step 51725: loss = 0.49683
Step 51730: loss = 0.08515
Step 51735: loss = 0.28486
Step 51740: loss = 0.42249
Step 51745: loss = 0.47190
Step 51750: loss = 0.37836
Step 51755: loss = 0.13218
Step 51760: loss = 0.41823
Step 51765: loss = 0.27349
Step 51770: loss = 0.35293
Step 51775: loss = 0.28918
Step 51780: loss = 0.37333
Step 51785: loss = 0.31332
Step 51790: loss = 0.25623
Step 51795: loss = 0.50931
Step 51800: loss = 0.25421
Step 51805: loss = 0.42774
Step 51810: loss = 0.48816
Step 51815: loss = 0.23797
Step 51820: loss = 0.32116
Step 51825: loss = 0.23183
Step 51830: loss = 0.31853
Step 51835: loss = 0.36739
Step 51840: loss = 0.26314
Step 51845: loss = 0.27332
Step 51850: loss = 0.24234
Step 51855: loss = 0.32404
Step 51860: loss = 0.25250
Step 51865: loss = 0.26395
Step 51870: loss = 0.46002
Step 51875: loss = 0.33365
Step 51880: loss = 0.56194
Step 51885: loss = 0.30837
Step 51890: loss = 0.21619
Step 51895: loss = 0.19424
Step 51900: loss = 0.32718
Step 51905: loss = 0.46942
Step 51910: loss = 0.19338
Step 51915: loss = 0.47275
Step 51920: loss = 0.54910
Step 51925: loss = 0.24807
Step 51930: loss = 0.20257
Step 51935: loss = 0.36131
Step 51940: loss = 0.36535
Step 51945: loss = 0.28080
Step 51950: loss = 0.22238
Step 51955: loss = 0.24986
Step 51960: loss = 0.57921
Step 51965: loss = 0.33160
Step 51970: loss = 0.26875
Step 51975: loss = 0.25634
Step 51980: loss = 0.17634
Step 51985: loss = 0.64396
Step 51990: loss = 0.19881
Step 51995: loss = 0.22689
Step 52000: loss = 0.21200
Training Data Eval:
  Num examples: 50000, Num correct: 44828, Precision @ 1: 0.8966
('Testing Data Eval: EPOCH->', 53)
  Num examples: 10000, Num correct: 6470, Precision @ 1: 0.6470
Step 52005: loss = 0.15679
Step 52010: loss = 0.17541
Step 52015: loss = 0.38897
Step 52020: loss = 0.23247
Step 52025: loss = 0.16103
Step 52030: loss = 0.26830
Step 52035: loss = 0.26357
Step 52040: loss = 0.27840
Step 52045: loss = 0.48070
Step 52050: loss = 0.17616
Step 52055: loss = 0.19116
Step 52060: loss = 0.41982
Step 52065: loss = 0.51646
Step 52070: loss = 0.30126
Step 52075: loss = 0.29349
Step 52080: loss = 0.10669
Step 52085: loss = 0.18924
Step 52090: loss = 0.19061
Step 52095: loss = 0.41697
Step 52100: loss = 0.19003
Step 52105: loss = 0.20644
Step 52110: loss = 0.61247
Step 52115: loss = 0.32652
Step 52120: loss = 0.21009
Step 52125: loss = 0.36080
Step 52130: loss = 0.48369
Step 52135: loss = 0.35169
Step 52140: loss = 0.35297
Step 52145: loss = 0.41139
Step 52150: loss = 0.20008
Step 52155: loss = 0.46802
Step 52160: loss = 0.15053
Step 52165: loss = 0.34941
Step 52170: loss = 0.16463
Step 52175: loss = 0.39518
Step 52180: loss = 0.45051
Step 52185: loss = 0.33734
Step 52190: loss = 0.30022
Step 52195: loss = 0.42061
Step 52200: loss = 0.23653
Step 52205: loss = 0.22436
Step 52210: loss = 0.41224
Step 52215: loss = 0.34404
Step 52220: loss = 0.35119
Step 52225: loss = 0.30005
Step 52230: loss = 0.40225
Step 52235: loss = 0.19795
Step 52240: loss = 0.31392
Step 52245: loss = 0.30800
Step 52250: loss = 0.52305
Step 52255: loss = 0.18991
Step 52260: loss = 0.15814
Step 52265: loss = 0.22204
Step 52270: loss = 0.47573
Step 52275: loss = 0.26820
Step 52280: loss = 0.40905
Step 52285: loss = 0.21224
Step 52290: loss = 0.18159
Step 52295: loss = 0.31889
Step 52300: loss = 0.30974
Step 52305: loss = 0.34329
Step 52310: loss = 0.43779
Step 52315: loss = 0.33043
Step 52320: loss = 0.34162
Step 52325: loss = 0.52697
Step 52330: loss = 0.34775
Step 52335: loss = 0.31875
Step 52340: loss = 0.26860
Step 52345: loss = 0.34358
Step 52350: loss = 0.42207
Step 52355: loss = 0.45240
Step 52360: loss = 0.33143
Step 52365: loss = 0.44126
Step 52370: loss = 0.20295
Step 52375: loss = 0.23568
Step 52380: loss = 0.26279
Step 52385: loss = 0.31454
Step 52390: loss = 0.37621
Step 52395: loss = 0.35666
Step 52400: loss = 0.50264
Step 52405: loss = 0.20163
Step 52410: loss = 0.25933
Step 52415: loss = 0.25797
Step 52420: loss = 0.46412
Step 52425: loss = 0.22905
Step 52430: loss = 0.46633
Step 52435: loss = 0.37301
Step 52440: loss = 0.28353
Step 52445: loss = 0.53505
Step 52450: loss = 0.45972
Step 52455: loss = 0.19073
Step 52460: loss = 0.35028
Step 52465: loss = 0.55330
Step 52470: loss = 0.37425
Step 52475: loss = 0.27022
Step 52480: loss = 0.32120
Step 52485: loss = 0.68495
Step 52490: loss = 0.28526
Step 52495: loss = 0.31316
Step 52500: loss = 0.19146
Step 52505: loss = 0.46965
Step 52510: loss = 0.34131
Step 52515: loss = 0.21931
Step 52520: loss = 0.46215
Step 52525: loss = 0.32412
Step 52530: loss = 0.48174
Step 52535: loss = 0.54868
Step 52540: loss = 0.20812
Step 52545: loss = 0.27419
Step 52550: loss = 0.72126
Step 52555: loss = 0.35777
Step 52560: loss = 0.38036
Step 52565: loss = 0.17908
Step 52570: loss = 0.52385
Step 52575: loss = 0.27522
Step 52580: loss = 0.54176
Step 52585: loss = 0.12273
Step 52590: loss = 0.31553
Step 52595: loss = 0.34774
Step 52600: loss = 0.34623
Step 52605: loss = 0.29467
Step 52610: loss = 0.49186
Step 52615: loss = 0.39680
Step 52620: loss = 0.35229
Step 52625: loss = 0.45411
Step 52630: loss = 0.40414
Step 52635: loss = 0.49160
Step 52640: loss = 0.43941
Step 52645: loss = 0.34722
Step 52650: loss = 0.13658
Step 52655: loss = 0.29442
Step 52660: loss = 0.44522
Step 52665: loss = 0.36097
Step 52670: loss = 0.34908
Step 52675: loss = 0.40929
Step 52680: loss = 0.22797
Step 52685: loss = 0.31581
Step 52690: loss = 0.25248
Step 52695: loss = 0.21487
Step 52700: loss = 0.38780
Step 52705: loss = 0.24208
Step 52710: loss = 0.18363
Step 52715: loss = 0.29588
Step 52720: loss = 0.16528
Step 52725: loss = 0.16718
Step 52730: loss = 0.38846
Step 52735: loss = 0.30891
Step 52740: loss = 0.15662
Step 52745: loss = 0.37999
Step 52750: loss = 0.18730
Step 52755: loss = 0.23978
Step 52760: loss = 0.15108
Step 52765: loss = 0.23839
Step 52770: loss = 0.39468
Step 52775: loss = 0.41270
Step 52780: loss = 0.35773
Step 52785: loss = 0.32316
Step 52790: loss = 0.22380
Step 52795: loss = 0.50673
Step 52800: loss = 0.14355
Step 52805: loss = 0.23638
Step 52810: loss = 0.20147
Step 52815: loss = 0.19739
Step 52820: loss = 0.39864
Step 52825: loss = 0.38823
Step 52830: loss = 0.34380
Step 52835: loss = 0.30976
Step 52840: loss = 0.47142
Step 52845: loss = 0.37764
Step 52850: loss = 0.19589
Step 52855: loss = 0.35763
Step 52860: loss = 0.30798
Step 52865: loss = 0.21066
Step 52870: loss = 0.41291
Step 52875: loss = 0.38053
Step 52880: loss = 0.25960
Step 52885: loss = 0.40913
Step 52890: loss = 0.41647
Step 52895: loss = 0.28299
Step 52900: loss = 0.47293
Step 52905: loss = 0.22959
Step 52910: loss = 0.25177
Step 52915: loss = 0.21095
Step 52920: loss = 0.36101
Step 52925: loss = 0.32056
Step 52930: loss = 0.25471
Step 52935: loss = 0.25940
Step 52940: loss = 0.38118
Step 52945: loss = 0.27252
Step 52950: loss = 0.15189
Step 52955: loss = 0.40931
Step 52960: loss = 0.35016
Step 52965: loss = 0.27202
Step 52970: loss = 0.40502
Step 52975: loss = 0.17826
Step 52980: loss = 0.32941
Step 52985: loss = 0.17974
Step 52990: loss = 0.17632
Step 52995: loss = 0.20184
Step 53000: loss = 0.64600
Training Data Eval:
  Num examples: 50000, Num correct: 44936, Precision @ 1: 0.8987
('Testing Data Eval: EPOCH->', 54)
  Num examples: 10000, Num correct: 6602, Precision @ 1: 0.6602
Step 53005: loss = 0.21889
Step 53010: loss = 0.38251
Step 53015: loss = 0.30954
Step 53020: loss = 0.33076
Step 53025: loss = 0.61368
Step 53030: loss = 0.17885
Step 53035: loss = 0.26180
Step 53040: loss = 0.21210
Step 53045: loss = 0.12551
Step 53050: loss = 0.22173
Step 53055: loss = 0.32974
Step 53060: loss = 0.15379
Step 53065: loss = 0.30326
Step 53070: loss = 0.34573
Step 53075: loss = 0.37492
Step 53080: loss = 0.37072
Step 53085: loss = 0.42911
Step 53090: loss = 0.36953
Step 53095: loss = 0.26549
Step 53100: loss = 0.24977
Step 53105: loss = 0.11646
Step 53110: loss = 0.09057
Step 53115: loss = 0.20234
Step 53120: loss = 0.22215
Step 53125: loss = 0.16160
Step 53130: loss = 0.31396
Step 53135: loss = 0.25691
Step 53140: loss = 0.29149
Step 53145: loss = 0.24957
Step 53150: loss = 0.35343
Step 53155: loss = 0.44406
Step 53160: loss = 0.25594
Step 53165: loss = 0.21013
Step 53170: loss = 0.24338
Step 53175: loss = 0.33019
Step 53180: loss = 0.34958
Step 53185: loss = 0.52039
Step 53190: loss = 0.31871
Step 53195: loss = 0.40902
Step 53200: loss = 0.20898
Step 53205: loss = 0.23870
Step 53210: loss = 0.15407
Step 53215: loss = 0.24982
Step 53220: loss = 0.22705
Step 53225: loss = 0.16846
Step 53230: loss = 0.21130
Step 53235: loss = 0.45587
Step 53240: loss = 0.25321
Step 53245: loss = 0.51737
Step 53250: loss = 0.29538
Step 53255: loss = 0.31561
Step 53260: loss = 0.37735
Step 53265: loss = 0.31740
Step 53270: loss = 0.13664
Step 53275: loss = 0.16854
Step 53280: loss = 0.51344
Step 53285: loss = 0.16541
Step 53290: loss = 0.35402
Step 53295: loss = 0.33180
Step 53300: loss = 0.34391
Step 53305: loss = 0.53170
Step 53310: loss = 0.22920
Step 53315: loss = 0.33248
Step 53320: loss = 0.63114
Step 53325: loss = 0.23788
Step 53330: loss = 0.44311
Step 53335: loss = 0.46925
Step 53340: loss = 0.33170
Step 53345: loss = 0.37646
Step 53350: loss = 0.28664
Step 53355: loss = 0.59788
Step 53360: loss = 0.20597
Step 53365: loss = 0.38931
Step 53370: loss = 0.31908
Step 53375: loss = 0.14843
Step 53380: loss = 0.19187
Step 53385: loss = 0.29585
Step 53390: loss = 0.20019
Step 53395: loss = 0.29850
Step 53400: loss = 0.27964
Step 53405: loss = 0.24851
Step 53410: loss = 0.48413
Step 53415: loss = 0.13346
Step 53420: loss = 0.41479
Step 53425: loss = 0.22667
Step 53430: loss = 0.34959
Step 53435: loss = 0.20648
Step 53440: loss = 0.45301
Step 53445: loss = 0.27313
Step 53450: loss = 0.19629
Step 53455: loss = 0.47198
Step 53460: loss = 0.59329
Step 53465: loss = 0.33917
Step 53470: loss = 0.23622
Step 53475: loss = 0.38714
Step 53480: loss = 0.28750
Step 53485: loss = 0.27897
Step 53490: loss = 0.08744
Step 53495: loss = 0.25221
Step 53500: loss = 0.23460
Step 53505: loss = 0.15127
Step 53510: loss = 0.32339
Step 53515: loss = 0.34504
Step 53520: loss = 0.32111
Step 53525: loss = 0.18435
Step 53530: loss = 0.37177
Step 53535: loss = 0.55621
Step 53540: loss = 0.25990
Step 53545: loss = 0.32075
Step 53550: loss = 0.23276
Step 53555: loss = 0.22244
Step 53560: loss = 0.23284
Step 53565: loss = 0.21911
Step 53570: loss = 0.16014
Step 53575: loss = 0.17421
Step 53580: loss = 0.16553
Step 53585: loss = 0.47773
Step 53590: loss = 0.22839
Step 53595: loss = 0.14013
Step 53600: loss = 0.28331
Step 53605: loss = 0.35007
Step 53610: loss = 0.37574
Step 53615: loss = 0.37825
Step 53620: loss = 0.56205
Step 53625: loss = 0.27872
Step 53630: loss = 0.28546
Step 53635: loss = 0.12560
Step 53640: loss = 0.42021
Step 53645: loss = 0.48498
Step 53650: loss = 0.32588
Step 53655: loss = 0.20585
Step 53660: loss = 0.25945
Step 53665: loss = 0.21481
Step 53670: loss = 0.48717
Step 53675: loss = 0.18910
Step 53680: loss = 0.33737
Step 53685: loss = 0.23590
Step 53690: loss = 0.32465
Step 53695: loss = 0.47293
Step 53700: loss = 0.21953
Step 53705: loss = 0.54030
Step 53710: loss = 0.29235
Step 53715: loss = 0.33708
Step 53720: loss = 0.19990
Step 53725: loss = 0.39090
Step 53730: loss = 0.25808
Step 53735: loss = 0.24847
Step 53740: loss = 0.31238
Step 53745: loss = 0.29767
Step 53750: loss = 0.27155
Step 53755: loss = 0.71339
Step 53760: loss = 0.44065
Step 53765: loss = 0.17233
Step 53770: loss = 0.22234
Step 53775: loss = 0.17615
Step 53780: loss = 0.37369
Step 53785: loss = 0.39593
Step 53790: loss = 0.34031
Step 53795: loss = 0.36593
Step 53800: loss = 0.17762
Step 53805: loss = 0.16570
Step 53810: loss = 0.40538
Step 53815: loss = 0.21090
Step 53820: loss = 0.27265
Step 53825: loss = 0.11136
Step 53830: loss = 0.26810
Step 53835: loss = 0.37327
Step 53840: loss = 0.25124
Step 53845: loss = 0.26556
Step 53850: loss = 0.27966
Step 53855: loss = 0.39811
Step 53860: loss = 0.31898
Step 53865: loss = 0.28555
Step 53870: loss = 0.16788
Step 53875: loss = 0.40698
Step 53880: loss = 0.31684
Step 53885: loss = 0.28100
Step 53890: loss = 0.29989
Step 53895: loss = 0.18699
Step 53900: loss = 0.15557
Step 53905: loss = 0.46967
Step 53910: loss = 0.33839
Step 53915: loss = 0.24189
Step 53920: loss = 0.23519
Step 53925: loss = 0.41965
Step 53930: loss = 0.49511
Step 53935: loss = 0.22765
Step 53940: loss = 0.24494
Step 53945: loss = 0.41691
Step 53950: loss = 0.39548
Step 53955: loss = 0.13884
Step 53960: loss = 0.22104
Step 53965: loss = 0.29857
Step 53970: loss = 0.21316
Step 53975: loss = 0.21123
Step 53980: loss = 0.42137
Step 53985: loss = 0.19902
Step 53990: loss = 0.30723
Step 53995: loss = 0.14351
Step 54000: loss = 0.43800
Training Data Eval:
  Num examples: 50000, Num correct: 45068, Precision @ 1: 0.9014
('Testing Data Eval: EPOCH->', 55)
  Num examples: 10000, Num correct: 6307, Precision @ 1: 0.6307
Step 54005: loss = 0.37276
Step 54010: loss = 0.21114
Step 54015: loss = 0.26354
Step 54020: loss = 0.39653
Step 54025: loss = 0.23806
Step 54030: loss = 0.43610
Step 54035: loss = 0.39702
Step 54040: loss = 0.13557
Step 54045: loss = 0.27873
Step 54050: loss = 0.31756
Step 54055: loss = 0.28166
Step 54060: loss = 0.25293
Step 54065: loss = 0.45323
Step 54070: loss = 0.18535
Step 54075: loss = 0.53531
Step 54080: loss = 0.17232
Step 54085: loss = 0.39354
Step 54090: loss = 0.32634
Step 54095: loss = 0.09860
Step 54100: loss = 0.45065
Step 54105: loss = 0.33601
Step 54110: loss = 0.39713
Step 54115: loss = 0.48752
Step 54120: loss = 0.32629
Step 54125: loss = 0.32662
Step 54130: loss = 0.30939
Step 54135: loss = 0.64127
Step 54140: loss = 0.29223
Step 54145: loss = 0.20843
Step 54150: loss = 0.26141
Step 54155: loss = 0.21801
Step 54160: loss = 0.69861
Step 54165: loss = 0.27252
Step 54170: loss = 0.32063
Step 54175: loss = 0.36839
Step 54180: loss = 0.46529
Step 54185: loss = 0.14351
Step 54190: loss = 0.28914
Step 54195: loss = 0.51567
Step 54200: loss = 0.24537
Step 54205: loss = 0.28141
Step 54210: loss = 0.17384
Step 54215: loss = 0.41372
Step 54220: loss = 0.20479
Step 54225: loss = 0.56222
Step 54230: loss = 0.32441
Step 54235: loss = 0.20509
Step 54240: loss = 0.16587
Step 54245: loss = 0.42756
Step 54250: loss = 0.25336
Step 54255: loss = 0.11659
Step 54260: loss = 0.38211
Step 54265: loss = 0.34708
Step 54270: loss = 0.22788
Step 54275: loss = 0.24656
Step 54280: loss = 0.60975
Step 54285: loss = 0.21725
Step 54290: loss = 0.16184
Step 54295: loss = 0.39361
Step 54300: loss = 0.10396
Step 54305: loss = 0.25918
Step 54310: loss = 0.18417
Step 54315: loss = 0.23396
Step 54320: loss = 0.24462
Step 54325: loss = 0.42123
Step 54330: loss = 0.32984
Step 54335: loss = 0.21892
Step 54340: loss = 0.27345
Step 54345: loss = 0.28605
Step 54350: loss = 0.39366
Step 54355: loss = 0.09198
Step 54360: loss = 0.43182
Step 54365: loss = 0.22220
Step 54370: loss = 0.23310
Step 54375: loss = 0.43165
Step 54380: loss = 0.30045
Step 54385: loss = 0.26607
Step 54390: loss = 0.34151
Step 54395: loss = 0.10480
Step 54400: loss = 0.24301
Step 54405: loss = 0.37177
Step 54410: loss = 0.29920
Step 54415: loss = 0.21439
Step 54420: loss = 0.42570
Step 54425: loss = 0.33787
Step 54430: loss = 0.22973
Step 54435: loss = 0.36172
Step 54440: loss = 0.16534
Step 54445: loss = 0.38412
Step 54450: loss = 0.20333
Step 54455: loss = 0.39221
Step 54460: loss = 0.47340
Step 54465: loss = 0.37370
Step 54470: loss = 0.24944
Step 54475: loss = 0.24083
Step 54480: loss = 0.13620
Step 54485: loss = 0.25712
Step 54490: loss = 0.12082
Step 54495: loss = 0.21356
Step 54500: loss = 0.31337
Step 54505: loss = 0.48545
Step 54510: loss = 0.23830
Step 54515: loss = 0.22489
Step 54520: loss = 0.25627
Step 54525: loss = 0.13285
Step 54530: loss = 0.10128
Step 54535: loss = 0.26077
Step 54540: loss = 0.13404
Step 54545: loss = 0.22887
Step 54550: loss = 0.34600
Step 54555: loss = 0.39779
Step 54560: loss = 0.23790
Step 54565: loss = 0.38228
Step 54570: loss = 0.28324
Step 54575: loss = 0.36735
Step 54580: loss = 0.21625
Step 54585: loss = 0.21538
Step 54590: loss = 0.40429
Step 54595: loss = 0.45570
Step 54600: loss = 0.36228
Step 54605: loss = 0.42486
Step 54610: loss = 0.34055
Step 54615: loss = 0.23010
Step 54620: loss = 0.28156
Step 54625: loss = 0.23884
Step 54630: loss = 0.33202
Step 54635: loss = 0.19322
Step 54640: loss = 0.34258
Step 54645: loss = 0.12414
Step 54650: loss = 0.19793
Step 54655: loss = 0.47269
Step 54660: loss = 0.15562
Step 54665: loss = 0.68620
Step 54670: loss = 0.35393
Step 54675: loss = 0.46778
Step 54680: loss = 0.29999
Step 54685: loss = 0.23821
Step 54690: loss = 0.24188
Step 54695: loss = 0.17141
Step 54700: loss = 0.17412
Step 54705: loss = 0.27705
Step 54710: loss = 0.14913
Step 54715: loss = 0.22401
Step 54720: loss = 0.17278
Step 54725: loss = 0.38675
Step 54730: loss = 0.17426
Step 54735: loss = 0.28944
Step 54740: loss = 0.16534
Step 54745: loss = 0.24107
Step 54750: loss = 0.27203
Step 54755: loss = 0.13905
Step 54760: loss = 0.31898
Step 54765: loss = 0.31435
Step 54770: loss = 0.23582
Step 54775: loss = 0.11982
Step 54780: loss = 0.18750
Step 54785: loss = 0.18875
Step 54790: loss = 0.33657
Step 54795: loss = 0.45722
Step 54800: loss = 0.44082
Step 54805: loss = 0.21807
Step 54810: loss = 0.28990
Step 54815: loss = 0.47579
Step 54820: loss = 0.18887
Step 54825: loss = 0.34411
Step 54830: loss = 0.40513
Step 54835: loss = 0.27900
Step 54840: loss = 0.33567
Step 54845: loss = 0.24836
Step 54850: loss = 0.49975
Step 54855: loss = 0.25224
Step 54860: loss = 0.39774
Step 54865: loss = 0.33240
Step 54870: loss = 0.20277
Step 54875: loss = 0.32169
Step 54880: loss = 0.42021
Step 54885: loss = 0.11411
Step 54890: loss = 0.28341
Step 54895: loss = 0.38098
Step 54900: loss = 0.21392
Step 54905: loss = 0.35768
Step 54910: loss = 0.36972
Step 54915: loss = 0.34935
Step 54920: loss = 0.31867
Step 54925: loss = 0.23594
Step 54930: loss = 0.28177
Step 54935: loss = 0.33295
Step 54940: loss = 0.13459
Step 54945: loss = 0.31230
Step 54950: loss = 0.35702
Step 54955: loss = 0.08342
Step 54960: loss = 0.72675
Step 54965: loss = 0.22158
Step 54970: loss = 0.20873
Step 54975: loss = 0.29988
Step 54980: loss = 0.27510
Step 54985: loss = 0.48421
Step 54990: loss = 0.25976
Step 54995: loss = 0.29084
Step 55000: loss = 0.16572
Training Data Eval:
  Num examples: 50000, Num correct: 45132, Precision @ 1: 0.9026
('Testing Data Eval: EPOCH->', 56)
  Num examples: 10000, Num correct: 6456, Precision @ 1: 0.6456
Step 55005: loss = 0.15834
Step 55010: loss = 0.11923
Step 55015: loss = 0.36642
Step 55020: loss = 0.21131
Step 55025: loss = 0.42077
Step 55030: loss = 0.36303
Step 55035: loss = 0.20276
Step 55040: loss = 0.57378
Step 55045: loss = 0.33807
Step 55050: loss = 0.28620
Step 55055: loss = 0.07944
Step 55060: loss = 0.16943
Step 55065: loss = 0.33580
Step 55070: loss = 0.26194
Step 55075: loss = 0.38355
Step 55080: loss = 0.25567
Step 55085: loss = 0.20062
Step 55090: loss = 0.30117
Step 55095: loss = 0.27722
Step 55100: loss = 0.28084
Step 55105: loss = 0.17624
Step 55110: loss = 0.38463
Step 55115: loss = 0.37265
Step 55120: loss = 0.25597
Step 55125: loss = 0.18711
Step 55130: loss = 0.50136
Step 55135: loss = 0.25240
Step 55140: loss = 0.16065
Step 55145: loss = 0.26389
Step 55150: loss = 0.47564
Step 55155: loss = 0.28035
Step 55160: loss = 0.37559
Step 55165: loss = 0.23962
Step 55170: loss = 0.28332
Step 55175: loss = 0.46349
Step 55180: loss = 0.18910
Step 55185: loss = 0.35041
Step 55190: loss = 0.28782
Step 55195: loss = 0.20636
Step 55200: loss = 0.23005
Step 55205: loss = 0.28882
Step 55210: loss = 0.27352
Step 55215: loss = 0.48625
Step 55220: loss = 0.27936
Step 55225: loss = 0.51144
Step 55230: loss = 0.45051
Step 55235: loss = 0.41397
Step 55240: loss = 0.28310
Step 55245: loss = 0.42324
Step 55250: loss = 0.23118
Step 55255: loss = 0.39729
Step 55260: loss = 0.33086
Step 55265: loss = 0.22112
Step 55270: loss = 0.35862
Step 55275: loss = 0.24916
Step 55280: loss = 0.19962
Step 55285: loss = 0.21507
Step 55290: loss = 0.45704
Step 55295: loss = 0.48498
Step 55300: loss = 0.24561
Step 55305: loss = 0.19527
Step 55310: loss = 0.38773
Step 55315: loss = 0.17923
Step 55320: loss = 0.36887
Step 55325: loss = 0.38851
Step 55330: loss = 0.30434
Step 55335: loss = 0.17285
Step 55340: loss = 0.43981
Step 55345: loss = 0.28165
Step 55350: loss = 0.13214
Step 55355: loss = 0.22030
Step 55360: loss = 0.35853
Step 55365: loss = 0.44556
Step 55370: loss = 0.34736
Step 55375: loss = 0.42781
Step 55380: loss = 0.33436
Step 55385: loss = 0.26887
Step 55390: loss = 0.40733
Step 55395: loss = 0.19344
Step 55400: loss = 0.17413
Step 55405: loss = 0.40068
Step 55410: loss = 0.28735
Step 55415: loss = 0.26643
Step 55420: loss = 0.24961
Step 55425: loss = 0.31756
Step 55430: loss = 0.14104
Step 55435: loss = 0.16021
Step 55440: loss = 0.41729
Step 55445: loss = 0.37263
Step 55450: loss = 0.34386
Step 55455: loss = 0.14203
Step 55460: loss = 0.37952
Step 55465: loss = 0.25222
Step 55470: loss = 0.17365
Step 55475: loss = 0.22001
Step 55480: loss = 0.27631
Step 55485: loss = 0.56049
Step 55490: loss = 0.15846
Step 55495: loss = 0.16086
Step 55500: loss = 0.42125
Step 55505: loss = 0.30981
Step 55510: loss = 0.32101
Step 55515: loss = 0.27266
Step 55520: loss = 0.27605
Step 55525: loss = 0.40727
Step 55530: loss = 0.25970
Step 55535: loss = 0.15266
Step 55540: loss = 0.41042
Step 55545: loss = 0.38171
Step 55550: loss = 0.39354
Step 55555: loss = 0.27122
Step 55560: loss = 0.20515
Step 55565: loss = 0.22926
Step 55570: loss = 0.47797
Step 55575: loss = 0.08909
Step 55580: loss = 0.19087
Step 55585: loss = 0.29390
Step 55590: loss = 0.25220
Step 55595: loss = 0.13900
Step 55600: loss = 0.37265
Step 55605: loss = 0.20047
Step 55610: loss = 0.22708
Step 55615: loss = 0.46537
Step 55620: loss = 0.20898
Step 55625: loss = 0.18392
Step 55630: loss = 0.20196
Step 55635: loss = 0.29541
Step 55640: loss = 0.34009
Step 55645: loss = 0.35194
Step 55650: loss = 0.22503
Step 55655: loss = 0.27161
Step 55660: loss = 0.20449
Step 55665: loss = 0.24070
Step 55670: loss = 0.34328
Step 55675: loss = 0.46129
Step 55680: loss = 0.35094
Step 55685: loss = 0.17579
Step 55690: loss = 0.29771
Step 55695: loss = 0.51852
Step 55700: loss = 0.25765
Step 55705: loss = 0.38826
Step 55710: loss = 0.25043
Step 55715: loss = 0.37693
Step 55720: loss = 0.35056
Step 55725: loss = 0.34535
Step 55730: loss = 0.43894
Step 55735: loss = 0.29311
Step 55740: loss = 0.40380
Step 55745: loss = 0.20696
Step 55750: loss = 0.28366
Step 55755: loss = 0.52160
Step 55760: loss = 0.18446
Step 55765: loss = 0.43358
Step 55770: loss = 0.41384
Step 55775: loss = 0.26894
Step 55780: loss = 0.19628
Step 55785: loss = 0.35134
Step 55790: loss = 0.24184
Step 55795: loss = 0.23726
Step 55800: loss = 0.26249
Step 55805: loss = 0.25458
Step 55810: loss = 0.14803
Step 55815: loss = 0.41939
Step 55820: loss = 0.18510
Step 55825: loss = 0.37014
Step 55830: loss = 0.11563
Step 55835: loss = 0.20927
Step 55840: loss = 0.23564
Step 55845: loss = 0.18703
Step 55850: loss = 0.26641
Step 55855: loss = 0.19335
Step 55860: loss = 0.22989
Step 55865: loss = 0.20616
Step 55870: loss = 0.32269
Step 55875: loss = 0.20403
Step 55880: loss = 0.15434
Step 55885: loss = 0.36070
Step 55890: loss = 0.25520
Step 55895: loss = 0.19081
Step 55900: loss = 0.31419
Step 55905: loss = 0.18251
Step 55910: loss = 0.18078
Step 55915: loss = 0.23806
Step 55920: loss = 0.14707
Step 55925: loss = 0.19306
Step 55930: loss = 0.21546
Step 55935: loss = 0.13129
Step 55940: loss = 0.26453
Step 55945: loss = 0.20784
Step 55950: loss = 0.35544
Step 55955: loss = 0.50265
Step 55960: loss = 0.64212
Step 55965: loss = 0.21440
Step 55970: loss = 0.32016
Step 55975: loss = 0.58879
Step 55980: loss = 0.36641
Step 55985: loss = 0.31631
Step 55990: loss = 0.21978
Step 55995: loss = 0.19161
Step 56000: loss = 0.11047
Training Data Eval:
  Num examples: 50000, Num correct: 44876, Precision @ 1: 0.8975
('Testing Data Eval: EPOCH->', 57)
  Num examples: 10000, Num correct: 6393, Precision @ 1: 0.6393
Step 56005: loss = 0.29988
Step 56010: loss = 0.25813
Step 56015: loss = 0.28839
Step 56020: loss = 0.23585
Step 56025: loss = 0.17531
Step 56030: loss = 0.49150
Step 56035: loss = 0.34369
Step 56040: loss = 0.18127
Step 56045: loss = 0.18477
Step 56050: loss = 0.27004
Step 56055: loss = 0.24804
Step 56060: loss = 0.40981
Step 56065: loss = 0.17467
Step 56070: loss = 0.25857
Step 56075: loss = 0.24971
Step 56080: loss = 0.44623
Step 56085: loss = 0.17677
Step 56090: loss = 0.35443
Step 56095: loss = 0.10264
Step 56100: loss = 0.44295
Step 56105: loss = 0.33090
Step 56110: loss = 0.27210
Step 56115: loss = 0.38858
Step 56120: loss = 0.26852
Step 56125: loss = 0.23995
Step 56130: loss = 0.28485
Step 56135: loss = 0.35089
Step 56140: loss = 0.34753
Step 56145: loss = 0.52904
Step 56150: loss = 0.13342
Step 56155: loss = 0.33508
Step 56160: loss = 0.14635
Step 56165: loss = 0.23056
Step 56170: loss = 0.26082
Step 56175: loss = 0.55096
Step 56180: loss = 0.32435
Step 56185: loss = 0.34956
Step 56190: loss = 0.30089
Step 56195: loss = 0.35948
Step 56200: loss = 0.30894
Step 56205: loss = 0.15628
Step 56210: loss = 0.44734
Step 56215: loss = 0.38298
Step 56220: loss = 0.14633
Step 56225: loss = 0.14526
Step 56230: loss = 0.40218
Step 56235: loss = 0.23085
Step 56240: loss = 0.41763
Step 56245: loss = 0.16149
Step 56250: loss = 0.47391
Step 56255: loss = 0.19149
Step 56260: loss = 0.31343
Step 56265: loss = 0.16869
Step 56270: loss = 0.28861
Step 56275: loss = 0.14203
Step 56280: loss = 0.29298
Step 56285: loss = 0.20015
Step 56290: loss = 0.28030
Step 56295: loss = 0.10364
Step 56300: loss = 0.21491
Step 56305: loss = 1.20076
Step 56310: loss = 0.61733
Step 56315: loss = 0.47333
Step 56320: loss = 0.33985
Step 56325: loss = 0.43533
Step 56330: loss = 0.22014
Step 56335: loss = 0.29192
Step 56340: loss = 0.46618
Step 56345: loss = 0.24051
Step 56350: loss = 0.13620
Step 56355: loss = 0.29038
Step 56360: loss = 0.37963
Step 56365: loss = 0.25169
Step 56370: loss = 0.28552
Step 56375: loss = 0.29447
Step 56380: loss = 0.17041
Step 56385: loss = 0.33940
Step 56390: loss = 0.52260
Step 56395: loss = 0.20856
Step 56400: loss = 0.17145
Step 56405: loss = 0.21222
Step 56410: loss = 0.36910
Step 56415: loss = 0.27813
Step 56420: loss = 0.17080
Step 56425: loss = 0.20681
Step 56430: loss = 0.25982
Step 56435: loss = 0.36712
Step 56440: loss = 0.25417
Step 56445: loss = 0.37741
Step 56450: loss = 0.24874
Step 56455: loss = 0.26642
Step 56460: loss = 0.13985
Step 56465: loss = 0.16307
Step 56470: loss = 0.37654
Step 56475: loss = 0.38135
Step 56480: loss = 0.24555
Step 56485: loss = 0.53085
Step 56490: loss = 0.41155
Step 56495: loss = 0.46802
Step 56500: loss = 0.23357
Step 56505: loss = 0.30369
Step 56510: loss = 0.14653
Step 56515: loss = 0.28856
Step 56520: loss = 0.15931
Step 56525: loss = 0.43288
Step 56530: loss = 0.23808
Step 56535: loss = 0.29245
Step 56540: loss = 0.15945
Step 56545: loss = 0.38666
Step 56550: loss = 0.25115
Step 56555: loss = 0.21327
Step 56560: loss = 0.36113
Step 56565: loss = 0.35072
Step 56570: loss = 0.26002
Step 56575: loss = 0.16223
Step 56580: loss = 0.13357
Step 56585: loss = 0.28251
Step 56590: loss = 0.33762
Step 56595: loss = 0.43865
Step 56600: loss = 0.17866
Step 56605: loss = 0.70825
Step 56610: loss = 0.67782
Step 56615: loss = 0.26865
Step 56620: loss = 0.15263
Step 56625: loss = 0.46029
Step 56630: loss = 0.28972
Step 56635: loss = 0.20689
Step 56640: loss = 0.42186
Step 56645: loss = 0.21952
Step 56650: loss = 0.43316
Step 56655: loss = 0.28996
Step 56660: loss = 0.25598
Step 56665: loss = 0.58609
Step 56670: loss = 0.11439
Step 56675: loss = 0.30690
Step 56680: loss = 0.12928
Step 56685: loss = 0.23848
Step 56690: loss = 0.38790
Step 56695: loss = 0.14307
Step 56700: loss = 0.40551
Step 56705: loss = 0.15099
Step 56710: loss = 0.31442
Step 56715: loss = 0.34458
Step 56720: loss = 0.24736
Step 56725: loss = 0.20664
Step 56730: loss = 0.32594
Step 56735: loss = 0.18520
Step 56740: loss = 0.30907
Step 56745: loss = 0.57702
Step 56750: loss = 0.21233
Step 56755: loss = 0.29931
Step 56760: loss = 0.15785
Step 56765: loss = 0.13701
Step 56770: loss = 0.18105
Step 56775: loss = 0.31991
Step 56780: loss = 0.27976
Step 56785: loss = 0.49203
Step 56790: loss = 0.26478
Step 56795: loss = 0.55918
Step 56800: loss = 0.29508
Step 56805: loss = 0.14015
Step 56810: loss = 0.16610
Step 56815: loss = 0.19876
Step 56820: loss = 0.57842
Step 56825: loss = 0.39667
Step 56830: loss = 0.16305
Step 56835: loss = 0.39152
Step 56840: loss = 0.27809
Step 56845: loss = 0.30371
Step 56850: loss = 0.25477
Step 56855: loss = 0.53755
Step 56860: loss = 0.13503
Step 56865: loss = 0.32290
Step 56870: loss = 0.21827
Step 56875: loss = 0.22673
Step 56880: loss = 0.33994
Step 56885: loss = 0.47349
Step 56890: loss = 0.39778
Step 56895: loss = 0.55166
Step 56900: loss = 0.45825
Step 56905: loss = 0.48617
Step 56910: loss = 0.43667
Step 56915: loss = 0.37115
Step 56920: loss = 0.18873
Step 56925: loss = 0.28202
Step 56930: loss = 0.27925
Step 56935: loss = 0.29661
Step 56940: loss = 0.38946
Step 56945: loss = 0.36040
Step 56950: loss = 0.55411
Step 56955: loss = 0.16927
Step 56960: loss = 0.57898
Step 56965: loss = 0.28050
Step 56970: loss = 0.56120
Step 56975: loss = 0.33262
Step 56980: loss = 0.33676
Step 56985: loss = 0.34560
Step 56990: loss = 0.26031
Step 56995: loss = 0.28126
Step 57000: loss = 0.24662
Training Data Eval:
  Num examples: 50000, Num correct: 45328, Precision @ 1: 0.9066
('Testing Data Eval: EPOCH->', 58)
  Num examples: 10000, Num correct: 6436, Precision @ 1: 0.6436
Step 57005: loss = 0.14899
Step 57010: loss = 0.38825
Step 57015: loss = 0.15841
Step 57020: loss = 0.30526
Step 57025: loss = 0.25661
Step 57030: loss = 0.20837
Step 57035: loss = 0.30017
Step 57040: loss = 0.33690
Step 57045: loss = 0.36975
Step 57050: loss = 0.11535
Step 57055: loss = 0.30576
Step 57060: loss = 0.37511
Step 57065: loss = 0.27419
Step 57070: loss = 0.40372
Step 57075: loss = 0.12842
Step 57080: loss = 0.13645
Step 57085: loss = 0.16065
Step 57090: loss = 0.45669
Step 57095: loss = 0.27811
Step 57100: loss = 0.39720
Step 57105: loss = 0.19856
Step 57110: loss = 0.18494
Step 57115: loss = 0.43883
Step 57120: loss = 0.26185
Step 57125: loss = 0.10978
Step 57130: loss = 0.15413
Step 57135: loss = 0.22730
Step 57140: loss = 0.33288
Step 57145: loss = 0.13879
Step 57150: loss = 0.38090
Step 57155: loss = 0.40495
Step 57160: loss = 0.44676
Step 57165: loss = 0.11451
Step 57170: loss = 0.28389
Step 57175: loss = 0.26196
Step 57180: loss = 0.29838
Step 57185: loss = 0.09524
Step 57190: loss = 0.25927
Step 57195: loss = 0.24320
Step 57200: loss = 0.11288
Step 57205: loss = 0.19807
Step 57210: loss = 0.23498
Step 57215: loss = 0.13456
Step 57220: loss = 0.23683
Step 57225: loss = 0.24893
Step 57230: loss = 0.22595
Step 57235: loss = 0.23867
Step 57240: loss = 0.28602
Step 57245: loss = 0.25581
Step 57250: loss = 0.17157
Step 57255: loss = 0.29016
Step 57260: loss = 0.20121
Step 57265: loss = 0.26957
Step 57270: loss = 0.19735
Step 57275: loss = 0.36762
Step 57280: loss = 0.33686
Step 57285: loss = 0.43048
Step 57290: loss = 0.25164
Step 57295: loss = 0.13688
Step 57300: loss = 0.19993
Step 57305: loss = 0.30267
Step 57310: loss = 0.26286
Step 57315: loss = 0.31237
Step 57320: loss = 0.10277
Step 57325: loss = 0.51270
Step 57330: loss = 0.25399
Step 57335: loss = 0.17242
Step 57340: loss = 0.26635
Step 57345: loss = 0.34178
Step 57350: loss = 0.33236
Step 57355: loss = 0.29888
Step 57360: loss = 0.19438
Step 57365: loss = 0.28912
Step 57370: loss = 0.34444
Step 57375: loss = 0.54325
Step 57380: loss = 0.16523
Step 57385: loss = 0.11583
Step 57390: loss = 0.16489
Step 57395: loss = 0.27324
Step 57400: loss = 0.15460
Step 57405: loss = 0.33362
Step 57410: loss = 0.23986
Step 57415: loss = 0.17378
Step 57420: loss = 0.25294
Step 57425: loss = 0.41534
Step 57430: loss = 0.44740
Step 57435: loss = 0.39628
Step 57440: loss = 0.09256
Step 57445: loss = 0.42613
Step 57450: loss = 0.22540
Step 57455: loss = 0.20396
Step 57460: loss = 0.25083
Step 57465: loss = 0.20559
Step 57470: loss = 0.21533
Step 57475: loss = 0.34170
Step 57480: loss = 0.49472
Step 57485: loss = 0.43153
Step 57490: loss = 0.26828
Step 57495: loss = 0.28152
Step 57500: loss = 0.12880
Step 57505: loss = 0.46272
Step 57510: loss = 0.23365
Step 57515: loss = 0.14187
Step 57520: loss = 0.28279
Step 57525: loss = 0.26351
Step 57530: loss = 0.27359
Step 57535: loss = 0.24545
Step 57540: loss = 0.43119
Step 57545: loss = 0.25958
Step 57550: loss = 0.20740
Step 57555: loss = 0.29294
Step 57560: loss = 0.40968
Step 57565: loss = 0.28042
Step 57570: loss = 0.21603
Step 57575: loss = 0.24031
Step 57580: loss = 0.15386
Step 57585: loss = 0.36345
Step 57590: loss = 0.27741
Step 57595: loss = 0.22251
Step 57600: loss = 0.26424
Step 57605: loss = 0.61956
Step 57610: loss = 0.42070
Step 57615: loss = 0.39979
Step 57620: loss = 0.43207
Step 57625: loss = 0.24268
Step 57630: loss = 0.57931
Step 57635: loss = 0.44347
Step 57640: loss = 0.19716
Step 57645: loss = 0.34512
Step 57650: loss = 0.39448
Step 57655: loss = 0.25097
Step 57660: loss = 0.81376
Step 57665: loss = 0.12945
Step 57670: loss = 0.40032
Step 57675: loss = 0.21943
Step 57680: loss = 0.33366
Step 57685: loss = 0.23820
Step 57690: loss = 0.22874
Step 57695: loss = 0.18235
Step 57700: loss = 0.35831
Step 57705: loss = 0.33536
Step 57710: loss = 0.44888
Step 57715: loss = 0.25189
Step 57720: loss = 0.18576
Step 57725: loss = 0.32736
Step 57730: loss = 0.12222
Step 57735: loss = 0.33656
Step 57740: loss = 0.34781
Step 57745: loss = 0.21825
Step 57750: loss = 0.31952
Step 57755: loss = 0.65451
Step 57760: loss = 0.26081
Step 57765: loss = 0.42179
Step 57770: loss = 0.18799
Step 57775: loss = 0.18573
Step 57780: loss = 0.45165
Step 57785: loss = 0.30157
Step 57790: loss = 0.33782
Step 57795: loss = 0.20108
Step 57800: loss = 0.07318
Step 57805: loss = 0.26815
Step 57810: loss = 0.16286
Step 57815: loss = 0.21626
Step 57820: loss = 0.28480
Step 57825: loss = 0.40881
Step 57830: loss = 0.33952
Step 57835: loss = 0.32632
Step 57840: loss = 0.35864
Step 57845: loss = 0.25345
Step 57850: loss = 0.30297
Step 57855: loss = 0.27121
Step 57860: loss = 0.24464
Step 57865: loss = 0.38437
Step 57870: loss = 0.36120
Step 57875: loss = 0.40912
Step 57880: loss = 0.42116
Step 57885: loss = 0.26839
Step 57890: loss = 0.18214
Step 57895: loss = 0.32648
Step 57900: loss = 0.26175
Step 57905: loss = 0.20227
Step 57910: loss = 0.30750
Step 57915: loss = 0.29290
Step 57920: loss = 0.17951
Step 57925: loss = 0.50788
Step 57930: loss = 0.36198
Step 57935: loss = 0.41280
Step 57940: loss = 0.35059
Step 57945: loss = 0.29027
Step 57950: loss = 0.12314
Step 57955: loss = 0.20079
Step 57960: loss = 0.34061
Step 57965: loss = 0.32023
Step 57970: loss = 0.53498
Step 57975: loss = 0.29131
Step 57980: loss = 0.28794
Step 57985: loss = 0.25206
Step 57990: loss = 0.19738
Step 57995: loss = 0.28461
Step 58000: loss = 0.34514
Training Data Eval:
  Num examples: 50000, Num correct: 45154, Precision @ 1: 0.9031
('Testing Data Eval: EPOCH->', 59)
  Num examples: 10000, Num correct: 6564, Precision @ 1: 0.6564
Step 58005: loss = 0.27135
Step 58010: loss = 0.40599
Step 58015: loss = 0.32424
Step 58020: loss = 0.38258
Step 58025: loss = 0.45411
Step 58030: loss = 0.55906
Step 58035: loss = 0.21388
Step 58040: loss = 0.10829
Step 58045: loss = 0.23316
Step 58050: loss = 0.43807
Step 58055: loss = 0.33813
Step 58060: loss = 0.15377
Step 58065: loss = 0.26197
Step 58070: loss = 0.17842
Step 58075: loss = 0.12631
Step 58080: loss = 0.19071
Step 58085: loss = 0.33418
Step 58090: loss = 0.33659
Step 58095: loss = 0.27617
Step 58100: loss = 0.20595
Step 58105: loss = 0.11341
Step 58110: loss = 0.52537
Step 58115: loss = 0.23102
Step 58120: loss = 0.24005
Step 58125: loss = 0.24700
Step 58130: loss = 0.37252
Step 58135: loss = 0.17843
Step 58140: loss = 0.26413
Step 58145: loss = 0.43371
Step 58150: loss = 0.50018
Step 58155: loss = 0.57169
Step 58160: loss = 0.14346
Step 58165: loss = 0.32654
Step 58170: loss = 0.16992
Step 58175: loss = 0.62230
Step 58180: loss = 0.32843
Step 58185: loss = 0.45894
Step 58190: loss = 0.17418
Step 58195: loss = 0.18122
Step 58200: loss = 0.35696
Step 58205: loss = 0.32955
Step 58210: loss = 0.41407
Step 58215: loss = 0.35387
Step 58220: loss = 0.19919
Step 58225: loss = 0.40896
Step 58230: loss = 0.35932
Step 58235: loss = 0.21550
Step 58240: loss = 0.19153
Step 58245: loss = 0.42816
Step 58250: loss = 0.30377
Step 58255: loss = 0.15196
Step 58260: loss = 0.25852
Step 58265: loss = 0.30021
Step 58270: loss = 0.23382
Step 58275: loss = 0.26537
Step 58280: loss = 0.40375
Step 58285: loss = 0.20914
Step 58290: loss = 0.17348
Step 58295: loss = 0.33797
Step 58300: loss = 0.19848
Step 58305: loss = 0.20310
Step 58310: loss = 0.34426
Step 58315: loss = 0.10317
Step 58320: loss = 0.34066
Step 58325: loss = 0.17057
Step 58330: loss = 0.45444
Step 58335: loss = 0.33652
Step 58340: loss = 0.18727
Step 58345: loss = 0.25065
Step 58350: loss = 0.32614
Step 58355: loss = 0.35375
Step 58360: loss = 0.59907
Step 58365: loss = 0.22180
Step 58370: loss = 0.32572
Step 58375: loss = 0.29588
Step 58380: loss = 0.24687
Step 58385: loss = 0.10328
Step 58390: loss = 0.18210
Step 58395: loss = 0.32526
Step 58400: loss = 0.37610
Step 58405: loss = 0.18652
Step 58410: loss = 0.16339
Step 58415: loss = 0.22078
Step 58420: loss = 0.23651
Step 58425: loss = 0.47271
Step 58430: loss = 0.27397
Step 58435: loss = 0.41225
Step 58440: loss = 0.43687
Step 58445: loss = 0.19817
Step 58450: loss = 0.27701
Step 58455: loss = 0.19068
Step 58460: loss = 0.28664
Step 58465: loss = 0.15615
Step 58470: loss = 0.20410
Step 58475: loss = 0.23194
Step 58480: loss = 0.31004
Step 58485: loss = 0.34367
Step 58490: loss = 0.30947
Step 58495: loss = 0.25502
Step 58500: loss = 0.42244
Step 58505: loss = 0.55452
Step 58510: loss = 0.60058
Step 58515: loss = 0.14621
Step 58520: loss = 0.19229
Step 58525: loss = 0.17086
Step 58530: loss = 0.18181
Step 58535: loss = 0.35330
Step 58540: loss = 0.28216
Step 58545: loss = 0.36573
Step 58550: loss = 0.51660
Step 58555: loss = 0.21102
Step 58560: loss = 0.17226
Step 58565: loss = 0.31809
Step 58570: loss = 0.25668
Step 58575: loss = 0.19921
Step 58580: loss = 0.28251
Step 58585: loss = 0.39782
Step 58590: loss = 0.20659
Step 58595: loss = 0.15213
Step 58600: loss = 0.24000
Step 58605: loss = 0.19050
Step 58610: loss = 0.35281
Step 58615: loss = 0.28806
Step 58620: loss = 0.33506
Step 58625: loss = 0.34276
Step 58630: loss = 0.28664
Step 58635: loss = 0.30830
Step 58640: loss = 0.64547
Step 58645: loss = 0.41184
Step 58650: loss = 0.25516
Step 58655: loss = 0.29653
Step 58660: loss = 0.38685
Step 58665: loss = 0.33076
Step 58670: loss = 0.29088
Step 58675: loss = 0.30835
Step 58680: loss = 0.38429
Step 58685: loss = 0.16954
Step 58690: loss = 0.18314
Step 58695: loss = 0.31371
Step 58700: loss = 0.41830
Step 58705: loss = 0.24081
Step 58710: loss = 0.29586
Step 58715: loss = 0.76931
Step 58720: loss = 0.21461
Step 58725: loss = 0.12962
Step 58730: loss = 0.27566
Step 58735: loss = 0.34629
Step 58740: loss = 0.13461
Step 58745: loss = 0.23058
Step 58750: loss = 0.12778
Step 58755: loss = 0.33093
Step 58760: loss = 0.23852
Step 58765: loss = 0.37292
Step 58770: loss = 0.23995
Step 58775: loss = 0.47844
Step 58780: loss = 0.20907
Step 58785: loss = 0.16955
Step 58790: loss = 0.23086
Step 58795: loss = 0.28045
Step 58800: loss = 0.25551
Step 58805: loss = 0.41563
Step 58810: loss = 0.30631
Step 58815: loss = 0.13206
Step 58820: loss = 0.48753
Step 58825: loss = 0.32560
Step 58830: loss = 0.23917
Step 58835: loss = 0.21248
Step 58840: loss = 0.15060
Step 58845: loss = 0.22045
Step 58850: loss = 0.22772
Step 58855: loss = 0.15089
Step 58860: loss = 0.20453
Step 58865: loss = 0.23975
Step 58870: loss = 0.20366
Step 58875: loss = 0.12383
Step 58880: loss = 0.28757
Step 58885: loss = 0.41265
Step 58890: loss = 0.11546
Step 58895: loss = 0.33267
Step 58900: loss = 0.33532
Step 58905: loss = 0.33493
Step 58910: loss = 0.26118
Step 58915: loss = 0.46774
Step 58920: loss = 0.16342
Step 58925: loss = 0.32426
Step 58930: loss = 0.45831
Step 58935: loss = 0.39996
Step 58940: loss = 0.23364
Step 58945: loss = 0.31554
Step 58950: loss = 0.22230
Step 58955: loss = 0.47643
Step 58960: loss = 0.27102
Step 58965: loss = 0.40504
Step 58970: loss = 0.24262
Step 58975: loss = 0.24847
Step 58980: loss = 0.40579
Step 58985: loss = 0.27612
Step 58990: loss = 0.34091
Step 58995: loss = 0.17659
Step 59000: loss = 0.21031
Training Data Eval:
  Num examples: 50000, Num correct: 45500, Precision @ 1: 0.9100
('Testing Data Eval: EPOCH->', 60)
  Num examples: 10000, Num correct: 6460, Precision @ 1: 0.6460
Step 59005: loss = 0.20992
Step 59010: loss = 0.43881
Step 59015: loss = 0.14414
Step 59020: loss = 0.17597
Step 59025: loss = 0.25572
Step 59030: loss = 0.21852
Step 59035: loss = 0.26676
Step 59040: loss = 0.35212
Step 59045: loss = 0.16420
Step 59050: loss = 0.31650
Step 59055: loss = 0.11810
Step 59060: loss = 0.71387
Step 59065: loss = 0.28347
Step 59070: loss = 0.33468
Step 59075: loss = 0.14975
Step 59080: loss = 0.41705
Step 59085: loss = 0.36473
Step 59090: loss = 0.16980
Step 59095: loss = 0.29188
Step 59100: loss = 0.28732
Step 59105: loss = 0.23298
Step 59110: loss = 0.16276
Step 59115: loss = 0.47111
Step 59120: loss = 0.28652
Step 59125: loss = 0.14800
Step 59130: loss = 0.22522
Step 59135: loss = 0.40615
Step 59140: loss = 0.24581
Step 59145: loss = 0.18760
Step 59150: loss = 0.14618
Step 59155: loss = 0.19413
Step 59160: loss = 0.22601
Step 59165: loss = 0.17063
Step 59170: loss = 0.30081
Step 59175: loss = 0.24160
Step 59180: loss = 0.52720
Step 59185: loss = 0.30267
Step 59190: loss = 0.17019
Step 59195: loss = 0.54962
Step 59200: loss = 0.28414
Step 59205: loss = 0.68663
Step 59210: loss = 0.34873
Step 59215: loss = 0.30125
Step 59220: loss = 0.14450
Step 59225: loss = 0.14966
Step 59230: loss = 0.28272
Step 59235: loss = 0.32956
Step 59240: loss = 0.10124
Step 59245: loss = 0.22929
Step 59250: loss = 0.30289
Step 59255: loss = 0.16606
Step 59260: loss = 0.29327
Step 59265: loss = 0.16136
Step 59270: loss = 0.28568
Step 59275: loss = 0.16082
Step 59280: loss = 0.18001
Step 59285: loss = 0.42532
Step 59290: loss = 0.43616
Step 59295: loss = 0.11690
Step 59300: loss = 0.46547
Step 59305: loss = 0.14297
Step 59310: loss = 0.13194
Step 59315: loss = 0.30905
Step 59320: loss = 0.23217
Step 59325: loss = 0.23144
Step 59330: loss = 0.29732
Step 59335: loss = 0.56283
Step 59340: loss = 0.26263
Step 59345: loss = 0.42801
Step 59350: loss = 0.26331
Step 59355: loss = 0.34769
Step 59360: loss = 0.35513
Step 59365: loss = 0.12358
Step 59370: loss = 0.47596
Step 59375: loss = 0.19609
Step 59380: loss = 0.21612
Step 59385: loss = 0.29623
Step 59390: loss = 0.25451
Step 59395: loss = 0.20990
Step 59400: loss = 0.38024
Step 59405: loss = 0.14361
Step 59410: loss = 0.45752
Step 59415: loss = 0.23513
Step 59420: loss = 0.17384
Step 59425: loss = 0.27099
Step 59430: loss = 0.18304
Step 59435: loss = 0.20049
Step 59440: loss = 0.27804
Step 59445: loss = 0.25678
Step 59450: loss = 0.27307
Step 59455: loss = 0.23449
Step 59460: loss = 0.35301
Step 59465: loss = 0.26586
Step 59470: loss = 0.25866
Step 59475: loss = 0.19479
Step 59480: loss = 0.31957
Step 59485: loss = 0.17879
Step 59490: loss = 0.15426
Step 59495: loss = 0.27069
Step 59500: loss = 0.21537
Step 59505: loss = 0.38113
Step 59510: loss = 0.19355
Step 59515: loss = 0.16080
Step 59520: loss = 0.13296
Step 59525: loss = 0.34267
Step 59530: loss = 0.32817
Step 59535: loss = 0.32266
Step 59540: loss = 0.32434
Step 59545: loss = 0.26671
Step 59550: loss = 0.51954
Step 59555: loss = 0.26785
Step 59560: loss = 0.30881
Step 59565: loss = 0.42944
Step 59570: loss = 0.43216
Step 59575: loss = 0.52111
Step 59580: loss = 0.39689
Step 59585: loss = 0.14372
Step 59590: loss = 0.27265
Step 59595: loss = 0.17696
Step 59600: loss = 0.32617
Step 59605: loss = 0.35464
Step 59610: loss = 0.18363
Step 59615: loss = 0.27118
Step 59620: loss = 0.29562
Step 59625: loss = 0.25141
Step 59630: loss = 0.19753
Step 59635: loss = 0.19073
Step 59640: loss = 0.13974
Step 59645: loss = 0.35068
Step 59650: loss = 0.45147
Step 59655: loss = 0.21930
Step 59660: loss = 0.34561
Step 59665: loss = 0.26521
Step 59670: loss = 0.20768
Step 59675: loss = 0.17152
Step 59680: loss = 0.26959
Step 59685: loss = 0.24413
Step 59690: loss = 0.19386
Step 59695: loss = 0.29539
Step 59700: loss = 0.29981
Step 59705: loss = 0.26837
Step 59710: loss = 0.17162
Step 59715: loss = 0.68768
Step 59720: loss = 0.20547
Step 59725: loss = 0.12754
Step 59730: loss = 0.45812
Step 59735: loss = 0.38761
Step 59740: loss = 0.25808
Step 59745: loss = 0.29684
Step 59750: loss = 0.32072
Step 59755: loss = 0.49386
Step 59760: loss = 0.34964
Step 59765: loss = 0.28553
Step 59770: loss = 0.34278
Step 59775: loss = 0.16061
Step 59780: loss = 0.25266
Step 59785: loss = 0.17336
Step 59790: loss = 0.18504
Step 59795: loss = 0.18516
Step 59800: loss = 0.29188
Step 59805: loss = 0.24614
Step 59810: loss = 0.09294
Step 59815: loss = 0.32789
Step 59820: loss = 0.26624
Step 59825: loss = 0.15349
Step 59830: loss = 0.23312
Step 59835: loss = 0.40750
Step 59840: loss = 0.28103
Step 59845: loss = 0.13937
Step 59850: loss = 0.26732
Step 59855: loss = 0.24457
Step 59860: loss = 0.42806
Step 59865: loss = 0.27989
Step 59870: loss = 0.16062
Step 59875: loss = 0.39519
Step 59880: loss = 0.21329
Step 59885: loss = 0.32873
Step 59890: loss = 0.22155
Step 59895: loss = 0.30464
Step 59900: loss = 0.28596
Step 59905: loss = 0.14828
Step 59910: loss = 0.16175
Step 59915: loss = 0.24445
Step 59920: loss = 0.24288
Step 59925: loss = 0.24670
Step 59930: loss = 0.36819
Step 59935: loss = 0.18836
Step 59940: loss = 0.44335
Step 59945: loss = 0.33264
Step 59950: loss = 0.33715
Step 59955: loss = 0.17719
Step 59960: loss = 0.24116
Step 59965: loss = 0.35769
Step 59970: loss = 0.29177
Step 59975: loss = 0.28130
Step 59980: loss = 0.11348
Step 59985: loss = 0.18252
Step 59990: loss = 0.16610
Step 59995: loss = 0.16437
Step 60000: loss = 0.28293
Training Data Eval:
  Num examples: 50000, Num correct: 45431, Precision @ 1: 0.9086
('Testing Data Eval: EPOCH->', 61)
  Num examples: 10000, Num correct: 6575, Precision @ 1: 0.6575
Step 60005: loss = 0.17280
Step 60010: loss = 0.15219
Step 60015: loss = 0.40143
Step 60020: loss = 0.44801
Step 60025: loss = 0.40789
Step 60030: loss = 0.17555
Step 60035: loss = 0.33604
Step 60040: loss = 0.28302
Step 60045: loss = 0.17101
Step 60050: loss = 0.22808
Step 60055: loss = 0.35870
Step 60060: loss = 0.30577
Step 60065: loss = 0.22643
Step 60070: loss = 0.20322
Step 60075: loss = 0.19860
Step 60080: loss = 0.09469
Step 60085: loss = 0.24317
Step 60090: loss = 0.25921
Step 60095: loss = 0.42289
Step 60100: loss = 0.15258
Step 60105: loss = 0.28359
Step 60110: loss = 0.39056
Step 60115: loss = 0.24329
Step 60120: loss = 0.52487
Step 60125: loss = 0.19181
Step 60130: loss = 0.20331
Step 60135: loss = 0.19835
Step 60140: loss = 0.28345
Step 60145: loss = 0.20249
Step 60150: loss = 0.27016
Step 60155: loss = 0.20263
Step 60160: loss = 0.41023
Step 60165: loss = 0.14249
Step 60170: loss = 0.54519
Step 60175: loss = 0.46646
Step 60180: loss = 0.45893
Step 60185: loss = 0.19107
Step 60190: loss = 0.33259
Step 60195: loss = 0.38322
Step 60200: loss = 0.25294
Step 60205: loss = 0.25255
Step 60210: loss = 0.11198
Step 60215: loss = 0.23544
Step 60220: loss = 0.14290
Step 60225: loss = 0.42566
Step 60230: loss = 0.19974
Step 60235: loss = 0.27096
Step 60240: loss = 0.42056
Step 60245: loss = 0.38670
Step 60250: loss = 0.17980
Step 60255: loss = 0.12425
Step 60260: loss = 0.25554
Step 60265: loss = 0.15520
Step 60270: loss = 0.21495
Step 60275: loss = 0.25762
Step 60280: loss = 0.48819
Step 60285: loss = 0.22553
Step 60290: loss = 0.08689
Step 60295: loss = 0.18691
Step 60300: loss = 0.22863
Step 60305: loss = 0.27446
Step 60310: loss = 0.30061
Step 60315: loss = 0.28893
Step 60320: loss = 0.33944
Step 60325: loss = 0.28535
Step 60330: loss = 0.46526
Step 60335: loss = 0.25407
Step 60340: loss = 0.40282
Step 60345: loss = 0.26512
Step 60350: loss = 0.34331
Step 60355: loss = 0.56992
Step 60360: loss = 0.52452
Step 60365: loss = 0.34123
Step 60370: loss = 0.46368
Step 60375: loss = 0.18772
Step 60380: loss = 0.33531
Step 60385: loss = 0.40855
Step 60390: loss = 0.48242
Step 60395: loss = 0.24927
Step 60400: loss = 0.33316
Step 60405: loss = 0.33010
Step 60410: loss = 0.26405
Step 60415: loss = 0.44190
Step 60420: loss = 0.15104
Step 60425: loss = 0.39622
Step 60430: loss = 0.18107
Step 60435: loss = 0.34843
Step 60440: loss = 0.26418
Step 60445: loss = 0.27149
Step 60450: loss = 0.35593
Step 60455: loss = 0.27944
Step 60460: loss = 0.22354
Step 60465: loss = 0.25239
Step 60470: loss = 0.32381
Step 60475: loss = 0.17572
Step 60480: loss = 0.19585
Step 60485: loss = 0.27981
Step 60490: loss = 0.21941
Step 60495: loss = 0.23030
Step 60500: loss = 0.46046
Step 60505: loss = 0.36525
Step 60510: loss = 0.53154
Step 60515: loss = 0.07632
Step 60520: loss = 0.16277
Step 60525: loss = 0.32235
Step 60530: loss = 0.33773
Step 60535: loss = 0.46083
Step 60540: loss = 0.27151
Step 60545: loss = 0.25824
Step 60550: loss = 0.36950
Step 60555: loss = 0.29214
Step 60560: loss = 0.41946
Step 60565: loss = 0.43337
Step 60570: loss = 0.34803
Step 60575: loss = 0.15197
Step 60580: loss = 0.27363
Step 60585: loss = 0.37827
Step 60590: loss = 0.24324
Step 60595: loss = 0.29930
Step 60600: loss = 0.24267
Step 60605: loss = 0.26557
Step 60610: loss = 0.48768
Step 60615: loss = 0.19482
Step 60620: loss = 0.36784
Step 60625: loss = 0.19595
Step 60630: loss = 0.42803
Step 60635: loss = 0.19742
Step 60640: loss = 0.29291
Step 60645: loss = 0.23998
Step 60650: loss = 0.16117
Step 60655: loss = 0.23077
Step 60660: loss = 0.45183
Step 60665: loss = 0.07920
Step 60670: loss = 0.20696
Step 60675: loss = 0.19525
Step 60680: loss = 0.12837
Step 60685: loss = 0.35428
Step 60690: loss = 0.36115
Step 60695: loss = 0.35415
Step 60700: loss = 0.18086
Step 60705: loss = 0.36352
Step 60710: loss = 0.22505
Step 60715: loss = 0.08030
Step 60720: loss = 0.39782
Step 60725: loss = 0.15871
Step 60730: loss = 0.43878
Step 60735: loss = 0.14673
Step 60740: loss = 0.29263
Step 60745: loss = 0.47631
Step 60750: loss = 0.28154
Step 60755: loss = 0.30311
Step 60760: loss = 0.17511
Step 60765: loss = 0.12551
Step 60770: loss = 0.23361
Step 60775: loss = 0.41025
Step 60780: loss = 0.52128
Step 60785: loss = 0.26027
Step 60790: loss = 0.29606
Step 60795: loss = 0.30342
Step 60800: loss = 0.27901
Step 60805: loss = 0.26070
Step 60810: loss = 0.27664
Step 60815: loss = 0.22222
Step 60820: loss = 0.28568
Step 60825: loss = 0.35563
Step 60830: loss = 0.39796
Step 60835: loss = 0.34978
Step 60840: loss = 0.24529
Step 60845: loss = 0.34983
Step 60850: loss = 0.23748
Step 60855: loss = 0.37932
Step 60860: loss = 0.07789
Step 60865: loss = 0.25832
Step 60870: loss = 0.29691
Step 60875: loss = 0.20685
Step 60880: loss = 0.32861
Step 60885: loss = 0.27683
Step 60890: loss = 0.62881
Step 60895: loss = 0.19097
Step 60900: loss = 0.17239
Step 60905: loss = 0.40447
Step 60910: loss = 0.12456
Step 60915: loss = 0.40911
Step 60920: loss = 0.35174
Step 60925: loss = 0.33580
Step 60930: loss = 0.11447
Step 60935: loss = 0.25444
Step 60940: loss = 0.25609
Step 60945: loss = 0.24030
Step 60950: loss = 0.30883
Step 60955: loss = 0.58486
Step 60960: loss = 0.40875
Step 60965: loss = 0.53324
Step 60970: loss = 0.27569
Step 60975: loss = 0.34615
Step 60980: loss = 0.22585
Step 60985: loss = 0.24750
Step 60990: loss = 0.18672
Step 60995: loss = 0.21663
Step 61000: loss = 0.51368
Training Data Eval:
  Num examples: 50000, Num correct: 45381, Precision @ 1: 0.9076
('Testing Data Eval: EPOCH->', 62)
  Num examples: 10000, Num correct: 6448, Precision @ 1: 0.6448
Step 61005: loss = 0.28857
Step 61010: loss = 0.29040
Step 61015: loss = 0.34024
Step 61020: loss = 0.32593
Step 61025: loss = 0.16803
Step 61030: loss = 0.38310
Step 61035: loss = 0.23545
Step 61040: loss = 0.24641
Step 61045: loss = 0.19674
Step 61050: loss = 0.44991
Step 61055: loss = 0.38048
Step 61060: loss = 0.33561
Step 61065: loss = 0.21877
Step 61070: loss = 0.23851
Step 61075: loss = 0.21363
Step 61080: loss = 0.23952
Step 61085: loss = 0.12339
Step 61090: loss = 0.13898
Step 61095: loss = 0.18702
Step 61100: loss = 0.13868
Step 61105: loss = 0.28715
Step 61110: loss = 0.18038
Step 61115: loss = 0.50784
Step 61120: loss = 0.44553
Step 61125: loss = 0.29510
Step 61130: loss = 0.28614
Step 61135: loss = 0.26570
Step 61140: loss = 0.26423
Step 61145: loss = 0.24310
Step 61150: loss = 0.56710
Step 61155: loss = 0.28557
Step 61160: loss = 0.55335
Step 61165: loss = 0.24319
Step 61170: loss = 0.30302
Step 61175: loss = 0.26751
Step 61180: loss = 0.18338
Step 61185: loss = 0.25874
Step 61190: loss = 0.17833
Step 61195: loss = 0.30846
Step 61200: loss = 0.16481
Step 61205: loss = 0.19500
Step 61210: loss = 0.16628
Step 61215: loss = 0.25083
Step 61220: loss = 0.25673
Step 61225: loss = 0.11852
Step 61230: loss = 0.23435
Step 61235: loss = 0.19548
Step 61240: loss = 0.41736
Step 61245: loss = 0.28138
Step 61250: loss = 0.34671
Step 61255: loss = 0.21190
Step 61260: loss = 0.11851
Step 61265: loss = 0.10559
Step 61270: loss = 0.21130
Step 61275: loss = 0.28704
Step 61280: loss = 0.27043
Step 61285: loss = 0.19144
Step 61290: loss = 0.15897
Step 61295: loss = 0.18359
Step 61300: loss = 0.30577
Step 61305: loss = 0.18024
Step 61310: loss = 0.24817
Step 61315: loss = 0.25867
Step 61320: loss = 0.31584
Step 61325: loss = 0.15671
Step 61330: loss = 0.07949
Step 61335: loss = 0.23271
Step 61340: loss = 0.22237
Step 61345: loss = 0.15872
Step 61350: loss = 0.19197
Step 61355: loss = 0.38587
Step 61360: loss = 0.25441
Step 61365: loss = 0.28909
Step 61370: loss = 0.17675
Step 61375: loss = 0.22172
Step 61380: loss = 0.29730
Step 61385: loss = 0.11120
Step 61390: loss = 0.50917
Step 61395: loss = 0.18190
Step 61400: loss = 0.17777
Step 61405: loss = 0.40280
Step 61410: loss = 0.34277
Step 61415: loss = 0.24131
Step 61420: loss = 0.29590
Step 61425: loss = 0.15538
Step 61430: loss = 0.23994
Step 61435: loss = 0.23150
Step 61440: loss = 0.19834
Step 61445: loss = 0.28938
Step 61450: loss = 0.13597
Step 61455: loss = 0.34337
Step 61460: loss = 0.29058
Step 61465: loss = 0.56366
Step 61470: loss = 0.36580
Step 61475: loss = 0.16373
Step 61480: loss = 0.32118
Step 61485: loss = 0.56041
Step 61490: loss = 0.19814
Step 61495: loss = 0.44198
Step 61500: loss = 0.23755
Step 61505: loss = 0.38002
Step 61510: loss = 0.22648
Step 61515: loss = 0.41743
Step 61520: loss = 0.10899
Step 61525: loss = 0.11655
Step 61530: loss = 0.08200
Step 61535: loss = 0.26512
Step 61540: loss = 0.18007
Step 61545: loss = 0.22359
Step 61550: loss = 0.22950
Step 61555: loss = 0.23210
Step 61560: loss = 0.19731
Step 61565: loss = 0.22793
Step 61570: loss = 0.12160
Step 61575: loss = 0.44779
Step 61580: loss = 0.13907
Step 61585: loss = 0.26613
Step 61590: loss = 0.29196
Step 61595: loss = 0.16878
Step 61600: loss = 0.42828
Step 61605: loss = 0.20992
Step 61610: loss = 0.16839
Step 61615: loss = 0.15896
Step 61620: loss = 0.28545
Step 61625: loss = 0.21104
Step 61630: loss = 0.10821
Step 61635: loss = 0.24684
Step 61640: loss = 0.42275
Step 61645: loss = 0.38556
Step 61650: loss = 0.19091
Step 61655: loss = 0.58980
Step 61660: loss = 0.15434
Step 61665: loss = 0.15925
Step 61670: loss = 0.18113
Step 61675: loss = 0.30727
Step 61680: loss = 0.31445
Step 61685: loss = 0.45843
Step 61690: loss = 0.33307
Step 61695: loss = 0.40554
Step 61700: loss = 0.32427
Step 61705: loss = 0.29993
Step 61710: loss = 0.34899
Step 61715: loss = 0.42459
Step 61720: loss = 0.07750
Step 61725: loss = 0.26407
Step 61730: loss = 0.25092
Step 61735: loss = 0.14416
Step 61740: loss = 0.19115
Step 61745: loss = 0.28723
Step 61750: loss = 0.25839
Step 61755: loss = 0.49071
Step 61760: loss = 0.55405
Step 61765: loss = 0.24680
Step 61770: loss = 0.20225
Step 61775: loss = 0.17394
Step 61780: loss = 0.25354
Step 61785: loss = 0.28890
Step 61790: loss = 0.35323
Step 61795: loss = 0.20040
Step 61800: loss = 0.10916
Step 61805: loss = 0.16999
Step 61810: loss = 0.42824
Step 61815: loss = 0.25347
Step 61820: loss = 0.33525
Step 61825: loss = 0.19010
Step 61830: loss = 0.14138
Step 61835: loss = 0.32745
Step 61840: loss = 0.28383
Step 61845: loss = 0.17858
Step 61850: loss = 0.28796
Step 61855: loss = 0.08690
Step 61860: loss = 0.20204
Step 61865: loss = 0.13676
Step 61870: loss = 0.21741
Step 61875: loss = 0.43278
Step 61880: loss = 0.22431
Step 61885: loss = 0.47475
Step 61890: loss = 0.21922
Step 61895: loss = 0.24866
Step 61900: loss = 0.30618
Step 61905: loss = 0.35851
Step 61910: loss = 0.43579
Step 61915: loss = 0.33737
Step 61920: loss = 0.38907
Step 61925: loss = 0.18758
Step 61930: loss = 0.24877
Step 61935: loss = 0.20866
Step 61940: loss = 0.32011
Step 61945: loss = 0.20072
Step 61950: loss = 0.48398
Step 61955: loss = 0.21146
Step 61960: loss = 0.23730
Step 61965: loss = 0.25438
Step 61970: loss = 0.55534
Step 61975: loss = 0.29219
Step 61980: loss = 0.29569
Step 61985: loss = 0.31408
Step 61990: loss = 0.53271
Step 61995: loss = 0.59649
Step 62000: loss = 0.26431
Training Data Eval:
  Num examples: 50000, Num correct: 45451, Precision @ 1: 0.9090
('Testing Data Eval: EPOCH->', 63)
  Num examples: 10000, Num correct: 6357, Precision @ 1: 0.6357
Step 62005: loss = 0.51158
Step 62010: loss = 0.20729
Step 62015: loss = 0.25303
Step 62020: loss = 0.25321
Step 62025: loss = 0.21546
Step 62030: loss = 0.24228
Step 62035: loss = 0.07451
Step 62040: loss = 0.15528
Step 62045: loss = 0.28028
Step 62050: loss = 0.38788
Step 62055: loss = 0.08485
Step 62060: loss = 0.35862
Step 62065: loss = 0.21425
Step 62070: loss = 0.10794
Step 62075: loss = 0.34072
Step 62080: loss = 0.44295
Step 62085: loss = 0.35976
Step 62090: loss = 0.42061
Step 62095: loss = 0.32476
Step 62100: loss = 0.27861
Step 62105: loss = 0.10351
Step 62110: loss = 0.23605
Step 62115: loss = 0.18907
Step 62120: loss = 0.23021
Step 62125: loss = 0.27630
Step 62130: loss = 0.25941
Step 62135: loss = 0.46398
Step 62140: loss = 0.35370
Step 62145: loss = 0.22386
Step 62150: loss = 0.10726
Step 62155: loss = 0.20586
Step 62160: loss = 0.22694
Step 62165: loss = 0.40657
Step 62170: loss = 0.30126
Step 62175: loss = 0.13189
Step 62180: loss = 0.15552
Step 62185: loss = 0.28938
Step 62190: loss = 0.35376
Step 62195: loss = 0.22879
Step 62200: loss = 0.14628
Step 62205: loss = 0.26094
Step 62210: loss = 0.23416
Step 62215: loss = 0.23203
Step 62220: loss = 0.43983
Step 62225: loss = 0.11444
Step 62230: loss = 0.33467
Step 62235: loss = 0.15055
Step 62240: loss = 0.26574
Step 62245: loss = 0.14883
Step 62250: loss = 0.31886
Step 62255: loss = 0.30207
Step 62260: loss = 0.22585
Step 62265: loss = 0.21948
Step 62270: loss = 0.28743
Step 62275: loss = 0.23438
Step 62280: loss = 0.38329
Step 62285: loss = 0.35594
Step 62290: loss = 0.27218
Step 62295: loss = 0.31728
Step 62300: loss = 0.26359
Step 62305: loss = 0.54797
Step 62310: loss = 0.18560
Step 62315: loss = 0.11182
Step 62320: loss = 0.26936
Step 62325: loss = 0.20346
Step 62330: loss = 0.36735
Step 62335: loss = 0.28902
Step 62340: loss = 0.21639
Step 62345: loss = 0.07865
Step 62350: loss = 0.09607
Step 62355: loss = 0.36102
Step 62360: loss = 0.12864
Step 62365: loss = 0.23948
Step 62370: loss = 0.34990
Step 62375: loss = 0.33505
Step 62380: loss = 0.28352
Step 62385: loss = 0.48346
Step 62390: loss = 0.31415
Step 62395: loss = 0.55435
Step 62400: loss = 0.69875
Step 62405: loss = 0.40970
Step 62410: loss = 0.16594
Step 62415: loss = 0.14678
Step 62420: loss = 0.27799
Step 62425: loss = 0.25746
Step 62430: loss = 0.10321
Step 62435: loss = 0.16166
Step 62440: loss = 0.74396
Step 62445: loss = 0.36799
Step 62450: loss = 0.15941
Step 62455: loss = 0.41010
Step 62460: loss = 0.51588
Step 62465: loss = 0.19365
Step 62470: loss = 0.21454
Step 62475: loss = 0.50645
Step 62480: loss = 0.31962
Step 62485: loss = 0.31371
Step 62490: loss = 0.15888
Step 62495: loss = 0.14217
Step 62500: loss = 0.18023
Step 62505: loss = 0.25898
Step 62510: loss = 0.25096
Step 62515: loss = 0.13842
Step 62520: loss = 0.56420
Step 62525: loss = 0.18016
Step 62530: loss = 0.17347
Step 62535: loss = 0.39797
Step 62540: loss = 0.24844
Step 62545: loss = 0.27727
Step 62550: loss = 0.22168
Step 62555: loss = 0.16982
Step 62560: loss = 0.54835
Step 62565: loss = 0.36322
Step 62570: loss = 0.33245
Step 62575: loss = 0.42781
Step 62580: loss = 0.33679
Step 62585: loss = 0.17496
Step 62590: loss = 0.24588
Step 62595: loss = 0.20482
Step 62600: loss = 0.24599
Step 62605: loss = 0.29707
Step 62610: loss = 0.17246
Step 62615: loss = 0.36570
Step 62620: loss = 0.28005
Step 62625: loss = 0.31312
Step 62630: loss = 0.29193
Step 62635: loss = 0.30724
Step 62640: loss = 0.26087
Step 62645: loss = 0.22304
Step 62650: loss = 0.23418
Step 62655: loss = 0.24147
Step 62660: loss = 0.06634
Step 62665: loss = 0.15081
Step 62670: loss = 0.19061
Step 62675: loss = 0.21743
Step 62680: loss = 0.36747
Step 62685: loss = 0.24595
Step 62690: loss = 0.43755
Step 62695: loss = 0.18263
Step 62700: loss = 0.21040
Step 62705: loss = 0.30443
Step 62710: loss = 0.43414
Step 62715: loss = 0.26520
Step 62720: loss = 0.62494
Step 62725: loss = 0.21824
Step 62730: loss = 0.41754
Step 62735: loss = 0.10465
Step 62740: loss = 0.17801
Step 62745: loss = 0.20312
Step 62750: loss = 0.39411
Step 62755: loss = 0.34856
Step 62760: loss = 0.20265
Step 62765: loss = 0.26513
Step 62770: loss = 0.27389
Step 62775: loss = 0.37093
Step 62780: loss = 0.19649
Step 62785: loss = 0.26014
Step 62790: loss = 0.36140
Step 62795: loss = 0.24393
Step 62800: loss = 0.19045
Step 62805: loss = 0.19204
Step 62810: loss = 0.29176
Step 62815: loss = 0.15292
Step 62820: loss = 0.45471
Step 62825: loss = 0.35904
Step 62830: loss = 0.17050
Step 62835: loss = 0.21902
Step 62840: loss = 0.24008
Step 62845: loss = 0.25103
Step 62850: loss = 0.36299
Step 62855: loss = 0.20672
Step 62860: loss = 0.25344
Step 62865: loss = 0.20104
Step 62870: loss = 0.28221
Step 62875: loss = 0.11881
Step 62880: loss = 0.15706
Step 62885: loss = 0.23206
Step 62890: loss = 0.53916
Step 62895: loss = 0.23608
Step 62900: loss = 0.08673
Step 62905: loss = 0.28007
Step 62910: loss = 0.20097
Step 62915: loss = 0.35006
Step 62920: loss = 0.41740
Step 62925: loss = 0.42457
Step 62930: loss = 0.38909
Step 62935: loss = 0.20122
Step 62940: loss = 0.23914
Step 62945: loss = 0.20240
Step 62950: loss = 0.22310
Step 62955: loss = 0.43890
Step 62960: loss = 0.21538
Step 62965: loss = 0.20895
Step 62970: loss = 0.51613
Step 62975: loss = 0.26664
Step 62980: loss = 0.44200
Step 62985: loss = 0.46543
Step 62990: loss = 0.19449
Step 62995: loss = 0.26367
Step 63000: loss = 0.23886
Training Data Eval:
  Num examples: 50000, Num correct: 45613, Precision @ 1: 0.9123
('Testing Data Eval: EPOCH->', 64)
  Num examples: 10000, Num correct: 6400, Precision @ 1: 0.6400
Step 63005: loss = 0.13303
Step 63010: loss = 0.30933
Step 63015: loss = 0.32729
Step 63020: loss = 0.18509
Step 63025: loss = 0.27810
Step 63030: loss = 0.29457
Step 63035: loss = 0.16906
Step 63040: loss = 0.10222
Step 63045: loss = 0.16899
Step 63050: loss = 0.24439
Step 63055: loss = 0.43308
Step 63060: loss = 0.15716
Step 63065: loss = 0.18262
Step 63070: loss = 0.21773
Step 63075: loss = 0.43961
Step 63080: loss = 0.24116
Step 63085: loss = 0.18752
Step 63090: loss = 0.26044
Step 63095: loss = 0.45802
Step 63100: loss = 0.13725
Step 63105: loss = 0.43448
Step 63110: loss = 0.53826
Step 63115: loss = 0.15048
Step 63120: loss = 0.18506
Step 63125: loss = 0.21243
Step 63130: loss = 0.16400
Step 63135: loss = 0.14618
Step 63140: loss = 0.20065
Step 63145: loss = 0.28315
Step 63150: loss = 0.30378
Step 63155: loss = 0.12803
Step 63160: loss = 0.27628
Step 63165: loss = 0.21925
Step 63170: loss = 0.22604
Step 63175: loss = 0.26218
Step 63180: loss = 0.26430
Step 63185: loss = 0.25930
Step 63190: loss = 0.40322
Step 63195: loss = 0.32274
Step 63200: loss = 0.50669
Step 63205: loss = 0.26625
Step 63210: loss = 0.35010
Step 63215: loss = 0.30138
Step 63220: loss = 0.08083
Step 63225: loss = 0.19930
Step 63230: loss = 0.28964
Step 63235: loss = 0.16055
Step 63240: loss = 0.44367
Step 63245: loss = 0.23365
Step 63250: loss = 0.21542
Step 63255: loss = 0.29952
Step 63260: loss = 0.15558
Step 63265: loss = 0.15295
Step 63270: loss = 0.12900
Step 63275: loss = 0.32651
Step 63280: loss = 0.36579
Step 63285: loss = 0.31191
Step 63290: loss = 0.18817
Step 63295: loss = 0.19363
Step 63300: loss = 0.40522
Step 63305: loss = 0.17918
Step 63310: loss = 0.32524
Step 63315: loss = 0.39027
Step 63320: loss = 0.24690
Step 63325: loss = 0.26015
Step 63330: loss = 0.50134
Step 63335: loss = 0.34507
Step 63340: loss = 0.33701
Step 63345: loss = 0.28132
Step 63350: loss = 0.35725
Step 63355: loss = 0.16764
Step 63360: loss = 0.27225
Step 63365: loss = 0.43150
Step 63370: loss = 0.29736
Step 63375: loss = 0.21714
Step 63380: loss = 0.24862
Step 63385: loss = 0.32296
Step 63390: loss = 0.33772
Step 63395: loss = 0.19475
Step 63400: loss = 0.09730
Step 63405: loss = 0.26993
Step 63410: loss = 0.35372
Step 63415: loss = 0.22048
Step 63420: loss = 0.10512
Step 63425: loss = 0.21335
Step 63430: loss = 0.27642
Step 63435: loss = 0.35172
Step 63440: loss = 0.14352
Step 63445: loss = 0.23313
Step 63450: loss = 0.52224
Step 63455: loss = 0.18397
Step 63460: loss = 0.08079
Step 63465: loss = 0.14607
Step 63470: loss = 0.31084
Step 63475: loss = 0.17528
Step 63480: loss = 0.14298
Step 63485: loss = 0.21513
Step 63490: loss = 0.29381
Step 63495: loss = 0.22932
Step 63500: loss = 0.17109
Step 63505: loss = 0.35662
Step 63510: loss = 0.36069
Step 63515: loss = 0.22415
Step 63520: loss = 0.13264
Step 63525: loss = 0.20887
Step 63530: loss = 0.36089
Step 63535: loss = 0.20664
Step 63540: loss = 0.35304
Step 63545: loss = 0.07310
Step 63550: loss = 0.37757
Step 63555: loss = 0.19272
Step 63560: loss = 0.29322
Step 63565: loss = 0.38894
Step 63570: loss = 0.39295
Step 63575: loss = 0.20142
Step 63580: loss = 0.34010
Step 63585: loss = 0.22186
Step 63590: loss = 0.14217
Step 63595: loss = 0.24593
Step 63600: loss = 0.45093
Step 63605: loss = 0.35449
Step 63610: loss = 0.23353
Step 63615: loss = 0.20462
Step 63620: loss = 0.41493
Step 63625: loss = 0.21564
Step 63630: loss = 0.14450
Step 63635: loss = 0.19879
Step 63640: loss = 0.20743
Step 63645: loss = 0.24056
Step 63650: loss = 0.15018
Step 63655: loss = 0.20009
Step 63660: loss = 0.51052
Step 63665: loss = 0.16921
Step 63670: loss = 0.17075
Step 63675: loss = 0.10766
Step 63680: loss = 0.19159
Step 63685: loss = 0.32730
Step 63690: loss = 0.31567
Step 63695: loss = 0.27893
Step 63700: loss = 0.24694
Step 63705: loss = 0.12955
Step 63710: loss = 0.23765
Step 63715: loss = 0.08805
Step 63720: loss = 0.28841
Step 63725: loss = 0.26534
Step 63730: loss = 0.27694
Step 63735: loss = 0.24693
Step 63740: loss = 0.33122
Step 63745: loss = 0.31439
Step 63750: loss = 0.35229
Step 63755: loss = 0.41941
Step 63760: loss = 0.53122
Step 63765: loss = 0.12191
Step 63770: loss = 0.35227
Step 63775: loss = 0.39715
Step 63780: loss = 0.22881
Step 63785: loss = 0.31354
Step 63790: loss = 0.21308
Step 63795: loss = 0.11970
Step 63800: loss = 0.21271
Step 63805: loss = 0.28554
Step 63810: loss = 0.24608
Step 63815: loss = 0.29313
Step 63820: loss = 0.30473
Step 63825: loss = 0.15870
Step 63830: loss = 0.19357
Step 63835: loss = 0.25197
Step 63840: loss = 0.20162
Step 63845: loss = 0.13751
Step 63850: loss = 0.22940
Step 63855: loss = 0.45547
Step 63860: loss = 0.16004
Step 63865: loss = 0.17344
Step 63870: loss = 0.20594
Step 63875: loss = 0.20952
Step 63880: loss = 0.31612
Step 63885: loss = 0.27493
Step 63890: loss = 0.36393
Step 63895: loss = 0.20181
Step 63900: loss = 0.10842
Step 63905: loss = 0.24687
Step 63910: loss = 0.22616
Step 63915: loss = 0.38822
Step 63920: loss = 0.44916
Step 63925: loss = 0.25508
Step 63930: loss = 0.35533
Step 63935: loss = 0.25981
Step 63940: loss = 0.13100
Step 63945: loss = 0.39873
Step 63950: loss = 0.17910
Step 63955: loss = 0.15524
Step 63960: loss = 0.26096
Step 63965: loss = 0.32115
Step 63970: loss = 0.28367
Step 63975: loss = 0.20951
Step 63980: loss = 0.24399
Step 63985: loss = 0.22522
Step 63990: loss = 0.26075
Step 63995: loss = 0.33101
Step 64000: loss = 0.30551
Training Data Eval:
  Num examples: 50000, Num correct: 45916, Precision @ 1: 0.9183
('Testing Data Eval: EPOCH->', 65)
  Num examples: 10000, Num correct: 6516, Precision @ 1: 0.6516
Step 64005: loss = 0.20937
Step 64010: loss = 0.35126
Step 64015: loss = 0.42845
Step 64020: loss = 0.39785
Step 64025: loss = 0.65902
Step 64030: loss = 0.18078
Step 64035: loss = 0.40557
Step 64040: loss = 0.22581
Step 64045: loss = 0.39534
Step 64050: loss = 0.10866
Step 64055: loss = 0.25357
Step 64060: loss = 0.37502
Step 64065: loss = 0.26616
Step 64070: loss = 0.28327
Step 64075: loss = 0.26292
Step 64080: loss = 0.16563
Step 64085: loss = 0.27429
Step 64090: loss = 0.14301
Step 64095: loss = 0.15365
Step 64100: loss = 0.17219
Step 64105: loss = 0.23744
Step 64110: loss = 0.22771
Step 64115: loss = 0.26079
Step 64120: loss = 0.28747
Step 64125: loss = 0.28985
Step 64130: loss = 0.42158
Step 64135: loss = 0.16657
Step 64140: loss = 0.22235
Step 64145: loss = 0.41813
Step 64150: loss = 0.31714
Step 64155: loss = 0.15469
Step 64160: loss = 0.22923
Step 64165: loss = 0.27241
Step 64170: loss = 0.35921
Step 64175: loss = 0.45672
Step 64180: loss = 0.47533
Step 64185: loss = 0.32424
Step 64190: loss = 0.22267
Step 64195: loss = 0.17899
Step 64200: loss = 0.29958
Step 64205: loss = 0.14537
Step 64210: loss = 0.30443
Step 64215: loss = 0.18247
Step 64220: loss = 0.29468
Step 64225: loss = 0.18296
Step 64230: loss = 0.20548
Step 64235: loss = 0.20050
Step 64240: loss = 0.18937
Step 64245: loss = 0.44046
Step 64250: loss = 0.43954
Step 64255: loss = 0.25693
Step 64260: loss = 0.10555
Step 64265: loss = 0.31708
Step 64270: loss = 0.15886
Step 64275: loss = 0.25781
Step 64280: loss = 0.21091
Step 64285: loss = 0.60887
Step 64290: loss = 0.15474
Step 64295: loss = 0.35095
Step 64300: loss = 0.22803
Step 64305: loss = 0.18054
Step 64310: loss = 0.20762
Step 64315: loss = 0.33502
Step 64320: loss = 0.16463
Step 64325: loss = 0.33643
Step 64330: loss = 0.26054
Step 64335: loss = 0.25145
Step 64340: loss = 0.12593
Step 64345: loss = 0.15005
Step 64350: loss = 0.33403
Step 64355: loss = 0.27190
Step 64360: loss = 0.07305
Step 64365: loss = 0.17184
Step 64370: loss = 0.42031
Step 64375: loss = 0.18023
Step 64380: loss = 0.26625
Step 64385: loss = 0.26498
Step 64390: loss = 0.25450
Step 64395: loss = 0.30908
Step 64400: loss = 0.33980
Step 64405: loss = 0.25802
Step 64410: loss = 0.21392
Step 64415: loss = 0.16734
Step 64420: loss = 0.51726
Step 64425: loss = 0.31835
Step 64430: loss = 0.66197
Step 64435: loss = 0.39366
Step 64440: loss = 0.19207
Step 64445: loss = 0.25371
Step 64450: loss = 0.26302
Step 64455: loss = 0.31115
Step 64460: loss = 0.33861
Step 64465: loss = 0.31443
Step 64470: loss = 0.20631
Step 64475: loss = 0.21215
Step 64480: loss = 0.18830
Step 64485: loss = 0.31205
Step 64490: loss = 0.17621
Step 64495: loss = 0.16997
Step 64500: loss = 0.21974
Step 64505: loss = 0.28622
Step 64510: loss = 0.21407
Step 64515: loss = 0.25258
Step 64520: loss = 0.31666
Step 64525: loss = 0.16812
Step 64530: loss = 0.33931
Step 64535: loss = 0.06874
Step 64540: loss = 0.12902
Step 64545: loss = 0.16152
Step 64550: loss = 0.23887
Step 64555: loss = 0.27099
Step 64560: loss = 0.15682
Step 64565: loss = 0.28298
Step 64570: loss = 0.26194
Step 64575: loss = 0.16181
Step 64580: loss = 0.15504
Step 64585: loss = 0.36539
Step 64590: loss = 0.35984
Step 64595: loss = 0.11526
Step 64600: loss = 0.24633
Step 64605: loss = 0.42124
Step 64610: loss = 0.30256
Step 64615: loss = 0.20225
Step 64620: loss = 0.31319
Step 64625: loss = 0.34247
Step 64630: loss = 0.20441
Step 64635: loss = 0.33609
Step 64640: loss = 0.23789
Step 64645: loss = 0.25210
Step 64650: loss = 0.34541
Step 64655: loss = 0.24066
Step 64660: loss = 0.08213
Step 64665: loss = 0.42171
Step 64670: loss = 0.18096
Step 64675: loss = 0.06021
Step 64680: loss = 0.17709
Step 64685: loss = 0.19483
Step 64690: loss = 0.27113
Step 64695: loss = 0.10593
Step 64700: loss = 0.17846
Step 64705: loss = 0.16256
Step 64710: loss = 0.14620
Step 64715: loss = 0.24196
Step 64720: loss = 0.18887
Step 64725: loss = 0.21470
Step 64730: loss = 0.09390
Step 64735: loss = 0.15942
Step 64740: loss = 0.25128
Step 64745: loss = 0.26356
Step 64750: loss = 0.31945
Step 64755: loss = 0.32662
Step 64760: loss = 0.14272
Step 64765: loss = 0.32029
Step 64770: loss = 0.28415
Step 64775: loss = 0.32028
Step 64780: loss = 0.18245
Step 64785: loss = 0.30498
Step 64790: loss = 0.40780
Step 64795: loss = 0.32489
Step 64800: loss = 0.63653
Step 64805: loss = 0.29914
Step 64810: loss = 0.27759
Step 64815: loss = 0.48581
Step 64820: loss = 0.22120
Step 64825: loss = 0.57697
Step 64830: loss = 0.39749
Step 64835: loss = 0.46535
Step 64840: loss = 0.26962
Step 64845: loss = 0.44972
Step 64850: loss = 0.30507
Step 64855: loss = 0.21493
Step 64860: loss = 0.05907
Step 64865: loss = 0.26028
Step 64870: loss = 0.30146
Step 64875: loss = 0.31928
Step 64880: loss = 0.31659
Step 64885: loss = 0.39162
Step 64890: loss = 0.19050
Step 64895: loss = 0.45473
Step 64900: loss = 0.21163
Step 64905: loss = 0.40112
Step 64910: loss = 0.08490
Step 64915: loss = 0.50507
Step 64920: loss = 0.10946
Step 64925: loss = 0.21346
Step 64930: loss = 0.20795
Step 64935: loss = 0.17119
Step 64940: loss = 0.38198
Step 64945: loss = 0.14283
Step 64950: loss = 0.48394
Step 64955: loss = 0.29182
Step 64960: loss = 0.18939
Step 64965: loss = 0.21812
Step 64970: loss = 0.18668
Step 64975: loss = 0.15358
Step 64980: loss = 0.18698
Step 64985: loss = 0.18205
Step 64990: loss = 0.17705
Step 64995: loss = 0.39215
Step 65000: loss = 0.32067
Training Data Eval:
  Num examples: 50000, Num correct: 45677, Precision @ 1: 0.9135
('Testing Data Eval: EPOCH->', 66)
  Num examples: 10000, Num correct: 6385, Precision @ 1: 0.6385
Step 65005: loss = 0.23282
Step 65010: loss = 0.11609
Step 65015: loss = 0.24092
Step 65020: loss = 0.28779
Step 65025: loss = 0.10190
Step 65030: loss = 0.14004
Step 65035: loss = 0.30359
Step 65040: loss = 0.19264
Step 65045: loss = 0.12517
Step 65050: loss = 0.22000
Step 65055: loss = 0.10385
Step 65060: loss = 0.27333
Step 65065: loss = 0.13047
Step 65070: loss = 0.21143
Step 65075: loss = 0.21961
Step 65080: loss = 0.37990
Step 65085: loss = 0.16450
Step 65090: loss = 0.16947
Step 65095: loss = 0.13830
Step 65100: loss = 0.16336
Step 65105: loss = 0.09646
Step 65110: loss = 0.12919
Step 65115: loss = 0.37652
Step 65120: loss = 0.26337
Step 65125: loss = 0.32541
Step 65130: loss = 0.14457
Step 65135: loss = 0.11036
Step 65140: loss = 0.33557
Step 65145: loss = 0.04684
Step 65150: loss = 0.36384
Step 65155: loss = 0.33939
Step 65160: loss = 0.39417
Step 65165: loss = 0.20655
Step 65170: loss = 0.45083
Step 65175: loss = 0.20551
Step 65180: loss = 0.28747
Step 65185: loss = 0.24228
Step 65190: loss = 0.30141
Step 65195: loss = 0.29914
Step 65200: loss = 0.10812
Step 65205: loss = 0.11186
Step 65210: loss = 0.20043
Step 65215: loss = 0.48453
Step 65220: loss = 0.18172
Step 65225: loss = 0.28497
Step 65230: loss = 0.22370
Step 65235: loss = 0.16535
Step 65240: loss = 0.19754
Step 65245: loss = 0.20040
Step 65250: loss = 0.10651
Step 65255: loss = 0.14046
Step 65260: loss = 0.24826
Step 65265: loss = 0.27516
Step 65270: loss = 0.22856
Step 65275: loss = 0.22981
Step 65280: loss = 0.26994
Step 65285: loss = 0.29822
Step 65290: loss = 0.28444
Step 65295: loss = 0.18056
Step 65300: loss = 0.32489
Step 65305: loss = 0.55374
Step 65310: loss = 0.42608
Step 65315: loss = 0.24278
Step 65320: loss = 0.16615
Step 65325: loss = 0.21240
Step 65330: loss = 0.10698
Step 65335: loss = 0.19997
Step 65340: loss = 0.26115
Step 65345: loss = 0.33564
Step 65350: loss = 0.25284
Step 65355: loss = 0.05787
Step 65360: loss = 0.07092
Step 65365: loss = 0.52810
Step 65370: loss = 0.42263
Step 65375: loss = 0.22318
Step 65380: loss = 0.25821
Step 65385: loss = 0.33884
Step 65390: loss = 0.13757
Step 65395: loss = 0.16431
Step 65400: loss = 0.24552
Step 65405: loss = 0.22413
Step 65410: loss = 0.26337
Step 65415: loss = 0.13849
Step 65420: loss = 0.12590
Step 65425: loss = 0.45673
Step 65430: loss = 0.21697
Step 65435: loss = 0.24512
Step 65440: loss = 0.12265
Step 65445: loss = 0.24037
Step 65450: loss = 0.17425
Step 65455: loss = 0.25980
Step 65460: loss = 0.25029
Step 65465: loss = 0.23831
Step 65470: loss = 0.34371
Step 65475: loss = 0.22046
Step 65480: loss = 0.26345
Step 65485: loss = 0.33269
Step 65490: loss = 0.22221
Step 65495: loss = 1.14520
Step 65500: loss = 0.23073
Step 65505: loss = 0.27595
Step 65510: loss = 0.44602
Step 65515: loss = 0.16229
Step 65520: loss = 0.50501
Step 65525: loss = 0.59504
Step 65530: loss = 0.42358
Step 65535: loss = 0.51208
Step 65540: loss = 0.57192
Step 65545: loss = 0.36244
Step 65550: loss = 0.34200
Step 65555: loss = 0.32048
Step 65560: loss = 0.11885
Step 65565: loss = 0.23922
Step 65570: loss = 0.37718
Step 65575: loss = 0.28630
Step 65580: loss = 0.26136
Step 65585: loss = 0.33690
Step 65590: loss = 0.27495
Step 65595: loss = 0.46243
Step 65600: loss = 0.27520
Step 65605: loss = 0.22518
Step 65610: loss = 0.18880
Step 65615: loss = 0.33535
Step 65620: loss = 0.36043
Step 65625: loss = 0.33783
Step 65630: loss = 0.20051
Step 65635: loss = 0.18883
Step 65640: loss = 0.08185
Step 65645: loss = 0.22942
Step 65650: loss = 0.25313
Step 65655: loss = 0.26090
Step 65660: loss = 0.24713
Step 65665: loss = 0.26108
Step 65670: loss = 0.26034
Step 65675: loss = 0.24661
Step 65680: loss = 0.17147
Step 65685: loss = 0.21762
Step 65690: loss = 0.29301
Step 65695: loss = 0.30663
Step 65700: loss = 0.11654
Step 65705: loss = 0.08759
Step 65710: loss = 0.22163
Step 65715: loss = 0.36187
Step 65720: loss = 0.32026
Step 65725: loss = 0.32442
Step 65730: loss = 0.67819
Step 65735: loss = 0.25247
Step 65740: loss = 0.21230
Step 65745: loss = 0.17394
Step 65750: loss = 0.08922
Step 65755: loss = 0.22094
Step 65760: loss = 0.27664
Step 65765: loss = 0.22930
Step 65770: loss = 0.19606
Step 65775: loss = 0.19042
Step 65780: loss = 0.17172
Step 65785: loss = 0.33247
Step 65790: loss = 0.22907
Step 65795: loss = 0.14084
Step 65800: loss = 0.25359
Step 65805: loss = 0.28514
Step 65810: loss = 0.18230
Step 65815: loss = 0.25812
Step 65820: loss = 0.21397
Step 65825: loss = 0.05630
Step 65830: loss = 0.24862
Step 65835: loss = 0.17514
Step 65840: loss = 0.13257
Step 65845: loss = 0.18385
Step 65850: loss = 0.23035
Step 65855: loss = 0.20362
Step 65860: loss = 0.21236
Step 65865: loss = 0.19631
Step 65870: loss = 0.33507
Step 65875: loss = 0.38744
Step 65880: loss = 0.20350
Step 65885: loss = 0.17187
Step 65890: loss = 0.67858
Step 65895: loss = 0.23532
Step 65900: loss = 0.10587
Step 65905: loss = 0.23883
Step 65910: loss = 0.23503
Step 65915: loss = 0.28358
Step 65920: loss = 0.32964
Step 65925: loss = 0.21958
Step 65930: loss = 0.68813
Step 65935: loss = 0.25582
Step 65940: loss = 0.36296
Step 65945: loss = 0.66367
Step 65950: loss = 0.48385
Step 65955: loss = 0.30510
Step 65960: loss = 0.40431
Step 65965: loss = 0.14591
Step 65970: loss = 0.17764
Step 65975: loss = 0.19104
Step 65980: loss = 0.47857
Step 65985: loss = 0.24942
Step 65990: loss = 0.21377
Step 65995: loss = 0.15642
Step 66000: loss = 0.14760
Training Data Eval:
  Num examples: 50000, Num correct: 45712, Precision @ 1: 0.9142
('Testing Data Eval: EPOCH->', 67)
  Num examples: 10000, Num correct: 6463, Precision @ 1: 0.6463
Step 66005: loss = 0.13276
Step 66010: loss = 0.22838
Step 66015: loss = 0.32072
Step 66020: loss = 0.27491
Step 66025: loss = 0.18100
Step 66030: loss = 0.17823
Step 66035: loss = 0.32979
Step 66040: loss = 0.28170
Step 66045: loss = 0.33290
Step 66050: loss = 0.29470
Step 66055: loss = 0.10926
Step 66060: loss = 0.25340
Step 66065: loss = 0.28955
Step 66070: loss = 0.22116
Step 66075: loss = 0.18270
Step 66080: loss = 0.16797
Step 66085: loss = 0.69284
Step 66090: loss = 0.26351
Step 66095: loss = 0.25550
Step 66100: loss = 0.24413
Step 66105: loss = 0.25524
Step 66110: loss = 0.17270
Step 66115: loss = 0.65199
Step 66120: loss = 0.18769
Step 66125: loss = 0.30082
Step 66130: loss = 0.23463
Step 66135: loss = 0.23895
Step 66140: loss = 0.24446
Step 66145: loss = 0.40123
Step 66150: loss = 0.55746
Step 66155: loss = 0.26044
Step 66160: loss = 0.14902
Step 66165: loss = 0.24210
Step 66170: loss = 0.16270
Step 66175: loss = 0.20762
Step 66180: loss = 0.26210
Step 66185: loss = 0.34130
Step 66190: loss = 0.18986
Step 66195: loss = 0.40551
Step 66200: loss = 0.25864
Step 66205: loss = 0.29101
Step 66210: loss = 0.41517
Step 66215: loss = 0.26132
Step 66220: loss = 0.19561
Step 66225: loss = 0.34860
Step 66230: loss = 0.11317
Step 66235: loss = 0.26384
Step 66240: loss = 0.31658
Step 66245: loss = 0.27026
Step 66250: loss = 0.12107
Step 66255: loss = 0.31356
Step 66260: loss = 0.19324
Step 66265: loss = 0.24918
Step 66270: loss = 0.22003
Step 66275: loss = 0.22475
Step 66280: loss = 0.35194
Step 66285: loss = 0.19067
Step 66290: loss = 0.22829
Step 66295: loss = 0.17459
Step 66300: loss = 0.35736
Step 66305: loss = 0.20912
Step 66310: loss = 0.22387
Step 66315: loss = 0.22290
Step 66320: loss = 0.15610
Step 66325: loss = 0.39113
Step 66330: loss = 0.12232
Step 66335: loss = 0.18993
Step 66340: loss = 0.17697
Step 66345: loss = 0.28398
Step 66350: loss = 0.13196
Step 66355: loss = 0.10552
Step 66360: loss = 0.51140
Step 66365: loss = 0.32944
Step 66370: loss = 0.18853
Step 66375: loss = 0.29456
Step 66380: loss = 0.18194
Step 66385: loss = 0.14903
Step 66390: loss = 0.28373
Step 66395: loss = 0.50618
Step 66400: loss = 0.15072
Step 66405: loss = 0.06450
Step 66410: loss = 0.24872
Step 66415: loss = 0.21556
Step 66420: loss = 0.11505
Step 66425: loss = 0.21229
Step 66430: loss = 0.40927
Step 66435: loss = 0.09893
Step 66440: loss = 0.28829
Step 66445: loss = 0.28773
Step 66450: loss = 0.10124
Step 66455: loss = 0.61172
Step 66460: loss = 0.35819
Step 66465: loss = 0.36123
Step 66470: loss = 0.31663
Step 66475: loss = 0.20448
Step 66480: loss = 0.26404
Step 66485: loss = 0.41215
Step 66490: loss = 0.12680
Step 66495: loss = 0.35972
Step 66500: loss = 0.19975
Step 66505: loss = 0.30483
Step 66510: loss = 0.29842
Step 66515: loss = 0.22238
Step 66520: loss = 0.23197
Step 66525: loss = 0.34104
Step 66530: loss = 0.18864
Step 66535: loss = 0.35732
Step 66540: loss = 0.33265
Step 66545: loss = 0.18264
Step 66550: loss = 0.34188
Step 66555: loss = 0.20015
Step 66560: loss = 0.09625
Step 66565: loss = 0.41852
Step 66570: loss = 0.21344
Step 66575: loss = 0.23272
Step 66580: loss = 0.31397
Step 66585: loss = 0.07724
Step 66590: loss = 0.65488
Step 66595: loss = 0.47793
Step 66600: loss = 0.29202
Step 66605: loss = 0.17165
Step 66610: loss = 0.21160
Step 66615: loss = 0.36295
Step 66620: loss = 0.04952
Step 66625: loss = 0.40057
Step 66630: loss = 0.16855
Step 66635: loss = 0.22408
Step 66640: loss = 0.39579
Step 66645: loss = 0.25468
Step 66650: loss = 0.40432
Step 66655: loss = 0.19137
Step 66660: loss = 0.30818
Step 66665: loss = 0.19647
Step 66670: loss = 0.20188
Step 66675: loss = 0.19315
Step 66680: loss = 0.18447
Step 66685: loss = 0.31940
Step 66690: loss = 0.21444
Step 66695: loss = 0.18725
Step 66700: loss = 0.18149
Step 66705: loss = 0.18612
Step 66710: loss = 0.19467
Step 66715: loss = 0.20467
Step 66720: loss = 0.19112
Step 66725: loss = 0.13963
Step 66730: loss = 0.44498
Step 66735: loss = 0.20157
Step 66740: loss = 0.48497
Step 66745: loss = 0.30003
Step 66750: loss = 0.23787
Step 66755: loss = 0.33808
Step 66760: loss = 0.30666
Step 66765: loss = 0.22046
Step 66770: loss = 0.22358
Step 66775: loss = 0.40184
Step 66780: loss = 0.09886
Step 66785: loss = 0.40491
Step 66790: loss = 0.34874
Step 66795: loss = 0.23372
Step 66800: loss = 0.32483
Step 66805: loss = 0.26518
Step 66810: loss = 0.16091
Step 66815: loss = 0.13195
Step 66820: loss = 0.22077
Step 66825: loss = 0.17820
Step 66830: loss = 0.18989
Step 66835: loss = 0.12256
Step 66840: loss = 0.16756
Step 66845: loss = 0.41293
Step 66850: loss = 0.18315
Step 66855: loss = 0.23824
Step 66860: loss = 0.25302
Step 66865: loss = 0.16915
Step 66870: loss = 0.25253
Step 66875: loss = 0.29619
Step 66880: loss = 0.17245
Step 66885: loss = 0.34052
Step 66890: loss = 0.16365
Step 66895: loss = 0.15580
Step 66900: loss = 0.18946
Step 66905: loss = 0.31764
Step 66910: loss = 0.32523
Step 66915: loss = 0.14768
Step 66920: loss = 0.24930
Step 66925: loss = 0.42754
Step 66930: loss = 0.18829
Step 66935: loss = 0.22333
Step 66940: loss = 0.23689
Step 66945: loss = 0.30301
Step 66950: loss = 0.35499
Step 66955: loss = 0.39603
Step 66960: loss = 0.22838
Step 66965: loss = 0.26522
Step 66970: loss = 0.08977
Step 66975: loss = 0.13852
Step 66980: loss = 0.16902
Step 66985: loss = 0.20996
Step 66990: loss = 0.24663
Step 66995: loss = 0.30996
Step 67000: loss = 0.09450
Training Data Eval:
  Num examples: 50000, Num correct: 45961, Precision @ 1: 0.9192
('Testing Data Eval: EPOCH->', 68)
  Num examples: 10000, Num correct: 6529, Precision @ 1: 0.6529
Step 67005: loss = 0.24850
Step 67010: loss = 0.30884
Step 67015: loss = 0.20636
Step 67020: loss = 0.19662
Step 67025: loss = 0.24493
Step 67030: loss = 0.12182
Step 67035: loss = 0.30083
Step 67040: loss = 0.10003
Step 67045: loss = 0.15488
Step 67050: loss = 0.21275
Step 67055: loss = 0.22580
Step 67060: loss = 0.13791
Step 67065: loss = 0.16736
Step 67070: loss = 0.30701
Step 67075: loss = 0.34979
Step 67080: loss = 0.32270
Step 67085: loss = 0.10733
Step 67090: loss = 0.23428
Step 67095: loss = 0.30710
Step 67100: loss = 0.17958
Step 67105: loss = 0.14870
Step 67110: loss = 0.19198
Step 67115: loss = 0.12832
Step 67120: loss = 0.13185
Step 67125: loss = 0.17067
Step 67130: loss = 0.34561
Step 67135: loss = 0.48983
Step 67140: loss = 0.23958
Step 67145: loss = 0.38533
Step 67150: loss = 0.18351
Step 67155: loss = 0.22782
Step 67160: loss = 0.09361
Step 67165: loss = 0.11993
Step 67170: loss = 0.18395
Step 67175: loss = 0.20220
Step 67180: loss = 0.14083
Step 67185: loss = 0.26390
Step 67190: loss = 0.19718
Step 67195: loss = 0.12994
Step 67200: loss = 0.28234
Step 67205: loss = 0.20463
Step 67210: loss = 0.19874
Step 67215: loss = 0.46456
Step 67220: loss = 0.18242
Step 67225: loss = 0.34768
Step 67230: loss = 0.07269
Step 67235: loss = 0.14722
Step 67240: loss = 0.25466
Step 67245: loss = 0.15745
Step 67250: loss = 0.28827
Step 67255: loss = 0.24273
Step 67260: loss = 0.15343
Step 67265: loss = 0.32050
Step 67270: loss = 0.25982
Step 67275: loss = 0.31302
Step 67280: loss = 0.57601
Step 67285: loss = 0.11693
Step 67290: loss = 0.09433
Step 67295: loss = 0.24578
Step 67300: loss = 0.27426
Step 67305: loss = 0.18857
Step 67310: loss = 0.17336
Step 67315: loss = 0.29278
Step 67320: loss = 0.39541
Step 67325: loss = 0.17337
Step 67330: loss = 0.14779
Step 67335: loss = 0.16270
Step 67340: loss = 0.57996
Step 67345: loss = 0.35811
Step 67350: loss = 0.22893
Step 67355: loss = 0.16561
Step 67360: loss = 0.23901
Step 67365: loss = 0.38025
Step 67370: loss = 0.30107
Step 67375: loss = 0.33659
Step 67380: loss = 0.47099
Step 67385: loss = 0.14158
Step 67390: loss = 0.19234
Step 67395: loss = 0.22930
Step 67400: loss = 0.13262
Step 67405: loss = 0.23050
Step 67410: loss = 0.08412
Step 67415: loss = 0.29535
Step 67420: loss = 0.28856
Step 67425: loss = 0.36155
Step 67430: loss = 0.18120
Step 67435: loss = 0.39694
Step 67440: loss = 0.19745
Step 67445: loss = 0.22338
Step 67450: loss = 0.32384
Step 67455: loss = 0.33215
Step 67460: loss = 0.13980
Step 67465: loss = 0.08937
Step 67470: loss = 0.22529
Step 67475: loss = 0.15767
Step 67480: loss = 0.24005
Step 67485: loss = 0.12315
Step 67490: loss = 0.13125
Step 67495: loss = 0.35889
Step 67500: loss = 0.22347
Step 67505: loss = 0.22840
Step 67510: loss = 0.14987
Step 67515: loss = 0.22161
Step 67520: loss = 0.12091
Step 67525: loss = 0.25268
Step 67530: loss = 0.18765
Step 67535: loss = 0.54212
Step 67540: loss = 0.20555
Step 67545: loss = 0.11124
Step 67550: loss = 0.41250
Step 67555: loss = 0.24294
Step 67560: loss = 0.18974
Step 67565: loss = 0.16574
Step 67570: loss = 0.12219
Step 67575: loss = 0.10342
Step 67580: loss = 0.40652
Step 67585: loss = 0.28011
Step 67590: loss = 0.22204
Step 67595: loss = 0.14603
Step 67600: loss = 0.17245
Step 67605: loss = 0.14137
Step 67610: loss = 0.29276
Step 67615: loss = 0.33095
Step 67620: loss = 0.18065
Step 67625: loss = 0.30656
Step 67630: loss = 0.24082
Step 67635: loss = 0.21678
Step 67640: loss = 0.17137
Step 67645: loss = 0.27851
Step 67650: loss = 0.17937
Step 67655: loss = 0.17625
Step 67660: loss = 0.12188
Step 67665: loss = 0.31953
Step 67670: loss = 0.31035
Step 67675: loss = 0.20432
Step 67680: loss = 0.12662
Step 67685: loss = 0.25508
Step 67690: loss = 0.25734
Step 67695: loss = 0.16219
Step 67700: loss = 0.12488
Step 67705: loss = 0.19432
Step 67710: loss = 0.14926
Step 67715: loss = 0.26355
Step 67720: loss = 0.30189
Step 67725: loss = 0.19957
Step 67730: loss = 0.32524
Step 67735: loss = 0.16023
Step 67740: loss = 0.11289
Step 67745: loss = 0.14077
Step 67750: loss = 0.37256
Step 67755: loss = 0.34950
Step 67760: loss = 0.13323
Step 67765: loss = 0.42352
Step 67770: loss = 0.17493
Step 67775: loss = 0.42477
Step 67780: loss = 0.11624
Step 67785: loss = 0.24356
Step 67790: loss = 0.34243
Step 67795: loss = 0.17152
Step 67800: loss = 0.41810
Step 67805: loss = 0.19586
Step 67810: loss = 0.19326
Step 67815: loss = 0.31879
Step 67820: loss = 0.37648
Step 67825: loss = 0.16596
Step 67830: loss = 0.34092
Step 67835: loss = 0.36906
Step 67840: loss = 0.08870
Step 67845: loss = 0.29623
Step 67850: loss = 0.21839
Step 67855: loss = 0.11257
Step 67860: loss = 0.31568
Step 67865: loss = 0.36412
Step 67870: loss = 0.24617
Step 67875: loss = 0.14001
Step 67880: loss = 0.25762
Step 67885: loss = 0.21128
Step 67890: loss = 0.18887
Step 67895: loss = 0.21805
Step 67900: loss = 0.35894
Step 67905: loss = 0.30119
Step 67910: loss = 0.18858
Step 67915: loss = 0.37204
Step 67920: loss = 0.27627
Step 67925: loss = 0.23061
Step 67930: loss = 0.28131
Step 67935: loss = 0.25102
Step 67940: loss = 0.23441
Step 67945: loss = 0.19441
Step 67950: loss = 0.28710
Step 67955: loss = 0.28707
Step 67960: loss = 0.21863
Step 67965: loss = 0.52836
Step 67970: loss = 0.22809
Step 67975: loss = 0.36265
Step 67980: loss = 0.38769
Step 67985: loss = 0.18278
Step 67990: loss = 0.13899
Step 67995: loss = 0.49814
Step 68000: loss = 0.19910
Training Data Eval:
  Num examples: 50000, Num correct: 45997, Precision @ 1: 0.9199
('Testing Data Eval: EPOCH->', 69)
  Num examples: 10000, Num correct: 6429, Precision @ 1: 0.6429
Step 68005: loss = 0.57606
Step 68010: loss = 0.34541
Step 68015: loss = 0.14113
Step 68020: loss = 0.36660
Step 68025: loss = 0.18726
Step 68030: loss = 0.17857
Step 68035: loss = 0.31602
Step 68040: loss = 0.16976
Step 68045: loss = 0.38122
Step 68050: loss = 0.15075
Step 68055: loss = 0.18577
Step 68060: loss = 0.44802
Step 68065: loss = 0.12333
Step 68070: loss = 0.15149
Step 68075: loss = 0.27158
Step 68080: loss = 0.21150
Step 68085: loss = 0.22094
Step 68090: loss = 0.31704
Step 68095: loss = 0.11939
Step 68100: loss = 0.26553
Step 68105: loss = 0.28694
Step 68110: loss = 0.35295
Step 68115: loss = 0.30481
Step 68120: loss = 0.13943
Step 68125: loss = 0.28545
Step 68130: loss = 0.19154
Step 68135: loss = 0.16133
Step 68140: loss = 0.16408
Step 68145: loss = 0.25663
Step 68150: loss = 0.25772
Step 68155: loss = 0.17666
Step 68160: loss = 0.36329
Step 68165: loss = 0.30483
Step 68170: loss = 0.21678
Step 68175: loss = 0.38365
Step 68180: loss = 0.24882
Step 68185: loss = 0.21423
Step 68190: loss = 0.14334
Step 68195: loss = 0.09645
Step 68200: loss = 0.15042
Step 68205: loss = 0.30264
Step 68210: loss = 0.32140
Step 68215: loss = 0.25935
Step 68220: loss = 0.08748
Step 68225: loss = 0.20536
Step 68230: loss = 0.33086
Step 68235: loss = 0.15569
Step 68240: loss = 0.12571
Step 68245: loss = 0.07862
Step 68250: loss = 0.16399
Step 68255: loss = 0.26945
Step 68260: loss = 0.29350
Step 68265: loss = 0.19440
Step 68270: loss = 0.12319
Step 68275: loss = 0.27720
Step 68280: loss = 0.23462
Step 68285: loss = 0.18739
Step 68290: loss = 0.11503
Step 68295: loss = 0.29642
Step 68300: loss = 0.12654
Step 68305: loss = 0.15638
Step 68310: loss = 0.29665
Step 68315: loss = 0.11561
Step 68320: loss = 0.24825
Step 68325: loss = 0.11942
Step 68330: loss = 0.30334
Step 68335: loss = 0.16991
Step 68340: loss = 0.27016
Step 68345: loss = 0.16234
Step 68350: loss = 0.29116
Step 68355: loss = 1.11604
Step 68360: loss = 0.20528
Step 68365: loss = 0.18902
Step 68370: loss = 0.08466
Step 68375: loss = 0.17470
Step 68380: loss = 0.56704
Step 68385: loss = 0.10479
Step 68390: loss = 0.29829
Step 68395: loss = 0.28049
Step 68400: loss = 0.16953
Step 68405: loss = 0.25123
Step 68410: loss = 0.13714
Step 68415: loss = 0.21881
Step 68420: loss = 0.30772
Step 68425: loss = 0.25545
Step 68430: loss = 0.27220
Step 68435: loss = 0.19859
Step 68440: loss = 0.28240
Step 68445: loss = 0.14586
Step 68450: loss = 0.17277
Step 68455: loss = 0.10195
Step 68460: loss = 0.26447
Step 68465: loss = 0.31282
Step 68470: loss = 0.23515
Step 68475: loss = 0.27170
Step 68480: loss = 0.21318
Step 68485: loss = 0.52897
Step 68490: loss = 0.27448
Step 68495: loss = 0.13680
Step 68500: loss = 0.31374
Step 68505: loss = 0.21943
Step 68510: loss = 0.20102
Step 68515: loss = 0.14276
Step 68520: loss = 0.24310
Step 68525: loss = 0.30381
Step 68530: loss = 0.44896
Step 68535: loss = 0.41563
Step 68540: loss = 0.21978
Step 68545: loss = 0.24103
Step 68550: loss = 0.34459
Step 68555: loss = 0.20990
Step 68560: loss = 0.34719
Step 68565: loss = 0.17126
Step 68570: loss = 0.10091
Step 68575: loss = 0.21188
Step 68580: loss = 0.11913
Step 68585: loss = 0.38927
Step 68590: loss = 0.26793
Step 68595: loss = 0.19688
Step 68600: loss = 0.42487
Step 68605: loss = 0.31125
Step 68610: loss = 0.36517
Step 68615: loss = 0.18633
Step 68620: loss = 0.26091
Step 68625: loss = 0.16541
Step 68630: loss = 0.10022
Step 68635: loss = 0.16001
Step 68640: loss = 0.20899
Step 68645: loss = 0.24005
Step 68650: loss = 0.23353
Step 68655: loss = 0.34509
Step 68660: loss = 0.48590
Step 68665: loss = 0.25769
Step 68670: loss = 0.33338
Step 68675: loss = 0.14655
Step 68680: loss = 0.25761
Step 68685: loss = 0.32090
Step 68690: loss = 0.43800
Step 68695: loss = 0.26551
Step 68700: loss = 0.31365
Step 68705: loss = 0.09360
Step 68710: loss = 0.27394
Step 68715: loss = 0.09457
Step 68720: loss = 0.19893
Step 68725: loss = 0.23676
Step 68730: loss = 0.25669
Step 68735: loss = 0.31264
Step 68740: loss = 0.29746
Step 68745: loss = 0.24593
Step 68750: loss = 0.34648
Step 68755: loss = 0.17539
Step 68760: loss = 0.32406
Step 68765: loss = 0.54287
Step 68770: loss = 0.14191
Step 68775: loss = 0.39830
Step 68780: loss = 0.37525
Step 68785: loss = 0.16949
Step 68790: loss = 0.24338
Step 68795: loss = 0.30391
Step 68800: loss = 0.12692
Step 68805: loss = 0.35613
Step 68810: loss = 0.24615
Step 68815: loss = 0.73429
Step 68820: loss = 0.10440
Step 68825: loss = 0.27384
Step 68830: loss = 0.23909
Step 68835: loss = 0.46004
Step 68840: loss = 0.24474
Step 68845: loss = 0.22148
Step 68850: loss = 0.22559
Step 68855: loss = 0.20186
Step 68860: loss = 0.19826
Step 68865: loss = 0.20302
Step 68870: loss = 0.39083
Step 68875: loss = 0.18543
Step 68880: loss = 0.31003
Step 68885: loss = 0.13937
Step 68890: loss = 0.30425
Step 68895: loss = 0.21597
Step 68900: loss = 0.25536
Step 68905: loss = 0.13090
Step 68910: loss = 0.24613
Step 68915: loss = 0.34724
Step 68920: loss = 0.25690
Step 68925: loss = 0.08163
Step 68930: loss = 0.28974
Step 68935: loss = 0.09221
Step 68940: loss = 0.20872
Step 68945: loss = 0.19882
Step 68950: loss = 0.22618
Step 68955: loss = 0.07229
Step 68960: loss = 0.29494
Step 68965: loss = 0.26721
Step 68970: loss = 0.09094
Step 68975: loss = 0.17164
Step 68980: loss = 0.27708
Step 68985: loss = 0.15250
Step 68990: loss = 0.55906
Step 68995: loss = 0.15960
Step 69000: loss = 0.33551
Training Data Eval:
  Num examples: 50000, Num correct: 45557, Precision @ 1: 0.9111
('Testing Data Eval: EPOCH->', 70)
  Num examples: 10000, Num correct: 6385, Precision @ 1: 0.6385
Step 69005: loss = 0.28052
Step 69010: loss = 0.28437
Step 69015: loss = 0.35899
Step 69020: loss = 0.22781
Step 69025: loss = 0.15526
Step 69030: loss = 0.15076
Step 69035: loss = 0.14072
Step 69040: loss = 0.25574
Step 69045: loss = 0.23155
Step 69050: loss = 0.11660
Step 69055: loss = 0.24755
Step 69060: loss = 0.24359
Step 69065: loss = 0.48199
Step 69070: loss = 0.26228
Step 69075: loss = 0.19327
Step 69080: loss = 0.29392
Step 69085: loss = 0.20155
Step 69090: loss = 0.14208
Step 69095: loss = 0.39820
Step 69100: loss = 0.31563
Step 69105: loss = 0.43991
Step 69110: loss = 0.07031
Step 69115: loss = 0.27631
Step 69120: loss = 0.09897
Step 69125: loss = 0.22732
Step 69130: loss = 0.15575
Step 69135: loss = 0.54906
Step 69140: loss = 0.48327
Step 69145: loss = 0.08064
Step 69150: loss = 0.19830
Step 69155: loss = 0.20824
Step 69160: loss = 0.13567
Step 69165: loss = 0.15848
Step 69170: loss = 0.09787
Step 69175: loss = 0.19025
Step 69180: loss = 0.33280
Step 69185: loss = 0.17895
Step 69190: loss = 0.22288
Step 69195: loss = 0.18791
Step 69200: loss = 0.16969
Step 69205: loss = 0.30002
Step 69210: loss = 0.29217
Step 69215: loss = 0.15185
Step 69220: loss = 0.25372
Step 69225: loss = 0.26398
Step 69230: loss = 0.23633
Step 69235: loss = 0.32272
Step 69240: loss = 0.16354
Step 69245: loss = 0.11686
Step 69250: loss = 0.18859
Step 69255: loss = 0.24502
Step 69260: loss = 0.30401
Step 69265: loss = 0.17534
Step 69270: loss = 0.20215
Step 69275: loss = 0.16263
Step 69280: loss = 0.24258
Step 69285: loss = 0.12456
Step 69290: loss = 0.09946
Step 69295: loss = 0.28538
Step 69300: loss = 0.35860
Step 69305: loss = 0.06874
Step 69310: loss = 0.20889
Step 69315: loss = 0.17643
Step 69320: loss = 0.20172
Step 69325: loss = 0.25435
Step 69330: loss = 0.18754
Step 69335: loss = 0.22274
Step 69340: loss = 0.22279
Step 69345: loss = 0.14666
Step 69350: loss = 0.18855
Step 69355: loss = 0.28213
Step 69360: loss = 0.18687
Step 69365: loss = 0.20873
Step 69370: loss = 0.24124
Step 69375: loss = 0.14879
Step 69380: loss = 0.20973
Step 69385: loss = 0.31384
Step 69390: loss = 0.24862
Step 69395: loss = 0.18199
Step 69400: loss = 0.17253
Step 69405: loss = 0.16307
Step 69410: loss = 0.26759
Step 69415: loss = 0.26342
Step 69420: loss = 0.17332
Step 69425: loss = 0.27207
Step 69430: loss = 0.26782
Step 69435: loss = 0.19529
Step 69440: loss = 0.31202
Step 69445: loss = 0.24081
Step 69450: loss = 0.07712
Step 69455: loss = 0.15729
Step 69460: loss = 0.35759
Step 69465: loss = 0.35554
Step 69470: loss = 0.30521
Step 69475: loss = 0.08186
Step 69480: loss = 0.32230
Step 69485: loss = 0.20786
Step 69490: loss = 0.10457
Step 69495: loss = 0.24214
Step 69500: loss = 0.06948
Step 69505: loss = 0.18601
Step 69510: loss = 0.24317
Step 69515: loss = 0.33704
Step 69520: loss = 0.17699
Step 69525: loss = 0.28378
Step 69530: loss = 0.09819
Step 69535: loss = 0.32704
Step 69540: loss = 0.21680
Step 69545: loss = 0.29687
Step 69550: loss = 0.24467
Step 69555: loss = 0.12228
Step 69560: loss = 0.20921
Step 69565: loss = 0.39676
Step 69570: loss = 0.10577
Step 69575: loss = 0.41402
Step 69580: loss = 0.07217
Step 69585: loss = 0.23151
Step 69590: loss = 0.18021
Step 69595: loss = 0.09338
Step 69600: loss = 0.31896
Step 69605: loss = 0.36628
Step 69610: loss = 0.34950
Step 69615: loss = 0.21069
Step 69620: loss = 0.25695
Step 69625: loss = 0.38126
Step 69630: loss = 0.22522
Step 69635: loss = 0.20894
Step 69640: loss = 0.21561
Step 69645: loss = 0.09747
Step 69650: loss = 0.10068
Step 69655: loss = 0.23779
Step 69660: loss = 0.31539
Step 69665: loss = 0.28167
Step 69670: loss = 0.28423
Step 69675: loss = 0.11290
Step 69680: loss = 0.17141
Step 69685: loss = 0.23503
Step 69690: loss = 0.33539
Step 69695: loss = 0.24442
Step 69700: loss = 0.24448
Step 69705: loss = 0.38735
Step 69710: loss = 0.21140
Step 69715: loss = 0.13928
Step 69720: loss = 0.17006
Step 69725: loss = 0.23454
Step 69730: loss = 0.09551
Step 69735: loss = 0.57412
Step 69740: loss = 0.24234
Step 69745: loss = 0.16762
Step 69750: loss = 0.30240
Step 69755: loss = 0.27487
Step 69760: loss = 0.23327
Step 69765: loss = 0.51120
Step 69770: loss = 0.43694
Step 69775: loss = 0.36334
Step 69780: loss = 0.38526
Step 69785: loss = 0.19758
Step 69790: loss = 0.31974
Step 69795: loss = 0.23396
Step 69800: loss = 0.21559
Step 69805: loss = 0.25400
Step 69810: loss = 0.46430
Step 69815: loss = 0.16367
Step 69820: loss = 0.24779
Step 69825: loss = 0.15296
Step 69830: loss = 0.20064
Step 69835: loss = 0.23318
Step 69840: loss = 0.21820
Step 69845: loss = 0.06880
Step 69850: loss = 0.21207
Step 69855: loss = 0.07621
Step 69860: loss = 0.10381
Step 69865: loss = 0.18203
Step 69870: loss = 0.18835
Step 69875: loss = 0.12779
Step 69880: loss = 0.43617
Step 69885: loss = 0.24389
Step 69890: loss = 0.32303
Step 69895: loss = 0.21855
Step 69900: loss = 0.18704
Step 69905: loss = 0.17047
Step 69910: loss = 0.16982
Step 69915: loss = 0.15326
Step 69920: loss = 0.21143
Step 69925: loss = 0.24088
Step 69930: loss = 0.10958
Step 69935: loss = 0.17221
Step 69940: loss = 0.11818
Step 69945: loss = 0.11455
Step 69950: loss = 0.26370
Step 69955: loss = 0.41171
Step 69960: loss = 0.27824
Step 69965: loss = 0.17184
Step 69970: loss = 0.11466
Step 69975: loss = 0.30019
Step 69980: loss = 0.22455
Step 69985: loss = 0.16250
Step 69990: loss = 0.09773
Step 69995: loss = 0.15284
Step 70000: loss = 0.12324
Training Data Eval:
  Num examples: 50000, Num correct: 46134, Precision @ 1: 0.9227
('Testing Data Eval: EPOCH->', 71)
  Num examples: 10000, Num correct: 6613, Precision @ 1: 0.6613
Step 70005: loss = 0.47682
Step 70010: loss = 0.11416
Step 70015: loss = 0.10579
Step 70020: loss = 0.26400
Step 70025: loss = 0.11327
Step 70030: loss = 0.09805
Step 70035: loss = 0.11341
Step 70040: loss = 0.13292
Step 70045: loss = 0.22059
Step 70050: loss = 0.18007
Step 70055: loss = 0.19677
Step 70060: loss = 0.32011
Step 70065: loss = 0.26409
Step 70070: loss = 0.13841
Step 70075: loss = 0.22410
Step 70080: loss = 0.36269
Step 70085: loss = 0.18848
Step 70090: loss = 0.36954
Step 70095: loss = 0.17516
Step 70100: loss = 0.30856
Step 70105: loss = 0.24278
Step 70110: loss = 0.14646
Step 70115: loss = 0.17805
Step 70120: loss = 0.26030
Step 70125: loss = 0.10506
Step 70130: loss = 0.38212
Step 70135: loss = 0.32637
Step 70140: loss = 0.24136
Step 70145: loss = 0.20043
Step 70150: loss = 0.21521
Step 70155: loss = 0.12314
Step 70160: loss = 0.35252
Step 70165: loss = 0.19339
Step 70170: loss = 0.11151
Step 70175: loss = 0.26291
Step 70180: loss = 0.17849
Step 70185: loss = 0.28520
Step 70190: loss = 0.31788
Step 70195: loss = 0.18557
Step 70200: loss = 0.26452
Step 70205: loss = 0.16779
Step 70210: loss = 0.30136
Step 70215: loss = 0.34468
Step 70220: loss = 0.34611
Step 70225: loss = 0.25560
Step 70230: loss = 0.18594
Step 70235: loss = 0.24250
Step 70240: loss = 0.13504
Step 70245: loss = 0.16409
Step 70250: loss = 0.23481
Step 70255: loss = 0.13956
Step 70260: loss = 0.35708
Step 70265: loss = 0.31000
Step 70270: loss = 0.13921
Step 70275: loss = 0.20701
Step 70280: loss = 0.21587
Step 70285: loss = 0.19915
Step 70290: loss = 0.32250
Step 70295: loss = 0.21412
Step 70300: loss = 0.21133
Step 70305: loss = 0.23390
Step 70310: loss = 0.13696
Step 70315: loss = 0.29425
Step 70320: loss = 0.58755
Step 70325: loss = 0.12701
Step 70330: loss = 0.26504
Step 70335: loss = 0.34320
Step 70340: loss = 0.12418
Step 70345: loss = 0.20211
Step 70350: loss = 0.25276
Step 70355: loss = 0.17020
Step 70360: loss = 0.22646
Step 70365: loss = 0.13162
Step 70370: loss = 0.25668
Step 70375: loss = 0.19808
Step 70380: loss = 0.23320
Step 70385: loss = 0.19785
Step 70390: loss = 0.34198
Step 70395: loss = 0.18477
Step 70400: loss = 0.10821
Step 70405: loss = 0.25440
Step 70410: loss = 0.20919
Step 70415: loss = 0.34229
Step 70420: loss = 0.20617
Step 70425: loss = 0.28815
Step 70430: loss = 0.06576
Step 70435: loss = 0.22991
Step 70440: loss = 0.15447
Step 70445: loss = 0.06428
Step 70450: loss = 0.23207
Step 70455: loss = 0.59319
Step 70460: loss = 0.28393
Step 70465: loss = 0.27178
Step 70470: loss = 0.15141
Step 70475: loss = 0.21449
Step 70480: loss = 0.14594
Step 70485: loss = 0.14000
Step 70490: loss = 0.28354
Step 70495: loss = 0.11353
Step 70500: loss = 0.26906
Step 70505: loss = 0.15435
Step 70510: loss = 0.25908
Step 70515: loss = 0.12558
Step 70520: loss = 0.54284
Step 70525: loss = 0.21032
Step 70530: loss = 0.30689
Step 70535: loss = 0.22223
Step 70540: loss = 0.34899
Step 70545: loss = 0.24471
Step 70550: loss = 0.14555
Step 70555: loss = 0.38814
Step 70560: loss = 0.18316
Step 70565: loss = 0.48772
Step 70570: loss = 0.29276
Step 70575: loss = 0.16466
Step 70580: loss = 0.12025
Step 70585: loss = 0.36619
Step 70590: loss = 0.30748
Step 70595: loss = 0.35070
Step 70600: loss = 0.27756
Step 70605: loss = 0.16775
Step 70610: loss = 0.21457
Step 70615: loss = 0.13543
Step 70620: loss = 0.24952
Step 70625: loss = 0.14123
Step 70630: loss = 0.08189
Step 70635: loss = 0.23933
Step 70640: loss = 0.54261
Step 70645: loss = 0.38483
Step 70650: loss = 0.25305
Step 70655: loss = 0.17386
Step 70660: loss = 0.07800
Step 70665: loss = 0.22401
Step 70670: loss = 0.26083
Step 70675: loss = 0.35595
Step 70680: loss = 0.17972
Step 70685: loss = 0.29520
Step 70690: loss = 0.14421
Step 70695: loss = 0.25996
Step 70700: loss = 0.42083
Step 70705: loss = 0.11356
Step 70710: loss = 0.18334
Step 70715: loss = 0.37593
Step 70720: loss = 0.21088
Step 70725: loss = 0.15396
Step 70730: loss = 0.28853
Step 70735: loss = 0.33805
Step 70740: loss = 0.20625
Step 70745: loss = 0.29797
Step 70750: loss = 0.15323
Step 70755: loss = 0.23291
Step 70760: loss = 0.25319
Step 70765: loss = 0.18538
Step 70770: loss = 0.33668
Step 70775: loss = 0.43477
Step 70780: loss = 0.25540
Step 70785: loss = 0.25831
Step 70790: loss = 0.57535
Step 70795: loss = 0.13472
Step 70800: loss = 0.30121
Step 70805: loss = 0.24387
Step 70810: loss = 0.26162
Step 70815: loss = 0.41283
Step 70820: loss = 0.15972
Step 70825: loss = 0.12963
Step 70830: loss = 0.07935
Step 70835: loss = 0.27225
Step 70840: loss = 0.23822
Step 70845: loss = 0.11743
Step 70850: loss = 0.15713
Step 70855: loss = 0.15826
Step 70860: loss = 0.34005
Step 70865: loss = 0.26510
Step 70870: loss = 0.22204
Step 70875: loss = 0.12835
Step 70880: loss = 0.04540
Step 70885: loss = 0.44020
Step 70890: loss = 0.23846
Step 70895: loss = 0.06756
Step 70900: loss = 0.42746
Step 70905: loss = 0.13344
Step 70910: loss = 0.17202
Step 70915: loss = 0.20020
Step 70920: loss = 0.31601
Step 70925: loss = 0.19214
Step 70930: loss = 0.43845
Step 70935: loss = 0.21177
Step 70940: loss = 0.29195
Step 70945: loss = 0.27877
Step 70950: loss = 0.37455
Step 70955: loss = 0.18041
Step 70960: loss = 0.21525
Step 70965: loss = 0.12628
Step 70970: loss = 0.16414
Step 70975: loss = 0.28253
Step 70980: loss = 0.29643
Step 70985: loss = 0.16709
Step 70990: loss = 0.30303
Step 70995: loss = 0.20717
Step 71000: loss = 0.12898
Training Data Eval:
  Num examples: 50000, Num correct: 46337, Precision @ 1: 0.9267
('Testing Data Eval: EPOCH->', 72)
  Num examples: 10000, Num correct: 6509, Precision @ 1: 0.6509
Step 71005: loss = 0.17902
Step 71010: loss = 0.30380
Step 71015: loss = 0.06586
Step 71020: loss = 0.23612
Step 71025: loss = 0.27532
Step 71030: loss = 0.15498
Step 71035: loss = 0.16045
Step 71040: loss = 0.11790
Step 71045: loss = 0.15477
Step 71050: loss = 0.25101
Step 71055: loss = 0.48477
Step 71060: loss = 0.22834
Step 71065: loss = 0.15205
Step 71070: loss = 0.18584
Step 71075: loss = 0.25710
Step 71080: loss = 0.14324
Step 71085: loss = 0.25247
Step 71090: loss = 0.21293
Step 71095: loss = 0.21616
Step 71100: loss = 0.27722
Step 71105: loss = 0.16547
Step 71110: loss = 0.35786
Step 71115: loss = 0.05498
Step 71120: loss = 0.23362
Step 71125: loss = 0.08485
Step 71130: loss = 0.38074
Step 71135: loss = 0.21307
Step 71140: loss = 0.12841
Step 71145: loss = 0.35232
Step 71150: loss = 0.21724
Step 71155: loss = 0.24533
Step 71160: loss = 0.20026
Step 71165: loss = 0.31959
Step 71170: loss = 0.24907
Step 71175: loss = 0.12079
Step 71180: loss = 0.21213
Step 71185: loss = 0.22400
Step 71190: loss = 0.18574
Step 71195: loss = 0.22803
Step 71200: loss = 0.12548
Step 71205: loss = 0.17348
Step 71210: loss = 0.32382
Step 71215: loss = 0.08279
Step 71220: loss = 0.25961
Step 71225: loss = 0.18736
Step 71230: loss = 0.25503
Step 71235: loss = 0.15933
Step 71240: loss = 0.27994
Step 71245: loss = 0.18890
Step 71250: loss = 0.17996
Step 71255: loss = 0.19686
Step 71260: loss = 0.20351
Step 71265: loss = 0.29759
Step 71270: loss = 0.09041
Step 71275: loss = 0.37248
Step 71280: loss = 0.07206
Step 71285: loss = 0.14036
Step 71290: loss = 0.20786
Step 71295: loss = 0.10966
Step 71300: loss = 0.15410
Step 71305: loss = 0.13711
Step 71310: loss = 0.19987
Step 71315: loss = 0.09485
Step 71320: loss = 0.15773
Step 71325: loss = 0.24650
Step 71330: loss = 0.24353
Step 71335: loss = 0.04773
Step 71340: loss = 0.07947
Step 71345: loss = 0.11152
Step 71350: loss = 0.15396
Step 71355: loss = 0.21111
Step 71360: loss = 0.26722
Step 71365: loss = 0.31974
Step 71370: loss = 0.28885
Step 71375: loss = 0.38687
Step 71380: loss = 0.10782
Step 71385: loss = 0.37711
Step 71390: loss = 0.06057
Step 71395: loss = 0.14000
Step 71400: loss = 0.12629
Step 71405: loss = 0.10789
Step 71410: loss = 0.30356
Step 71415: loss = 0.53720
Step 71420: loss = 0.22392
Step 71425: loss = 0.21326
Step 71430: loss = 0.22053
Step 71435: loss = 0.10061
Step 71440: loss = 0.33203
Step 71445: loss = 0.12290
Step 71450: loss = 0.48389
Step 71455: loss = 0.09584
Step 71460: loss = 0.13208
Step 71465: loss = 0.10749
Step 71470: loss = 0.15285
Step 71475: loss = 0.24521
Step 71480: loss = 0.25379
Step 71485: loss = 0.19153
Step 71490: loss = 0.12504
Step 71495: loss = 0.26831
Step 71500: loss = 0.10705
Step 71505: loss = 0.22585
Step 71510: loss = 0.09049
Step 71515: loss = 0.13990
Step 71520: loss = 0.21564
Step 71525: loss = 0.38326
Step 71530: loss = 0.16910
Step 71535: loss = 0.21542
Step 71540: loss = 0.32352
Step 71545: loss = 0.29871
Step 71550: loss = 0.33592
Step 71555: loss = 0.20356
Step 71560: loss = 0.11018
Step 71565: loss = 0.19833
Step 71570: loss = 0.09324
Step 71575: loss = 0.19510
Step 71580: loss = 0.15457
Step 71585: loss = 0.20983
Step 71590: loss = 0.23706
Step 71595: loss = 0.24594
Step 71600: loss = 0.13312
Step 71605: loss = 0.63355
Step 71610: loss = 0.14544
Step 71615: loss = 0.32769
Step 71620: loss = 0.09001
Step 71625: loss = 0.30087
Step 71630: loss = 0.25990
Step 71635: loss = 0.28497
Step 71640: loss = 0.16889
Step 71645: loss = 0.10963
Step 71650: loss = 0.14011
Step 71655: loss = 0.24766
Step 71660: loss = 0.38506
Step 71665: loss = 0.31861
Step 71670: loss = 0.10680
Step 71675: loss = 0.71825
Step 71680: loss = 0.29931
Step 71685: loss = 0.22806
Step 71690: loss = 0.43554
Step 71695: loss = 0.11840
Step 71700: loss = 0.21356
Step 71705: loss = 0.15554
Step 71710: loss = 0.12831
Step 71715: loss = 0.12506
Step 71720: loss = 0.41224
Step 71725: loss = 0.16406
Step 71730: loss = 0.09808
Step 71735: loss = 0.32982
Step 71740: loss = 0.44848
Step 71745: loss = 0.47448
Step 71750: loss = 0.37555
Step 71755: loss = 0.25126
Step 71760: loss = 0.27794
Step 71765: loss = 0.42242
Step 71770: loss = 0.25076
Step 71775: loss = 0.25302
Step 71780: loss = 0.18980
Step 71785: loss = 0.32248
Step 71790: loss = 0.48273
Step 71795: loss = 0.18878
Step 71800: loss = 0.19075
Step 71805: loss = 0.22926
Step 71810: loss = 0.53024
Step 71815: loss = 0.21237
Step 71820: loss = 0.18503
Step 71825: loss = 0.28490
Step 71830: loss = 0.15442
Step 71835: loss = 0.24638
Step 71840: loss = 0.23170
Step 71845: loss = 0.40585
Step 71850: loss = 0.24492
Step 71855: loss = 0.25606
Step 71860: loss = 0.43628
Step 71865: loss = 0.49777
Step 71870: loss = 0.39039
Step 71875: loss = 0.17455
Step 71880: loss = 0.19972
Step 71885: loss = 0.14839
Step 71890: loss = 0.13282
Step 71895: loss = 0.45162
Step 71900: loss = 0.27872
Step 71905: loss = 0.23838
Step 71910: loss = 0.26600
Step 71915: loss = 0.32683
Step 71920: loss = 0.17254
Step 71925: loss = 0.29237
Step 71930: loss = 0.13133
Step 71935: loss = 0.32398
Step 71940: loss = 0.13787
Step 71945: loss = 0.30947
Step 71950: loss = 0.06194
Step 71955: loss = 0.37592
Step 71960: loss = 0.30271
Step 71965: loss = 0.17982
Step 71970: loss = 0.15788
Step 71975: loss = 0.19395
Step 71980: loss = 0.21734
Step 71985: loss = 0.11822
Step 71990: loss = 0.08844
Step 71995: loss = 0.42209
Step 72000: loss = 0.25592
Training Data Eval:
  Num examples: 50000, Num correct: 46181, Precision @ 1: 0.9236
('Testing Data Eval: EPOCH->', 73)
  Num examples: 10000, Num correct: 6534, Precision @ 1: 0.6534
Step 72005: loss = 0.25651
Step 72010: loss = 0.22205
Step 72015: loss = 0.17766
Step 72020: loss = 0.25589
Step 72025: loss = 0.13902
Step 72030: loss = 0.12831
Step 72035: loss = 0.14706
Step 72040: loss = 0.15647
Step 72045: loss = 0.15475
Step 72050: loss = 0.06801
Step 72055: loss = 0.23420
Step 72060: loss = 0.30448
Step 72065: loss = 0.42934
Step 72070: loss = 0.36670
Step 72075: loss = 0.15760
Step 72080: loss = 0.25756
Step 72085: loss = 0.23789
Step 72090: loss = 0.10552
Step 72095: loss = 0.17754
Step 72100: loss = 0.15547
Step 72105: loss = 0.28193
Step 72110: loss = 0.25413
Step 72115: loss = 0.32602
Step 72120: loss = 0.27530
Step 72125: loss = 0.30886
Step 72130: loss = 0.09789
Step 72135: loss = 0.32031
Step 72140: loss = 0.20470
Step 72145: loss = 0.44771
Step 72150: loss = 0.18421
Step 72155: loss = 0.19901
Step 72160: loss = 0.25829
Step 72165: loss = 0.07484
Step 72170: loss = 0.16971
Step 72175: loss = 0.30460
Step 72180: loss = 0.31013
Step 72185: loss = 0.07918
Step 72190: loss = 0.20852
Step 72195: loss = 0.26932
Step 72200: loss = 0.27047
Step 72205: loss = 0.20821
Step 72210: loss = 0.12295
Step 72215: loss = 0.23509
Step 72220: loss = 0.09161
Step 72225: loss = 0.33237
Step 72230: loss = 0.34990
Step 72235: loss = 0.13838
Step 72240: loss = 0.25531
Step 72245: loss = 0.31257
Step 72250: loss = 0.51305
Step 72255: loss = 0.22121
Step 72260: loss = 0.26084
Step 72265: loss = 0.32234
Step 72270: loss = 0.24705
Step 72275: loss = 0.42079
Step 72280: loss = 0.20611
Step 72285: loss = 0.10858
Step 72290: loss = 0.18084
Step 72295: loss = 0.44523
Step 72300: loss = 0.29026
Step 72305: loss = 0.23135
Step 72310: loss = 0.20992
Step 72315: loss = 0.27938
Step 72320: loss = 0.29123
Step 72325: loss = 0.05245
Step 72330: loss = 0.17018
Step 72335: loss = 0.14477
Step 72340: loss = 0.19243
Step 72345: loss = 0.14635
Step 72350: loss = 0.15195
Step 72355: loss = 0.16933
Step 72360: loss = 0.27475
Step 72365: loss = 0.13796
Step 72370: loss = 0.16352
Step 72375: loss = 0.24881
Step 72380: loss = 0.18006
Step 72385: loss = 0.07645
Step 72390: loss = 0.15411
Step 72395: loss = 0.17594
Step 72400: loss = 0.11116
Step 72405: loss = 0.15107
Step 72410: loss = 0.19622
Step 72415: loss = 0.18314
Step 72420: loss = 0.63006
Step 72425: loss = 0.19097
Step 72430: loss = 0.29968
Step 72435: loss = 0.32131
Step 72440: loss = 0.44204
Step 72445: loss = 0.18161
Step 72450: loss = 0.14166
Step 72455: loss = 0.19843
Step 72460: loss = 0.20961
Step 72465: loss = 0.12070
Step 72470: loss = 0.31725
Step 72475: loss = 0.17888
Step 72480: loss = 0.18679
Step 72485: loss = 0.25210
Step 72490: loss = 0.13927
Step 72495: loss = 0.32983
Step 72500: loss = 0.30611
Step 72505: loss = 0.18820
Step 72510: loss = 0.26978
Step 72515: loss = 0.18456
Step 72520: loss = 0.19946
Step 72525: loss = 0.24007
Step 72530: loss = 0.29180
Step 72535: loss = 0.15004
Step 72540: loss = 0.25869
Step 72545: loss = 0.28829
Step 72550: loss = 0.09864
Step 72555: loss = 0.30327
Step 72560: loss = 0.39510
Step 72565: loss = 0.18520
Step 72570: loss = 0.22810
Step 72575: loss = 0.12094
Step 72580: loss = 0.36470
Step 72585: loss = 0.31401
Step 72590: loss = 0.20911
Step 72595: loss = 0.07163
Step 72600: loss = 0.29746
Step 72605: loss = 0.18896
Step 72610: loss = 0.27966
Step 72615: loss = 0.35418
Step 72620: loss = 0.18133
Step 72625: loss = 0.41409
Step 72630: loss = 0.08047
Step 72635: loss = 0.38446
Step 72640: loss = 0.22313
Step 72645: loss = 0.10336
Step 72650: loss = 0.08643
Step 72655: loss = 0.32404
Step 72660: loss = 0.21034
Step 72665: loss = 0.25233
Step 72670: loss = 0.26724
Step 72675: loss = 0.11638
Step 72680: loss = 0.19166
Step 72685: loss = 0.21315
Step 72690: loss = 0.30996
Step 72695: loss = 0.09705
Step 72700: loss = 0.14498
Step 72705: loss = 0.13550
Step 72710: loss = 0.15682
Step 72715: loss = 0.23200
Step 72720: loss = 0.17447
Step 72725: loss = 0.10203
Step 72730: loss = 0.19585
Step 72735: loss = 0.19659
Step 72740: loss = 0.14616
Step 72745: loss = 0.55996
Step 72750: loss = 0.23521
Step 72755: loss = 0.10509
Step 72760: loss = 0.09557
Step 72765: loss = 0.25369
Step 72770: loss = 0.12558
Step 72775: loss = 0.13276
Step 72780: loss = 0.16696
Step 72785: loss = 0.23910
Step 72790: loss = 0.12098
Step 72795: loss = 0.07020
Step 72800: loss = 0.27245
Step 72805: loss = 0.22207
Step 72810: loss = 0.24904
Step 72815: loss = 0.10927
Step 72820: loss = 0.11785
Step 72825: loss = 0.23585
Step 72830: loss = 0.12115
Step 72835: loss = 0.04980
Step 72840: loss = 0.14498
Step 72845: loss = 0.11244
Step 72850: loss = 0.16010
Step 72855: loss = 0.11863
Step 72860: loss = 0.17756
Step 72865: loss = 0.27668
Step 72870: loss = 0.50305
Step 72875: loss = 0.25884
Step 72880: loss = 0.41960
Step 72885: loss = 0.22706
Step 72890: loss = 0.07390
Step 72895: loss = 0.16588
Step 72900: loss = 0.28020
Step 72905: loss = 0.26700
Step 72910: loss = 0.22570
Step 72915: loss = 0.31227
Step 72920: loss = 0.23982
Step 72925: loss = 0.26764
Step 72930: loss = 0.10395
Step 72935: loss = 0.17834
Step 72940: loss = 0.17718
Step 72945: loss = 0.21240
Step 72950: loss = 0.16059
Step 72955: loss = 0.22806
Step 72960: loss = 0.13332
Step 72965: loss = 0.25406
Step 72970: loss = 0.22595
Step 72975: loss = 0.19429
Step 72980: loss = 0.06328
Step 72985: loss = 0.14347
Step 72990: loss = 0.24293
Step 72995: loss = 0.21824
Step 73000: loss = 0.14280
Training Data Eval:
  Num examples: 50000, Num correct: 46494, Precision @ 1: 0.9299
('Testing Data Eval: EPOCH->', 74)
  Num examples: 10000, Num correct: 6601, Precision @ 1: 0.6601
Step 73005: loss = 0.13971
Step 73010: loss = 0.26121
Step 73015: loss = 0.26915
Step 73020: loss = 0.28043
Step 73025: loss = 0.11262
Step 73030: loss = 0.10377
Step 73035: loss = 0.34276
Step 73040: loss = 0.24987
Step 73045: loss = 0.43895
Step 73050: loss = 0.24058
Step 73055: loss = 0.07546
Step 73060: loss = 0.10137
Step 73065: loss = 0.25763
Step 73070: loss = 0.09772
Step 73075: loss = 0.22126
Step 73080: loss = 0.18477
Step 73085: loss = 0.13886
Step 73090: loss = 0.32320
Step 73095: loss = 0.18302
Step 73100: loss = 0.20603
Step 73105: loss = 0.30474
Step 73110: loss = 0.05963
Step 73115: loss = 0.27358
Step 73120: loss = 0.29489
Step 73125: loss = 0.19740
Step 73130: loss = 0.21321
Step 73135: loss = 0.05200
Step 73140: loss = 0.07913
Step 73145: loss = 0.30924
Step 73150: loss = 0.29978
Step 73155: loss = 0.34933
Step 73160: loss = 0.19010
Step 73165: loss = 0.18056
Step 73170: loss = 0.21568
Step 73175: loss = 0.24017
Step 73180: loss = 0.37066
Step 73185: loss = 0.15969
Step 73190: loss = 0.13523
Step 73195: loss = 0.08604
Step 73200: loss = 0.35546
Step 73205: loss = 0.35455
Step 73210: loss = 0.09009
Step 73215: loss = 0.20227
Step 73220: loss = 0.18836
Step 73225: loss = 0.24442
Step 73230: loss = 0.23256
Step 73235: loss = 0.08304
Step 73240: loss = 0.11533
Step 73245: loss = 0.16135
Step 73250: loss = 0.25443
Step 73255: loss = 0.44512
Step 73260: loss = 0.56513
Step 73265: loss = 0.19108
Step 73270: loss = 0.20264
Step 73275: loss = 0.17825
Step 73280: loss = 0.26490
Step 73285: loss = 0.19173
Step 73290: loss = 0.19157
Step 73295: loss = 0.23144
Step 73300: loss = 0.28875
Step 73305: loss = 0.08645
Step 73310: loss = 0.12994
Step 73315: loss = 0.19972
Step 73320: loss = 0.13145
Step 73325: loss = 0.40492
Step 73330: loss = 0.12689
Step 73335: loss = 0.14012
Step 73340: loss = 0.08240
Step 73345: loss = 0.13865
Step 73350: loss = 0.23949
Step 73355: loss = 0.33996
Step 73360: loss = 0.18471
Step 73365: loss = 0.22371
Step 73370: loss = 0.13307
Step 73375: loss = 0.31982
Step 73380: loss = 0.26909
Step 73385: loss = 0.12763
Step 73390: loss = 0.16299
Step 73395: loss = 0.30572
Step 73400: loss = 0.13352
Step 73405: loss = 0.07092
Step 73410: loss = 0.28512
Step 73415: loss = 0.15612
Step 73420: loss = 0.27804
Step 73425: loss = 0.66294
Step 73430: loss = 0.28590
Step 73435: loss = 0.30968
Step 73440: loss = 0.17463
Step 73445: loss = 0.20311
Step 73450: loss = 0.30845
Step 73455: loss = 0.17824
Step 73460: loss = 0.19001
Step 73465: loss = 0.26730
Step 73470: loss = 0.34075
Step 73475: loss = 0.13207
Step 73480: loss = 0.17951
Step 73485: loss = 0.55210
Step 73490: loss = 0.12595
Step 73495: loss = 0.35627
Step 73500: loss = 0.26113
Step 73505: loss = 0.11341
Step 73510: loss = 0.24880
Step 73515: loss = 0.25483
Step 73520: loss = 0.15095
Step 73525: loss = 0.13525
Step 73530: loss = 0.22452
Step 73535: loss = 0.10930
Step 73540: loss = 0.24157
Step 73545: loss = 0.37248
Step 73550: loss = 0.11309
Step 73555: loss = 0.28896
Step 73560: loss = 0.14813
Step 73565: loss = 0.12038
Step 73570: loss = 0.32714
Step 73575: loss = 0.21637
Step 73580: loss = 0.14308
Step 73585: loss = 0.15099
Step 73590: loss = 0.12702
Step 73595: loss = 0.26263
Step 73600: loss = 0.20819
Step 73605: loss = 0.14854
Step 73610: loss = 0.23901
Step 73615: loss = 0.38221
Step 73620: loss = 0.40927
Step 73625: loss = 0.37675
Step 73630: loss = 0.45999
Step 73635: loss = 0.11505
Step 73640: loss = 0.21292
Step 73645: loss = 0.09524
Step 73650: loss = 0.30968
Step 73655: loss = 0.13767
Step 73660: loss = 0.21876
Step 73665: loss = 0.22901
Step 73670: loss = 0.19663
Step 73675: loss = 0.14024
Step 73680: loss = 0.40425
Step 73685: loss = 0.33934
Step 73690: loss = 0.43131
Step 73695: loss = 0.30756
Step 73700: loss = 0.19731
Step 73705: loss = 0.33751
Step 73710: loss = 0.28663
Step 73715: loss = 0.30900
Step 73720: loss = 0.25371
Step 73725: loss = 0.27707
Step 73730: loss = 0.25196
Step 73735: loss = 0.21458
Step 73740: loss = 0.16687
Step 73745: loss = 0.08272
Step 73750: loss = 0.43537
Step 73755: loss = 0.25841
Step 73760: loss = 0.29325
Step 73765: loss = 0.18772
Step 73770: loss = 0.10053
Step 73775: loss = 0.13865
Step 73780: loss = 0.15557
Step 73785: loss = 0.15213
Step 73790: loss = 0.24224
Step 73795: loss = 0.20501
Step 73800: loss = 0.20072
Step 73805: loss = 0.41946
Step 73810: loss = 0.08452
Step 73815: loss = 0.11264
Step 73820: loss = 0.19249
Step 73825: loss = 0.25190
Step 73830: loss = 0.21111
Step 73835: loss = 0.32871
Step 73840: loss = 0.22259
Step 73845: loss = 0.17436
Step 73850: loss = 0.31234
Step 73855: loss = 0.36147
Step 73860: loss = 0.30169
Step 73865: loss = 0.31340
Step 73870: loss = 0.32429
Step 73875: loss = 0.11884
Step 73880: loss = 0.43844
Step 73885: loss = 0.28654
Step 73890: loss = 0.14857
Step 73895: loss = 0.24686
Step 73900: loss = 0.18785
Step 73905: loss = 0.20897
Step 73910: loss = 0.25948
Step 73915: loss = 0.12562
Step 73920: loss = 0.18508
Step 73925: loss = 0.23893
Step 73930: loss = 0.25830
Step 73935: loss = 0.14793
Step 73940: loss = 0.08931
Step 73945: loss = 0.20841
Step 73950: loss = 0.15557
Step 73955: loss = 0.11774
Step 73960: loss = 0.15228
Step 73965: loss = 0.38431
Step 73970: loss = 0.28953
Step 73975: loss = 0.10905
Step 73980: loss = 0.28708
Step 73985: loss = 0.13959
Step 73990: loss = 0.12101
Step 73995: loss = 0.18780
Step 74000: loss = 0.25551
Training Data Eval:
  Num examples: 50000, Num correct: 46300, Precision @ 1: 0.9260
('Testing Data Eval: EPOCH->', 75)
  Num examples: 10000, Num correct: 6570, Precision @ 1: 0.6570
Step 74005: loss = 0.18406
Step 74010: loss = 0.14832
Step 74015: loss = 0.16514
Step 74020: loss = 0.19862
Step 74025: loss = 0.32042
Step 74030: loss = 0.41804
Step 74035: loss = 0.21292
Step 74040: loss = 0.40168
Step 74045: loss = 0.13113
Step 74050: loss = 0.31379
Step 74055: loss = 0.22372
Step 74060: loss = 0.15350
Step 74065: loss = 0.33820
Step 74070: loss = 0.13127
Step 74075: loss = 0.29644
Step 74080: loss = 0.20226
Step 74085: loss = 0.38754
Step 74090: loss = 0.16305
Step 74095: loss = 0.23558
Step 74100: loss = 0.19251
Step 74105: loss = 0.18420
Step 74110: loss = 0.23409
Step 74115: loss = 0.23804
Step 74120: loss = 0.17145
Step 74125: loss = 0.25376
Step 74130: loss = 0.06926
Step 74135: loss = 0.19247
Step 74140: loss = 0.15045
Step 74145: loss = 0.17630
Step 74150: loss = 0.07189
Step 74155: loss = 0.25215
Step 74160: loss = 0.15440
Step 74165: loss = 0.20018
Step 74170: loss = 0.16326
Step 74175: loss = 0.29162
Step 74180: loss = 0.25727
Step 74185: loss = 0.21456
Step 74190: loss = 0.27621
Step 74195: loss = 0.16596
Step 74200: loss = 0.12069
Step 74205: loss = 0.14394
Step 74210: loss = 0.15736
Step 74215: loss = 0.14205
Step 74220: loss = 0.13479
Step 74225: loss = 0.12018
Step 74230: loss = 0.10019
Step 74235: loss = 0.18356
Step 74240: loss = 0.44037
Step 74245: loss = 0.11251
Step 74250: loss = 0.15704
Step 74255: loss = 0.33022
Step 74260: loss = 0.43580
Step 74265: loss = 0.18388
Step 74270: loss = 0.39612
Step 74275: loss = 0.21387
Step 74280: loss = 0.19289
Step 74285: loss = 0.24050
Step 74290: loss = 0.33984
Step 74295: loss = 0.33584
Step 74300: loss = 0.25065
Step 74305: loss = 0.19717
Step 74310: loss = 0.25117
Step 74315: loss = 0.18327
Step 74320: loss = 0.11818
Step 74325: loss = 0.09260
Step 74330: loss = 0.22030
Step 74335: loss = 0.32134
Step 74340: loss = 0.17229
Step 74345: loss = 0.25677
Step 74350: loss = 0.33329
Step 74355: loss = 0.18896
Step 74360: loss = 0.37588
Step 74365: loss = 0.18292
Step 74370: loss = 0.12050
Step 74375: loss = 0.20107
Step 74380: loss = 0.24488
Step 74385: loss = 0.23558
Step 74390: loss = 0.48332
Step 74395: loss = 0.07926
Step 74400: loss = 0.62515
Step 74405: loss = 0.10280
Step 74410: loss = 0.15948
Step 74415: loss = 0.11832
Step 74420: loss = 0.07911
Step 74425: loss = 0.39369
Step 74430: loss = 0.19128
Step 74435: loss = 0.21019
Step 74440: loss = 0.19970
Step 74445: loss = 0.27501
Step 74450: loss = 0.14941
Step 74455: loss = 0.22768
Step 74460: loss = 0.23208
Step 74465: loss = 0.19795
Step 74470: loss = 0.32789
Step 74475: loss = 0.15263
Step 74480: loss = 0.27266
Step 74485: loss = 0.15148
Step 74490: loss = 0.13713
Step 74495: loss = 0.27312
Step 74500: loss = 0.06202
Step 74505: loss = 0.17161
Step 74510: loss = 0.12381
Step 74515: loss = 0.34680
Step 74520: loss = 0.06879
Step 74525: loss = 0.29384
Step 74530: loss = 0.29159
Step 74535: loss = 0.13003
Step 74540: loss = 0.49979
Step 74545: loss = 0.15806
Step 74550: loss = 0.16727
Step 74555: loss = 0.36450
Step 74560: loss = 0.47748
Step 74565: loss = 0.03580
Step 74570: loss = 0.31452
Step 74575: loss = 0.26536
Step 74580: loss = 0.15352
Step 74585: loss = 0.30426
Step 74590: loss = 0.10945
Step 74595: loss = 0.21069
Step 74600: loss = 0.16385
Step 74605: loss = 0.20841
Step 74610: loss = 0.32488
Step 74615: loss = 0.20470
Step 74620: loss = 0.21519
Step 74625: loss = 0.18251
Step 74630: loss = 0.33662
Step 74635: loss = 0.19953
Step 74640: loss = 0.24064
Step 74645: loss = 0.10522
Step 74650: loss = 0.30554
Step 74655: loss = 0.28859
Step 74660: loss = 0.23058
Step 74665: loss = 0.41549
Step 74670: loss = 0.24460
Step 74675: loss = 0.08546
Step 74680: loss = 0.08405
Step 74685: loss = 0.25264
Step 74690: loss = 0.27812
Step 74695: loss = 0.20532
Step 74700: loss = 0.29856
Step 74705: loss = 0.17240
Step 74710: loss = 0.10158
Step 74715: loss = 0.31637
Step 74720: loss = 0.68486
Step 74725: loss = 0.08238
Step 74730: loss = 0.11237
Step 74735: loss = 0.13487
Step 74740: loss = 0.31516
Step 74745: loss = 0.38646
Step 74750: loss = 0.40694
Step 74755: loss = 0.13752
Step 74760: loss = 0.28563
Step 74765: loss = 0.18833
Step 74770: loss = 0.26811
Step 74775: loss = 0.40986
Step 74780: loss = 0.47529
Step 74785: loss = 0.30307
Step 74790: loss = 0.16968
Step 74795: loss = 0.13684
Step 74800: loss = 0.35717
Step 74805: loss = 0.25351
Step 74810: loss = 0.35523
Step 74815: loss = 0.23650
Step 74820: loss = 0.08020
Step 74825: loss = 0.24747
Step 74830: loss = 0.23174
Step 74835: loss = 0.15621
Step 74840: loss = 0.15216
Step 74845: loss = 0.14254
Step 74850: loss = 0.20362
Step 74855: loss = 0.21209
Step 74860: loss = 0.31452
Step 74865: loss = 0.16879
Step 74870: loss = 0.22598
Step 74875: loss = 0.21305
Step 74880: loss = 0.25290
Step 74885: loss = 0.06803
Step 74890: loss = 0.28511
Step 74895: loss = 0.22968
Step 74900: loss = 0.23426
Step 74905: loss = 0.18516
Step 74910: loss = 0.15944
Step 74915: loss = 0.08622
Step 74920: loss = 0.20419
Step 74925: loss = 0.22894
Step 74930: loss = 0.26696
Step 74935: loss = 0.09249
Step 74940: loss = 0.41516
Step 74945: loss = 0.16575
Step 74950: loss = 0.26927
Step 74955: loss = 0.25338
Step 74960: loss = 0.22249
Step 74965: loss = 0.46792
Step 74970: loss = 0.11874
Step 74975: loss = 0.10914
Step 74980: loss = 0.29710
Step 74985: loss = 0.38157
Step 74990: loss = 0.24129
Step 74995: loss = 0.19182
Step 75000: loss = 0.25840
Training Data Eval:
  Num examples: 50000, Num correct: 46229, Precision @ 1: 0.9246
('Testing Data Eval: EPOCH->', 76)
  Num examples: 10000, Num correct: 6476, Precision @ 1: 0.6476
Step 75005: loss = 0.16853
Step 75010: loss = 0.18592
Step 75015: loss = 0.21710
Step 75020: loss = 0.26933
Step 75025: loss = 0.13773
Step 75030: loss = 0.15755
Step 75035: loss = 0.07883
Step 75040: loss = 0.25494
Step 75045: loss = 0.12768
Step 75050: loss = 0.32093
Step 75055: loss = 0.15241
Step 75060: loss = 0.11408
Step 75065: loss = 0.25529
Step 75070: loss = 0.34938
Step 75075: loss = 0.09943
Step 75080: loss = 0.14081
Step 75085: loss = 0.06417
Step 75090: loss = 0.12543
Step 75095: loss = 0.30184
Step 75100: loss = 0.16994
Step 75105: loss = 0.14477
Step 75110: loss = 0.22896
Step 75115: loss = 0.23640
Step 75120: loss = 0.09962
Step 75125: loss = 0.16566
Step 75130: loss = 0.18327
Step 75135: loss = 0.12761
Step 75140: loss = 0.27677
Step 75145: loss = 0.15759
Step 75150: loss = 0.29333
Step 75155: loss = 0.09602
Step 75160: loss = 0.23516
Step 75165: loss = 0.14138
Step 75170: loss = 0.32011
Step 75175: loss = 0.26518
Step 75180: loss = 0.14009
Step 75185: loss = 0.35642
Step 75190: loss = 0.18820
Step 75195: loss = 0.20040
Step 75200: loss = 0.15249
Step 75205: loss = 0.25420
Step 75210: loss = 0.23630
Step 75215: loss = 0.28996
Step 75220: loss = 0.22965
Step 75225: loss = 0.13847
Step 75230: loss = 0.14073
Step 75235: loss = 0.23087
Step 75240: loss = 0.39528
Step 75245: loss = 0.30390
Step 75250: loss = 0.23062
Step 75255: loss = 0.30863
Step 75260: loss = 0.14862
Step 75265: loss = 0.14248
Step 75270: loss = 0.43210
Step 75275: loss = 0.23397
Step 75280: loss = 0.16054
Step 75285: loss = 0.10660
Step 75290: loss = 0.22101
Step 75295: loss = 0.32631
Step 75300: loss = 0.15926
Step 75305: loss = 0.37568
Step 75310: loss = 0.22753
Step 75315: loss = 0.32273
Step 75320: loss = 0.28114
Step 75325: loss = 0.27983
Step 75330: loss = 0.31043
Step 75335: loss = 0.44217
Step 75340: loss = 0.11359
Step 75345: loss = 0.22961
Step 75350: loss = 0.11616
Step 75355: loss = 0.21355
Step 75360: loss = 0.27148
Step 75365: loss = 0.30189
Step 75370: loss = 0.27950
Step 75375: loss = 0.22260
Step 75380: loss = 0.08687
Step 75385: loss = 0.16864
Step 75390: loss = 0.30821
Step 75395: loss = 0.09521
Step 75400: loss = 0.31922
Step 75405: loss = 0.16176
Step 75410: loss = 0.21396
Step 75415: loss = 0.13632
Step 75420: loss = 0.21239
Step 75425: loss = 0.22856
Step 75430: loss = 0.11046
Step 75435: loss = 0.23700
Step 75440: loss = 0.17944
Step 75445: loss = 0.19460
Step 75450: loss = 0.33925
Step 75455: loss = 0.05974
Step 75460: loss = 0.08776
Step 75465: loss = 0.07934
Step 75470: loss = 0.27809
Step 75475: loss = 0.26394
Step 75480: loss = 0.15837
Step 75485: loss = 0.18192
Step 75490: loss = 0.07645
Step 75495: loss = 0.36683
Step 75500: loss = 0.25145
Step 75505: loss = 0.38095
Step 75510: loss = 0.16566
Step 75515: loss = 0.04867
Step 75520: loss = 0.31531
Step 75525: loss = 0.32424
Step 75530: loss = 0.15660
Step 75535: loss = 0.22715
Step 75540: loss = 0.21755
Step 75545: loss = 0.37826
Step 75550: loss = 0.18922
Step 75555: loss = 0.30815
Step 75560: loss = 0.20886
Step 75565: loss = 0.26576
Step 75570: loss = 0.22338
Step 75575: loss = 0.07640
Step 75580: loss = 0.28682
Step 75585: loss = 0.12019
Step 75590: loss = 0.21476
Step 75595: loss = 0.10133
Step 75600: loss = 0.19528
Step 75605: loss = 0.11790
Step 75610: loss = 0.09668
Step 75615: loss = 0.25424
Step 75620: loss = 0.18644
Step 75625: loss = 0.90121
Step 75630: loss = 0.24086
Step 75635: loss = 0.29065
Step 75640: loss = 0.23093
Step 75645: loss = 0.34670
Step 75650: loss = 0.41693
Step 75655: loss = 0.19054
Step 75660: loss = 0.09516
Step 75665: loss = 0.24572
Step 75670: loss = 0.45492
Step 75675: loss = 0.52690
Step 75680: loss = 0.16924
Step 75685: loss = 0.12124
Step 75690: loss = 0.26463
Step 75695: loss = 0.32836
Step 75700: loss = 0.34646
Step 75705: loss = 0.21909
Step 75710: loss = 0.26408
Step 75715: loss = 0.18360
Step 75720: loss = 0.33839
Step 75725: loss = 0.37573
Step 75730: loss = 0.11178
Step 75735: loss = 0.20020
Step 75740: loss = 0.19407
Step 75745: loss = 0.24178
Step 75750: loss = 0.32493
Step 75755: loss = 0.11269
Step 75760: loss = 0.44313
Step 75765: loss = 0.34955
Step 75770: loss = 0.16657
Step 75775: loss = 0.30729
Step 75780: loss = 0.11717
Step 75785: loss = 0.38762
Step 75790: loss = 0.10935
Step 75795: loss = 0.16088
Step 75800: loss = 0.27950
Step 75805: loss = 0.27807
Step 75810: loss = 0.16439
Step 75815: loss = 0.35716
Step 75820: loss = 0.12477
Step 75825: loss = 0.27903
Step 75830: loss = 0.29749
Step 75835: loss = 0.17553
Step 75840: loss = 0.23985
Step 75845: loss = 0.22630
Step 75850: loss = 0.10827
Step 75855: loss = 0.35943
Step 75860: loss = 0.12169
Step 75865: loss = 0.20666
Step 75870: loss = 0.21490
Step 75875: loss = 0.14082
Step 75880: loss = 0.06293
Step 75885: loss = 0.14685
Step 75890: loss = 0.15664
Step 75895: loss = 0.32784
Step 75900: loss = 0.07946
Step 75905: loss = 0.17418
Step 75910: loss = 0.16390
Step 75915: loss = 0.23346
Step 75920: loss = 0.12426
Step 75925: loss = 0.16604
Step 75930: loss = 0.16932
Step 75935: loss = 0.31047
Step 75940: loss = 0.16976
Step 75945: loss = 0.44280
Step 75950: loss = 0.15149
Step 75955: loss = 0.36133
Step 75960: loss = 0.12926
Step 75965: loss = 0.26587
Step 75970: loss = 0.18920
Step 75975: loss = 0.44796
Step 75980: loss = 0.21906
Step 75985: loss = 0.11615
Step 75990: loss = 0.14515
Step 75995: loss = 0.30705
Step 76000: loss = 0.16945
Training Data Eval:
  Num examples: 50000, Num correct: 46503, Precision @ 1: 0.9301
('Testing Data Eval: EPOCH->', 77)
  Num examples: 10000, Num correct: 6597, Precision @ 1: 0.6597
Step 76005: loss = 0.11654
Step 76010: loss = 0.28132
Step 76015: loss = 0.39196
Step 76020: loss = 0.21375
Step 76025: loss = 0.06790
Step 76030: loss = 0.31891
Step 76035: loss = 0.17953
Step 76040: loss = 0.35774
Step 76045: loss = 0.48028
Step 76050: loss = 0.12014
Step 76055: loss = 0.40147
Step 76060: loss = 0.21645
Step 76065: loss = 0.13151
Step 76070: loss = 0.15744
Step 76075: loss = 0.06171
Step 76080: loss = 0.49859
Step 76085: loss = 0.09763
Step 76090: loss = 0.12070
Step 76095: loss = 0.32570
Step 76100: loss = 0.10581
Step 76105: loss = 0.37139
Step 76110: loss = 0.25782
Step 76115: loss = 0.11243
Step 76120: loss = 0.25264
Step 76125: loss = 0.16338
Step 76130: loss = 0.05754
Step 76135: loss = 0.23471
Step 76140: loss = 0.26926
Step 76145: loss = 0.50718
Step 76150: loss = 0.18507
Step 76155: loss = 0.30138
Step 76160: loss = 0.15801
Step 76165: loss = 0.12343
Step 76170: loss = 0.33070
Step 76175: loss = 0.66448
Step 76180: loss = 0.58133
Step 76185: loss = 0.13220
Step 76190: loss = 0.16638
Step 76195: loss = 0.16033
Step 76200: loss = 0.42386
Step 76205: loss = 0.29422
Step 76210: loss = 0.20901
Step 76215: loss = 0.16765
Step 76220: loss = 0.54071
Step 76225: loss = 0.27766
Step 76230: loss = 0.19922
Step 76235: loss = 0.31832
Step 76240: loss = 0.15317
Step 76245: loss = 0.29707
Step 76250: loss = 0.30918
Step 76255: loss = 0.27614
Step 76260: loss = 0.19557
Step 76265: loss = 0.06713
Step 76270: loss = 0.24589
Step 76275: loss = 0.32884
Step 76280: loss = 0.17563
Step 76285: loss = 0.42134
Step 76290: loss = 0.15390
Step 76295: loss = 0.06862
Step 76300: loss = 0.31023
Step 76305: loss = 0.40585
Step 76310: loss = 0.21784
Step 76315: loss = 0.20044
Step 76320: loss = 0.23265
Step 76325: loss = 0.10942
Step 76330: loss = 0.08218
Step 76335: loss = 0.19264
Step 76340: loss = 0.11090
Step 76345: loss = 0.23187
Step 76350: loss = 0.10981
Step 76355: loss = 0.25747
Step 76360: loss = 0.28995
Step 76365: loss = 0.17716
Step 76370: loss = 0.42640
Step 76375: loss = 0.24600
Step 76380: loss = 0.35952
Step 76385: loss = 0.22083
Step 76390: loss = 0.21552
Step 76395: loss = 0.09749
Step 76400: loss = 0.26553
Step 76405: loss = 0.28531
Step 76410: loss = 0.15560
Step 76415: loss = 0.35844
Step 76420: loss = 0.22149
Step 76425: loss = 0.20493
Step 76430: loss = 0.29206
Step 76435: loss = 0.20570
Step 76440: loss = 0.29071
Step 76445: loss = 0.15443
Step 76450: loss = 0.18769
Step 76455: loss = 0.32562
Step 76460: loss = 0.21306
Step 76465: loss = 0.12716
Step 76470: loss = 0.18685
Step 76475: loss = 0.27371
Step 76480: loss = 0.13313
Step 76485: loss = 0.10062
Step 76490: loss = 0.17870
Step 76495: loss = 0.11282
Step 76500: loss = 0.28943
Step 76505: loss = 0.26271
Step 76510: loss = 0.24004
Step 76515: loss = 0.26059
Step 76520: loss = 0.50386
Step 76525: loss = 0.12197
Step 76530: loss = 0.23308
Step 76535: loss = 0.17550
Step 76540: loss = 0.30745
Step 76545: loss = 0.06642
Step 76550: loss = 0.12568
Step 76555: loss = 0.28316
Step 76560: loss = 0.11767
Step 76565: loss = 0.04286
Step 76570: loss = 0.43448
Step 76575: loss = 0.31893
Step 76580: loss = 0.18286
Step 76585: loss = 0.16305
Step 76590: loss = 0.15903
Step 76595: loss = 0.31003
Step 76600: loss = 0.32797
Step 76605: loss = 0.37504
Step 76610: loss = 0.11107
Step 76615: loss = 0.26321
Step 76620: loss = 0.13713
Step 76625: loss = 0.15413
Step 76630: loss = 0.27802
Step 76635: loss = 0.08616
Step 76640: loss = 0.41883
Step 76645: loss = 0.17669
Step 76650: loss = 0.21820
Step 76655: loss = 0.11665
Step 76660: loss = 0.18621
Step 76665: loss = 0.14479
Step 76670: loss = 0.11182
Step 76675: loss = 0.22089
Step 76680: loss = 0.25558
Step 76685: loss = 0.26593
Step 76690: loss = 0.26678
Step 76695: loss = 0.16602
Step 76700: loss = 0.09976
Step 76705: loss = 0.22236
Step 76710: loss = 0.43695
Step 76715: loss = 0.23567
Step 76720: loss = 0.46790
Step 76725: loss = 0.27913
Step 76730: loss = 0.30615
Step 76735: loss = 0.20857
Step 76740: loss = 0.16320
Step 76745: loss = 0.29689
Step 76750: loss = 0.20047
Step 76755: loss = 0.12578
Step 76760: loss = 0.28919
Step 76765: loss = 0.16655
Step 76770: loss = 0.13091
Step 76775: loss = 0.15062
Step 76780: loss = 0.10100
Step 76785: loss = 0.40684
Step 76790: loss = 0.18603
Step 76795: loss = 0.12172
Step 76800: loss = 0.19712
Step 76805: loss = 0.13152
Step 76810: loss = 0.22482
Step 76815: loss = 0.27066
Step 76820: loss = 0.18192
Step 76825: loss = 0.13858
Step 76830: loss = 0.08190
Step 76835: loss = 0.24990
Step 76840: loss = 0.25358
Step 76845: loss = 0.48480
Step 76850: loss = 0.11745
Step 76855: loss = 0.17214
Step 76860: loss = 0.21300
Step 76865: loss = 0.12292
Step 76870: loss = 0.20123
Step 76875: loss = 0.25833
Step 76880: loss = 0.23710
Step 76885: loss = 0.13705
Step 76890: loss = 0.19793
Step 76895: loss = 0.21690
Step 76900: loss = 0.28117
Step 76905: loss = 0.33224
Step 76910: loss = 0.11550
Step 76915: loss = 0.09750
Step 76920: loss = 0.35205
Step 76925: loss = 0.16097
Step 76930: loss = 0.21336
Step 76935: loss = 0.16256
Step 76940: loss = 0.09231
Step 76945: loss = 0.21368
Step 76950: loss = 0.25122
Step 76955: loss = 0.16489
Step 76960: loss = 0.11696
Step 76965: loss = 0.11006
Step 76970: loss = 0.18542
Step 76975: loss = 0.26345
Step 76980: loss = 0.06803
Step 76985: loss = 0.34270
Step 76990: loss = 0.40184
Step 76995: loss = 0.22905
Step 77000: loss = 0.39740
Training Data Eval:
  Num examples: 50000, Num correct: 46236, Precision @ 1: 0.9247
('Testing Data Eval: EPOCH->', 78)
  Num examples: 10000, Num correct: 6493, Precision @ 1: 0.6493
Step 77005: loss = 0.22246
Step 77010: loss = 0.16114
Step 77015: loss = 0.17304
Step 77020: loss = 0.20344
Step 77025: loss = 0.47700
Step 77030: loss = 0.15411
Step 77035: loss = 0.15257
Step 77040: loss = 0.18661
Step 77045: loss = 0.19557
Step 77050: loss = 0.08058
Step 77055: loss = 0.16516
Step 77060: loss = 0.20327
Step 77065: loss = 0.23864
Step 77070: loss = 0.07755
Step 77075: loss = 0.19206
Step 77080: loss = 0.30531
Step 77085: loss = 0.25655
Step 77090: loss = 0.10174
Step 77095: loss = 0.44313
Step 77100: loss = 0.41864
Step 77105: loss = 0.14711
Step 77110: loss = 0.35895
Step 77115: loss = 0.25022
Step 77120: loss = 0.17698
Step 77125: loss = 0.27155
Step 77130: loss = 0.43408
Step 77135: loss = 0.06006
Step 77140: loss = 0.21174
Step 77145: loss = 0.59817
Step 77150: loss = 0.13731
Step 77155: loss = 0.26498
Step 77160: loss = 0.20943
Step 77165: loss = 0.19857
Step 77170: loss = 0.08213
Step 77175: loss = 0.42553
Step 77180: loss = 0.14120
Step 77185: loss = 0.30353
Step 77190: loss = 0.15730
Step 77195: loss = 0.31674
Step 77200: loss = 0.25993
Step 77205: loss = 0.26454
Step 77210: loss = 0.18884
Step 77215: loss = 0.14314
Step 77220: loss = 0.28409
Step 77225: loss = 0.40829
Step 77230: loss = 0.18205
Step 77235: loss = 0.17154
Step 77240: loss = 0.15962
Step 77245: loss = 0.23152
Step 77250: loss = 0.21822
Step 77255: loss = 0.14442
Step 77260: loss = 0.41677
Step 77265: loss = 0.29017
Step 77270: loss = 0.25471
Step 77275: loss = 0.11590
Step 77280: loss = 0.28627
Step 77285: loss = 0.30039
Step 77290: loss = 0.30972
Step 77295: loss = 0.33726
Step 77300: loss = 0.12866
Step 77305: loss = 0.35072
Step 77310: loss = 0.18663
Step 77315: loss = 0.13798
Step 77320: loss = 0.47049
Step 77325: loss = 0.18317
Step 77330: loss = 0.16623
Step 77335: loss = 0.38670
Step 77340: loss = 0.25820
Step 77345: loss = 0.25677
Step 77350: loss = 0.16867
Step 77355: loss = 0.25504
Step 77360: loss = 0.05923
Step 77365: loss = 0.24634
Step 77370: loss = 0.22016
Step 77375: loss = 0.10680
Step 77380: loss = 0.13319
Step 77385: loss = 0.14173
Step 77390: loss = 0.24708
Step 77395: loss = 0.16641
Step 77400: loss = 0.20062
Step 77405: loss = 0.16930
Step 77410: loss = 0.44196
Step 77415: loss = 0.17843
Step 77420: loss = 0.29639
Step 77425: loss = 0.25024
Step 77430: loss = 0.11733
Step 77435: loss = 0.45319
Step 77440: loss = 0.14093
Step 77445: loss = 0.19811
Step 77450: loss = 0.26475
Step 77455: loss = 0.41524
Step 77460: loss = 0.40699
Step 77465: loss = 0.15776
Step 77470: loss = 0.22910
Step 77475: loss = 0.13696
Step 77480: loss = 0.11281
Step 77485: loss = 0.19375
Step 77490: loss = 0.31479
Step 77495: loss = 0.15664
Step 77500: loss = 0.05940
Step 77505: loss = 0.26062
Step 77510: loss = 0.35468
Step 77515: loss = 0.10296
Step 77520: loss = 0.10436
Step 77525: loss = 0.05925
Step 77530: loss = 0.15146
Step 77535: loss = 0.07279
Step 77540: loss = 0.16516
Step 77545: loss = 0.05553
Step 77550: loss = 0.30432
Step 77555: loss = 0.32691
Step 77560: loss = 0.08817
Step 77565: loss = 0.27841
Step 77570: loss = 0.11477
Step 77575: loss = 0.05295
Step 77580: loss = 0.15958
Step 77585: loss = 0.43107
Step 77590: loss = 0.11477
Step 77595: loss = 0.09978
Step 77600: loss = 0.26653
Step 77605: loss = 0.14368
Step 77610: loss = 0.54946
Step 77615: loss = 0.19697
Step 77620: loss = 0.17598
Step 77625: loss = 0.22745
Step 77630: loss = 0.27899
Step 77635: loss = 0.16995
Step 77640: loss = 0.12662
Step 77645: loss = 0.13038
Step 77650: loss = 0.22217
Step 77655: loss = 0.21150
Step 77660: loss = 0.21877
Step 77665: loss = 0.48975
Step 77670: loss = 0.21061
Step 77675: loss = 0.58679
Step 77680: loss = 0.34990
Step 77685: loss = 0.30264
Step 77690: loss = 0.16867
Step 77695: loss = 0.25819
Step 77700: loss = 0.16006
Step 77705: loss = 0.17280
Step 77710: loss = 0.09756
Step 77715: loss = 0.21339
Step 77720: loss = 0.42872
Step 77725: loss = 0.19704
Step 77730: loss = 0.39364
Step 77735: loss = 0.23618
Step 77740: loss = 0.20961
Step 77745: loss = 0.23193
Step 77750: loss = 0.07541
Step 77755: loss = 0.12666
Step 77760: loss = 0.06264
Step 77765: loss = 0.34120
Step 77770: loss = 0.08913
Step 77775: loss = 0.11411
Step 77780: loss = 0.30365
Step 77785: loss = 0.21972
Step 77790: loss = 0.19511
Step 77795: loss = 0.11240
Step 77800: loss = 0.17242
Step 77805: loss = 0.18794
Step 77810: loss = 0.24641
Step 77815: loss = 0.29903
Step 77820: loss = 0.13014
Step 77825: loss = 0.13269
Step 77830: loss = 0.14675
Step 77835: loss = 0.51142
Step 77840: loss = 0.19005
Step 77845: loss = 0.24930
Step 77850: loss = 0.17754
Step 77855: loss = 0.27970
Step 77860: loss = 0.31257
Step 77865: loss = 0.11344
Step 77870: loss = 0.21878
Step 77875: loss = 0.17327
Step 77880: loss = 0.15529
Step 77885: loss = 0.05210
Step 77890: loss = 0.19992
Step 77895: loss = 0.24170
Step 77900: loss = 0.28981
Step 77905: loss = 0.11664
Step 77910: loss = 0.17003
Step 77915: loss = 0.19234
Step 77920: loss = 0.28829
Step 77925: loss = 0.25385
Step 77930: loss = 0.27891
Step 77935: loss = 0.23604
Step 77940: loss = 0.18467
Step 77945: loss = 0.17623
Step 77950: loss = 0.06967
Step 77955: loss = 0.31544
Step 77960: loss = 0.11038
Step 77965: loss = 0.16063
Step 77970: loss = 0.13377
Step 77975: loss = 0.26600
Step 77980: loss = 0.47857
Step 77985: loss = 0.21806
Step 77990: loss = 0.17031
Step 77995: loss = 0.34308
Step 78000: loss = 0.23776
Training Data Eval:
  Num examples: 50000, Num correct: 46594, Precision @ 1: 0.9319
('Testing Data Eval: EPOCH->', 79)
  Num examples: 10000, Num correct: 6539, Precision @ 1: 0.6539
Step 78005: loss = 0.10573
Step 78010: loss = 0.10406
Step 78015: loss = 0.24048
Step 78020: loss = 0.05721
Step 78025: loss = 0.09522
Step 78030: loss = 0.23304
Step 78035: loss = 0.29901
Step 78040: loss = 0.17475
Step 78045: loss = 0.33579
Step 78050: loss = 0.09876
Step 78055: loss = 0.20051
Step 78060: loss = 0.21125
Step 78065: loss = 0.15378
Step 78070: loss = 0.22703
Step 78075: loss = 0.38353
Step 78080: loss = 0.14028
Step 78085: loss = 0.29640
Step 78090: loss = 0.16846
Step 78095: loss = 0.21823
Step 78100: loss = 0.12123
Step 78105: loss = 0.18801
Step 78110: loss = 0.27350
Step 78115: loss = 0.07930
Step 78120: loss = 0.21096
Step 78125: loss = 0.08175
Step 78130: loss = 0.11455
Step 78135: loss = 0.27593
Step 78140: loss = 0.12539
Step 78145: loss = 0.50216
Step 78150: loss = 0.10540
Step 78155: loss = 0.12965
Step 78160: loss = 0.14174
Step 78165: loss = 0.13885
Step 78170: loss = 0.29590
Step 78175: loss = 0.15603
Step 78180: loss = 0.16647
Step 78185: loss = 0.18911
Step 78190: loss = 0.04218
Step 78195: loss = 0.36436
Step 78200: loss = 0.17798
Step 78205: loss = 0.29993
Step 78210: loss = 0.16313
Step 78215: loss = 0.21122
Step 78220: loss = 0.20099
Step 78225: loss = 0.25781
Step 78230: loss = 0.10896
Step 78235: loss = 0.05881
Step 78240: loss = 0.12423
Step 78245: loss = 0.14319
Step 78250: loss = 0.36031
Step 78255: loss = 0.22180
Step 78260: loss = 0.31096
Step 78265: loss = 0.16850
Step 78270: loss = 0.36834
Step 78275: loss = 0.25478
Step 78280: loss = 0.14335
Step 78285: loss = 0.09637
Step 78290: loss = 0.39209
Step 78295: loss = 0.25181
Step 78300: loss = 0.24501
Step 78305: loss = 0.23265
Step 78310: loss = 0.11520
Step 78315: loss = 0.31025
Step 78320: loss = 0.23248
Step 78325: loss = 0.24687
Step 78330: loss = 0.43979
Step 78335: loss = 0.32434
Step 78340: loss = 0.13202
Step 78345: loss = 0.11862
Step 78350: loss = 0.17930
Step 78355: loss = 0.39102
Step 78360: loss = 0.25837
Step 78365: loss = 0.26103
Step 78370: loss = 0.21481
Step 78375: loss = 0.31282
Step 78380: loss = 0.34501
Step 78385: loss = 0.12370
Step 78390: loss = 0.25422
Step 78395: loss = 0.19775
Step 78400: loss = 0.17811
Step 78405: loss = 0.19599
Step 78410: loss = 0.43521
Step 78415: loss = 0.22043
Step 78420: loss = 0.26769
Step 78425: loss = 0.22744
Step 78430: loss = 0.51337
Step 78435: loss = 0.16141
Step 78440: loss = 0.24816
Step 78445: loss = 0.04096
Step 78450: loss = 0.33711
Step 78455: loss = 0.27787
Step 78460: loss = 0.17336
Step 78465: loss = 0.16013
Step 78470: loss = 0.39942
Step 78475: loss = 0.11217
Step 78480: loss = 0.23735
Step 78485: loss = 0.33440
Step 78490: loss = 0.16300
Step 78495: loss = 0.34432
Step 78500: loss = 0.30215
Step 78505: loss = 0.27502
Step 78510: loss = 0.26471
Step 78515: loss = 0.10152
Step 78520: loss = 0.35466
Step 78525: loss = 0.19469
Step 78530: loss = 0.20311
Step 78535: loss = 0.20658
Step 78540: loss = 0.07088
Step 78545: loss = 0.24728
Step 78550: loss = 0.16003
Step 78555: loss = 0.35190
Step 78560: loss = 0.48130
Step 78565: loss = 0.37120
Step 78570: loss = 0.25267
Step 78575: loss = 0.15229
Step 78580: loss = 0.22980
Step 78585: loss = 0.12787
Step 78590: loss = 0.20594
Step 78595: loss = 0.10638
Step 78600: loss = 0.21913
Step 78605: loss = 0.20190
Step 78610: loss = 0.23099
Step 78615: loss = 0.24245
Step 78620: loss = 0.19698
Step 78625: loss = 0.12125
Step 78630: loss = 0.22051
Step 78635: loss = 0.35697
Step 78640: loss = 0.23793
Step 78645: loss = 0.09192
Step 78650: loss = 0.31301
Step 78655: loss = 0.17116
Step 78660: loss = 0.18024
Step 78665: loss = 0.51182
Step 78670: loss = 0.16200
Step 78675: loss = 0.09742
Step 78680: loss = 0.18001
Step 78685: loss = 0.26425
Step 78690: loss = 0.20432
Step 78695: loss = 0.16873
Step 78700: loss = 0.17749
Step 78705: loss = 0.46632
Step 78710: loss = 0.12590
Step 78715: loss = 0.36626
Step 78720: loss = 0.19172
Step 78725: loss = 0.25464
Step 78730: loss = 0.36179
Step 78735: loss = 0.23665
Step 78740: loss = 0.21979
Step 78745: loss = 0.24515
Step 78750: loss = 0.23858
Step 78755: loss = 0.23244
Step 78760: loss = 0.30169
Step 78765: loss = 0.27609
Step 78770: loss = 0.08064
Step 78775: loss = 0.05483
Step 78780: loss = 0.18877
Step 78785: loss = 0.19312
Step 78790: loss = 0.40687
Step 78795: loss = 0.07134
Step 78800: loss = 0.09653
Step 78805: loss = 0.11835
Step 78810: loss = 0.09002
Step 78815: loss = 0.23083
Step 78820: loss = 0.31321
Step 78825: loss = 0.17992
Step 78830: loss = 0.08075
Step 78835: loss = 0.34319
Step 78840: loss = 0.10792
Step 78845: loss = 0.24078
Step 78850: loss = 0.24877
Step 78855: loss = 0.28850
Step 78860: loss = 0.16050
Step 78865: loss = 0.27404
Step 78870: loss = 0.14809
Step 78875: loss = 0.11236
Step 78880: loss = 0.16928
Step 78885: loss = 0.19314
Step 78890: loss = 0.21715
Step 78895: loss = 0.17160
Step 78900: loss = 0.13268
Step 78905: loss = 0.08567
Step 78910: loss = 0.12227
Step 78915: loss = 0.20260
Step 78920: loss = 0.15891
Step 78925: loss = 0.23209
Step 78930: loss = 0.20839
Step 78935: loss = 0.37000
Step 78940: loss = 0.27554
Step 78945: loss = 0.23518
Step 78950: loss = 0.09115
Step 78955: loss = 0.38650
Step 78960: loss = 0.22880
Step 78965: loss = 0.31665
Step 78970: loss = 0.30645
Step 78975: loss = 0.38131
Step 78980: loss = 0.27628
Step 78985: loss = 0.27988
Step 78990: loss = 0.22042
Step 78995: loss = 0.13896
Step 79000: loss = 0.70693
Training Data Eval:
  Num examples: 50000, Num correct: 46548, Precision @ 1: 0.9310
('Testing Data Eval: EPOCH->', 80)
  Num examples: 10000, Num correct: 6546, Precision @ 1: 0.6546
Step 79005: loss = 0.22901
Step 79010: loss = 0.32369
Step 79015: loss = 0.11716
Step 79020: loss = 0.17910
Step 79025: loss = 0.53707
Step 79030: loss = 0.18933
Step 79035: loss = 0.24819
Step 79040: loss = 0.15458
Step 79045: loss = 0.28614
Step 79050: loss = 0.51744
Step 79055: loss = 0.19731
Step 79060: loss = 0.14609
Step 79065: loss = 0.13925
Step 79070: loss = 0.56031
Step 79075: loss = 0.27398
Step 79080: loss = 0.25088
Step 79085: loss = 0.11973
Step 79090: loss = 0.30529
Step 79095: loss = 0.23686
Step 79100: loss = 0.17338
Step 79105: loss = 0.26494
Step 79110: loss = 0.19218
Step 79115: loss = 0.20083
Step 79120: loss = 0.29234
Step 79125: loss = 0.36474
Step 79130: loss = 0.13105
Step 79135: loss = 0.34488
Step 79140: loss = 0.20558
Step 79145: loss = 0.26005
Step 79150: loss = 0.31657
Step 79155: loss = 0.16117
Step 79160: loss = 0.19330
Step 79165: loss = 0.12598
Step 79170: loss = 0.39236
Step 79175: loss = 0.22716
Step 79180: loss = 0.28458
Step 79185: loss = 0.19106
Step 79190: loss = 0.37202
Step 79195: loss = 0.23208
Step 79200: loss = 0.19662
Step 79205: loss = 0.19312
Step 79210: loss = 0.16035
Step 79215: loss = 0.30033
Step 79220: loss = 0.22358
Step 79225: loss = 0.08547
Step 79230: loss = 0.20111
Step 79235: loss = 0.27405
Step 79240: loss = 0.21625
Step 79245: loss = 0.37128
Step 79250: loss = 0.19836
Step 79255: loss = 0.34973
Step 79260: loss = 0.19619
Step 79265: loss = 0.13122
Step 79270: loss = 0.15231
Step 79275: loss = 0.22003
Step 79280: loss = 0.20026
Step 79285: loss = 0.11830
Step 79290: loss = 0.19406
Step 79295: loss = 0.22883
Step 79300: loss = 0.11214
Step 79305: loss = 0.30955
Step 79310: loss = 0.22637
Step 79315: loss = 0.19635
Step 79320: loss = 0.11498
Step 79325: loss = 0.13359
Step 79330: loss = 0.14152
Step 79335: loss = 0.09869
Step 79340: loss = 0.11809
Step 79345: loss = 0.08897
Step 79350: loss = 0.15412
Step 79355: loss = 0.08091
Step 79360: loss = 0.40263
Step 79365: loss = 0.40529
Step 79370: loss = 0.40085
Step 79375: loss = 0.33688
Step 79380: loss = 0.18278
Step 79385: loss = 0.13173
Step 79390: loss = 0.21924
Step 79395: loss = 0.09033
Step 79400: loss = 0.47358
Step 79405: loss = 0.08404
Step 79410: loss = 0.08386
Step 79415: loss = 0.20872
Step 79420: loss = 0.40275
Step 79425: loss = 0.16081
Step 79430: loss = 0.14299
Step 79435: loss = 0.10364
Step 79440: loss = 0.10826
Step 79445: loss = 0.06924
Step 79450: loss = 0.33335
Step 79455: loss = 0.31475
Step 79460: loss = 0.12709
Step 79465: loss = 0.16697
Step 79470: loss = 0.27240
Step 79475: loss = 0.50057
Step 79480: loss = 0.23301
Step 79485: loss = 0.31362
Step 79490: loss = 0.23143
Step 79495: loss = 0.10098
Step 79500: loss = 0.35341
Step 79505: loss = 0.20471
Step 79510: loss = 0.12431
Step 79515: loss = 0.12540
Step 79520: loss = 0.15485
Step 79525: loss = 0.15811
Step 79530: loss = 0.20512
Step 79535: loss = 0.28829
Step 79540: loss = 0.20877
Step 79545: loss = 0.15688
Step 79550: loss = 0.18120
Step 79555: loss = 0.18030
Step 79560: loss = 0.28335
Step 79565: loss = 0.28102
Step 79570: loss = 0.12629
Step 79575: loss = 0.18684
Step 79580: loss = 0.24445
Step 79585: loss = 0.21086
Step 79590: loss = 0.18355
Step 79595: loss = 0.27607
Step 79600: loss = 0.23968
Step 79605: loss = 0.20715
Step 79610: loss = 0.14084
Step 79615: loss = 0.13598
Step 79620: loss = 0.25944
Step 79625: loss = 0.22166
Step 79630: loss = 0.13148
Step 79635: loss = 0.23376
Step 79640: loss = 0.07789
Step 79645: loss = 0.17746
Step 79650: loss = 0.14645
Step 79655: loss = 0.16321
Step 79660: loss = 0.22342
Step 79665: loss = 0.19049
Step 79670: loss = 0.12925
Step 79675: loss = 0.05464
Step 79680: loss = 0.13500
Step 79685: loss = 0.10184
Step 79690: loss = 0.23669
Step 79695: loss = 0.23174
Step 79700: loss = 0.39776
Step 79705: loss = 0.24434
Step 79710: loss = 0.14144
Step 79715: loss = 0.17297
Step 79720: loss = 0.40598
Step 79725: loss = 0.19667
Step 79730: loss = 0.17305
Step 79735: loss = 0.17250
Step 79740: loss = 0.34380
Step 79745: loss = 0.20664
Step 79750: loss = 0.06336
Step 79755: loss = 0.42432
Step 79760: loss = 0.14480
Step 79765: loss = 0.18996
Step 79770: loss = 0.12746
Step 79775: loss = 0.11360
Step 79780: loss = 0.10581
Step 79785: loss = 0.19132
Step 79790: loss = 0.10993
Step 79795: loss = 0.23292
Step 79800: loss = 0.30212
Step 79805: loss = 0.06424
Step 79810: loss = 0.27125
Step 79815: loss = 0.07866
Step 79820: loss = 0.29088
Step 79825: loss = 0.18055
Step 79830: loss = 0.45795
Step 79835: loss = 0.43623
Step 79840: loss = 0.23468
Step 79845: loss = 0.09798
Step 79850: loss = 0.12645
Step 79855: loss = 0.14911
Step 79860: loss = 0.16597
Step 79865: loss = 0.27513
Step 79870: loss = 0.11668
Step 79875: loss = 0.16478
Step 79880: loss = 0.10078
Step 79885: loss = 0.11626
Step 79890: loss = 0.16442
Step 79895: loss = 0.09085
Step 79900: loss = 0.09590
Step 79905: loss = 0.32813
Step 79910: loss = 0.05460
Step 79915: loss = 0.25415
Step 79920: loss = 0.07270
Step 79925: loss = 0.33570
Step 79930: loss = 0.19825
Step 79935: loss = 0.24503
Step 79940: loss = 0.26753
Step 79945: loss = 0.14598
Step 79950: loss = 0.13444
Step 79955: loss = 0.12535
Step 79960: loss = 0.20191
Step 79965: loss = 0.33006
Step 79970: loss = 0.18747
Step 79975: loss = 0.33343
Step 79980: loss = 0.33255
Step 79985: loss = 0.17886
Step 79990: loss = 0.24339
Step 79995: loss = 0.20214
Step 80000: loss = 0.19637
Training Data Eval:
  Num examples: 50000, Num correct: 46655, Precision @ 1: 0.9331
('Testing Data Eval: EPOCH->', 81)
  Num examples: 10000, Num correct: 6551, Precision @ 1: 0.6551
Step 80005: loss = 0.14776
Step 80010: loss = 0.29469
Step 80015: loss = 0.43387
Step 80020: loss = 0.16407
Step 80025: loss = 0.23579
Step 80030: loss = 0.16642
Step 80035: loss = 0.10278
Step 80040: loss = 0.06071
Step 80045: loss = 0.13500
Step 80050: loss = 0.08992
Step 80055: loss = 0.39637
Step 80060: loss = 0.03539
Step 80065: loss = 0.25958
Step 80070: loss = 0.12715
Step 80075: loss = 0.42295
Step 80080: loss = 0.05395
Step 80085: loss = 0.11777
Step 80090: loss = 0.33604
Step 80095: loss = 0.18175
Step 80100: loss = 0.07320
Step 80105: loss = 0.11613
Step 80110: loss = 0.19316
Step 80115: loss = 0.19194
Step 80120: loss = 0.17341
Step 80125: loss = 0.25080
Step 80130: loss = 0.26849
Step 80135: loss = 0.05981
Step 80140: loss = 0.18330
Step 80145: loss = 0.13842
Step 80150: loss = 0.20193
Step 80155: loss = 0.23421
Step 80160: loss = 0.30057
Step 80165: loss = 0.19485
Step 80170: loss = 0.24167
Step 80175: loss = 0.46206
Step 80180: loss = 0.14450
Step 80185: loss = 0.26668
Step 80190: loss = 0.32724
Step 80195: loss = 0.14030
Step 80200: loss = 0.14138
Step 80205: loss = 0.14545
Step 80210: loss = 0.12571
Step 80215: loss = 0.26910
Step 80220: loss = 0.25755
Step 80225: loss = 0.09317
Step 80230: loss = 0.24468
Step 80235: loss = 0.33348
Step 80240: loss = 0.27176
Step 80245: loss = 0.17426
Step 80250: loss = 0.27059
Step 80255: loss = 0.17332
Step 80260: loss = 0.07006
Step 80265: loss = 0.15230
Step 80270: loss = 0.25467
Step 80275: loss = 0.20363
Step 80280: loss = 0.26088
Step 80285: loss = 0.19173
Step 80290: loss = 0.28301
Step 80295: loss = 0.14852
Step 80300: loss = 0.28302
Step 80305: loss = 0.17377
Step 80310: loss = 0.25900
Step 80315: loss = 0.26088
Step 80320: loss = 0.26664
Step 80325: loss = 0.16027
Step 80330: loss = 0.21263
Step 80335: loss = 0.31449
Step 80340: loss = 0.22794
Step 80345: loss = 0.22767
Step 80350: loss = 0.15400
Step 80355: loss = 0.17201
Step 80360: loss = 0.43636
Step 80365: loss = 0.29327
Step 80370: loss = 0.27814
Step 80375: loss = 0.12633
Step 80380: loss = 0.23214
Step 80385: loss = 0.16735
Step 80390: loss = 0.23679
Step 80395: loss = 0.24556
Step 80400: loss = 0.16069
Step 80405: loss = 0.14212
Step 80410: loss = 0.19730
Step 80415: loss = 0.17054
Step 80420: loss = 0.23687
Step 80425: loss = 0.11576
Step 80430: loss = 0.21821
Step 80435: loss = 0.14990
Step 80440: loss = 0.26888
Step 80445: loss = 0.29338
Step 80450: loss = 0.08034
Step 80455: loss = 0.17714
Step 80460: loss = 0.20944
Step 80465: loss = 0.12909
Step 80470: loss = 0.20676
Step 80475: loss = 0.32081
Step 80480: loss = 0.29090
Step 80485: loss = 0.61894
Step 80490: loss = 0.10669
Step 80495: loss = 0.15655
Step 80500: loss = 0.36249
Step 80505: loss = 0.30377
Step 80510: loss = 0.10925
Step 80515: loss = 0.19828
Step 80520: loss = 0.19565
Step 80525: loss = 0.60564
Step 80530: loss = 0.35919
Step 80535: loss = 0.32324
Step 80540: loss = 0.29285
Step 80545: loss = 0.52464
Step 80550: loss = 0.09337
Step 80555: loss = 0.19022
Step 80560: loss = 0.25169
Step 80565: loss = 0.46907
Step 80570: loss = 0.22585
Step 80575: loss = 0.21630
Step 80580: loss = 0.09793
Step 80585: loss = 0.15211
Step 80590: loss = 0.12230
Step 80595: loss = 0.13108
Step 80600: loss = 0.12730
Step 80605: loss = 0.07930
Step 80610: loss = 0.19470
Step 80615: loss = 0.15739
Step 80620: loss = 0.16388
Step 80625: loss = 0.21758
Step 80630: loss = 0.11242
Step 80635: loss = 0.18528
Step 80640: loss = 0.15034
Step 80645: loss = 0.09846
Step 80650: loss = 0.16307
Step 80655: loss = 0.21396
Step 80660: loss = 0.15915
Step 80665: loss = 0.11279
Step 80670: loss = 0.26749
Step 80675: loss = 0.11126
Step 80680: loss = 0.45290
Step 80685: loss = 0.24942
Step 80690: loss = 0.08663
Step 80695: loss = 0.15525
Step 80700: loss = 0.08024
Step 80705: loss = 0.12383
Step 80710: loss = 0.16173
Step 80715: loss = 0.33796
Step 80720: loss = 0.07948
Step 80725: loss = 0.12463
Step 80730: loss = 0.09609
Step 80735: loss = 0.26753
Step 80740: loss = 0.10038
Step 80745: loss = 0.12709
Step 80750: loss = 0.33010
Step 80755: loss = 0.21186
Step 80760: loss = 0.16564
Step 80765: loss = 0.41367
Step 80770: loss = 0.16866
Step 80775: loss = 0.25614
Step 80780: loss = 0.10019
Step 80785: loss = 0.24822
Step 80790: loss = 0.10999
Step 80795: loss = 0.28777
Step 80800: loss = 0.09839
Step 80805: loss = 0.27920
Step 80810: loss = 0.32516
Step 80815: loss = 0.15440
Step 80820: loss = 0.24480
Step 80825: loss = 0.19951
Step 80830: loss = 0.12719
Step 80835: loss = 0.11584
Step 80840: loss = 0.05970
Step 80845: loss = 0.13164
Step 80850: loss = 0.19634
Step 80855: loss = 0.36878
Step 80860: loss = 0.16089
Step 80865: loss = 0.53103
Step 80870: loss = 0.40050
Step 80875: loss = 0.17249
Step 80880: loss = 0.24091
Step 80885: loss = 0.22211
Step 80890: loss = 0.14242
Step 80895: loss = 0.38591
Step 80900: loss = 0.19565
Step 80905: loss = 0.15995
Step 80910: loss = 0.13178
Step 80915: loss = 0.22105
Step 80920: loss = 0.11985
Step 80925: loss = 0.37894
Step 80930: loss = 0.21718
Step 80935: loss = 0.13317
Step 80940: loss = 0.22464
Step 80945: loss = 0.39459
Step 80950: loss = 0.20602
Step 80955: loss = 0.32973
Step 80960: loss = 0.17199
Step 80965: loss = 0.09557
Step 80970: loss = 0.22982
Step 80975: loss = 0.10658
Step 80980: loss = 0.18989
Step 80985: loss = 0.09651
Step 80990: loss = 0.17939
Step 80995: loss = 0.12981
Step 81000: loss = 0.15306
Training Data Eval:
  Num examples: 50000, Num correct: 46911, Precision @ 1: 0.9382
('Testing Data Eval: EPOCH->', 82)
  Num examples: 10000, Num correct: 6550, Precision @ 1: 0.6550
Step 81005: loss = 0.17294
Step 81010: loss = 0.07601
Step 81015: loss = 0.17395
Step 81020: loss = 0.08113
Step 81025: loss = 0.10889
Step 81030: loss = 0.14449
Step 81035: loss = 0.25914
Step 81040: loss = 0.13488
Step 81045: loss = 0.24549
Step 81050: loss = 0.15483
Step 81055: loss = 0.26608
Step 81060: loss = 0.24546
Step 81065: loss = 0.16935
Step 81070: loss = 0.43876
Step 81075: loss = 0.17293
Step 81080: loss = 0.13743
Step 81085: loss = 0.19296
Step 81090: loss = 0.19574
Step 81095: loss = 0.22065
Step 81100: loss = 0.16299
Step 81105: loss = 0.16410
Step 81110: loss = 0.14953
Step 81115: loss = 0.11987
Step 81120: loss = 0.15392
Step 81125: loss = 0.32105
Step 81130: loss = 0.11669
Step 81135: loss = 0.16675
Step 81140: loss = 0.18751
Step 81145: loss = 0.19936
Step 81150: loss = 0.10640
Step 81155: loss = 0.20955
Step 81160: loss = 0.26605
Step 81165: loss = 0.25666
Step 81170: loss = 0.22358
Step 81175: loss = 0.13817
Step 81180: loss = 0.10566
Step 81185: loss = 0.31303
Step 81190: loss = 0.15524
Step 81195: loss = 0.07085
Step 81200: loss = 0.17557
Step 81205: loss = 0.14632
Step 81210: loss = 0.15174
Step 81215: loss = 0.35006
Step 81220: loss = 0.12631
Step 81225: loss = 0.07465
Step 81230: loss = 0.09987
Step 81235: loss = 0.33131
Step 81240: loss = 0.20185
Step 81245: loss = 0.19469
Step 81250: loss = 0.09568
Step 81255: loss = 0.29800
Step 81260: loss = 0.32570
Step 81265: loss = 0.27811
Step 81270: loss = 0.13286
Step 81275: loss = 0.28138
Step 81280: loss = 0.17511
Step 81285: loss = 0.16586
Step 81290: loss = 0.28951
Step 81295: loss = 0.17822
Step 81300: loss = 0.29363
Step 81305: loss = 0.16909
Step 81310: loss = 0.38262
Step 81315: loss = 0.33875
Step 81320: loss = 0.16771
Step 81325: loss = 0.20969
Step 81330: loss = 0.22979
Step 81335: loss = 0.49352
Step 81340: loss = 0.29053
Step 81345: loss = 0.11686
Step 81350: loss = 0.31539
Step 81355: loss = 0.36760
Step 81360: loss = 0.17188
Step 81365: loss = 0.22285
Step 81370: loss = 0.11231
Step 81375: loss = 0.13313
Step 81380: loss = 0.05834
Step 81385: loss = 0.34098
Step 81390: loss = 0.11823
Step 81395: loss = 0.27003
Step 81400: loss = 0.05983
Step 81405: loss = 0.48770
Step 81410: loss = 0.18237
Step 81415: loss = 0.10807
Step 81420: loss = 0.37341
Step 81425: loss = 0.36937
Step 81430: loss = 0.24981
Step 81435: loss = 0.20840
Step 81440: loss = 0.22005
Step 81445: loss = 0.06434
Step 81450: loss = 0.36039
Step 81455: loss = 0.30229
Step 81460: loss = 0.29521
Step 81465: loss = 0.15056
Step 81470: loss = 0.21773
Step 81475: loss = 0.12692
Step 81480: loss = 0.29683
Step 81485: loss = 0.08524
Step 81490: loss = 0.21669
Step 81495: loss = 0.17899
Step 81500: loss = 0.41503
Step 81505: loss = 0.28011
Step 81510: loss = 0.07334
Step 81515: loss = 0.25122
Step 81520: loss = 0.18486
Step 81525: loss = 0.21568
Step 81530: loss = 0.24365
Step 81535: loss = 0.15356
Step 81540: loss = 0.22356
Step 81545: loss = 0.33130
Step 81550: loss = 0.13025
Step 81555: loss = 0.12375
Step 81560: loss = 0.38919
Step 81565: loss = 0.27303
Step 81570: loss = 0.15732
Step 81575: loss = 0.16241
Step 81580: loss = 0.17350
Step 81585: loss = 0.06866
Step 81590: loss = 0.15105
Step 81595: loss = 0.15440
Step 81600: loss = 0.23131
Step 81605: loss = 0.33836
Step 81610: loss = 0.25035
Step 81615: loss = 0.17732
Step 81620: loss = 0.08778
Step 81625: loss = 0.18513
Step 81630: loss = 0.13116
Step 81635: loss = 0.22488
Step 81640: loss = 0.29482
Step 81645: loss = 0.24462
Step 81650: loss = 0.24208
Step 81655: loss = 0.53318
Step 81660: loss = 0.22662
Step 81665: loss = 0.12104
Step 81670: loss = 0.29472
Step 81675: loss = 0.21795
Step 81680: loss = 0.15675
Step 81685: loss = 0.33950
Step 81690: loss = 0.20996
Step 81695: loss = 0.15717
Step 81700: loss = 0.14771
Step 81705: loss = 0.42594
Step 81710: loss = 0.20000
Step 81715: loss = 0.27786
Step 81720: loss = 0.08748
Step 81725: loss = 0.18113
Step 81730: loss = 0.12108
Step 81735: loss = 0.30820
Step 81740: loss = 0.14361
Step 81745: loss = 0.27239
Step 81750: loss = 0.12197
Step 81755: loss = 0.30440
Step 81760: loss = 0.17939
Step 81765: loss = 0.27730
Step 81770: loss = 0.37545
Step 81775: loss = 0.20398
Step 81780: loss = 0.31662
Step 81785: loss = 0.31651
Step 81790: loss = 0.13083
Step 81795: loss = 0.17444
Step 81800: loss = 0.10352
Step 81805: loss = 0.21312
Step 81810: loss = 0.29115
Step 81815: loss = 0.23097
Step 81820: loss = 0.30624
Step 81825: loss = 0.16871
Step 81830: loss = 0.35385
Step 81835: loss = 0.21666
Step 81840: loss = 0.19952
Step 81845: loss = 0.24294
Step 81850: loss = 0.18688
Step 81855: loss = 0.11569
Step 81860: loss = 0.21390
Step 81865: loss = 0.24587
Step 81870: loss = 0.22756
Step 81875: loss = 0.24388
Step 81880: loss = 0.23341
Step 81885: loss = 0.21849
Step 81890: loss = 0.22838
Step 81895: loss = 0.20960
Step 81900: loss = 0.32197
Step 81905: loss = 0.20842
Step 81910: loss = 0.23847
Step 81915: loss = 0.09157
Step 81920: loss = 0.14402
Step 81925: loss = 0.19297
Step 81930: loss = 0.09774
Step 81935: loss = 0.19143
Step 81940: loss = 0.07260
Step 81945: loss = 0.18875
Step 81950: loss = 0.35774
Step 81955: loss = 0.39994
Step 81960: loss = 0.20766
Step 81965: loss = 0.19183
Step 81970: loss = 0.36978
Step 81975: loss = 0.15838
Step 81980: loss = 0.07532
Step 81985: loss = 0.28797
Step 81990: loss = 0.12006
Step 81995: loss = 0.18415
Step 82000: loss = 0.07132
Training Data Eval:
  Num examples: 50000, Num correct: 46496, Precision @ 1: 0.9299
('Testing Data Eval: EPOCH->', 83)
  Num examples: 10000, Num correct: 6540, Precision @ 1: 0.6540
Step 82005: loss = 0.20496
Step 82010: loss = 0.14132
Step 82015: loss = 0.10737
Step 82020: loss = 0.29089
Step 82025: loss = 0.18241
Step 82030: loss = 0.16477
Step 82035: loss = 0.25029
Step 82040: loss = 0.12439
Step 82045: loss = 0.14488
Step 82050: loss = 0.08712
Step 82055: loss = 0.23573
Step 82060: loss = 0.26779
Step 82065: loss = 0.31592
Step 82070: loss = 0.08391
Step 82075: loss = 0.31512
Step 82080: loss = 0.21563
Step 82085: loss = 0.12465
Step 82090: loss = 0.37794
Step 82095: loss = 0.47685
Step 82100: loss = 0.10965
Step 82105: loss = 0.38914
Step 82110: loss = 0.21451
Step 82115: loss = 0.17433
Step 82120: loss = 0.33351
Step 82125: loss = 0.22080
Step 82130: loss = 0.07923
Step 82135: loss = 0.21905
Step 82140: loss = 0.06654
Step 82145: loss = 0.15509
Step 82150: loss = 0.13707
Step 82155: loss = 0.15012
Step 82160: loss = 0.09968
Step 82165: loss = 0.17485
Step 82170: loss = 0.20298
Step 82175: loss = 0.09172
Step 82180: loss = 0.28372
Step 82185: loss = 0.16853
Step 82190: loss = 0.08765
Step 82195: loss = 0.50119
Step 82200: loss = 0.19122
Step 82205: loss = 0.21112
Step 82210: loss = 0.21639
Step 82215: loss = 0.15202
Step 82220: loss = 0.03283
Step 82225: loss = 0.28309
Step 82230: loss = 0.16208
Step 82235: loss = 0.09058
Step 82240: loss = 0.09889
Step 82245: loss = 0.12211
Step 82250: loss = 0.17087
Step 82255: loss = 0.19726
Step 82260: loss = 0.16476
Step 82265: loss = 0.20583
Step 82270: loss = 0.26880
Step 82275: loss = 0.17401
Step 82280: loss = 0.20319
Step 82285: loss = 0.18580
Step 82290: loss = 0.19496
Step 82295: loss = 0.40128
Step 82300: loss = 0.19008
Step 82305: loss = 0.17451
Step 82310: loss = 0.27429
Step 82315: loss = 0.06043
Step 82320: loss = 0.04023
Step 82325: loss = 0.41027
Step 82330: loss = 0.41617
Step 82335: loss = 0.21488
Step 82340: loss = 0.18250
Step 82345: loss = 0.15621
Step 82350: loss = 0.20248
Step 82355: loss = 0.09499
Step 82360: loss = 0.14963
Step 82365: loss = 0.21931
Step 82370: loss = 0.21093
Step 82375: loss = 0.12296
Step 82380: loss = 0.18160
Step 82385: loss = 0.31893
Step 82390: loss = 0.15197
Step 82395: loss = 0.33651
Step 82400: loss = 0.15166
Step 82405: loss = 0.14677
Step 82410: loss = 0.16132
Step 82415: loss = 0.28199
Step 82420: loss = 0.36523
Step 82425: loss = 0.18358
Step 82430: loss = 0.29759
Step 82435: loss = 0.26706
Step 82440: loss = 0.19859
Step 82445: loss = 0.18116
Step 82450: loss = 0.14635
Step 82455: loss = 0.11359
Step 82460: loss = 0.12905
Step 82465: loss = 0.12830
Step 82470: loss = 0.12678
Step 82475: loss = 0.24436
Step 82480: loss = 0.13424
Step 82485: loss = 0.14972
Step 82490: loss = 0.05765
Step 82495: loss = 0.23854
Step 82500: loss = 0.28465
Step 82505: loss = 0.07728
Step 82510: loss = 0.13526
Step 82515: loss = 0.16301
Step 82520: loss = 0.40303
Step 82525: loss = 0.17124
Step 82530: loss = 0.30804
Step 82535: loss = 0.16686
Step 82540: loss = 0.21565
Step 82545: loss = 0.45306
Step 82550: loss = 0.36294
Step 82555: loss = 0.22680
Step 82560: loss = 0.35634
Step 82565: loss = 0.30896
Step 82570: loss = 0.38649
Step 82575: loss = 0.33692
Step 82580: loss = 0.11834
Step 82585: loss = 0.34099
Step 82590: loss = 0.30291
Step 82595: loss = 0.41477
Step 82600: loss = 0.27783
Step 82605: loss = 0.13179
Step 82610: loss = 0.12144
Step 82615: loss = 0.12494
Step 82620: loss = 0.29063
Step 82625: loss = 0.16332
Step 82630: loss = 0.10069
Step 82635: loss = 0.30340
Step 82640: loss = 0.32152
Step 82645: loss = 0.21585
Step 82650: loss = 0.06823
Step 82655: loss = 0.16540
Step 82660: loss = 0.23535
Step 82665: loss = 0.19669
Step 82670: loss = 0.17023
Step 82675: loss = 0.15432
Step 82680: loss = 0.28615
Step 82685: loss = 0.12775
Step 82690: loss = 0.25115
Step 82695: loss = 0.21417
Step 82700: loss = 0.18249
Step 82705: loss = 0.13164
Step 82710: loss = 0.25598
Step 82715: loss = 0.10465
Step 82720: loss = 0.08573
Step 82725: loss = 0.26487
Step 82730: loss = 0.16965
Step 82735: loss = 0.16378
Step 82740: loss = 0.34186
Step 82745: loss = 0.21392
Step 82750: loss = 0.11427
Step 82755: loss = 0.11979
Step 82760: loss = 0.16677
Step 82765: loss = 0.16868
Step 82770: loss = 0.05506
Step 82775: loss = 0.21197
Step 82780: loss = 0.13517
Step 82785: loss = 0.11330
Step 82790: loss = 0.19145
Step 82795: loss = 0.17948
Step 82800: loss = 0.12412
Step 82805: loss = 0.33228
Step 82810: loss = 0.33048
Step 82815: loss = 0.20469
Step 82820: loss = 0.35858
Step 82825: loss = 0.20708
Step 82830: loss = 0.17993
Step 82835: loss = 0.44621
Step 82840: loss = 0.14592
Step 82845: loss = 0.13986
Step 82850: loss = 0.23392
Step 82855: loss = 0.22970
Step 82860: loss = 0.20214
Step 82865: loss = 0.14395
Step 82870: loss = 0.20334
Step 82875: loss = 0.22172
Step 82880: loss = 0.33371
Step 82885: loss = 0.13560
Step 82890: loss = 0.13553
Step 82895: loss = 0.12989
Step 82900: loss = 0.28712
Step 82905: loss = 0.25227
Step 82910: loss = 0.12430
Step 82915: loss = 0.11638
Step 82920: loss = 0.37362
Step 82925: loss = 0.12928
Step 82930: loss = 0.23428
Step 82935: loss = 0.17131
Step 82940: loss = 0.25684
Step 82945: loss = 0.35278
Step 82950: loss = 0.23841
Step 82955: loss = 0.18164
Step 82960: loss = 0.10909
Step 82965: loss = 0.43865
Step 82970: loss = 0.25462
Step 82975: loss = 0.20641
Step 82980: loss = 0.18215
Step 82985: loss = 0.21307
Step 82990: loss = 0.29469
Step 82995: loss = 0.24072
Step 83000: loss = 0.20147
Training Data Eval:
  Num examples: 50000, Num correct: 46507, Precision @ 1: 0.9301
('Testing Data Eval: EPOCH->', 84)
  Num examples: 10000, Num correct: 6560, Precision @ 1: 0.6560
Step 83005: loss = 0.07114
Step 83010: loss = 0.05259
Step 83015: loss = 0.13977
Step 83020: loss = 0.47757
Step 83025: loss = 0.06073
Step 83030: loss = 0.18980
Step 83035: loss = 0.28719
Step 83040: loss = 0.28142
Step 83045: loss = 0.15505
Step 83050: loss = 0.29344
Step 83055: loss = 0.17299
Step 83060: loss = 0.34609
Step 83065: loss = 0.14847
Step 83070: loss = 0.10679
Step 83075: loss = 0.06733
Step 83080: loss = 0.25602
Step 83085: loss = 0.14628
Step 83090: loss = 0.15707
Step 83095: loss = 0.26916
Step 83100: loss = 0.06710
Step 83105: loss = 0.31580
Step 83110: loss = 0.17569
Step 83115: loss = 0.09100
Step 83120: loss = 0.19056
Step 83125: loss = 0.19948
Step 83130: loss = 0.25558
Step 83135: loss = 0.30248
Step 83140: loss = 0.23899
Step 83145: loss = 0.18107
Step 83150: loss = 0.27169
Step 83155: loss = 0.15872
Step 83160: loss = 0.12690
Step 83165: loss = 0.21491
Step 83170: loss = 0.14394
Step 83175: loss = 0.15285
Step 83180: loss = 0.07516
Step 83185: loss = 0.21658
Step 83190: loss = 0.21671
Step 83195: loss = 0.17885
Step 83200: loss = 0.30290
Step 83205: loss = 0.11333
Step 83210: loss = 0.12481
Step 83215: loss = 0.19467
Step 83220: loss = 0.22792
Step 83225: loss = 0.12610
Step 83230: loss = 0.12385
Step 83235: loss = 0.32988
Step 83240: loss = 0.29010
Step 83245: loss = 0.21392
Step 83250: loss = 0.08522
Step 83255: loss = 0.16106
Step 83260: loss = 0.37973
Step 83265: loss = 0.22404
Step 83270: loss = 0.10356
Step 83275: loss = 0.15716
Step 83280: loss = 0.24267
Step 83285: loss = 0.23676
Step 83290: loss = 0.36315
Step 83295: loss = 0.20667
Step 83300: loss = 0.55138
Step 83305: loss = 0.21169
Step 83310: loss = 0.30925
Step 83315: loss = 0.23915
Step 83320: loss = 0.09420
Step 83325: loss = 0.34407
Step 83330: loss = 0.21386
Step 83335: loss = 0.23065
Step 83340: loss = 0.14777
Step 83345: loss = 0.27532
Step 83350: loss = 0.19340
Step 83355: loss = 0.26785
Step 83360: loss = 0.11730
Step 83365: loss = 0.11901
Step 83370: loss = 0.11162
Step 83375: loss = 0.29376
Step 83380: loss = 0.23224
Step 83385: loss = 0.42829
Step 83390: loss = 0.44263
Step 83395: loss = 0.20635
Step 83400: loss = 0.13878
Step 83405: loss = 0.29185
Step 83410: loss = 0.10735
Step 83415: loss = 0.11969
Step 83420: loss = 0.19633
Step 83425: loss = 0.10754
Step 83430: loss = 0.18608
Step 83435: loss = 0.09616
Step 83440: loss = 0.07983
Step 83445: loss = 0.19343
Step 83450: loss = 0.13213
Step 83455: loss = 0.22125
Step 83460: loss = 0.14459
Step 83465: loss = 0.36316
Step 83470: loss = 0.29089
Step 83475: loss = 0.07172
Step 83480: loss = 0.17618
Step 83485: loss = 0.09100
Step 83490: loss = 0.22523
Step 83495: loss = 0.22930
Step 83500: loss = 0.11279
Step 83505: loss = 0.29944
Step 83510: loss = 0.25175
Step 83515: loss = 0.18103
Step 83520: loss = 0.32396
Step 83525: loss = 0.48141
Step 83530: loss = 0.27205
Step 83535: loss = 0.20151
Step 83540: loss = 0.15866
Step 83545: loss = 0.44359
Step 83550: loss = 0.24341
Step 83555: loss = 0.18813
Step 83560: loss = 0.32983
Step 83565: loss = 0.25098
Step 83570: loss = 0.13940
Step 83575: loss = 0.21496
Step 83580: loss = 0.37578
Step 83585: loss = 0.18821
Step 83590: loss = 0.27124
Step 83595: loss = 0.17230
Step 83600: loss = 0.08598
Step 83605: loss = 0.21044
Step 83610: loss = 0.16393
Step 83615: loss = 0.11675
Step 83620: loss = 0.23284
Step 83625: loss = 0.17954
Step 83630: loss = 0.40683
Step 83635: loss = 0.30105
Step 83640: loss = 0.26784
Step 83645: loss = 0.14819
Step 83650: loss = 0.35144
Step 83655: loss = 0.25819
Step 83660: loss = 0.07920
Step 83665: loss = 0.16148
Step 83670: loss = 0.21918
Step 83675: loss = 0.18388
Step 83680: loss = 0.11521
Step 83685: loss = 0.19974
Step 83690: loss = 0.34449
Step 83695: loss = 0.25402
Step 83700: loss = 0.43887
Step 83705: loss = 0.10686
Step 83710: loss = 0.48698
Step 83715: loss = 0.20200
Step 83720: loss = 0.27604
Step 83725: loss = 0.20685
Step 83730: loss = 0.19067
Step 83735: loss = 0.11968
Step 83740: loss = 0.16936
Step 83745: loss = 0.26537
Step 83750: loss = 0.09975
Step 83755: loss = 0.19751
Step 83760: loss = 0.12192
Step 83765: loss = 0.27911
Step 83770: loss = 0.13265
Step 83775: loss = 0.38568
Step 83780: loss = 0.28423
Step 83785: loss = 0.20695
Step 83790: loss = 0.10269
Step 83795: loss = 0.29127
Step 83800: loss = 0.37962
Step 83805: loss = 0.41977
Step 83810: loss = 0.14784
Step 83815: loss = 0.10499
Step 83820: loss = 0.17060
Step 83825: loss = 0.09667
Step 83830: loss = 0.32276
Step 83835: loss = 0.10905
Step 83840: loss = 0.22617
Step 83845: loss = 0.25517
Step 83850: loss = 0.08031
Step 83855: loss = 0.20127
Step 83860: loss = 0.13444
Step 83865: loss = 0.16625
Step 83870: loss = 0.23769
Step 83875: loss = 0.13284
Step 83880: loss = 0.14995
Step 83885: loss = 0.32109
Step 83890: loss = 0.35659
Step 83895: loss = 0.17013
Step 83900: loss = 0.09480
Step 83905: loss = 0.15907
Step 83910: loss = 0.41729
Step 83915: loss = 0.24842
Step 83920: loss = 0.17799
Step 83925: loss = 0.11419
Step 83930: loss = 0.10590
Step 83935: loss = 0.13904
Step 83940: loss = 0.25783
Step 83945: loss = 0.16235
Step 83950: loss = 0.12132
Step 83955: loss = 0.15461
Step 83960: loss = 0.40686
Step 83965: loss = 0.15144
Step 83970: loss = 0.16811
Step 83975: loss = 0.18610
Step 83980: loss = 0.30098
Step 83985: loss = 0.41632
Step 83990: loss = 0.27582
Step 83995: loss = 0.25252
Step 84000: loss = 0.45988
Training Data Eval:
  Num examples: 50000, Num correct: 46790, Precision @ 1: 0.9358
('Testing Data Eval: EPOCH->', 85)
  Num examples: 10000, Num correct: 6478, Precision @ 1: 0.6478
Step 84005: loss = 0.15855
Step 84010: loss = 0.21295
Step 84015: loss = 0.13593
Step 84020: loss = 0.30649
Step 84025: loss = 0.33743
Step 84030: loss = 0.03214
Step 84035: loss = 0.16784
Step 84040: loss = 0.09268
Step 84045: loss = 0.21924
Step 84050: loss = 0.25667
Step 84055: loss = 0.10915
Step 84060: loss = 0.24003
Step 84065: loss = 0.25752
Step 84070: loss = 0.22324
Step 84075: loss = 0.19452
Step 84080: loss = 0.42310
Step 84085: loss = 0.07611
Step 84090: loss = 0.32750
Step 84095: loss = 0.20342
Step 84100: loss = 0.18187
Step 84105: loss = 0.15026
Step 84110: loss = 0.26742
Step 84115: loss = 0.26901
Step 84120: loss = 0.19292
Step 84125: loss = 0.11797
Step 84130: loss = 0.14735
Step 84135: loss = 0.16148
Step 84140: loss = 0.21252
Step 84145: loss = 0.15304
Step 84150: loss = 0.50489
Step 84155: loss = 0.38388
Step 84160: loss = 0.17786
Step 84165: loss = 0.19218
Step 84170: loss = 0.42051
Step 84175: loss = 0.16846
Step 84180: loss = 0.25218
Step 84185: loss = 0.08600
Step 84190: loss = 0.10147
Step 84195: loss = 0.20576
Step 84200: loss = 0.11208
Step 84205: loss = 0.19618
Step 84210: loss = 0.10544
Step 84215: loss = 0.12562
Step 84220: loss = 0.26368
Step 84225: loss = 0.22916
Step 84230: loss = 0.21280
Step 84235: loss = 0.06523
Step 84240: loss = 0.24691
Step 84245: loss = 0.10184
Step 84250: loss = 0.33273
Step 84255: loss = 0.25602
Step 84260: loss = 0.14709
Step 84265: loss = 0.11181
Step 84270: loss = 0.12970
Step 84275: loss = 0.25481
Step 84280: loss = 0.31576
Step 84285: loss = 0.39163
Step 84290: loss = 0.43757
Step 84295: loss = 0.16227
Step 84300: loss = 0.09477
Step 84305: loss = 0.45534
Step 84310: loss = 0.20691
Step 84315: loss = 0.13429
Step 84320: loss = 0.45246
Step 84325: loss = 0.18352
Step 84330: loss = 0.15642
Step 84335: loss = 0.09017
Step 84340: loss = 0.11994
Step 84345: loss = 0.33113
Step 84350: loss = 0.43227
Step 84355: loss = 0.31114
Step 84360: loss = 0.22759
Step 84365: loss = 0.31721
Step 84370: loss = 0.17046
Step 84375: loss = 0.12309
Step 84380: loss = 0.28358
Step 84385: loss = 0.18708
Step 84390: loss = 0.16559
Step 84395: loss = 0.10482
Step 84400: loss = 0.19046
Step 84405: loss = 0.20398
Step 84410: loss = 0.28351
Step 84415: loss = 0.22515
Step 84420: loss = 0.08846
Step 84425: loss = 0.34256
Step 84430: loss = 0.16669
Step 84435: loss = 0.22819
Step 84440: loss = 0.17585
Step 84445: loss = 0.19427
Step 84450: loss = 0.33577
Step 84455: loss = 0.15515
Step 84460: loss = 0.36964
Step 84465: loss = 0.36441
Step 84470: loss = 0.17502
Step 84475: loss = 0.08130
Step 84480: loss = 0.28669
Step 84485: loss = 0.07030
Step 84490: loss = 0.09557
Step 84495: loss = 0.30069
Step 84500: loss = 0.16166
Step 84505: loss = 0.11561
Step 84510: loss = 0.29398
Step 84515: loss = 0.12652
Step 84520: loss = 0.10847
Step 84525: loss = 0.20263
Step 84530: loss = 0.22256
Step 84535: loss = 0.14973
Step 84540: loss = 0.27059
Step 84545: loss = 0.15717
Step 84550: loss = 0.16113
Step 84555: loss = 0.12437
Step 84560: loss = 0.21967
Step 84565: loss = 0.15939
Step 84570: loss = 0.26439
Step 84575: loss = 0.25668
Step 84580: loss = 0.22481
Step 84585: loss = 0.27473
Step 84590: loss = 0.11721
Step 84595: loss = 0.13531
Step 84600: loss = 0.13473
Step 84605: loss = 0.11843
Step 84610: loss = 0.18963
Step 84615: loss = 0.05506
Step 84620: loss = 0.11854
Step 84625: loss = 0.15325
Step 84630: loss = 0.16854
Step 84635: loss = 0.20284
Step 84640: loss = 0.19145
Step 84645: loss = 0.26042
Step 84650: loss = 0.09529
Step 84655: loss = 0.05493
Step 84660: loss = 0.10843
Step 84665: loss = 0.37939
Step 84670: loss = 0.12806
Step 84675: loss = 0.25459
Step 84680: loss = 0.23481
Step 84685: loss = 0.35242
Step 84690: loss = 0.22302
Step 84695: loss = 0.17488
Step 84700: loss = 0.39675
Step 84705: loss = 0.25474
Step 84710: loss = 0.38741
Step 84715: loss = 0.12357
Step 84720: loss = 0.20278
Step 84725: loss = 0.15242
Step 84730: loss = 0.09131
Step 84735: loss = 0.32566
Step 84740: loss = 0.12229
Step 84745: loss = 0.19690
Step 84750: loss = 0.43769
Step 84755: loss = 0.10366
Step 84760: loss = 0.18966
Step 84765: loss = 0.42207
Step 84770: loss = 0.16616
Step 84775: loss = 0.22892
Step 84780: loss = 0.15032
Step 84785: loss = 0.23639
Step 84790: loss = 0.34040
Step 84795: loss = 0.05766
Step 84800: loss = 0.23499
Step 84805: loss = 0.28114
Step 84810: loss = 0.19874
Step 84815: loss = 0.14992
Step 84820: loss = 0.29605
Step 84825: loss = 0.37430
Step 84830: loss = 0.13771
Step 84835: loss = 0.17191
Step 84840: loss = 0.57297
Step 84845: loss = 0.18160
Step 84850: loss = 0.07770
Step 84855: loss = 0.27536
Step 84860: loss = 0.07196
Step 84865: loss = 0.22470
Step 84870: loss = 0.11910
Step 84875: loss = 0.16573
Step 84880: loss = 0.11332
Step 84885: loss = 0.07591
Step 84890: loss = 0.20696
Step 84895: loss = 0.61069
Step 84900: loss = 0.21079
Step 84905: loss = 0.40889
Step 84910: loss = 0.13503
Step 84915: loss = 0.26261
Step 84920: loss = 0.18321
Step 84925: loss = 0.22493
Step 84930: loss = 0.16693
Step 84935: loss = 0.17620
Step 84940: loss = 0.13155
Step 84945: loss = 0.41444
Step 84950: loss = 0.27701
Step 84955: loss = 0.58549
Step 84960: loss = 0.26656
Step 84965: loss = 0.28731
Step 84970: loss = 0.34005
Step 84975: loss = 0.15446
Step 84980: loss = 0.15058
Step 84985: loss = 0.28516
Step 84990: loss = 0.30042
Step 84995: loss = 0.23687
Step 85000: loss = 0.36483
Training Data Eval:
  Num examples: 50000, Num correct: 46539, Precision @ 1: 0.9308
('Testing Data Eval: EPOCH->', 86)
  Num examples: 10000, Num correct: 6550, Precision @ 1: 0.6550
Step 85005: loss = 0.36935
Step 85010: loss = 0.25043
Step 85015: loss = 0.43909
Step 85020: loss = 0.12699
Step 85025: loss = 0.10812
Step 85030: loss = 0.27437
Step 85035: loss = 0.10238
Step 85040: loss = 0.11970
Step 85045: loss = 0.19996
Step 85050: loss = 0.09046
Step 85055: loss = 0.16593
Step 85060: loss = 0.13432
Step 85065: loss = 0.11412
Step 85070: loss = 0.18147
Step 85075: loss = 0.30691
Step 85080: loss = 0.14582
Step 85085: loss = 0.11564
Step 85090: loss = 0.13071
Step 85095: loss = 0.13348
Step 85100: loss = 0.46750
Step 85105: loss = 0.26283
Step 85110: loss = 0.27503
Step 85115: loss = 0.19044
Step 85120: loss = 0.15104
Step 85125: loss = 0.18511
Step 85130: loss = 0.14983
Step 85135: loss = 0.23860
Step 85140: loss = 0.13139
Step 85145: loss = 0.19870
Step 85150: loss = 0.37928
Step 85155: loss = 0.38588
Step 85160: loss = 0.11516
Step 85165: loss = 0.16262
Step 85170: loss = 0.20895
Step 85175: loss = 0.10073
Step 85180: loss = 0.13176
Step 85185: loss = 0.25710
Step 85190: loss = 0.35914
Step 85195: loss = 0.15649
Step 85200: loss = 0.24854
Step 85205: loss = 0.21435
Step 85210: loss = 0.33148
Step 85215: loss = 0.24702
Step 85220: loss = 0.16376
Step 85225: loss = 0.11944
Step 85230: loss = 0.30511
Step 85235: loss = 0.25588
Step 85240: loss = 0.13611
Step 85245: loss = 0.16242
Step 85250: loss = 0.27350
Step 85255: loss = 0.20975
Step 85260: loss = 0.13089
Step 85265: loss = 0.14876
Step 85270: loss = 0.29421
Step 85275: loss = 0.14223
Step 85280: loss = 0.08480
Step 85285: loss = 0.16334
Step 85290: loss = 0.18002
Step 85295: loss = 0.13404
Step 85300: loss = 0.09316
Step 85305: loss = 0.24619
Step 85310: loss = 0.14991
Step 85315: loss = 0.21598
Step 85320: loss = 0.18561
Step 85325: loss = 0.33141
Step 85330: loss = 0.09925
Step 85335: loss = 0.21838
Step 85340: loss = 0.43848
Step 85345: loss = 0.14078
Step 85350: loss = 0.15166
Step 85355: loss = 0.25047
Step 85360: loss = 0.04222
Step 85365: loss = 0.10916
Step 85370: loss = 0.21696
Step 85375: loss = 0.36072
Step 85380: loss = 0.15644
Step 85385: loss = 0.32415
Step 85390: loss = 0.33876
Step 85395: loss = 0.11739
Step 85400: loss = 0.17262
Step 85405: loss = 0.25772
Step 85410: loss = 0.18287
Step 85415: loss = 0.12330
Step 85420: loss = 0.12574
Step 85425: loss = 0.55998
Step 85430: loss = 0.08937
Step 85435: loss = 0.16073
Step 85440: loss = 0.13769
Step 85445: loss = 0.25683
Step 85450: loss = 0.04477
Step 85455: loss = 0.40644
Step 85460: loss = 0.13675
Step 85465: loss = 0.19066
Step 85470: loss = 0.08806
Step 85475: loss = 0.15058
Step 85480: loss = 0.18164
Step 85485: loss = 0.41085
Step 85490: loss = 0.28825
Step 85495: loss = 0.36239
Step 85500: loss = 0.18806
Step 85505: loss = 0.10581
Step 85510: loss = 0.15566
Step 85515: loss = 0.25000
Step 85520: loss = 0.28062
Step 85525: loss = 0.25968
Step 85530: loss = 0.38608
Step 85535: loss = 0.38695
Step 85540: loss = 0.09543
Step 85545: loss = 0.16108
Step 85550: loss = 0.20804
Step 85555: loss = 0.27909
Step 85560: loss = 0.14428
Step 85565: loss = 0.18734
Step 85570: loss = 0.48853
Step 85575: loss = 0.20090
Step 85580: loss = 0.26385
Step 85585: loss = 0.10362
Step 85590: loss = 0.45640
Step 85595: loss = 0.22136
Step 85600: loss = 0.24591
Step 85605: loss = 0.08108
Step 85610: loss = 0.22771
Step 85615: loss = 0.13890
Step 85620: loss = 0.25523
Step 85625: loss = 0.37209
Step 85630: loss = 0.11385
Step 85635: loss = 0.14907
Step 85640: loss = 0.21111
Step 85645: loss = 0.13550
Step 85650: loss = 0.12531
Step 85655: loss = 0.06152
Step 85660: loss = 0.19862
Step 85665: loss = 0.08311
Step 85670: loss = 0.31458
Step 85675: loss = 0.37462
Step 85680: loss = 0.09983
Step 85685: loss = 0.30254
Step 85690: loss = 0.17985
Step 85695: loss = 0.11153
Step 85700: loss = 0.15781
Step 85705: loss = 0.22007
Step 85710: loss = 0.14390
Step 85715: loss = 0.14135
Step 85720: loss = 0.33325
Step 85725: loss = 0.05712
Step 85730: loss = 0.28826
Step 85735: loss = 0.30194
Step 85740: loss = 0.43314
Step 85745: loss = 0.12083
Step 85750: loss = 0.04754
Step 85755: loss = 0.14932
Step 85760: loss = 0.21307
Step 85765: loss = 0.18007
Step 85770: loss = 0.17420
Step 85775: loss = 0.18780
Step 85780: loss = 0.17644
Step 85785: loss = 0.20262
Step 85790: loss = 0.22546
Step 85795: loss = 0.18712
Step 85800: loss = 0.11230
Step 85805: loss = 0.12833
Step 85810: loss = 0.33569
Step 85815: loss = 0.28291
Step 85820: loss = 0.09815
Step 85825: loss = 0.10765
Step 85830: loss = 0.38263
Step 85835: loss = 0.10420
Step 85840: loss = 0.13711
Step 85845: loss = 0.32189
Step 85850: loss = 0.17078
Step 85855: loss = 0.40387
Step 85860: loss = 0.36045
Step 85865: loss = 0.36038
Step 85870: loss = 0.23262
Step 85875: loss = 0.24303
Step 85880: loss = 0.07191
Step 85885: loss = 0.08351
Step 85890: loss = 0.21395
Step 85895: loss = 0.19646
Step 85900: loss = 0.23804
Step 85905: loss = 0.14146
Step 85910: loss = 0.15027
Step 85915: loss = 0.12510
Step 85920: loss = 0.08965
Step 85925: loss = 0.19385
Step 85930: loss = 0.19760
Step 85935: loss = 0.24141
Step 85940: loss = 0.05235
Step 85945: loss = 0.12329
Step 85950: loss = 0.14034
Step 85955: loss = 0.20060
Step 85960: loss = 0.23871
Step 85965: loss = 0.22625
Step 85970: loss = 0.15806
Step 85975: loss = 0.22307
Step 85980: loss = 0.24209
Step 85985: loss = 0.19814
Step 85990: loss = 0.20977
Step 85995: loss = 0.23203
Step 86000: loss = 0.09746
Training Data Eval:
  Num examples: 50000, Num correct: 46731, Precision @ 1: 0.9346
('Testing Data Eval: EPOCH->', 87)
  Num examples: 10000, Num correct: 6559, Precision @ 1: 0.6559
Step 86005: loss = 0.25522
Step 86010: loss = 0.03688
Step 86015: loss = 0.06089
Step 86020: loss = 0.07290
Step 86025: loss = 0.32829
Step 86030: loss = 0.11846
Step 86035: loss = 0.25973
Step 86040: loss = 0.20369
Step 86045: loss = 0.13760
Step 86050: loss = 0.10334
Step 86055: loss = 0.08524
Step 86060: loss = 0.12604
Step 86065: loss = 0.24244
Step 86070: loss = 0.18009
Step 86075: loss = 0.07107
Step 86080: loss = 0.16575
Step 86085: loss = 0.13413
Step 86090: loss = 0.31778
Step 86095: loss = 0.11953
Step 86100: loss = 0.07055
Step 86105: loss = 0.20041
Step 86110: loss = 0.13830
Step 86115: loss = 0.18762
Step 86120: loss = 0.12183
Step 86125: loss = 0.12686
Step 86130: loss = 0.27848
Step 86135: loss = 0.27749
Step 86140: loss = 0.35601
Step 86145: loss = 0.08284
Step 86150: loss = 0.12557
Step 86155: loss = 0.13182
Step 86160: loss = 0.15328
Step 86165: loss = 0.16421
Step 86170: loss = 0.22844
Step 86175: loss = 0.12580
Step 86180: loss = 0.34542
Step 86185: loss = 0.11197
Step 86190: loss = 0.18031
Step 86195: loss = 0.23379
Step 86200: loss = 0.32200
Step 86205: loss = 0.26999
Step 86210: loss = 0.10868
Step 86215: loss = 0.15151
Step 86220: loss = 0.15274
Step 86225: loss = 0.34168
Step 86230: loss = 0.10432
Step 86235: loss = 0.27967
Step 86240: loss = 0.17873
Step 86245: loss = 0.14309
Step 86250: loss = 0.46165
Step 86255: loss = 0.37148
Step 86260: loss = 0.53897
Step 86265: loss = 0.14039
Step 86270: loss = 0.34196
Step 86275: loss = 0.12106
Step 86280: loss = 0.21493
Step 86285: loss = 0.09330
Step 86290: loss = 0.14905
Step 86295: loss = 0.11303
Step 86300: loss = 0.22305
Step 86305: loss = 0.10627
Step 86310: loss = 0.12480
Step 86315: loss = 0.11867
Step 86320: loss = 0.20246
Step 86325: loss = 0.09816
Step 86330: loss = 0.21375
Step 86335: loss = 0.24293
Step 86340: loss = 0.14828
Step 86345: loss = 0.15420
Step 86350: loss = 0.10987
Step 86355: loss = 0.25155
Step 86360: loss = 0.09531
Step 86365: loss = 0.36267
Step 86370: loss = 0.14791
Step 86375: loss = 0.29721
Step 86380: loss = 0.03962
Step 86385: loss = 0.19663
Step 86390: loss = 0.28683
Step 86395: loss = 0.09350
Step 86400: loss = 0.14855
Step 86405: loss = 0.23980
Step 86410: loss = 0.40875
Step 86415: loss = 0.27309
Step 86420: loss = 0.23194
Step 86425: loss = 0.16786
Step 86430: loss = 0.35117
Step 86435: loss = 0.10938
Step 86440: loss = 0.20683
Step 86445: loss = 0.19914
Step 86450: loss = 0.22528
Step 86455: loss = 0.14402
Step 86460: loss = 0.15599
Step 86465: loss = 0.18172
Step 86470: loss = 0.13864
Step 86475: loss = 0.17878
Step 86480: loss = 0.35942
Step 86485: loss = 0.40617
Step 86490: loss = 0.28132
Step 86495: loss = 0.08258
Step 86500: loss = 0.14600
Step 86505: loss = 0.08580
Step 86510: loss = 0.19879
Step 86515: loss = 0.19586
Step 86520: loss = 0.16577
Step 86525: loss = 0.20171
Step 86530: loss = 0.12862
Step 86535: loss = 0.20773
Step 86540: loss = 0.19917
Step 86545: loss = 0.44143
Step 86550: loss = 0.29682
Step 86555: loss = 0.21854
Step 86560: loss = 0.39308
Step 86565: loss = 0.21621
Step 86570: loss = 0.17383
Step 86575: loss = 0.12185
Step 86580: loss = 0.22839
Step 86585: loss = 0.13724
Step 86590: loss = 0.10993
Step 86595: loss = 0.19784
Step 86600: loss = 0.38960
Step 86605: loss = 0.28267
Step 86610: loss = 0.30198
Step 86615: loss = 0.32333
Step 86620: loss = 0.15184
Step 86625: loss = 0.32417
Step 86630: loss = 0.07797
Step 86635: loss = 0.23820
Step 86640: loss = 0.17064
Step 86645: loss = 0.19507
Step 86650: loss = 0.10495
Step 86655: loss = 0.19851
Step 86660: loss = 0.15212
Step 86665: loss = 0.17444
Step 86670: loss = 0.26028
Step 86675: loss = 0.16958
Step 86680: loss = 0.10531
Step 86685: loss = 0.20433
Step 86690: loss = 0.20585
Step 86695: loss = 0.22322
Step 86700: loss = 0.22795
Step 86705: loss = 0.35993
Step 86710: loss = 0.09337
Step 86715: loss = 0.12728
Step 86720: loss = 0.25268
Step 86725: loss = 0.23201
Step 86730: loss = 0.30978
Step 86735: loss = 0.27483
Step 86740: loss = 0.16974
Step 86745: loss = 0.48348
Step 86750: loss = 0.22126
Step 86755: loss = 0.14473
Step 86760: loss = 0.13941
Step 86765: loss = 0.15740
Step 86770: loss = 0.14257
Step 86775: loss = 0.27722
Step 86780: loss = 0.11769
Step 86785: loss = 0.20469
Step 86790: loss = 0.36185
Step 86795: loss = 0.23249
Step 86800: loss = 0.23977
Step 86805: loss = 0.19257
Step 86810: loss = 0.16305
Step 86815: loss = 0.31800
Step 86820: loss = 0.26171
Step 86825: loss = 0.24352
Step 86830: loss = 0.26038
Step 86835: loss = 0.26126
Step 86840: loss = 0.15106
Step 86845: loss = 0.27724
Step 86850: loss = 0.29676
Step 86855: loss = 0.14756
Step 86860: loss = 0.18331
Step 86865: loss = 0.34002
Step 86870: loss = 0.14416
Step 86875: loss = 0.14980
Step 86880: loss = 0.07439
Step 86885: loss = 0.56564
Step 86890: loss = 0.38475
Step 86895: loss = 0.20025
Step 86900: loss = 0.13435
Step 86905: loss = 0.23469
Step 86910: loss = 0.13334
Step 86915: loss = 0.22571
Step 86920: loss = 0.15730
Step 86925: loss = 0.23237
Step 86930: loss = 0.11154
Step 86935: loss = 0.17504
Step 86940: loss = 0.14646
Step 86945: loss = 0.10475
Step 86950: loss = 0.19600
Step 86955: loss = 0.22978
Step 86960: loss = 0.11210
Step 86965: loss = 0.14992
Step 86970: loss = 0.21269
Step 86975: loss = 0.16508
Step 86980: loss = 0.16532
Step 86985: loss = 0.25474
Step 86990: loss = 0.27906
Step 86995: loss = 0.24928
Step 87000: loss = 0.14359
Training Data Eval:
  Num examples: 50000, Num correct: 46703, Precision @ 1: 0.9341
('Testing Data Eval: EPOCH->', 88)
  Num examples: 10000, Num correct: 6521, Precision @ 1: 0.6521
Step 87005: loss = 0.22886
Step 87010: loss = 0.15919
Step 87015: loss = 0.12109
Step 87020: loss = 0.21473
Step 87025: loss = 0.06366
Step 87030: loss = 0.11975
Step 87035: loss = 0.18622
Step 87040: loss = 0.32897
Step 87045: loss = 0.35351
Step 87050: loss = 0.13697
Step 87055: loss = 0.13258
Step 87060: loss = 0.06407
Step 87065: loss = 0.16300
Step 87070: loss = 0.13138
Step 87075: loss = 0.10641
Step 87080: loss = 0.15130
Step 87085: loss = 0.30900
Step 87090: loss = 0.12027
Step 87095: loss = 0.37853
Step 87100: loss = 0.30764
Step 87105: loss = 0.28378
Step 87110: loss = 0.14773
Step 87115: loss = 0.42611
Step 87120: loss = 0.06328
Step 87125: loss = 0.22925
Step 87130: loss = 0.28853
Step 87135: loss = 0.07508
Step 87140: loss = 0.15923
Step 87145: loss = 0.23686
Step 87150: loss = 0.10655
Step 87155: loss = 0.11630
Step 87160: loss = 0.12941
Step 87165: loss = 0.10266
Step 87170: loss = 0.23379
Step 87175: loss = 0.13256
Step 87180: loss = 0.05972
Step 87185: loss = 0.17940
Step 87190: loss = 0.38028
Step 87195: loss = 0.24175
Step 87200: loss = 0.14739
Step 87205: loss = 0.16418
Step 87210: loss = 0.30475
Step 87215: loss = 0.13447
Step 87220: loss = 0.24043
Step 87225: loss = 0.21175
Step 87230: loss = 0.13115
Step 87235: loss = 0.21556
Step 87240: loss = 0.28033
Step 87245: loss = 0.15653
Step 87250: loss = 0.19645
Step 87255: loss = 0.11028
Step 87260: loss = 0.13138
Step 87265: loss = 0.20576
Step 87270: loss = 0.11911
Step 87275: loss = 0.18762
Step 87280: loss = 0.29196
Step 87285: loss = 0.07934
Step 87290: loss = 0.44337
Step 87295: loss = 0.04590
Step 87300: loss = 0.18131
Step 87305: loss = 0.40994
Step 87310: loss = 0.31553
Step 87315: loss = 0.12282
Step 87320: loss = 0.13460
Step 87325: loss = 0.13385
Step 87330: loss = 0.18130
Step 87335: loss = 0.17974
Step 87340: loss = 0.07018
Step 87345: loss = 0.21041
Step 87350: loss = 0.17758
Step 87355: loss = 0.23973
Step 87360: loss = 0.09225
Step 87365: loss = 0.28453
Step 87370: loss = 0.12854
Step 87375: loss = 0.41112
Step 87380: loss = 0.45307
Step 87385: loss = 0.18087
Step 87390: loss = 0.31211
Step 87395: loss = 0.19228
Step 87400: loss = 0.22869
Step 87405: loss = 0.15255
Step 87410: loss = 0.16107
Step 87415: loss = 0.15305
Step 87420: loss = 0.55369
Step 87425: loss = 0.19462
Step 87430: loss = 0.28622
Step 87435: loss = 0.16238
Step 87440: loss = 0.23537
Step 87445: loss = 0.06121
Step 87450: loss = 0.31035
Step 87455: loss = 0.19659
Step 87460: loss = 0.08014
Step 87465: loss = 0.07940
Step 87470: loss = 0.09703
Step 87475: loss = 0.25766
Step 87480: loss = 0.28099
Step 87485: loss = 0.13878
Step 87490: loss = 0.19387
Step 87495: loss = 0.09637
Step 87500: loss = 0.22671
Step 87505: loss = 0.12392
Step 87510: loss = 0.31343
Step 87515: loss = 0.16997
Step 87520: loss = 0.19347
Step 87525: loss = 0.26904
Step 87530: loss = 0.11313
Step 87535: loss = 0.13608
Step 87540: loss = 0.09745
Step 87545: loss = 0.23481
Step 87550: loss = 0.16882
Step 87555: loss = 0.41816
Step 87560: loss = 0.12534
Step 87565: loss = 0.11064
Step 87570: loss = 0.09669
Step 87575: loss = 0.25157
Step 87580: loss = 0.41828
Step 87585: loss = 0.16136
Step 87590: loss = 0.33794
Step 87595: loss = 0.21386
Step 87600: loss = 0.08901
Step 87605: loss = 0.18305
Step 87610: loss = 0.13705
Step 87615: loss = 0.09929
Step 87620: loss = 0.08299
Step 87625: loss = 0.37618
Step 87630: loss = 0.16631
Step 87635: loss = 0.19555
Step 87640: loss = 0.23216
Step 87645: loss = 0.08499
Step 87650: loss = 0.25558
Step 87655: loss = 0.18154
Step 87660: loss = 0.10823
Step 87665: loss = 0.06257
Step 87670: loss = 0.25852
Step 87675: loss = 0.24292
Step 87680: loss = 0.15703
Step 87685: loss = 0.17715
Step 87690: loss = 0.08765
Step 87695: loss = 0.15495
Step 87700: loss = 0.11236
Step 87705: loss = 0.14848
Step 87710: loss = 0.24328
Step 87715: loss = 0.16128
Step 87720: loss = 0.70914
Step 87725: loss = 0.15606
Step 87730: loss = 0.18817
Step 87735: loss = 0.06248
Step 87740: loss = 0.11718
Step 87745: loss = 0.14919
Step 87750: loss = 0.29522
Step 87755: loss = 0.13136
Step 87760: loss = 0.10143
Step 87765: loss = 0.21790
Step 87770: loss = 0.20138
Step 87775: loss = 0.08580
Step 87780: loss = 0.14742
Step 87785: loss = 0.15132
Step 87790: loss = 0.15749
Step 87795: loss = 0.43190
Step 87800: loss = 0.12092
Step 87805: loss = 0.25340
Step 87810: loss = 0.19092
Step 87815: loss = 0.22302
Step 87820: loss = 0.20438
Step 87825: loss = 0.17681
Step 87830: loss = 0.14282
Step 87835: loss = 0.22675
Step 87840: loss = 0.19025
Step 87845: loss = 0.19822
Step 87850: loss = 0.21940
Step 87855: loss = 0.32684
Step 87860: loss = 0.15988
Step 87865: loss = 0.19403
Step 87870: loss = 0.24871
Step 87875: loss = 0.23627
Step 87880: loss = 0.10092
Step 87885: loss = 0.18495
Step 87890: loss = 0.16490
Step 87895: loss = 0.15690
Step 87900: loss = 0.18015
Step 87905: loss = 0.28217
Step 87910: loss = 0.23264
Step 87915: loss = 0.12737
Step 87920: loss = 0.19431
Step 87925: loss = 0.29166
Step 87930: loss = 0.46702
Step 87935: loss = 0.10663
Step 87940: loss = 0.43921
Step 87945: loss = 0.08047
Step 87950: loss = 0.24015
Step 87955: loss = 0.39505
Step 87960: loss = 0.16094
Step 87965: loss = 0.15874
Step 87970: loss = 0.24688
Step 87975: loss = 0.12145
Step 87980: loss = 0.22378
Step 87985: loss = 0.18125
Step 87990: loss = 0.29203
Step 87995: loss = 0.14949
Step 88000: loss = 0.12115
Training Data Eval:
  Num examples: 50000, Num correct: 46861, Precision @ 1: 0.9372
('Testing Data Eval: EPOCH->', 89)
  Num examples: 10000, Num correct: 6670, Precision @ 1: 0.6670
Step 88005: loss = 0.10383
Step 88010: loss = 0.60845
Step 88015: loss = 0.10776
Step 88020: loss = 0.14239
Step 88025: loss = 0.33794
Step 88030: loss = 0.19260
Step 88035: loss = 0.09971
Step 88040: loss = 0.20785
Step 88045: loss = 0.20614
Step 88050: loss = 0.24134
Step 88055: loss = 0.19015
Step 88060: loss = 0.26057
Step 88065: loss = 0.07240
Step 88070: loss = 0.28123
Step 88075: loss = 0.09810
Step 88080: loss = 0.19699
Step 88085: loss = 0.16683
Step 88090: loss = 0.27740
Step 88095: loss = 0.44862
Step 88100: loss = 0.19568
Step 88105: loss = 0.04769
Step 88110: loss = 0.27221
Step 88115: loss = 0.20059
Step 88120: loss = 0.43288
Step 88125: loss = 0.09365
Step 88130: loss = 0.12753
Step 88135: loss = 0.31444
Step 88140: loss = 0.27430
Step 88145: loss = 0.23280
Step 88150: loss = 0.24000
Step 88155: loss = 0.15534
Step 88160: loss = 0.22840
Step 88165: loss = 0.09056
Step 88170: loss = 0.19911
Step 88175: loss = 0.13769
Step 88180: loss = 0.25717
Step 88185: loss = 0.18026
Step 88190: loss = 0.14844
Step 88195: loss = 0.16306
Step 88200: loss = 0.08194
Step 88205: loss = 0.08410
Step 88210: loss = 0.24142
Step 88215: loss = 0.10288
Step 88220: loss = 0.09989
Step 88225: loss = 0.36112
Step 88230: loss = 0.07694
Step 88235: loss = 0.07101
Step 88240: loss = 0.17486
Step 88245: loss = 0.30711
Step 88250: loss = 0.24892
Step 88255: loss = 0.28357
Step 88260: loss = 0.43142
Step 88265: loss = 0.16599
Step 88270: loss = 0.14993
Step 88275: loss = 0.15484
Step 88280: loss = 0.18993
Step 88285: loss = 0.07830
Step 88290: loss = 0.41120
Step 88295: loss = 0.16434
Step 88300: loss = 0.14096
Step 88305: loss = 0.11260
Step 88310: loss = 0.11443
Step 88315: loss = 0.36202
Step 88320: loss = 0.14632
Step 88325: loss = 0.26160
Step 88330: loss = 0.33931
Step 88335: loss = 0.14255
Step 88340: loss = 0.35794
Step 88345: loss = 0.08055
Step 88350: loss = 0.10366
Step 88355: loss = 0.29481
Step 88360: loss = 0.31558
Step 88365: loss = 0.20300
Step 88370: loss = 0.11886
Step 88375: loss = 0.17602
Step 88380: loss = 0.16400
Step 88385: loss = 0.15769
Step 88390: loss = 0.10900
Step 88395: loss = 0.13391
Step 88400: loss = 0.24652
Step 88405: loss = 0.13159
Step 88410: loss = 0.21863
Step 88415: loss = 0.07775
Step 88420: loss = 0.10800
Step 88425: loss = 0.21888
Step 88430: loss = 0.28853
Step 88435: loss = 0.12197
Step 88440: loss = 0.04996
Step 88445: loss = 0.08741
Step 88450: loss = 0.33932
Step 88455: loss = 0.26563
Step 88460: loss = 0.10126
Step 88465: loss = 0.09571
Step 88470: loss = 0.18012
Step 88475: loss = 0.12995
Step 88480: loss = 0.16468
Step 88485: loss = 0.26213
Step 88490: loss = 0.21392
Step 88495: loss = 0.08950
Step 88500: loss = 0.39444
Step 88505: loss = 0.21043
Step 88510: loss = 0.31265
Step 88515: loss = 0.15337
Step 88520: loss = 0.32816
Step 88525: loss = 0.37069
Step 88530: loss = 0.16854
Step 88535: loss = 0.22424
Step 88540: loss = 0.32606
Step 88545: loss = 0.10879
Step 88550: loss = 0.19874
Step 88555: loss = 0.13775
Step 88560: loss = 0.06403
Step 88565: loss = 0.18325
Step 88570: loss = 0.11270
Step 88575: loss = 0.12587
Step 88580: loss = 0.16087
Step 88585: loss = 0.27166
Step 88590: loss = 0.20704
Step 88595: loss = 0.21960
Step 88600: loss = 0.24501
Step 88605: loss = 0.40848
Step 88610: loss = 0.25452
Step 88615: loss = 0.10556
Step 88620: loss = 0.36986
Step 88625: loss = 0.10859
Step 88630: loss = 0.14047
Step 88635: loss = 0.22635
Step 88640: loss = 0.16327
Step 88645: loss = 0.24867
Step 88650: loss = 0.21263
Step 88655: loss = 0.02897
Step 88660: loss = 0.42815
Step 88665: loss = 0.19921
Step 88670: loss = 0.14413
Step 88675: loss = 0.08475
Step 88680: loss = 0.14697
Step 88685: loss = 0.09148
Step 88690: loss = 0.16758
Step 88695: loss = 0.21872
Step 88700: loss = 0.19054
Step 88705: loss = 0.09237
Step 88710: loss = 0.08740
Step 88715: loss = 0.08914
Step 88720: loss = 0.46265
Step 88725: loss = 0.09459
Step 88730: loss = 0.13577
Step 88735: loss = 0.31094
Step 88740: loss = 0.07686
Step 88745: loss = 0.22910
Step 88750: loss = 0.16340
Step 88755: loss = 0.12661
Step 88760: loss = 0.17270
Step 88765: loss = 0.23649
Step 88770: loss = 0.16102
Step 88775: loss = 0.11373
Step 88780: loss = 0.11716
Step 88785: loss = 0.19725
Step 88790: loss = 0.06405
Step 88795: loss = 0.07538
Step 88800: loss = 0.15841
Step 88805: loss = 0.12503
Step 88810: loss = 0.22292
Step 88815: loss = 0.11425
Step 88820: loss = 0.20798
Step 88825: loss = 0.34739
Step 88830: loss = 0.13919
Step 88835: loss = 0.16522
Step 88840: loss = 0.12928
Step 88845: loss = 0.24722
Step 88850: loss = 0.15035
Step 88855: loss = 0.27277
Step 88860: loss = 0.24083
Step 88865: loss = 0.06043
Step 88870: loss = 0.20176
Step 88875: loss = 0.60770
Step 88880: loss = 0.11675
Step 88885: loss = 0.24875
Step 88890: loss = 0.41208
Step 88895: loss = 0.39978
Step 88900: loss = 0.38142
Step 88905: loss = 0.29094
Step 88910: loss = 0.37387
Step 88915: loss = 0.22619
Step 88920: loss = 0.16153
Step 88925: loss = 0.18547
Step 88930: loss = 0.13966
Step 88935: loss = 0.10792
Step 88940: loss = 0.27049
Step 88945: loss = 0.23325
Step 88950: loss = 0.13989
Step 88955: loss = 0.15492
Step 88960: loss = 0.39947
Step 88965: loss = 0.08422
Step 88970: loss = 0.16546
Step 88975: loss = 0.24178
Step 88980: loss = 0.22442
Step 88985: loss = 0.08546
Step 88990: loss = 0.22140
Step 88995: loss = 0.18977
Step 89000: loss = 0.18919
Training Data Eval:
  Num examples: 50000, Num correct: 46859, Precision @ 1: 0.9372
('Testing Data Eval: EPOCH->', 90)
  Num examples: 10000, Num correct: 6380, Precision @ 1: 0.6380
Step 89005: loss = 0.09964
Step 89010: loss = 0.08185
Step 89015: loss = 0.27649
Step 89020: loss = 0.15916
Step 89025: loss = 0.14201
Step 89030: loss = 0.36158
Step 89035: loss = 0.28086
Step 89040: loss = 0.16206
Step 89045: loss = 0.13873
Step 89050: loss = 0.18173
Step 89055: loss = 0.11090
Step 89060: loss = 0.17410
Step 89065: loss = 0.18648
Step 89070: loss = 0.17212
Step 89075: loss = 0.14754
Step 89080: loss = 0.20229
Step 89085: loss = 0.16978
Step 89090: loss = 0.18276
Step 89095: loss = 0.52116
Step 89100: loss = 0.35258
Step 89105: loss = 0.12919
Step 89110: loss = 0.17468
Step 89115: loss = 0.37131
Step 89120: loss = 0.15394
Step 89125: loss = 0.14680
Step 89130: loss = 0.14303
Step 89135: loss = 0.34673
Step 89140: loss = 0.26824
Step 89145: loss = 0.21337
Step 89150: loss = 0.18333
Step 89155: loss = 0.18503
Step 89160: loss = 0.12366
Step 89165: loss = 0.15734
Step 89170: loss = 0.19321
Step 89175: loss = 0.32563
Step 89180: loss = 0.21845
Step 89185: loss = 0.20520
Step 89190: loss = 0.21510
Step 89195: loss = 0.07862
Step 89200: loss = 0.14491
Step 89205: loss = 0.34102
Step 89210: loss = 0.06887
Step 89215: loss = 0.07517
Step 89220: loss = 0.25214
Step 89225: loss = 0.12729
Step 89230: loss = 0.16050
Step 89235: loss = 0.13084
Step 89240: loss = 0.13668
Step 89245: loss = 0.28188
Step 89250: loss = 0.26543
Step 89255: loss = 0.17944
Step 89260: loss = 0.21806
Step 89265: loss = 0.17489
Step 89270: loss = 0.23109
Step 89275: loss = 0.26899
Step 89280: loss = 0.27381
Step 89285: loss = 0.13302
Step 89290: loss = 0.15054
Step 89295: loss = 0.17595
Step 89300: loss = 0.23640
Step 89305: loss = 0.33865
Step 89310: loss = 0.11510
Step 89315: loss = 0.11545
Step 89320: loss = 0.25107
Step 89325: loss = 0.10797
Step 89330: loss = 0.03912
Step 89335: loss = 0.16505
Step 89340: loss = 0.26331
Step 89345: loss = 0.12897
Step 89350: loss = 0.17184
Step 89355: loss = 0.18812
Step 89360: loss = 0.12555
Step 89365: loss = 0.06147
Step 89370: loss = 0.15765
Step 89375: loss = 0.11912
Step 89380: loss = 0.24152
Step 89385: loss = 0.26786
Step 89390: loss = 0.16151
Step 89395: loss = 0.13068
Step 89400: loss = 0.24355
Step 89405: loss = 0.15608
Step 89410: loss = 0.31803
Step 89415: loss = 0.34558
Step 89420: loss = 0.32807
Step 89425: loss = 0.17830
Step 89430: loss = 0.48764
Step 89435: loss = 0.24688
Step 89440: loss = 0.20891
Step 89445: loss = 0.19295
Step 89450: loss = 0.07897
Step 89455: loss = 0.16463
Step 89460: loss = 0.33214
Step 89465: loss = 0.21070
Step 89470: loss = 0.15823
Step 89475: loss = 0.31795
Step 89480: loss = 0.19860
Step 89485: loss = 0.28515
Step 89490: loss = 0.10707
Step 89495: loss = 0.14989
Step 89500: loss = 0.24161
Step 89505: loss = 0.31516
Step 89510: loss = 0.21240
Step 89515: loss = 0.16118
Step 89520: loss = 0.15845
Step 89525: loss = 0.22184
Step 89530: loss = 0.15442
Step 89535: loss = 0.09406
Step 89540: loss = 0.15659
Step 89545: loss = 0.28557
Step 89550: loss = 0.28147
Step 89555: loss = 0.08620
Step 89560: loss = 0.11547
Step 89565: loss = 0.10663
Step 89570: loss = 0.20927
Step 89575: loss = 0.13605
Step 89580: loss = 0.20709
Step 89585: loss = 0.20516
Step 89590: loss = 0.10480
Step 89595: loss = 0.11297
Step 89600: loss = 0.16061
Step 89605: loss = 0.16309
Step 89610: loss = 0.08825
Step 89615: loss = 0.10872
Step 89620: loss = 0.08158
Step 89625: loss = 0.14979
Step 89630: loss = 0.08848
Step 89635: loss = 0.22883
Step 89640: loss = 0.14816
Step 89645: loss = 0.30517
Step 89650: loss = 0.24998
Step 89655: loss = 0.14173
Step 89660: loss = 0.23909
Step 89665: loss = 0.15715
Step 89670: loss = 0.34020
Step 89675: loss = 0.21650
Step 89680: loss = 0.11523
Step 89685: loss = 0.16066
Step 89690: loss = 0.18755
Step 89695: loss = 0.11292
Step 89700: loss = 0.06917
Step 89705: loss = 0.23481
Step 89710: loss = 0.32970
Step 89715: loss = 0.19998
Step 89720: loss = 0.31140
Step 89725: loss = 0.09051
Step 89730: loss = 0.17789
Step 89735: loss = 0.24773
Step 89740: loss = 0.33424
Step 89745: loss = 0.17396
Step 89750: loss = 0.26682
Step 89755: loss = 0.32120
Step 89760: loss = 0.11369
Step 89765: loss = 0.28558
Step 89770: loss = 0.31423
Step 89775: loss = 0.26852
Step 89780: loss = 0.23560
Step 89785: loss = 0.19805
Step 89790: loss = 0.42065
Step 89795: loss = 0.19417
Step 89800: loss = 0.12958
Step 89805: loss = 0.07706
Step 89810: loss = 0.13966
Step 89815: loss = 0.17747
Step 89820: loss = 0.11623
Step 89825: loss = 0.07494
Step 89830: loss = 0.14845
Step 89835: loss = 0.05401
Step 89840: loss = 0.27409
Step 89845: loss = 0.10385
Step 89850: loss = 0.27192
Step 89855: loss = 0.13461
Step 89860: loss = 0.10381
Step 89865: loss = 0.07718
Step 89870: loss = 0.28782
Step 89875: loss = 0.14616
Step 89880: loss = 0.13146
Step 89885: loss = 0.25053
Step 89890: loss = 0.20927
Step 89895: loss = 0.31333
Step 89900: loss = 0.18976
Step 89905: loss = 0.28455
Step 89910: loss = 0.25973
Step 89915: loss = 0.13261
Step 89920: loss = 0.31205
Step 89925: loss = 0.15356
Step 89930: loss = 0.43289
Step 89935: loss = 0.14115
Step 89940: loss = 0.18199
Step 89945: loss = 0.04400
Step 89950: loss = 0.11308
Step 89955: loss = 0.15956
Step 89960: loss = 0.34739
Step 89965: loss = 0.20328
Step 89970: loss = 0.10978
Step 89975: loss = 0.07945
Step 89980: loss = 0.08785
Step 89985: loss = 0.14852
Step 89990: loss = 0.31264
Step 89995: loss = 0.13261
Step 90000: loss = 0.09851
Training Data Eval:
  Num examples: 50000, Num correct: 47164, Precision @ 1: 0.9433
('Testing Data Eval: EPOCH->', 91)
  Num examples: 10000, Num correct: 6533, Precision @ 1: 0.6533
Step 90005: loss = 0.37649
Step 90010: loss = 0.09689
Step 90015: loss = 0.33174
Step 90020: loss = 0.19064
Step 90025: loss = 0.27817
Step 90030: loss = 0.14331
Step 90035: loss = 0.49316
Step 90040: loss = 0.17012
Step 90045: loss = 0.34695
Step 90050: loss = 0.25882
Step 90055: loss = 0.17357
Step 90060: loss = 0.13045
Step 90065: loss = 0.10274
Step 90070: loss = 0.16404
Step 90075: loss = 0.13950
Step 90080: loss = 0.07573
Step 90085: loss = 0.07848
Step 90090: loss = 0.33165
Step 90095: loss = 0.26206
Step 90100: loss = 0.16756
Step 90105: loss = 0.13848
Step 90110: loss = 0.06661
Step 90115: loss = 0.16157
Step 90120: loss = 0.23254
Step 90125: loss = 0.24173
Step 90130: loss = 0.06297
Step 90135: loss = 0.23643
Step 90140: loss = 0.09808
Step 90145: loss = 0.16615
Step 90150: loss = 0.11848
Step 90155: loss = 0.23847
Step 90160: loss = 0.20908
Step 90165: loss = 0.16388
Step 90170: loss = 0.19652
Step 90175: loss = 0.08943
Step 90180: loss = 0.25896
Step 90185: loss = 0.11855
Step 90190: loss = 0.11016
Step 90195: loss = 0.17407
Step 90200: loss = 0.12061
Step 90205: loss = 0.08608
Step 90210: loss = 0.23430
Step 90215: loss = 0.31670
Step 90220: loss = 0.18739
Step 90225: loss = 0.16262
Step 90230: loss = 0.38137
Step 90235: loss = 0.12469
Step 90240: loss = 0.03274
Step 90245: loss = 0.10522
Step 90250: loss = 0.19005
Step 90255: loss = 0.36393
Step 90260: loss = 0.18796
Step 90265: loss = 0.08442
Step 90270: loss = 0.04788
Step 90275: loss = 0.22531
Step 90280: loss = 0.20506
Step 90285: loss = 0.23193
Step 90290: loss = 0.20879
Step 90295: loss = 0.13962
Step 90300: loss = 0.09676
Step 90305: loss = 0.19817
Step 90310: loss = 0.16244
Step 90315: loss = 0.11250
Step 90320: loss = 0.23682
Step 90325: loss = 0.16327
Step 90330: loss = 0.31523
Step 90335: loss = 0.17325
Step 90340: loss = 0.14277
Step 90345: loss = 0.25448
Step 90350: loss = 0.12612
Step 90355: loss = 0.16544
Step 90360: loss = 0.31248
Step 90365: loss = 0.34451
Step 90370: loss = 0.15947
Step 90375: loss = 0.17870
Step 90380: loss = 0.15834
Step 90385: loss = 0.13088
Step 90390: loss = 0.12085
Step 90395: loss = 0.29060
Step 90400: loss = 0.29682
Step 90405: loss = 0.19957
Step 90410: loss = 0.07369
Step 90415: loss = 0.17924
Step 90420: loss = 0.22893
Step 90425: loss = 0.30415
Step 90430: loss = 0.13316
Step 90435: loss = 0.12189
Step 90440: loss = 0.11521
Step 90445: loss = 0.26150
Step 90450: loss = 0.25502
Step 90455: loss = 0.16137
Step 90460: loss = 0.15707
Step 90465: loss = 0.39962
Step 90470: loss = 0.15121
Step 90475: loss = 0.08633
Step 90480: loss = 0.12548
Step 90485: loss = 0.12967
Step 90490: loss = 0.20114
Step 90495: loss = 0.03758
Step 90500: loss = 0.15912
Step 90505: loss = 0.26360
Step 90510: loss = 0.17076
Step 90515: loss = 0.09772
Step 90520: loss = 0.23732
Step 90525: loss = 0.10625
Step 90530: loss = 0.21839
Step 90535: loss = 0.24336
Step 90540: loss = 0.19169
Step 90545: loss = 0.22771
Step 90550: loss = 0.19275
Step 90555: loss = 0.28030
Step 90560: loss = 0.23947
Step 90565: loss = 0.23233
Step 90570: loss = 0.14751
Step 90575: loss = 0.22523
Step 90580: loss = 0.22623
Step 90585: loss = 0.24153
Step 90590: loss = 0.15227
Step 90595: loss = 0.10566
Step 90600: loss = 0.14053
Step 90605: loss = 0.25253
Step 90610: loss = 0.21805
Step 90615: loss = 0.12399
Step 90620: loss = 0.26150
Step 90625: loss = 0.09081
Step 90630: loss = 0.24706
Step 90635: loss = 0.13686
Step 90640: loss = 0.21727
Step 90645: loss = 0.25640
Step 90650: loss = 0.19711
Step 90655: loss = 0.24693
Step 90660: loss = 0.20476
Step 90665: loss = 0.12380
Step 90670: loss = 0.15194
Step 90675: loss = 0.17286
Step 90680: loss = 0.09676
Step 90685: loss = 0.12170
Step 90690: loss = 0.20129
Step 90695: loss = 0.16474
Step 90700: loss = 0.22425
Step 90705: loss = 0.15634
Step 90710: loss = 0.19530
Step 90715: loss = 0.10282
Step 90720: loss = 0.20943
Step 90725: loss = 0.21566
Step 90730: loss = 0.32316
Step 90735: loss = 0.10078
Step 90740: loss = 0.20805
Step 90745: loss = 0.19747
Step 90750: loss = 0.18964
Step 90755: loss = 0.26596
Step 90760: loss = 0.27382
Step 90765: loss = 0.26580
Step 90770: loss = 0.17493
Step 90775: loss = 0.14838
Step 90780: loss = 0.23340
Step 90785: loss = 0.20610
Step 90790: loss = 0.22169
Step 90795: loss = 0.15836
Step 90800: loss = 0.14717
Step 90805: loss = 0.19997
Step 90810: loss = 0.20357
Step 90815: loss = 0.07198
Step 90820: loss = 0.11966
Step 90825: loss = 0.42738
Step 90830: loss = 0.15256
Step 90835: loss = 0.10341
Step 90840: loss = 0.08584
Step 90845: loss = 0.17378
Step 90850: loss = 0.18521
Step 90855: loss = 0.24820
Step 90860: loss = 0.13490
Step 90865: loss = 0.14006
Step 90870: loss = 0.04994
Step 90875: loss = 0.12898
Step 90880: loss = 0.11178
Step 90885: loss = 0.08753
Step 90890: loss = 0.06801
Step 90895: loss = 0.14317
Step 90900: loss = 0.13097
Step 90905: loss = 0.17469
Step 90910: loss = 0.27966
Step 90915: loss = 0.14236
Step 90920: loss = 0.29470
Step 90925: loss = 0.43724
Step 90930: loss = 0.17384
Step 90935: loss = 0.07687
Step 90940: loss = 0.08286
Step 90945: loss = 0.12582
Step 90950: loss = 0.13051
Step 90955: loss = 0.26713
Step 90960: loss = 0.08667
Step 90965: loss = 0.23724
Step 90970: loss = 0.07788
Step 90975: loss = 0.17592
Step 90980: loss = 0.15590
Step 90985: loss = 0.07727
Step 90990: loss = 0.10139
Step 90995: loss = 0.06104
Step 91000: loss = 0.32964
Training Data Eval:
  Num examples: 50000, Num correct: 47229, Precision @ 1: 0.9446
('Testing Data Eval: EPOCH->', 92)
  Num examples: 10000, Num correct: 6646, Precision @ 1: 0.6646
Step 91005: loss = 0.09152
Step 91010: loss = 0.20384
Step 91015: loss = 0.05764
Step 91020: loss = 0.21985
Step 91025: loss = 0.13651
Step 91030: loss = 0.15505
Step 91035: loss = 0.09533
Step 91040: loss = 0.17187
Step 91045: loss = 0.08637
Step 91050: loss = 0.15680
Step 91055: loss = 0.08932
Step 91060: loss = 0.11345
Step 91065: loss = 0.09066
Step 91070: loss = 0.17529
Step 91075: loss = 0.12743
Step 91080: loss = 0.26867
Step 91085: loss = 0.29413
Step 91090: loss = 0.24365
Step 91095: loss = 0.19944
Step 91100: loss = 0.10329
Step 91105: loss = 0.18685
Step 91110: loss = 0.12041
Step 91115: loss = 0.22651
Step 91120: loss = 0.16171
Step 91125: loss = 0.16529
Step 91130: loss = 0.08717
Step 91135: loss = 0.11793
Step 91140: loss = 0.13177
Step 91145: loss = 0.08541
Step 91150: loss = 0.19153
Step 91155: loss = 0.12685
Step 91160: loss = 0.08293
Step 91165: loss = 0.15758
Step 91170: loss = 0.16715
Step 91175: loss = 0.16107
Step 91180: loss = 0.12052
Step 91185: loss = 0.22187
Step 91190: loss = 0.04541
Step 91195: loss = 0.13816
Step 91200: loss = 0.13171
Step 91205: loss = 0.28958
Step 91210: loss = 0.13725
Step 91215: loss = 0.36569
Step 91220: loss = 0.10032
Step 91225: loss = 0.12469
Step 91230: loss = 0.13965
Step 91235: loss = 0.20465
Step 91240: loss = 0.17480
Step 91245: loss = 0.33819
Step 91250: loss = 0.08770
Step 91255: loss = 0.16328
Step 91260: loss = 0.20243
Step 91265: loss = 0.21799
Step 91270: loss = 0.37300
Step 91275: loss = 0.22771
Step 91280: loss = 0.20492
Step 91285: loss = 0.11581
Step 91290: loss = 0.26661
Step 91295: loss = 0.32118
Step 91300: loss = 0.06672
Step 91305: loss = 0.28973
Step 91310: loss = 0.10776
Step 91315: loss = 0.12297
Step 91320: loss = 0.17459
Step 91325: loss = 0.11305
Step 91330: loss = 0.20678
Step 91335: loss = 0.10970
Step 91340: loss = 0.15319
Step 91345: loss = 0.18094
Step 91350: loss = 0.39485
Step 91355: loss = 0.41458
Step 91360: loss = 0.17362
Step 91365: loss = 0.12287
Step 91370: loss = 0.18317
Step 91375: loss = 0.08867
Step 91380: loss = 0.35804
Step 91385: loss = 0.20249
Step 91390: loss = 0.30295
Step 91395: loss = 0.26748
Step 91400: loss = 0.08670
Step 91405: loss = 0.17843
Step 91410: loss = 0.20023
Step 91415: loss = 0.29511
Step 91420: loss = 0.20067
Step 91425: loss = 0.26712
Step 91430: loss = 0.14102
Step 91435: loss = 0.32672
Step 91440: loss = 0.04712
Step 91445: loss = 0.19072
Step 91450: loss = 0.08545
Step 91455: loss = 0.09964
Step 91460: loss = 0.38193
Step 91465: loss = 0.06682
Step 91470: loss = 0.12738
Step 91475: loss = 0.11665
Step 91480: loss = 0.06387
Step 91485: loss = 0.16438
Step 91490: loss = 0.14663
Step 91495: loss = 0.04655
Step 91500: loss = 0.18899
Step 91505: loss = 0.10508
Step 91510: loss = 0.29411
Step 91515: loss = 0.11230
Step 91520: loss = 0.06901
Step 91525: loss = 0.18582
Step 91530: loss = 0.29374
Step 91535: loss = 0.10137
Step 91540: loss = 0.18360
Step 91545: loss = 0.14184
Step 91550: loss = 0.28244
Step 91555: loss = 0.08584
Step 91560: loss = 0.25661
Step 91565: loss = 0.29020
Step 91570: loss = 0.06475
Step 91575: loss = 0.08823
Step 91580: loss = 0.20112
Step 91585: loss = 0.38098
Step 91590: loss = 0.16455
Step 91595: loss = 0.14459
Step 91600: loss = 0.11368
Step 91605: loss = 0.19318
Step 91610: loss = 0.22491
Step 91615: loss = 0.18997
Step 91620: loss = 0.13971
Step 91625: loss = 0.17319
Step 91630: loss = 0.15104
Step 91635: loss = 0.14136
Step 91640: loss = 0.07744
Step 91645: loss = 0.46151
Step 91650: loss = 0.21170
Step 91655: loss = 0.30198
Step 91660: loss = 0.15923
Step 91665: loss = 0.16154
Step 91670: loss = 0.05828
Step 91675: loss = 0.12156
Step 91680: loss = 0.10182
Step 91685: loss = 0.04551
Step 91690: loss = 0.40243
Step 91695: loss = 0.09142
Step 91700: loss = 0.06483
Step 91705: loss = 0.10746
Step 91710: loss = 0.34233
Step 91715: loss = 0.16545
Step 91720: loss = 0.15328
Step 91725: loss = 0.25134
Step 91730: loss = 0.28472
Step 91735: loss = 0.14313
Step 91740: loss = 0.19806
Step 91745: loss = 0.36512
Step 91750: loss = 0.19127
Step 91755: loss = 0.33660
Step 91760: loss = 0.32118
Step 91765: loss = 0.10365
Step 91770: loss = 0.31471
Step 91775: loss = 0.19247
Step 91780: loss = 0.17529
Step 91785: loss = 0.09817
Step 91790: loss = 0.28058
Step 91795: loss = 0.16587
Step 91800: loss = 0.21192
Step 91805: loss = 0.12418
Step 91810: loss = 0.06962
Step 91815: loss = 0.14386
Step 91820: loss = 0.20498
Step 91825: loss = 0.32163
Step 91830: loss = 0.11987
Step 91835: loss = 0.37568
Step 91840: loss = 0.14854
Step 91845: loss = 0.36690
Step 91850: loss = 0.21514
Step 91855: loss = 0.11185
Step 91860: loss = 0.13379
Step 91865: loss = 0.25872
Step 91870: loss = 0.10769
Step 91875: loss = 0.13044
Step 91880: loss = 0.34347
Step 91885: loss = 0.25031
Step 91890: loss = 0.25029
Step 91895: loss = 0.21292
Step 91900: loss = 0.22657
Step 91905: loss = 0.13701
Step 91910: loss = 0.20924
Step 91915: loss = 0.28172
Step 91920: loss = 0.28454
Step 91925: loss = 0.37583
Step 91930: loss = 0.27821
Step 91935: loss = 0.18597
Step 91940: loss = 0.15739
Step 91945: loss = 0.19261
Step 91950: loss = 0.15728
Step 91955: loss = 0.12026
Step 91960: loss = 0.19615
Step 91965: loss = 0.08517
Step 91970: loss = 0.24317
Step 91975: loss = 0.09712
Step 91980: loss = 0.10637
Step 91985: loss = 0.20347
Step 91990: loss = 0.10753
Step 91995: loss = 0.09765
Step 92000: loss = 0.10987
Training Data Eval:
  Num examples: 50000, Num correct: 46964, Precision @ 1: 0.9393
('Testing Data Eval: EPOCH->', 93)
  Num examples: 10000, Num correct: 6628, Precision @ 1: 0.6628
Step 92005: loss = 0.09445
Step 92010: loss = 0.24377
Step 92015: loss = 0.14127
Step 92020: loss = 0.14798
Step 92025: loss = 0.12395
Step 92030: loss = 0.07838
Step 92035: loss = 0.37734
Step 92040: loss = 0.09528
Step 92045: loss = 0.27848
Step 92050: loss = 0.17459
Step 92055: loss = 0.11140
Step 92060: loss = 0.14655
Step 92065: loss = 0.26266
Step 92070: loss = 0.12126
Step 92075: loss = 0.13980
Step 92080: loss = 0.16770
Step 92085: loss = 0.12932
Step 92090: loss = 0.24422
Step 92095: loss = 0.10050
Step 92100: loss = 0.17245
Step 92105: loss = 0.10075
Step 92110: loss = 0.17187
Step 92115: loss = 0.10853
Step 92120: loss = 0.05906
Step 92125: loss = 0.49918
Step 92130: loss = 0.09884
Step 92135: loss = 0.16703
Step 92140: loss = 0.18382
Step 92145: loss = 0.22941
Step 92150: loss = 0.17063
Step 92155: loss = 0.19031
Step 92160: loss = 0.14143
Step 92165: loss = 0.18510
Step 92170: loss = 0.03278
Step 92175: loss = 0.28815
Step 92180: loss = 0.10345
Step 92185: loss = 0.07000
Step 92190: loss = 0.04655
Step 92195: loss = 0.13851
Step 92200: loss = 0.10711
Step 92205: loss = 0.07258
Step 92210: loss = 0.34401
Step 92215: loss = 0.13045
Step 92220: loss = 0.06749
Step 92225: loss = 0.12741
Step 92230: loss = 0.19564
Step 92235: loss = 0.06199
Step 92240: loss = 0.25767
Step 92245: loss = 0.17064
Step 92250: loss = 0.15477
Step 92255: loss = 0.37736
Step 92260: loss = 0.12392
Step 92265: loss = 0.17032
Step 92270: loss = 0.39676
Step 92275: loss = 0.09502
Step 92280: loss = 0.44696
Step 92285: loss = 0.21179
Step 92290: loss = 0.14909
Step 92295: loss = 0.16724
Step 92300: loss = 0.35660
Step 92305: loss = 0.19851
Step 92310: loss = 0.96141
Step 92315: loss = 0.12833
Step 92320: loss = 0.17290
Step 92325: loss = 0.23611
Step 92330: loss = 0.28149
Step 92335: loss = 0.30081
Step 92340: loss = 0.22013
Step 92345: loss = 0.17649
Step 92350: loss = 0.24992
Step 92355: loss = 0.10452
Step 92360: loss = 0.08684
Step 92365: loss = 0.19610
Step 92370: loss = 0.19346
Step 92375: loss = 0.19662
Step 92380: loss = 0.08404
Step 92385: loss = 0.19457
Step 92390: loss = 0.24747
Step 92395: loss = 0.19725
Step 92400: loss = 0.11199
Step 92405: loss = 0.16281
Step 92410: loss = 0.07292
Step 92415: loss = 0.17169
Step 92420: loss = 0.22707
Step 92425: loss = 0.17927
Step 92430: loss = 0.17579
Step 92435: loss = 0.15503
Step 92440: loss = 0.35825
Step 92445: loss = 0.12603
Step 92450: loss = 0.41398
Step 92455: loss = 0.08979
Step 92460: loss = 0.13303
Step 92465: loss = 0.06925
Step 92470: loss = 0.14805
Step 92475: loss = 0.17469
Step 92480: loss = 0.13338
Step 92485: loss = 0.13705
Step 92490: loss = 0.20753
Step 92495: loss = 0.15527
Step 92500: loss = 0.21373
Step 92505: loss = 0.12840
Step 92510: loss = 0.14045
Step 92515: loss = 0.16196
Step 92520: loss = 0.42935
Step 92525: loss = 0.11849
Step 92530: loss = 0.23721
Step 92535: loss = 0.08863
Step 92540: loss = 0.27175
Step 92545: loss = 0.11910
Step 92550: loss = 0.11274
Step 92555: loss = 0.50955
Step 92560: loss = 0.12000
Step 92565: loss = 0.25616
Step 92570: loss = 0.14375
Step 92575: loss = 0.08862
Step 92580: loss = 0.07948
Step 92585: loss = 0.13359
Step 92590: loss = 0.25467
Step 92595: loss = 0.10371
Step 92600: loss = 0.12147
Step 92605: loss = 0.23905
Step 92610: loss = 0.11589
Step 92615: loss = 0.26957
Step 92620: loss = 0.25274
Step 92625: loss = 0.31531
Step 92630: loss = 0.32080
Step 92635: loss = 0.06572
Step 92640: loss = 0.14482
Step 92645: loss = 0.18300
Step 92650: loss = 0.26008
Step 92655: loss = 0.13290
Step 92660: loss = 0.09977
Step 92665: loss = 0.15195
Step 92670: loss = 0.13686
Step 92675: loss = 0.02903
Step 92680: loss = 0.20456
Step 92685: loss = 0.05047
Step 92690: loss = 0.12897
Step 92695: loss = 0.30690
Step 92700: loss = 0.15109
Step 92705: loss = 0.10670
Step 92710: loss = 0.07166
Step 92715: loss = 0.17744
Step 92720: loss = 0.21675
Step 92725: loss = 0.23058
Step 92730: loss = 0.16786
Step 92735: loss = 0.18282
Step 92740: loss = 0.20861
Step 92745: loss = 0.11716
Step 92750: loss = 0.22943
Step 92755: loss = 0.03862
Step 92760: loss = 0.12693
Step 92765: loss = 0.10847
Step 92770: loss = 0.16433
Step 92775: loss = 0.20508
Step 92780: loss = 0.13055
Step 92785: loss = 0.17778
Step 92790: loss = 0.02167
Step 92795: loss = 0.10881
Step 92800: loss = 0.23529
Step 92805: loss = 0.19440
Step 92810: loss = 0.12495
Step 92815: loss = 0.11375
Step 92820: loss = 0.09855
Step 92825: loss = 0.20979
Step 92830: loss = 0.13275
Step 92835: loss = 0.04584
Step 92840: loss = 0.15495
Step 92845: loss = 0.19653
Step 92850: loss = 0.35663
Step 92855: loss = 0.06269
Step 92860: loss = 0.36994
Step 92865: loss = 0.07509
Step 92870: loss = 0.05480
Step 92875: loss = 0.08212
Step 92880: loss = 0.09244
Step 92885: loss = 0.33529
Step 92890: loss = 0.07959
Step 92895: loss = 0.58725
Step 92900: loss = 0.13587
Step 92905: loss = 0.31147
Step 92910: loss = 0.16724
Step 92915: loss = 0.20178
Step 92920: loss = 0.05915
Step 92925: loss = 0.24212
Step 92930: loss = 0.10054
Step 92935: loss = 0.25143
Step 92940: loss = 0.17687
Step 92945: loss = 0.21300
Step 92950: loss = 0.10931
Step 92955: loss = 0.10784
Step 92960: loss = 0.22505
Step 92965: loss = 0.09366
Step 92970: loss = 0.11302
Step 92975: loss = 0.29301
Step 92980: loss = 0.23765
Step 92985: loss = 0.04203
Step 92990: loss = 0.09746
Step 92995: loss = 0.14196
Step 93000: loss = 0.11868
Training Data Eval:
  Num examples: 50000, Num correct: 47241, Precision @ 1: 0.9448
('Testing Data Eval: EPOCH->', 94)
  Num examples: 10000, Num correct: 6667, Precision @ 1: 0.6667
Step 93005: loss = 0.11956
Step 93010: loss = 0.12292
Step 93015: loss = 0.20666
Step 93020: loss = 0.22880
Step 93025: loss = 0.54212
Step 93030: loss = 0.27203
Step 93035: loss = 0.19337
Step 93040: loss = 0.07894
Step 93045: loss = 0.15038
Step 93050: loss = 0.09313
Step 93055: loss = 0.08704
Step 93060: loss = 0.22831
Step 93065: loss = 0.07802
Step 93070: loss = 0.11715
Step 93075: loss = 0.20450
Step 93080: loss = 0.23749
Step 93085: loss = 0.06962
Step 93090: loss = 0.06134
Step 93095: loss = 0.16830
Step 93100: loss = 0.13691
Step 93105: loss = 0.09414
Step 93110: loss = 0.08880
Step 93115: loss = 0.17809
Step 93120: loss = 0.16093
Step 93125: loss = 0.19510
Step 93130: loss = 0.14568
Step 93135: loss = 0.06660
Step 93140: loss = 0.24270
Step 93145: loss = 0.07915
Step 93150: loss = 0.04570
Step 93155: loss = 0.09914
Step 93160: loss = 0.16246
Step 93165: loss = 0.18962
Step 93170: loss = 0.11925
Step 93175: loss = 0.13049
Step 93180: loss = 0.18459
Step 93185: loss = 0.15917
Step 93190: loss = 0.20330
Step 93195: loss = 0.18725
Step 93200: loss = 0.19056
Step 93205: loss = 0.10995
Step 93210: loss = 0.17226
Step 93215: loss = 0.05678
Step 93220: loss = 0.09667
Step 93225: loss = 0.29372
Step 93230: loss = 0.28403
Step 93235: loss = 0.08785
Step 93240: loss = 0.09589
Step 93245: loss = 0.14218
Step 93250: loss = 0.83611
Step 93255: loss = 0.29526
Step 93260: loss = 0.39953
Step 93265: loss = 0.37417
Step 93270: loss = 0.08351
Step 93275: loss = 0.27199
Step 93280: loss = 0.16786
Step 93285: loss = 0.09453
Step 93290: loss = 0.31263
Step 93295: loss = 0.25455
Step 93300: loss = 0.15282
Step 93305: loss = 0.13663
Step 93310: loss = 0.10257
Step 93315: loss = 0.06441
Step 93320: loss = 0.25660
Step 93325: loss = 0.06156
Step 93330: loss = 0.14176
Step 93335: loss = 0.29817
Step 93340: loss = 0.17763
Step 93345: loss = 0.07643
Step 93350: loss = 0.19708
Step 93355: loss = 0.16498
Step 93360: loss = 0.27552
Step 93365: loss = 0.11954
Step 93370: loss = 0.32939
Step 93375: loss = 0.31963
Step 93380: loss = 0.20675
Step 93385: loss = 0.11242
Step 93390: loss = 0.09901
Step 93395: loss = 0.15645
Step 93400: loss = 0.29636
Step 93405: loss = 0.13949
Step 93410: loss = 0.11215
Step 93415: loss = 0.33673
Step 93420: loss = 0.15385
Step 93425: loss = 0.14028
Step 93430: loss = 0.27563
Step 93435: loss = 0.33934
Step 93440: loss = 0.08247
Step 93445: loss = 0.25267
Step 93450: loss = 0.04756
Step 93455: loss = 0.16631
Step 93460: loss = 0.18034
Step 93465: loss = 0.08224
Step 93470: loss = 0.14458
Step 93475: loss = 0.13480
Step 93480: loss = 0.11408
Step 93485: loss = 0.19336
Step 93490: loss = 0.11397
Step 93495: loss = 0.05806
Step 93500: loss = 0.31723
Step 93505: loss = 0.30400
Step 93510: loss = 0.11657
Step 93515: loss = 0.22654
Step 93520: loss = 0.15908
Step 93525: loss = 0.10339
Step 93530: loss = 0.05574
Step 93535: loss = 0.08531
Step 93540: loss = 0.20680
Step 93545: loss = 0.15270
Step 93550: loss = 0.18318
Step 93555: loss = 0.22608
Step 93560: loss = 0.23732
Step 93565: loss = 0.21375
Step 93570: loss = 0.14466
Step 93575: loss = 0.17208
Step 93580: loss = 0.14554
Step 93585: loss = 0.11927
Step 93590: loss = 0.29497
Step 93595: loss = 0.16222
Step 93600: loss = 0.18206
Step 93605: loss = 0.23572
Step 93610: loss = 0.12104
Step 93615: loss = 0.18765
Step 93620: loss = 0.28109
Step 93625: loss = 0.15434
Step 93630: loss = 0.13327
Step 93635: loss = 0.20670
Step 93640: loss = 0.36648
Step 93645: loss = 0.19361
Step 93650: loss = 0.31065
Step 93655: loss = 0.30631
Step 93660: loss = 0.34677
Step 93665: loss = 0.06709
Step 93670: loss = 0.07607
Step 93675: loss = 0.48984
Step 93680: loss = 0.06781
Step 93685: loss = 0.16976
Step 93690: loss = 0.23036
Step 93695: loss = 0.06574
Step 93700: loss = 0.15661
Step 93705: loss = 0.14665
Step 93710: loss = 0.11799
Step 93715: loss = 0.22986
Step 93720: loss = 0.11667
Step 93725: loss = 0.21822
Step 93730: loss = 0.36687
Step 93735: loss = 0.28100
Step 93740: loss = 0.08242
Step 93745: loss = 0.04801
Step 93750: loss = 0.03957
Step 93755: loss = 0.17942
Step 93760: loss = 0.30712
Step 93765: loss = 0.10925
Step 93770: loss = 0.18296
Step 93775: loss = 0.21625
Step 93780: loss = 0.37473
Step 93785: loss = 0.26840
Step 93790: loss = 0.16116
Step 93795: loss = 0.21946
Step 93800: loss = 0.26631
Step 93805: loss = 0.16793
Step 93810: loss = 0.31381
Step 93815: loss = 0.21413
Step 93820: loss = 0.12841
Step 93825: loss = 0.14313
Step 93830: loss = 0.07266
Step 93835: loss = 0.14331
Step 93840: loss = 0.18450
Step 93845: loss = 0.12032
Step 93850: loss = 0.13084
Step 93855: loss = 0.30547
Step 93860: loss = 0.04893
Step 93865: loss = 0.10842
Step 93870: loss = 0.16566
Step 93875: loss = 0.24934
Step 93880: loss = 0.41417
Step 93885: loss = 0.27096
Step 93890: loss = 0.24971
Step 93895: loss = 0.12045
Step 93900: loss = 0.22165
Step 93905: loss = 0.10802
Step 93910: loss = 0.24010
Step 93915: loss = 0.28122
Step 93920: loss = 0.17556
Step 93925: loss = 0.06712
Step 93930: loss = 0.31402
Step 93935: loss = 0.12146
Step 93940: loss = 0.07307
Step 93945: loss = 0.18518
Step 93950: loss = 0.12907
Step 93955: loss = 0.14471
Step 93960: loss = 0.14639
Step 93965: loss = 0.29070
Step 93970: loss = 0.21560
Step 93975: loss = 0.15461
Step 93980: loss = 0.05441
Step 93985: loss = 0.46644
Step 93990: loss = 0.27095
Step 93995: loss = 0.47909
Step 94000: loss = 0.25284
Training Data Eval:
  Num examples: 50000, Num correct: 45870, Precision @ 1: 0.9174
('Testing Data Eval: EPOCH->', 95)
  Num examples: 10000, Num correct: 6328, Precision @ 1: 0.6328
Step 94005: loss = 0.36662
Step 94010: loss = 0.15800
Step 94015: loss = 0.34700
Step 94020: loss = 0.30195
Step 94025: loss = 0.29431
Step 94030: loss = 0.19850
Step 94035: loss = 0.07965
Step 94040: loss = 0.17525
Step 94045: loss = 0.10344
Step 94050: loss = 0.16133
Step 94055: loss = 0.18558
Step 94060: loss = 0.50092
Step 94065: loss = 0.19696
Step 94070: loss = 0.35605
Step 94075: loss = 0.15617
Step 94080: loss = 0.28302
Step 94085: loss = 0.03681
Step 94090: loss = 0.09556
Step 94095: loss = 0.27680
Step 94100: loss = 0.12611
Step 94105: loss = 0.30405
Step 94110: loss = 0.12502
Step 94115: loss = 0.25044
Step 94120: loss = 0.28204
Step 94125: loss = 0.15892
Step 94130: loss = 0.25440
Step 94135: loss = 0.16554
Step 94140: loss = 0.16882
Step 94145: loss = 0.18237
Step 94150: loss = 0.19713
Step 94155: loss = 0.18091
Step 94160: loss = 0.10998
Step 94165: loss = 0.40726
Step 94170: loss = 0.37052
Step 94175: loss = 0.14773
Step 94180: loss = 0.18351
Step 94185: loss = 0.40064
Step 94190: loss = 0.15852
Step 94195: loss = 0.19889
Step 94200: loss = 0.30251
Step 94205: loss = 0.23610
Step 94210: loss = 0.07434
Step 94215: loss = 0.22305
Step 94220: loss = 0.10987
Step 94225: loss = 0.11306
Step 94230: loss = 0.17024
Step 94235: loss = 0.22612
Step 94240: loss = 0.17049
Step 94245: loss = 0.16542
Step 94250: loss = 0.29973
Step 94255: loss = 0.33967
Step 94260: loss = 0.24552
Step 94265: loss = 0.33948
Step 94270: loss = 0.22237
Step 94275: loss = 0.15366
Step 94280: loss = 0.27247
Step 94285: loss = 0.11640
Step 94290: loss = 0.03257
Step 94295: loss = 0.13550
Step 94300: loss = 0.23825
Step 94305: loss = 0.25487
Step 94310: loss = 0.35611
Step 94315: loss = 0.13073
Step 94320: loss = 0.09427
Step 94325: loss = 0.10230
Step 94330: loss = 0.59504
Step 94335: loss = 0.06619
Step 94340: loss = 0.11552
Step 94345: loss = 0.11498
Step 94350: loss = 0.11911
Step 94355: loss = 0.31216
Step 94360: loss = 0.09535
Step 94365: loss = 0.32366
Step 94370: loss = 0.07338
Step 94375: loss = 0.12562
Step 94380: loss = 0.14958
Step 94385: loss = 0.10385
Step 94390: loss = 0.14022
Step 94395: loss = 0.26753
Step 94400: loss = 0.27362
Step 94405: loss = 0.26828
Step 94410: loss = 0.10159
Step 94415: loss = 0.28159
Step 94420: loss = 0.05848
Step 94425: loss = 0.22853
Step 94430: loss = 0.13256
Step 94435: loss = 0.12491
Step 94440: loss = 0.09751
Step 94445: loss = 0.27594
Step 94450: loss = 0.15441
Step 94455: loss = 0.15870
Step 94460: loss = 0.10737
Step 94465: loss = 0.06779
Step 94470: loss = 0.13111
Step 94475: loss = 0.21137
Step 94480: loss = 0.06417
Step 94485: loss = 0.09384
Step 94490: loss = 0.25716
Step 94495: loss = 0.27890
Step 94500: loss = 0.23610
Step 94505: loss = 0.11251
Step 94510: loss = 0.09035
Step 94515: loss = 0.25338
Step 94520: loss = 0.14876
Step 94525: loss = 0.22752
Step 94530: loss = 0.34725
Step 94535: loss = 0.09116
Step 94540: loss = 0.23412
Step 94545: loss = 0.18816
Step 94550: loss = 0.10982
Step 94555: loss = 0.22636
Step 94560: loss = 0.19411
Step 94565: loss = 0.43159
Step 94570: loss = 0.16022
Step 94575: loss = 0.26727
Step 94580: loss = 0.28368
Step 94585: loss = 0.09458
Step 94590: loss = 0.08229
Step 94595: loss = 0.78464
Step 94600: loss = 0.19218
Step 94605: loss = 0.13422
Step 94610: loss = 0.16459
Step 94615: loss = 0.14178
Step 94620: loss = 0.06907
Step 94625: loss = 0.16178
Step 94630: loss = 0.28801
Step 94635: loss = 0.05867
Step 94640: loss = 0.12084
Step 94645: loss = 0.21243
Step 94650: loss = 0.15100
Step 94655: loss = 0.17351
Step 94660: loss = 0.06271
Step 94665: loss = 0.08313
Step 94670: loss = 0.17241
Step 94675: loss = 0.08496
Step 94680: loss = 0.40810
Step 94685: loss = 0.11023
Step 94690: loss = 0.21221
Step 94695: loss = 0.21029
Step 94700: loss = 0.25574
Step 94705: loss = 0.14313
Step 94710: loss = 0.10794
Step 94715: loss = 0.28404
Step 94720: loss = 0.08038
Step 94725: loss = 0.24158
Step 94730: loss = 0.08030
Step 94735: loss = 0.10143
Step 94740: loss = 0.14734
Step 94745: loss = 0.06976
Step 94750: loss = 0.25078
Step 94755: loss = 0.02592
Step 94760: loss = 0.16438
Step 94765: loss = 0.11186
Step 94770: loss = 0.07808
Step 94775: loss = 0.20215
Step 94780: loss = 0.06433
Step 94785: loss = 0.16816
Step 94790: loss = 0.13449
Step 94795: loss = 0.24214
Step 94800: loss = 0.08404
Step 94805: loss = 0.21319
Step 94810: loss = 0.19870
Step 94815: loss = 0.10606
Step 94820: loss = 0.10915
Step 94825: loss = 0.15881
Step 94830: loss = 0.19214
Step 94835: loss = 0.10197
Step 94840: loss = 0.23771
Step 94845: loss = 0.19801
Step 94850: loss = 0.05668
Step 94855: loss = 0.12083
Step 94860: loss = 0.05553
Step 94865: loss = 0.24367
Step 94870: loss = 0.12655
Step 94875: loss = 0.15858
Step 94880: loss = 0.15678
Step 94885: loss = 0.34016
Step 94890: loss = 0.10230
Step 94895: loss = 0.20670
Step 94900: loss = 0.09986
Step 94905: loss = 0.11130
Step 94910: loss = 0.07898
Step 94915: loss = 0.06375
Step 94920: loss = 0.17097
Step 94925: loss = 0.07620
Step 94930: loss = 0.16711
Step 94935: loss = 0.24173
Step 94940: loss = 0.12417
Step 94945: loss = 0.10831
Step 94950: loss = 0.29733
Step 94955: loss = 0.08801
Step 94960: loss = 0.05804
Step 94965: loss = 0.08671
Step 94970: loss = 0.34061
Step 94975: loss = 0.37054
Step 94980: loss = 0.12094
Step 94985: loss = 0.38636
Step 94990: loss = 0.18713
Step 94995: loss = 0.45580
Step 95000: loss = 0.35576
Training Data Eval:
  Num examples: 50000, Num correct: 46944, Precision @ 1: 0.9389
('Testing Data Eval: EPOCH->', 96)
  Num examples: 10000, Num correct: 6575, Precision @ 1: 0.6575
Step 95005: loss = 0.11293
Step 95010: loss = 0.38811
Step 95015: loss = 0.18433
Step 95020: loss = 0.16936
Step 95025: loss = 0.26335
Step 95030: loss = 0.13602
Step 95035: loss = 0.16291
Step 95040: loss = 0.19735
Step 95045: loss = 0.11052
Step 95050: loss = 0.10541
Step 95055: loss = 0.13700
Step 95060: loss = 0.08859
Step 95065: loss = 0.13049
Step 95070: loss = 0.29893
Step 95075: loss = 0.09185
Step 95080: loss = 0.09542
Step 95085: loss = 0.12696
Step 95090: loss = 0.15310
Step 95095: loss = 0.15726
Step 95100: loss = 0.13668
Step 95105: loss = 0.10671
Step 95110: loss = 0.15811
Step 95115: loss = 0.11475
Step 95120: loss = 0.15361
Step 95125: loss = 0.29776
Step 95130: loss = 0.52942
Step 95135: loss = 0.18860
Step 95140: loss = 0.05555
Step 95145: loss = 0.12857
Step 95150: loss = 0.21226
Step 95155: loss = 0.16481
Step 95160: loss = 0.16683
Step 95165: loss = 0.05921
Step 95170: loss = 0.09536
Step 95175: loss = 0.36797
Step 95180: loss = 0.11992
Step 95185: loss = 0.30830
Step 95190: loss = 0.16973
Step 95195: loss = 0.20431
Step 95200: loss = 0.08200
Step 95205: loss = 0.05238
Step 95210: loss = 0.28726
Step 95215: loss = 0.20579
Step 95220: loss = 0.18811
Step 95225: loss = 0.06893
Step 95230: loss = 0.07172
Step 95235: loss = 0.23453
Step 95240: loss = 0.27318
Step 95245: loss = 0.31002
Step 95250: loss = 0.05538
Step 95255: loss = 0.37013
Step 95260: loss = 0.17510
Step 95265: loss = 0.38116
Step 95270: loss = 0.12061
Step 95275: loss = 0.04444
Step 95280: loss = 0.17234
Step 95285: loss = 0.21335
Step 95290: loss = 0.18510
Step 95295: loss = 0.12622
Step 95300: loss = 0.27101
Step 95305: loss = 0.07474
Step 95310: loss = 0.20540
Step 95315: loss = 0.26291
Step 95320: loss = 0.18015
Step 95325: loss = 0.23737
Step 95330: loss = 0.33744
Step 95335: loss = 0.14059
Step 95340: loss = 0.28601
Step 95345: loss = 0.27874
Step 95350: loss = 0.10431
Step 95355: loss = 0.15996
Step 95360: loss = 0.21877
Step 95365: loss = 0.09749
Step 95370: loss = 0.21916
Step 95375: loss = 0.25292
Step 95380: loss = 0.33435
Step 95385: loss = 0.08188
Step 95390: loss = 0.08466
Step 95395: loss = 0.14877
Step 95400: loss = 0.31416
Step 95405: loss = 0.35344
Step 95410: loss = 0.09439
Step 95415: loss = 0.22008
Step 95420: loss = 0.04742
Step 95425: loss = 0.24988
Step 95430: loss = 0.35934
Step 95435: loss = 0.26641
Step 95440: loss = 0.22613
Step 95445: loss = 0.18976
Step 95450: loss = 0.20701
Step 95455: loss = 0.07445
Step 95460: loss = 0.50761
Step 95465: loss = 0.12684
Step 95470: loss = 0.13123
Step 95475: loss = 0.19799
Step 95480: loss = 0.21222
Step 95485: loss = 0.45443
Step 95490: loss = 0.22411
Step 95495: loss = 0.08627
Step 95500: loss = 0.15691
Step 95505: loss = 0.24042
Step 95510: loss = 0.16981
Step 95515: loss = 0.09672
Step 95520: loss = 0.32286
Step 95525: loss = 0.12859
Step 95530: loss = 0.07854
Step 95535: loss = 0.10139
Step 95540: loss = 0.20443
Step 95545: loss = 0.29519
Step 95550: loss = 0.28418
Step 95555: loss = 0.08243
Step 95560: loss = 0.40605
Step 95565: loss = 0.19787
Step 95570: loss = 0.14788
Step 95575: loss = 0.37693
Step 95580: loss = 0.23544
Step 95585: loss = 0.38648
Step 95590: loss = 0.15267
Step 95595: loss = 0.06981
Step 95600: loss = 0.12443
Step 95605: loss = 0.06666
Step 95610: loss = 0.23691
Step 95615: loss = 0.20504
Step 95620: loss = 0.10067
Step 95625: loss = 0.23025
Step 95630: loss = 0.09029
Step 95635: loss = 0.22024
Step 95640: loss = 0.21110
Step 95645: loss = 0.11004
Step 95650: loss = 0.12551
Step 95655: loss = 0.08844
Step 95660: loss = 0.10368
Step 95665: loss = 0.17410
Step 95670: loss = 0.20212
Step 95675: loss = 0.14021
Step 95680: loss = 0.14838
Step 95685: loss = 0.19072
Step 95690: loss = 0.29249
Step 95695: loss = 0.30834
Step 95700: loss = 0.25829
Step 95705: loss = 0.21460
Step 95710: loss = 0.07461
Step 95715: loss = 0.15280
Step 95720: loss = 0.25221
Step 95725: loss = 0.17135
Step 95730: loss = 0.17632
Step 95735: loss = 0.07117
Step 95740: loss = 0.08100
Step 95745: loss = 0.31327
Step 95750: loss = 0.22204
Step 95755: loss = 0.12839
Step 95760: loss = 0.32857
Step 95765: loss = 0.55367
Step 95770: loss = 0.24038
Step 95775: loss = 0.18708
Step 95780: loss = 0.22270
Step 95785: loss = 0.42890
Step 95790: loss = 0.09570
Step 95795: loss = 0.52642
Step 95800: loss = 0.07515
Step 95805: loss = 0.11093
Step 95810: loss = 0.25438
Step 95815: loss = 0.25379
Step 95820: loss = 0.09083
Step 95825: loss = 0.11349
Step 95830: loss = 0.04641
Step 95835: loss = 0.23051
Step 95840: loss = 0.18143
Step 95845: loss = 0.12862
Step 95850: loss = 0.11742
Step 95855: loss = 0.25278
Step 95860: loss = 0.47448
Step 95865: loss = 0.30671
Step 95870: loss = 0.16606
Step 95875: loss = 0.13107
Step 95880: loss = 0.21612
Step 95885: loss = 0.10661
Step 95890: loss = 0.12656
Step 95895: loss = 0.36199
Step 95900: loss = 0.18846
Step 95905: loss = 0.16315
Step 95910: loss = 0.11473
Step 95915: loss = 0.22363
Step 95920: loss = 0.12516
Step 95925: loss = 0.10391
Step 95930: loss = 0.13818
Step 95935: loss = 0.06919
Step 95940: loss = 0.16969
Step 95945: loss = 0.02701
Step 95950: loss = 0.24229
Step 95955: loss = 0.13396
Step 95960: loss = 0.13005
Step 95965: loss = 0.17512
Step 95970: loss = 0.04831
Step 95975: loss = 0.33312
Step 95980: loss = 0.29546
Step 95985: loss = 0.15485
Step 95990: loss = 0.14164
Step 95995: loss = 0.14488
Step 96000: loss = 0.21700
Training Data Eval:
  Num examples: 50000, Num correct: 47261, Precision @ 1: 0.9452
('Testing Data Eval: EPOCH->', 97)
  Num examples: 10000, Num correct: 6651, Precision @ 1: 0.6651
Step 96005: loss = 0.17604
Step 96010: loss = 0.12504
Step 96015: loss = 0.10434
Step 96020: loss = 0.40637
Step 96025: loss = 0.11131
Step 96030: loss = 0.16072
Step 96035: loss = 0.15166
Step 96040: loss = 0.23250
Step 96045: loss = 0.11465
Step 96050: loss = 0.23419
Step 96055: loss = 0.20179
Step 96060: loss = 0.26499
Step 96065: loss = 0.13601
Step 96070: loss = 0.22812
Step 96075: loss = 0.32551
Step 96080: loss = 0.32825
Step 96085: loss = 0.10154
Step 96090: loss = 0.17142
Step 96095: loss = 0.16498
Step 96100: loss = 0.47403
Step 96105: loss = 0.14154
Step 96110: loss = 0.45167
Step 96115: loss = 0.16334
Step 96120: loss = 0.25116
Step 96125: loss = 0.10585
Step 96130: loss = 0.04146
Step 96135: loss = 0.10231
Step 96140: loss = 0.34613
Step 96145: loss = 0.18190
Step 96150: loss = 0.49021
Step 96155: loss = 0.11729
Step 96160: loss = 0.27033
Step 96165: loss = 0.33757
Step 96170: loss = 0.11276
Step 96175: loss = 0.14758
Step 96180: loss = 0.19226
Step 96185: loss = 0.14616
Step 96190: loss = 0.36348
Step 96195: loss = 0.06097
Step 96200: loss = 0.15260
Step 96205: loss = 0.26170
Step 96210: loss = 0.09545
Step 96215: loss = 0.12787
Step 96220: loss = 0.11400
Step 96225: loss = 0.08158
Step 96230: loss = 0.11369
Step 96235: loss = 0.16401
Step 96240: loss = 0.14744
Step 96245: loss = 0.23791
Step 96250: loss = 0.09639
Step 96255: loss = 0.05792
Step 96260: loss = 0.16515
Step 96265: loss = 0.19945
Step 96270: loss = 0.28665
Step 96275: loss = 0.08188
Step 96280: loss = 0.18633
Step 96285: loss = 0.11865
Step 96290: loss = 0.35797
Step 96295: loss = 0.20721
Step 96300: loss = 0.10513
Step 96305: loss = 0.09814
Step 96310: loss = 0.30400
Step 96315: loss = 0.16746
Step 96320: loss = 0.10662
Step 96325: loss = 0.16043
Step 96330: loss = 0.31249
Step 96335: loss = 0.13473
Step 96340: loss = 0.23894
Step 96345: loss = 0.16212
Step 96350: loss = 0.05953
Step 96355: loss = 0.15504
Step 96360: loss = 0.19596
Step 96365: loss = 0.11240
Step 96370: loss = 0.13076
Step 96375: loss = 0.19081
Step 96380: loss = 0.32091
Step 96385: loss = 0.45415
Step 96390: loss = 0.07227
Step 96395: loss = 0.15235
Step 96400: loss = 0.40904
Step 96405: loss = 0.19128
Step 96410: loss = 0.28826
Step 96415: loss = 0.17424
Step 96420: loss = 0.43034
Step 96425: loss = 0.08839
Step 96430: loss = 0.31606
Step 96435: loss = 0.11438
Step 96440: loss = 0.10071
Step 96445: loss = 0.18541
Step 96450: loss = 0.10743
Step 96455: loss = 0.07490
Step 96460: loss = 0.18695
Step 96465: loss = 0.20727
Step 96470: loss = 0.13156
Step 96475: loss = 0.08354
Step 96480: loss = 0.18549
Step 96485: loss = 0.22659
Step 96490: loss = 0.35900
Step 96495: loss = 0.14635
Step 96500: loss = 0.11156
Step 96505: loss = 0.13878
Step 96510: loss = 0.24803
Step 96515: loss = 0.07606
Step 96520: loss = 0.30495
Step 96525: loss = 0.10493
Step 96530: loss = 0.07510
Step 96535: loss = 0.07276
Step 96540: loss = 0.44348
Step 96545: loss = 0.20980
Step 96550: loss = 0.06248
Step 96555: loss = 0.44768
Step 96560: loss = 0.23005
Step 96565: loss = 0.08710
Step 96570: loss = 0.14890
Step 96575: loss = 0.19906
Step 96580: loss = 0.25809
Step 96585: loss = 0.34490
Step 96590: loss = 0.36791
Step 96595: loss = 0.22794
Step 96600: loss = 0.20544
Step 96605: loss = 0.09280
Step 96610: loss = 0.27344
Step 96615: loss = 0.12354
Step 96620: loss = 0.16825
Step 96625: loss = 0.20143
Step 96630: loss = 0.11351
Step 96635: loss = 0.09431
Step 96640: loss = 0.08666
Step 96645: loss = 0.23033
Step 96650: loss = 0.23116
Step 96655: loss = 0.11142
Step 96660: loss = 0.19638
Step 96665: loss = 0.11092
Step 96670: loss = 0.20510
Step 96675: loss = 0.08361
Step 96680: loss = 0.08177
Step 96685: loss = 0.16162
Step 96690: loss = 0.09398
Step 96695: loss = 0.28112
Step 96700: loss = 0.10421
Step 96705: loss = 0.19603
Step 96710: loss = 0.05825
Step 96715: loss = 0.46652
Step 96720: loss = 0.25187
Step 96725: loss = 0.06540
Step 96730: loss = 0.15658
Step 96735: loss = 0.17582
Step 96740: loss = 0.06002
Step 96745: loss = 0.14554
Step 96750: loss = 0.15758
Step 96755: loss = 0.11752
Step 96760: loss = 0.31813
Step 96765: loss = 0.16032
Step 96770: loss = 0.22534
Step 96775: loss = 0.24359
Step 96780: loss = 0.31971
Step 96785: loss = 0.15498
Step 96790: loss = 0.25266
Step 96795: loss = 0.10366
Step 96800: loss = 0.30524
Step 96805: loss = 0.12501
Step 96810: loss = 0.18105
Step 96815: loss = 0.18821
Step 96820: loss = 0.19472
Step 96825: loss = 0.18337
Step 96830: loss = 0.07287
Step 96835: loss = 0.31815
Step 96840: loss = 0.25002
Step 96845: loss = 0.27634
Step 96850: loss = 0.12005
Step 96855: loss = 0.09683
Step 96860: loss = 0.26213
Step 96865: loss = 0.24715
Step 96870: loss = 0.31378
Step 96875: loss = 0.13522
Step 96880: loss = 0.10194
Step 96885: loss = 0.12233
Step 96890: loss = 0.43556
Step 96895: loss = 0.33062
Step 96900: loss = 0.29056
Step 96905: loss = 0.15414
Step 96910: loss = 0.06474
Step 96915: loss = 0.13381
Step 96920: loss = 0.11776
Step 96925: loss = 0.29049
Step 96930: loss = 0.16674
Step 96935: loss = 0.09095
Step 96940: loss = 0.07915
Step 96945: loss = 0.11645
Step 96950: loss = 0.11702
Step 96955: loss = 0.09400
Step 96960: loss = 0.14099
Step 96965: loss = 0.05042
Step 96970: loss = 0.14893
Step 96975: loss = 0.17964
Step 96980: loss = 0.24930
Step 96985: loss = 0.33819
Step 96990: loss = 0.11155
Step 96995: loss = 0.28040
Step 97000: loss = 0.03824
Training Data Eval:
  Num examples: 50000, Num correct: 47093, Precision @ 1: 0.9419
('Testing Data Eval: EPOCH->', 98)
  Num examples: 10000, Num correct: 6569, Precision @ 1: 0.6569
Step 97005: loss = 0.21301
Step 97010: loss = 0.29457
Step 97015: loss = 0.14561
Step 97020: loss = 0.13712
Step 97025: loss = 0.34465
Step 97030: loss = 0.06684
Step 97035: loss = 0.18567
Step 97040: loss = 0.07809
Step 97045: loss = 0.10918
Step 97050: loss = 0.28357
Step 97055: loss = 0.12992
Step 97060: loss = 0.23472
Step 97065: loss = 0.11959
Step 97070: loss = 0.20204
Step 97075: loss = 0.20834
Step 97080: loss = 0.18914
Step 97085: loss = 0.24051
Step 97090: loss = 0.09285
Step 97095: loss = 0.24512
Step 97100: loss = 0.33335
Step 97105: loss = 0.22668
Step 97110: loss = 0.05840
Step 97115: loss = 0.21488
Step 97120: loss = 0.16288
Step 97125: loss = 0.07124
Step 97130: loss = 0.16868
Step 97135: loss = 0.04375
Step 97140: loss = 0.24953
Step 97145: loss = 0.18339
Step 97150: loss = 0.05920
Step 97155: loss = 0.08713
Step 97160: loss = 0.18833
Step 97165: loss = 0.16591
Step 97170: loss = 0.22586
Step 97175: loss = 0.05019
Step 97180: loss = 0.07613
Step 97185: loss = 0.11989
Step 97190: loss = 0.10485
Step 97195: loss = 0.07762
Step 97200: loss = 0.18417
Step 97205: loss = 0.14600
Step 97210: loss = 0.09086
Step 97215: loss = 0.23735
Step 97220: loss = 0.07496
Step 97225: loss = 0.14718
Step 97230: loss = 0.22522
Step 97235: loss = 0.18674
Step 97240: loss = 0.12213
Step 97245: loss = 0.25510
Step 97250: loss = 0.11232
Step 97255: loss = 0.11830
Step 97260: loss = 0.18469
Step 97265: loss = 0.17283
Step 97270: loss = 0.13784
Step 97275: loss = 0.22497
Step 97280: loss = 0.25376
Step 97285: loss = 0.15213
Step 97290: loss = 0.16072
Step 97295: loss = 0.06714
Step 97300: loss = 0.09950
Step 97305: loss = 0.27575
Step 97310: loss = 0.35969
Step 97315: loss = 0.17079
Step 97320: loss = 0.25155
Step 97325: loss = 0.08354
Step 97330: loss = 0.18871
Step 97335: loss = 0.14526
Step 97340: loss = 0.14087
Step 97345: loss = 0.17135
Step 97350: loss = 0.19099
Step 97355: loss = 0.12023
Step 97360: loss = 0.13579
Step 97365: loss = 0.16320
Step 97370: loss = 0.14705
Step 97375: loss = 0.20165
Step 97380: loss = 0.06831
Step 97385: loss = 0.28426
Step 97390: loss = 0.21874
Step 97395: loss = 0.13195
Step 97400: loss = 0.25296
Step 97405: loss = 0.11868
Step 97410: loss = 0.08884
Step 97415: loss = 0.43013
Step 97420: loss = 0.04910
Step 97425: loss = 0.25274
Step 97430: loss = 0.17409
Step 97435: loss = 0.08105
Step 97440: loss = 0.09446
Step 97445: loss = 0.08678
Step 97450: loss = 0.27430
Step 97455: loss = 0.14060
Step 97460: loss = 0.11239
Step 97465: loss = 0.13621
Step 97470: loss = 0.27659
Step 97475: loss = 0.14672
Step 97480: loss = 0.22390
Step 97485: loss = 0.11959
Step 97490: loss = 0.10032
Step 97495: loss = 0.21472
Step 97500: loss = 0.13846
Step 97505: loss = 0.11914
Step 97510: loss = 0.14129
Step 97515: loss = 0.18340
Step 97520: loss = 0.07923
Step 97525: loss = 0.07781
Step 97530: loss = 0.16168
Step 97535: loss = 0.16095
Step 97540: loss = 0.13393
Step 97545: loss = 0.17518
Step 97550: loss = 0.09390
Step 97555: loss = 0.20819
Step 97560: loss = 0.08142
Step 97565: loss = 0.25445
Step 97570: loss = 0.28941
Step 97575: loss = 0.25717
Step 97580: loss = 0.22321
Step 97585: loss = 0.07232
Step 97590: loss = 0.17540
Step 97595: loss = 0.30619
Step 97600: loss = 0.05914
Step 97605: loss = 0.11577
Step 97610: loss = 0.12289
Step 97615: loss = 0.13353
Step 97620: loss = 0.08338
Step 97625: loss = 0.15726
Step 97630: loss = 0.09040
Step 97635: loss = 0.26179
Step 97640: loss = 0.09849
Step 97645: loss = 0.26505
Step 97650: loss = 0.03295
Step 97655: loss = 0.18956
Step 97660: loss = 0.18423
Step 97665: loss = 0.19872
Step 97670: loss = 0.38374
Step 97675: loss = 0.06352
Step 97680: loss = 0.21317
Step 97685: loss = 0.20552
Step 97690: loss = 0.17519
Step 97695: loss = 0.22863
Step 97700: loss = 0.18173
Step 97705: loss = 0.16095
Step 97710: loss = 0.42919
Step 97715: loss = 0.26789
Step 97720: loss = 0.55382
Step 97725: loss = 0.17316
Step 97730: loss = 0.12603
Step 97735: loss = 0.17255
Step 97740: loss = 0.09811
Step 97745: loss = 0.20035
Step 97750: loss = 0.30180
Step 97755: loss = 0.29846
Step 97760: loss = 0.12460
Step 97765: loss = 0.16355
Step 97770: loss = 0.17729
Step 97775: loss = 0.19576
Step 97780: loss = 0.10816
Step 97785: loss = 0.19508
Step 97790: loss = 0.21942
Step 97795: loss = 0.19522
Step 97800: loss = 0.05978
Step 97805: loss = 0.08841
Step 97810: loss = 0.26095
Step 97815: loss = 0.38498
Step 97820: loss = 0.32338
Step 97825: loss = 0.23573
Step 97830: loss = 0.12575
Step 97835: loss = 0.07032
Step 97840: loss = 0.16826
Step 97845: loss = 0.31320
Step 97850: loss = 0.31773
Step 97855: loss = 0.11019
Step 97860: loss = 0.14113
Step 97865: loss = 0.12434
Step 97870: loss = 0.16877
Step 97875: loss = 0.33528
Step 97880: loss = 0.15309
Step 97885: loss = 0.09362
Step 97890: loss = 0.24006
Step 97895: loss = 0.28490
Step 97900: loss = 0.18034
Step 97905: loss = 0.26698
Step 97910: loss = 0.10071
Step 97915: loss = 0.09316
Step 97920: loss = 0.15492
Step 97925: loss = 0.30869
Step 97930: loss = 0.04580
Step 97935: loss = 0.29267
Step 97940: loss = 0.20313
Step 97945: loss = 0.24041
Step 97950: loss = 0.14470
Step 97955: loss = 0.15867
Step 97960: loss = 0.15648
Step 97965: loss = 0.21649
Step 97970: loss = 0.14058
Step 97975: loss = 0.27953
Step 97980: loss = 0.15866
Step 97985: loss = 0.34568
Step 97990: loss = 0.08638
Step 97995: loss = 0.10511
Step 98000: loss = 0.18810
Training Data Eval:
  Num examples: 50000, Num correct: 46872, Precision @ 1: 0.9374
('Testing Data Eval: EPOCH->', 99)
  Num examples: 10000, Num correct: 6607, Precision @ 1: 0.6607
Step 98005: loss = 0.09775
Step 98010: loss = 0.10175
Step 98015: loss = 0.10518
Step 98020: loss = 0.12409
Step 98025: loss = 0.17330
Step 98030: loss = 0.09526
Step 98035: loss = 0.33050
Step 98040: loss = 0.08024
Step 98045: loss = 0.26115
Step 98050: loss = 0.06552
Step 98055: loss = 0.08933
Step 98060: loss = 0.26431
Step 98065: loss = 0.12035
Step 98070: loss = 0.32736
Step 98075: loss = 0.10447
Step 98080: loss = 0.12128
Step 98085: loss = 0.24108
Step 98090: loss = 0.12561
Step 98095: loss = 0.22907
Step 98100: loss = 0.42469
Step 98105: loss = 0.19936
Step 98110: loss = 0.08858
Step 98115: loss = 0.12836
Step 98120: loss = 0.06788
Step 98125: loss = 0.13312
Step 98130: loss = 0.17079
Step 98135: loss = 0.09028
Step 98140: loss = 0.14129
Step 98145: loss = 0.31939
Step 98150: loss = 0.12031
Step 98155: loss = 0.23301
Step 98160: loss = 0.08916
Step 98165: loss = 0.19877
Step 98170: loss = 0.20910
Step 98175: loss = 0.16352
Step 98180: loss = 0.18389
Step 98185: loss = 0.18520
Step 98190: loss = 0.29957
Step 98195: loss = 0.07350
Step 98200: loss = 0.23225
Step 98205: loss = 0.14807
Step 98210: loss = 0.15101
Step 98215: loss = 0.13360
Step 98220: loss = 0.10567
Step 98225: loss = 0.39367
Step 98230: loss = 0.22511
Step 98235: loss = 0.07572
Step 98240: loss = 0.32753
Step 98245: loss = 0.13840
Step 98250: loss = 0.16994
Step 98255: loss = 0.36712
Step 98260: loss = 0.11801
Step 98265: loss = 0.36745
Step 98270: loss = 0.06519
Step 98275: loss = 0.12954
Step 98280: loss = 0.19312
Step 98285: loss = 0.13556
Step 98290: loss = 0.21526
Step 98295: loss = 0.22718
Step 98300: loss = 0.28348
Step 98305: loss = 0.05448
Step 98310: loss = 0.18760
Step 98315: loss = 0.25508
Step 98320: loss = 0.07622
Step 98325: loss = 0.20005
Step 98330: loss = 0.07130
Step 98335: loss = 0.20226
Step 98340: loss = 0.12653
Step 98345: loss = 0.14441
Step 98350: loss = 0.24925
Step 98355: loss = 0.13169
Step 98360: loss = 0.07004
Step 98365: loss = 0.25887
Step 98370: loss = 0.07190
Step 98375: loss = 0.03925
Step 98380: loss = 0.24790
Step 98385: loss = 0.20136
Step 98390: loss = 0.06422
Step 98395: loss = 0.33972
Step 98400: loss = 0.08194
Step 98405: loss = 0.14016
Step 98410: loss = 0.08748
Step 98415: loss = 0.21631
Step 98420: loss = 0.16572
Step 98425: loss = 0.08985
Step 98430: loss = 0.12913
Step 98435: loss = 0.20767
Step 98440: loss = 0.15583
Step 98445: loss = 0.16995
Step 98450: loss = 0.26516
Step 98455: loss = 0.12115
Step 98460: loss = 0.30712
Step 98465: loss = 0.11642
Step 98470: loss = 0.29384
Step 98475: loss = 0.06959
Step 98480: loss = 0.16869
Step 98485: loss = 0.08580
Step 98490: loss = 0.21389
Step 98495: loss = 0.13535
Step 98500: loss = 0.16046
Step 98505: loss = 0.08779
Step 98510: loss = 0.18049
Step 98515: loss = 0.15228
Step 98520: loss = 0.08165
Step 98525: loss = 0.05059
Step 98530: loss = 0.22611
Step 98535: loss = 0.14633
Step 98540: loss = 0.10194
Step 98545: loss = 0.13682
Step 98550: loss = 0.12863
Step 98555: loss = 0.16213
Step 98560: loss = 0.22757
Step 98565: loss = 0.13876
Step 98570: loss = 0.34761
Step 98575: loss = 0.17165
Step 98580: loss = 0.11169
Step 98585: loss = 0.06276
Step 98590: loss = 0.07906
Step 98595: loss = 0.13323
Step 98600: loss = 0.18114
Step 98605: loss = 0.12960
Step 98610: loss = 0.14684
Step 98615: loss = 0.06191
Step 98620: loss = 0.11507
Step 98625: loss = 0.31122
Step 98630: loss = 0.10645
Step 98635: loss = 0.18169
Step 98640: loss = 0.02915
Step 98645: loss = 0.11654
Step 98650: loss = 0.08352
Step 98655: loss = 0.37043
Step 98660: loss = 0.16921
Step 98665: loss = 0.33759
Step 98670: loss = 0.28543
Step 98675: loss = 0.29837
Step 98680: loss = 0.34047
Step 98685: loss = 0.06524
Step 98690: loss = 0.14949
Step 98695: loss = 0.05526
Step 98700: loss = 0.15486
Step 98705: loss = 0.08194
Step 98710: loss = 0.22613
Step 98715: loss = 0.13034
Step 98720: loss = 0.20072
Step 98725: loss = 0.19600
Step 98730: loss = 0.13556
Step 98735: loss = 0.13361
Step 98740: loss = 0.11430
Step 98745: loss = 0.11381
Step 98750: loss = 0.10114
Step 98755: loss = 0.10321
Step 98760: loss = 0.16802
Step 98765: loss = 0.13038
Step 98770: loss = 0.17919
Step 98775: loss = 0.13145
Step 98780: loss = 0.24245
Step 98785: loss = 0.05424
Step 98790: loss = 0.12535
Step 98795: loss = 0.17648
Step 98800: loss = 0.06713
Step 98805: loss = 0.13040
Step 98810: loss = 0.16819
Step 98815: loss = 0.16598
Step 98820: loss = 0.15422
Step 98825: loss = 0.26376
Step 98830: loss = 0.22498
Step 98835: loss = 0.27827
Step 98840: loss = 0.17405
Step 98845: loss = 0.17528
Step 98850: loss = 0.08160
Step 98855: loss = 0.60568
Step 98860: loss = 0.23872
Step 98865: loss = 0.09505
Step 98870: loss = 0.19333
Step 98875: loss = 0.16093
Step 98880: loss = 0.23193
Step 98885: loss = 0.16811
Step 98890: loss = 0.26406
Step 98895: loss = 0.16032
Step 98900: loss = 0.42251
Step 98905: loss = 0.16303
Step 98910: loss = 0.14500
Step 98915: loss = 0.10452
Step 98920: loss = 0.25741
Step 98925: loss = 0.19213
Step 98930: loss = 0.09553
Step 98935: loss = 0.21533
Step 98940: loss = 0.30287
Step 98945: loss = 0.17046
Step 98950: loss = 0.13733
Step 98955: loss = 0.30017
Step 98960: loss = 0.23098
Step 98965: loss = 0.15196
Step 98970: loss = 0.23146
Step 98975: loss = 0.17530
Step 98980: loss = 0.30594
Step 98985: loss = 0.23526
Step 98990: loss = 0.24146
Step 98995: loss = 0.13417
Step 99000: loss = 0.06840
Training Data Eval:
  Num examples: 50000, Num correct: 47172, Precision @ 1: 0.9434
('Testing Data Eval: EPOCH->', 100)
  Num examples: 10000, Num correct: 6693, Precision @ 1: 0.6693
Step 99005: loss = 0.13592
Step 99010: loss = 0.14939
Step 99015: loss = 0.13747
Step 99020: loss = 0.07696
Step 99025: loss = 0.14176
Step 99030: loss = 0.35141
Step 99035: loss = 0.27359
Step 99040: loss = 0.23563
Step 99045: loss = 0.13969
Step 99050: loss = 0.34677
Step 99055: loss = 0.24633
Step 99060: loss = 0.15793
Step 99065: loss = 0.34459
Step 99070: loss = 0.28076
Step 99075: loss = 0.06961
Step 99080: loss = 0.18411
Step 99085: loss = 0.46663
Step 99090: loss = 0.11048
Step 99095: loss = 0.33941
Step 99100: loss = 0.27861
Step 99105: loss = 0.16269
Step 99110: loss = 0.28923
Step 99115: loss = 0.27648
Step 99120: loss = 0.07198
Step 99125: loss = 0.07819
Step 99130: loss = 0.09752
Step 99135: loss = 0.35475
Step 99140: loss = 0.10111
Step 99145: loss = 0.14329
Step 99150: loss = 0.21647
Step 99155: loss = 0.09409
Step 99160: loss = 0.12793
Step 99165: loss = 0.38313
Step 99170: loss = 0.10822
Step 99175: loss = 0.15674
Step 99180: loss = 0.07697
Step 99185: loss = 0.12885
Step 99190: loss = 0.15651
Step 99195: loss = 0.12600
Step 99200: loss = 0.14527
Step 99205: loss = 0.17677
Step 99210: loss = 0.07563
Step 99215: loss = 0.11747
Step 99220: loss = 0.23447
Step 99225: loss = 0.15719
Step 99230: loss = 0.15600
Step 99235: loss = 0.16677
Step 99240: loss = 0.37219
Step 99245: loss = 0.12501
Step 99250: loss = 0.12729
Step 99255: loss = 0.16518
Step 99260: loss = 0.03541
Step 99265: loss = 0.18874
Step 99270: loss = 0.16905
Step 99275: loss = 0.09762
Step 99280: loss = 0.13908
Step 99285: loss = 0.22480
Step 99290: loss = 0.37958
Step 99295: loss = 0.19114
Step 99300: loss = 0.16403
Step 99305: loss = 0.41146
Step 99310: loss = 0.12065
Step 99315: loss = 0.33165
Step 99320: loss = 0.05495
Step 99325: loss = 0.06940
Step 99330: loss = 0.47404
Step 99335: loss = 0.10778
Step 99340: loss = 0.22406
Step 99345: loss = 0.12809
Step 99350: loss = 0.20056
Step 99355: loss = 0.12335
Step 99360: loss = 0.15388
Step 99365: loss = 0.11927
Step 99370: loss = 0.04841
Step 99375: loss = 0.28337
Step 99380: loss = 0.14209
Step 99385: loss = 0.27489
Step 99390: loss = 0.14499
Step 99395: loss = 0.11720
Step 99400: loss = 0.06188
Step 99405: loss = 0.35759
Step 99410: loss = 0.24540
Step 99415: loss = 0.10243
Step 99420: loss = 0.12294
Step 99425: loss = 0.17450
Step 99430: loss = 0.23775
Step 99435: loss = 0.15840
Step 99440: loss = 0.19066
Step 99445: loss = 0.33437
Step 99450: loss = 0.17463
Step 99455: loss = 0.20991
Step 99460: loss = 0.05015
Step 99465: loss = 0.36770
Step 99470: loss = 0.19171
Step 99475: loss = 0.18468
Step 99480: loss = 0.02592
Step 99485: loss = 0.35654
Step 99490: loss = 0.19131
Step 99495: loss = 0.23544
Step 99500: loss = 0.13781
Step 99505: loss = 0.07709
Step 99510: loss = 0.05823
Step 99515: loss = 0.15086
Step 99520: loss = 0.16712
Step 99525: loss = 0.06743
Step 99530: loss = 0.12324
Step 99535: loss = 0.09589
Step 99540: loss = 0.28215
Step 99545: loss = 0.07570
Step 99550: loss = 0.14481
Step 99555: loss = 0.22548
Step 99560: loss = 0.30745
Step 99565: loss = 0.19750
Step 99570: loss = 0.30086
Step 99575: loss = 0.08757
Step 99580: loss = 0.38255
Step 99585: loss = 0.28592
Step 99590: loss = 0.15379
Step 99595: loss = 0.22248
Step 99600: loss = 0.19994
Step 99605: loss = 0.19686
Step 99610: loss = 0.13620
Step 99615: loss = 0.31994
Step 99620: loss = 0.09380
Step 99625: loss = 0.31946
Step 99630: loss = 0.11749
Step 99635: loss = 0.14398
Step 99640: loss = 0.31478
Step 99645: loss = 0.26809
Step 99650: loss = 0.45890
Step 99655: loss = 0.11728
Step 99660: loss = 0.11777
Step 99665: loss = 0.16406
Step 99670: loss = 0.10915
Step 99675: loss = 0.19831
Step 99680: loss = 0.27404
Step 99685: loss = 0.35877
Step 99690: loss = 0.14024
Step 99695: loss = 0.05434
Step 99700: loss = 0.55212
Step 99705: loss = 0.21562
Step 99710: loss = 0.11683
Step 99715: loss = 0.08431
Step 99720: loss = 0.50564
Step 99725: loss = 0.24865
Step 99730: loss = 0.17821
Step 99735: loss = 0.10745
Step 99740: loss = 0.09361
Step 99745: loss = 0.09759
Step 99750: loss = 0.15163
Step 99755: loss = 0.04642
Step 99760: loss = 0.19419
Step 99765: loss = 0.33329
Step 99770: loss = 0.08367
Step 99775: loss = 0.15551
Step 99780: loss = 0.12091
Step 99785: loss = 0.07690
Step 99790: loss = 0.08385
Step 99795: loss = 0.08505
Step 99800: loss = 0.13448
Step 99805: loss = 0.25296
Step 99810: loss = 0.25950
Step 99815: loss = 0.26378
Step 99820: loss = 0.18994
Step 99825: loss = 0.15039
Step 99830: loss = 0.18644
Step 99835: loss = 0.17307
Step 99840: loss = 0.16029
Step 99845: loss = 0.10433
Step 99850: loss = 0.26764
Step 99855: loss = 0.18936
Step 99860: loss = 0.38314
Step 99865: loss = 0.18258
Step 99870: loss = 0.22100
Step 99875: loss = 0.27101
Step 99880: loss = 0.03305
Step 99885: loss = 0.18418
Step 99890: loss = 0.39487
Step 99895: loss = 0.08382
Step 99900: loss = 0.07613
Step 99905: loss = 0.22163
Step 99910: loss = 0.39597
Step 99915: loss = 0.33975
Step 99920: loss = 0.19328
Step 99925: loss = 0.12756
Step 99930: loss = 0.10194
Step 99935: loss = 0.05661
Step 99940: loss = 0.08351
Step 99945: loss = 0.06910
Step 99950: loss = 0.16839
Step 99955: loss = 0.02757
Step 99960: loss = 0.21045
Step 99965: loss = 0.07562
Step 99970: loss = 0.26422
Step 99975: loss = 0.16029
Step 99980: loss = 0.10991
Step 99985: loss = 0.27719
Step 99990: loss = 0.22364
Step 99995: loss = 0.06468
Step 100000: loss = 0.16265
Training Data Eval:
  Num examples: 50000, Num correct: 47161, Precision @ 1: 0.9432
('Testing Data Eval: EPOCH->', 101)
  Num examples: 10000, Num correct: 6614, Precision @ 1: 0.6614
Step 100005: loss = 0.07334
Step 100010: loss = 0.13259
Step 100015: loss = 0.17271
Step 100020: loss = 0.15858
Step 100025: loss = 0.24284
Step 100030: loss = 0.05516
Step 100035: loss = 0.08355
Step 100040: loss = 0.10739
Step 100045: loss = 0.09966
Step 100050: loss = 0.10304
Step 100055: loss = 0.09047
Step 100060: loss = 0.18523
Step 100065: loss = 0.32578
Step 100070: loss = 0.14412
Step 100075: loss = 0.33455
Step 100080: loss = 0.13499
Step 100085: loss = 0.27750
Step 100090: loss = 0.03056
Step 100095: loss = 0.16921
Step 100100: loss = 0.23345
Step 100105: loss = 0.14082
Step 100110: loss = 0.13871
Step 100115: loss = 0.06681
Step 100120: loss = 0.28199
Step 100125: loss = 0.19884
Step 100130: loss = 0.14040
Step 100135: loss = 0.20656
Step 100140: loss = 0.08038
Step 100145: loss = 0.11281
Step 100150: loss = 0.08997
Step 100155: loss = 0.12913
Step 100160: loss = 0.32009
Step 100165: loss = 0.13064
Step 100170: loss = 0.14051
Step 100175: loss = 0.07364
Step 100180: loss = 0.29392
Step 100185: loss = 0.23158
Step 100190: loss = 0.06782
Step 100195: loss = 0.04081
Step 100200: loss = 0.25602
Step 100205: loss = 0.15955
Step 100210: loss = 0.11817
Step 100215: loss = 0.09472
Step 100220: loss = 0.24764
Step 100225: loss = 0.22477
Step 100230: loss = 0.07769
Step 100235: loss = 0.14428
Step 100240: loss = 0.04749
Step 100245: loss = 0.12393
Step 100250: loss = 0.09524
Step 100255: loss = 0.19099
Step 100260: loss = 0.10510
Step 100265: loss = 0.40327
Step 100270: loss = 0.04334
Step 100275: loss = 0.32632
Step 100280: loss = 0.15177
Step 100285: loss = 0.17204
Step 100290: loss = 0.09725
Step 100295: loss = 0.07248
Step 100300: loss = 0.05553
Step 100305: loss = 0.15187
Step 100310: loss = 0.27001
Step 100315: loss = 0.14789
Step 100320: loss = 0.17371
Step 100325: loss = 0.25574
Step 100330: loss = 0.16312
Step 100335: loss = 0.18792
Step 100340: loss = 0.18935
Step 100345: loss = 0.18336
Step 100350: loss = 0.08403
Step 100355: loss = 0.16757
Step 100360: loss = 0.33173
Step 100365: loss = 0.24394
Step 100370: loss = 0.09989
Step 100375: loss = 0.23801
Step 100380: loss = 0.10109
Step 100385: loss = 0.12168
Step 100390: loss = 0.19201
Step 100395: loss = 0.22945
Step 100400: loss = 0.15588
Step 100405: loss = 0.12150
Step 100410: loss = 0.21321
Step 100415: loss = 0.10606
Step 100420: loss = 0.17904
Step 100425: loss = 0.14172
Step 100430: loss = 0.08474
Step 100435: loss = 0.17176
Step 100440: loss = 0.12346
Step 100445: loss = 0.13108
Step 100450: loss = 0.37341
Step 100455: loss = 0.15886
Step 100460: loss = 0.11615
Step 100465: loss = 0.06918
Step 100470: loss = 0.28997
Step 100475: loss = 0.27659
Step 100480: loss = 0.19422
Step 100485: loss = 0.31702
Step 100490: loss = 0.16690
Step 100495: loss = 0.14394
Step 100500: loss = 0.14671
Step 100505: loss = 0.16812
Step 100510: loss = 0.19827
Step 100515: loss = 0.19389
Step 100520: loss = 0.18291
Step 100525: loss = 0.34541
Step 100530: loss = 0.32157
Step 100535: loss = 0.47840
Step 100540: loss = 0.07453
Step 100545: loss = 0.10622
Step 100550: loss = 0.17290
Step 100555: loss = 0.31310
Step 100560: loss = 0.06257
Step 100565: loss = 0.32517
Step 100570: loss = 0.35704
Step 100575: loss = 0.22390
Step 100580: loss = 0.02360
Step 100585: loss = 0.24074
Step 100590: loss = 0.20883
Step 100595: loss = 0.22851
Step 100600: loss = 0.14791
Step 100605: loss = 0.15239
Step 100610: loss = 0.17211
Step 100615: loss = 0.28748
Step 100620: loss = 0.32882
Step 100625: loss = 0.02981
Step 100630: loss = 0.13434
Step 100635: loss = 0.07152
Step 100640: loss = 0.23488
Step 100645: loss = 0.22912
Step 100650: loss = 0.08217
Step 100655: loss = 0.21253
Step 100660: loss = 0.23982
Step 100665: loss = 0.23586
Step 100670: loss = 0.16286
Step 100675: loss = 0.08789
Step 100680: loss = 0.35918
Step 100685: loss = 0.14467
Step 100690: loss = 0.33894
Step 100695: loss = 0.08984
Step 100700: loss = 0.19428
Step 100705: loss = 0.11677
Step 100710: loss = 0.13270
Step 100715: loss = 0.13865
Step 100720: loss = 0.10837
Step 100725: loss = 0.12519
Step 100730: loss = 0.30705
Step 100735: loss = 0.15341
Step 100740: loss = 0.18637
Step 100745: loss = 0.12124
Step 100750: loss = 0.33284
Step 100755: loss = 0.12402
Step 100760: loss = 0.38052
Step 100765: loss = 0.12635
Step 100770: loss = 0.04318
Step 100775: loss = 0.14079
Step 100780: loss = 0.08188
Step 100785: loss = 0.33594
Step 100790: loss = 0.17412
Step 100795: loss = 0.07749
Step 100800: loss = 0.15065
Step 100805: loss = 0.35883
Step 100810: loss = 0.18709
Step 100815: loss = 0.26721
Step 100820: loss = 0.21983
Step 100825: loss = 0.14295
Step 100830: loss = 0.18921
Step 100835: loss = 0.20578
Step 100840: loss = 0.11909
Step 100845: loss = 0.35328
Step 100850: loss = 0.09836
Step 100855: loss = 0.14605
Step 100860: loss = 0.20606
Step 100865: loss = 0.15520
Step 100870: loss = 0.17295
Step 100875: loss = 0.08876
Step 100880: loss = 0.07237
Step 100885: loss = 0.15281
Step 100890: loss = 0.09265
Step 100895: loss = 0.11360
Step 100900: loss = 0.19277
Step 100905: loss = 0.43712
Step 100910: loss = 0.08460
Step 100915: loss = 0.13665
Step 100920: loss = 0.11942
Step 100925: loss = 0.34907
Step 100930: loss = 0.11879
Step 100935: loss = 0.23118
Step 100940: loss = 0.11840
Step 100945: loss = 0.27685
Step 100950: loss = 0.10357
Step 100955: loss = 0.31708
Step 100960: loss = 0.08679
Step 100965: loss = 0.24224
Step 100970: loss = 0.12260
Step 100975: loss = 0.24115
Step 100980: loss = 0.26294
Step 100985: loss = 0.10224
Step 100990: loss = 0.09847
Step 100995: loss = 0.11281
Step 101000: loss = 0.27361
Training Data Eval:
  Num examples: 50000, Num correct: 47098, Precision @ 1: 0.9420
('Testing Data Eval: EPOCH->', 102)
  Num examples: 10000, Num correct: 6687, Precision @ 1: 0.6687
Step 101005: loss = 0.19636
Step 101010: loss = 0.06199
Step 101015: loss = 0.14225
Step 101020: loss = 0.17428
Step 101025: loss = 0.01443
Step 101030: loss = 0.07045
Step 101035: loss = 0.21291
Step 101040: loss = 0.10122
Step 101045: loss = 0.09368
Step 101050: loss = 0.04200
Step 101055: loss = 0.18874
Step 101060: loss = 0.20017
Step 101065: loss = 0.19805
Step 101070: loss = 0.14237
Step 101075: loss = 0.14795
Step 101080: loss = 0.11275
Step 101085: loss = 0.15439
Step 101090: loss = 0.14808
Step 101095: loss = 0.06135
Step 101100: loss = 0.13094
Step 101105: loss = 0.13586
Step 101110: loss = 0.19399
Step 101115: loss = 0.29486
Step 101120: loss = 0.11085
Step 101125: loss = 0.32813
Step 101130: loss = 0.07556
Step 101135: loss = 0.10374
Step 101140: loss = 0.10861
Step 101145: loss = 0.32892
Step 101150: loss = 0.11973
Step 101155: loss = 0.25262
Step 101160: loss = 0.21248
Step 101165: loss = 0.15670
Step 101170: loss = 0.10434
Step 101175: loss = 0.18150
Step 101180: loss = 0.12912
Step 101185: loss = 0.14158
Step 101190: loss = 0.21272
Step 101195: loss = 0.14890
Step 101200: loss = 0.06733
Step 101205: loss = 0.26739
Step 101210: loss = 0.23614
Step 101215: loss = 0.11816
Step 101220: loss = 0.07402
Step 101225: loss = 0.12916
Step 101230: loss = 0.21678
Step 101235: loss = 0.08063
Step 101240: loss = 0.24296
Step 101245: loss = 0.26118
Step 101250: loss = 0.16264
Step 101255: loss = 0.18034
Step 101260: loss = 0.09379
Step 101265: loss = 0.13226
Step 101270: loss = 0.06588
Step 101275: loss = 0.10266
Step 101280: loss = 0.06873
Step 101285: loss = 0.15256
Step 101290: loss = 0.11968
Step 101295: loss = 0.09487
Step 101300: loss = 0.08973
Step 101305: loss = 0.17006
Step 101310: loss = 0.18456
Step 101315: loss = 0.52766
Step 101320: loss = 0.08683
Step 101325: loss = 0.08798
Step 101330: loss = 0.11195
Step 101335: loss = 0.09467
Step 101340: loss = 0.29184
Step 101345: loss = 0.08113
Step 101350: loss = 0.17323
Step 101355: loss = 0.06446
Step 101360: loss = 0.24664
Step 101365: loss = 0.18027
Step 101370: loss = 0.15186
Step 101375: loss = 0.22876
Step 101380: loss = 0.28585
Step 101385: loss = 0.09409
Step 101390: loss = 0.15720
Step 101395: loss = 0.20294
Step 101400: loss = 0.08404
Step 101405: loss = 0.21730
Step 101410: loss = 0.32382
Step 101415: loss = 0.31266
Step 101420: loss = 0.09241
Step 101425: loss = 0.07110
Step 101430: loss = 0.10387
Step 101435: loss = 0.12297
Step 101440: loss = 0.12671
Step 101445: loss = 0.07351
Step 101450: loss = 0.21878
Step 101455: loss = 0.12080
Step 101460: loss = 0.20955
Step 101465: loss = 0.10660
Step 101470: loss = 0.07754
Step 101475: loss = 0.24001
Step 101480: loss = 0.10765
Step 101485: loss = 0.21861
Step 101490: loss = 0.16255
Step 101495: loss = 0.16732
Step 101500: loss = 0.27772
Step 101505: loss = 0.11980
Step 101510: loss = 0.18251
Step 101515: loss = 0.36632
Step 101520: loss = 0.11146
Step 101525: loss = 0.20660
Step 101530: loss = 0.15509
Step 101535: loss = 0.13604
Step 101540: loss = 0.14139
Step 101545: loss = 0.16995
Step 101550: loss = 0.02772
Step 101555: loss = 0.11708
Step 101560: loss = 0.05375
Step 101565: loss = 0.19931
Step 101570: loss = 0.12278
Step 101575: loss = 0.09412
Step 101580: loss = 0.08544
Step 101585: loss = 0.10105
Step 101590: loss = 0.17449
Step 101595: loss = 0.11374
Step 101600: loss = 0.13803
Step 101605: loss = 0.12626
Step 101610: loss = 0.08417
Step 101615: loss = 0.12508
Step 101620: loss = 0.06003
Step 101625: loss = 0.12235
Step 101630: loss = 0.13228
Step 101635: loss = 0.26265
Step 101640: loss = 0.15600
Step 101645: loss = 0.10777
Step 101650: loss = 0.23172
Step 101655: loss = 0.10879
Step 101660: loss = 0.28705
Step 101665: loss = 0.18019
Step 101670: loss = 0.16412
Step 101675: loss = 0.11287
Step 101680: loss = 0.12914
Step 101685: loss = 0.46370
Step 101690: loss = 0.11395
Step 101695: loss = 0.21373
Step 101700: loss = 0.08424
Step 101705: loss = 0.15723
Step 101710: loss = 0.19171
Step 101715: loss = 0.29982
Step 101720: loss = 0.17464
Step 101725: loss = 0.20070
Step 101730: loss = 0.21528
Step 101735: loss = 0.14760
Step 101740: loss = 0.17865
Step 101745: loss = 0.06803
Step 101750: loss = 0.10691
Step 101755: loss = 0.17262
Step 101760: loss = 0.17280
Step 101765: loss = 0.12023
Step 101770: loss = 0.09760
Step 101775: loss = 0.08954
Step 101780: loss = 0.29719
Step 101785: loss = 0.16402
Step 101790: loss = 0.19202
Step 101795: loss = 0.26871
Step 101800: loss = 0.05461
Step 101805: loss = 0.15108
Step 101810: loss = 0.11626
Step 101815: loss = 0.10101
Step 101820: loss = 0.14444
Step 101825: loss = 0.12212
Step 101830: loss = 0.40789
Step 101835: loss = 0.43493
Step 101840: loss = 0.25538
Step 101845: loss = 0.16357
Step 101850: loss = 0.15680
Step 101855: loss = 0.25385
Step 101860: loss = 0.08881
Step 101865: loss = 0.23047
Step 101870: loss = 0.06909
Step 101875: loss = 0.16891
Step 101880: loss = 0.20855
Step 101885: loss = 0.05336
Step 101890: loss = 0.16667
Step 101895: loss = 0.39146
Step 101900: loss = 0.21101
Step 101905: loss = 0.10296
Step 101910: loss = 0.09918
Step 101915: loss = 0.12541
Step 101920: loss = 0.30055
Step 101925: loss = 0.22913
Step 101930: loss = 0.27992
Step 101935: loss = 0.15463
Step 101940: loss = 0.28704
Step 101945: loss = 0.33020
Step 101950: loss = 0.28211
Step 101955: loss = 0.25292
Step 101960: loss = 0.22231
Step 101965: loss = 0.30587
Step 101970: loss = 0.19713
Step 101975: loss = 0.25044
Step 101980: loss = 0.09809
Step 101985: loss = 0.09756
Step 101990: loss = 0.17755
Step 101995: loss = 0.16943
Step 102000: loss = 0.11167
Training Data Eval:
  Num examples: 50000, Num correct: 47254, Precision @ 1: 0.9451
('Testing Data Eval: EPOCH->', 103)
  Num examples: 10000, Num correct: 6611, Precision @ 1: 0.6611
Step 102005: loss = 0.38510
Step 102010: loss = 0.27094
Step 102015: loss = 0.10037
Step 102020: loss = 0.16293
Step 102025: loss = 0.09227
Step 102030: loss = 0.24355
Step 102035: loss = 0.08685
Step 102040: loss = 0.07780
Step 102045: loss = 0.20044
Step 102050: loss = 0.09502
Step 102055: loss = 0.52137
Step 102060: loss = 0.18942
Step 102065: loss = 0.08383
Step 102070: loss = 0.19319
Step 102075: loss = 0.29755
Step 102080: loss = 0.06658
Step 102085: loss = 0.34048
Step 102090: loss = 0.04927
Step 102095: loss = 0.53361
Step 102100: loss = 0.18828
Step 102105: loss = 0.18789
Step 102110: loss = 0.31618
Step 102115: loss = 0.13164
Step 102120: loss = 0.07424
Step 102125: loss = 0.08610
Step 102130: loss = 0.31167
Step 102135: loss = 0.16004
Step 102140: loss = 0.15933
Step 102145: loss = 0.15015
Step 102150: loss = 0.11405
Step 102155: loss = 0.25438
Step 102160: loss = 0.26344
Step 102165: loss = 0.07688
Step 102170: loss = 0.08861
Step 102175: loss = 0.09795
Step 102180: loss = 0.16167
Step 102185: loss = 0.24569
Step 102190: loss = 0.26879
Step 102195: loss = 0.21527
Step 102200: loss = 0.05910
Step 102205: loss = 0.24738
Step 102210: loss = 0.27219
Step 102215: loss = 0.24244
Step 102220: loss = 0.15654
Step 102225: loss = 0.09090
Step 102230: loss = 0.20577
Step 102235: loss = 0.28422
Step 102240: loss = 0.21666
Step 102245: loss = 0.16491
Step 102250: loss = 0.09035
Step 102255: loss = 0.13143
Step 102260: loss = 0.08320
Step 102265: loss = 0.06425
Step 102270: loss = 0.52788
Step 102275: loss = 0.09412
Step 102280: loss = 0.11924
Step 102285: loss = 0.17724
Step 102290: loss = 0.31405
Step 102295: loss = 0.30797
Step 102300: loss = 0.29354
Step 102305: loss = 0.11121
Step 102310: loss = 0.16614
Step 102315: loss = 0.34097
Step 102320: loss = 0.05557
Step 102325: loss = 0.09939
Step 102330: loss = 0.17269
Step 102335: loss = 0.22458
Step 102340: loss = 0.23241
Step 102345: loss = 0.11089
Step 102350: loss = 0.09774
Step 102355: loss = 0.10285
Step 102360: loss = 0.14219
Step 102365: loss = 0.35985
Step 102370: loss = 0.09856
Step 102375: loss = 0.21531
Step 102380: loss = 0.07620
Step 102385: loss = 0.13443
Step 102390: loss = 0.08878
Step 102395: loss = 0.15749
Step 102400: loss = 0.23877
Step 102405: loss = 0.12189
Step 102410: loss = 0.14982
Step 102415: loss = 0.08173
Step 102420: loss = 0.20626
Step 102425: loss = 0.08903
Step 102430: loss = 0.11021
Step 102435: loss = 0.33021
Step 102440: loss = 0.14578
Step 102445: loss = 0.12349
Step 102450: loss = 0.24847
Step 102455: loss = 0.12156
Step 102460: loss = 0.07010
Step 102465: loss = 0.09729
Step 102470: loss = 0.12787
Step 102475: loss = 0.22415
Step 102480: loss = 0.27628
Step 102485: loss = 0.14185
Step 102490: loss = 0.04356
Step 102495: loss = 0.09508
Step 102500: loss = 0.59571
Step 102505: loss = 0.10544
Step 102510: loss = 0.13185
Step 102515: loss = 0.07041
Step 102520: loss = 0.25209
Step 102525: loss = 0.24880
Step 102530: loss = 0.10988
Step 102535: loss = 0.22606
Step 102540: loss = 0.20916
Step 102545: loss = 0.10098
Step 102550: loss = 0.16958
Step 102555: loss = 0.12175
Step 102560: loss = 0.12731
Step 102565: loss = 0.18151
Step 102570: loss = 0.04934
Step 102575: loss = 0.21420
Step 102580: loss = 0.02019
Step 102585: loss = 0.15472
Step 102590: loss = 0.09326
Step 102595: loss = 0.16454
Step 102600: loss = 0.11517
Step 102605: loss = 0.27930
Step 102610: loss = 0.21447
Step 102615: loss = 0.25188
Step 102620: loss = 0.10786
Step 102625: loss = 0.12333
Step 102630: loss = 0.19760
Step 102635: loss = 0.15131
Step 102640: loss = 0.17109
Step 102645: loss = 0.06583
Step 102650: loss = 0.16236
Step 102655: loss = 0.17920
Step 102660: loss = 0.16126
Step 102665: loss = 0.14217
Step 102670: loss = 0.07134
Step 102675: loss = 0.24172
Step 102680: loss = 0.16119
Step 102685: loss = 0.12144
Step 102690: loss = 0.30740
Step 102695: loss = 0.21633
Step 102700: loss = 0.19169
Step 102705: loss = 0.08852
Step 102710: loss = 0.11083
Step 102715: loss = 0.14739
Step 102720: loss = 0.07434
Step 102725: loss = 0.13077
Step 102730: loss = 0.16910
Step 102735: loss = 0.21488
Step 102740: loss = 0.30653
Step 102745: loss = 0.05364
Step 102750: loss = 0.17863
Step 102755: loss = 0.17831
Step 102760: loss = 0.11017
Step 102765: loss = 0.03829
Step 102770: loss = 0.13831
Step 102775: loss = 0.09699
Step 102780: loss = 0.19148
Step 102785: loss = 0.11717
Step 102790: loss = 0.09442
Step 102795: loss = 0.35034
Step 102800: loss = 0.24022
Step 102805: loss = 0.20213
Step 102810: loss = 0.09860
Step 102815: loss = 0.27560
Step 102820: loss = 0.15731
Step 102825: loss = 0.12187
Step 102830: loss = 0.22510
Step 102835: loss = 0.13280
Step 102840: loss = 0.24598
Step 102845: loss = 0.16897
Step 102850: loss = 0.07268
Step 102855: loss = 0.11486
Step 102860: loss = 0.26419
Step 102865: loss = 0.16667
Step 102870: loss = 0.23701
Step 102875: loss = 0.39257
Step 102880: loss = 0.20537
Step 102885: loss = 0.14619
Step 102890: loss = 0.27420
Step 102895: loss = 0.47023
Step 102900: loss = 0.10022
Step 102905: loss = 0.05712
Step 102910: loss = 0.31060
Step 102915: loss = 0.10544
Step 102920: loss = 0.17919
Step 102925: loss = 0.25484
Step 102930: loss = 0.14576
Step 102935: loss = 0.25762
Step 102940: loss = 0.06643
Step 102945: loss = 0.06971
Step 102950: loss = 0.11366
Step 102955: loss = 0.08453
Step 102960: loss = 0.13146
Step 102965: loss = 0.19906
Step 102970: loss = 0.30045
Step 102975: loss = 0.17092
Step 102980: loss = 0.19699
Step 102985: loss = 0.28355
Step 102990: loss = 0.14117
Step 102995: loss = 0.09528
Step 103000: loss = 0.07270
Training Data Eval:
  Num examples: 50000, Num correct: 47355, Precision @ 1: 0.9471
('Testing Data Eval: EPOCH->', 104)
  Num examples: 10000, Num correct: 6613, Precision @ 1: 0.6613
Step 103005: loss = 0.19003
Step 103010: loss = 0.11105
Step 103015: loss = 0.22303
Step 103020: loss = 0.06440
Step 103025: loss = 0.07226
Step 103030: loss = 0.26182
Step 103035: loss = 0.14223
Step 103040: loss = 0.14857
Step 103045: loss = 0.10582
Step 103050: loss = 0.19740
Step 103055: loss = 0.14060
Step 103060: loss = 0.09071
Step 103065: loss = 0.08380
Step 103070: loss = 0.19381
Step 103075: loss = 0.22072
Step 103080: loss = 0.14164
Step 103085: loss = 0.07936
Step 103090: loss = 0.10240
Step 103095: loss = 0.23992
Step 103100: loss = 0.16792
Step 103105: loss = 0.15335
Step 103110: loss = 0.21989
Step 103115: loss = 0.15572
Step 103120: loss = 0.08984
Step 103125: loss = 0.02117
Step 103130: loss = 0.21030
Step 103135: loss = 0.09681
Step 103140: loss = 0.18953
Step 103145: loss = 0.15514
Step 103150: loss = 0.10740
Step 103155: loss = 0.44957
Step 103160: loss = 0.08544
Step 103165: loss = 0.16688
Step 103170: loss = 0.31125
Step 103175: loss = 0.26581
Step 103180: loss = 0.17648
Step 103185: loss = 0.12797
Step 103190: loss = 0.02312
Step 103195: loss = 0.19942
Step 103200: loss = 0.04480
Step 103205: loss = 0.06875
Step 103210: loss = 0.08430
Step 103215: loss = 0.27843
Step 103220: loss = 0.09744
Step 103225: loss = 0.18408
Step 103230: loss = 0.27148
Step 103235: loss = 0.34247
Step 103240: loss = 0.13657
Step 103245: loss = 0.06049
Step 103250: loss = 0.27739
Step 103255: loss = 0.08649
Step 103260: loss = 0.24669
Step 103265: loss = 0.53840
Step 103270: loss = 0.08356
Step 103275: loss = 0.09063
Step 103280: loss = 0.20975
Step 103285: loss = 0.09941
Step 103290: loss = 0.08930
Step 103295: loss = 0.07085
Step 103300: loss = 0.08364
Step 103305: loss = 0.09491
Step 103310: loss = 0.36808
Step 103315: loss = 0.02177
Step 103320: loss = 0.30606
Step 103325: loss = 0.06397
Step 103330: loss = 0.10981
Step 103335: loss = 0.17018
Step 103340: loss = 0.11285
Step 103345: loss = 0.12278
Step 103350: loss = 0.26795
Step 103355: loss = 0.05437
Step 103360: loss = 0.20714
Step 103365: loss = 0.11161
Step 103370: loss = 0.18628
Step 103375: loss = 0.13441
Step 103380: loss = 0.21810
Step 103385: loss = 0.08321
Step 103390: loss = 0.27065
Step 103395: loss = 0.32968
Step 103400: loss = 0.15900
Step 103405: loss = 0.15847
Step 103410: loss = 0.09943
Step 103415: loss = 0.09670
Step 103420: loss = 0.25951
Step 103425: loss = 0.05008
Step 103430: loss = 0.26136
Step 103435: loss = 0.12591
Step 103440: loss = 0.29394
Step 103445: loss = 0.10871
Step 103450: loss = 0.18488
Step 103455: loss = 0.28890
Step 103460: loss = 0.13603
Step 103465: loss = 0.48202
Step 103470: loss = 0.16447
Step 103475: loss = 0.33573
Step 103480: loss = 0.11886
Step 103485: loss = 0.06174
Step 103490: loss = 0.03526
Step 103495: loss = 0.22497
Step 103500: loss = 0.21487
Step 103505: loss = 0.12874
Step 103510: loss = 0.11302
Step 103515: loss = 0.11491
Step 103520: loss = 0.14511
Step 103525: loss = 0.33744
Step 103530: loss = 0.19814
Step 103535: loss = 0.20696
Step 103540: loss = 0.19147
Step 103545: loss = 0.18664
Step 103550: loss = 0.05410
Step 103555: loss = 0.14570
Step 103560: loss = 0.11283
Step 103565: loss = 0.13082
Step 103570: loss = 0.27599
Step 103575: loss = 0.27383
Step 103580: loss = 0.17476
Step 103585: loss = 0.17881
Step 103590: loss = 0.14750
Step 103595: loss = 0.11885
Step 103600: loss = 0.10324
Step 103605: loss = 0.29934
Step 103610: loss = 0.24399
Step 103615: loss = 0.19159
Step 103620: loss = 0.18008
Step 103625: loss = 0.07763
Step 103630: loss = 0.21474
Step 103635: loss = 0.17026
Step 103640: loss = 0.12656
Step 103645: loss = 0.03798
Step 103650: loss = 0.10662
Step 103655: loss = 0.14192
Step 103660: loss = 0.24671
Step 103665: loss = 0.10169
Step 103670: loss = 0.23521
Step 103675: loss = 0.06674
Step 103680: loss = 0.31403
Step 103685: loss = 0.14037
Step 103690: loss = 0.09960
Step 103695: loss = 0.12679
Step 103700: loss = 0.15323
Step 103705: loss = 0.12200
Step 103710: loss = 0.11150
Step 103715: loss = 0.11959
Step 103720: loss = 0.05057
Step 103725: loss = 0.17610
Step 103730: loss = 0.16980
Step 103735: loss = 0.27227
Step 103740: loss = 0.30987
Step 103745: loss = 0.12855
Step 103750: loss = 0.05821
Step 103755: loss = 0.11683
Step 103760: loss = 0.09646
Step 103765: loss = 0.14728
Step 103770: loss = 0.13798
Step 103775: loss = 0.20706
Step 103780: loss = 0.08913
Step 103785: loss = 0.09941
Step 103790: loss = 0.05175
Step 103795: loss = 0.21987
Step 103800: loss = 0.10438
Step 103805: loss = 0.08947
Step 103810: loss = 0.12012
Step 103815: loss = 0.23092
Step 103820: loss = 0.12666
Step 103825: loss = 0.08052
Step 103830: loss = 0.27249
Step 103835: loss = 0.16115
Step 103840: loss = 0.16190
Step 103845: loss = 0.27265
Step 103850: loss = 0.29955
Step 103855: loss = 0.18848
Step 103860: loss = 0.17387
Step 103865: loss = 0.04643
Step 103870: loss = 0.21023
Step 103875: loss = 0.21948
Step 103880: loss = 0.08209
Step 103885: loss = 0.13266
Step 103890: loss = 0.08169
Step 103895: loss = 0.24392
Step 103900: loss = 0.13766
Step 103905: loss = 0.07318
Step 103910: loss = 0.16440
Step 103915: loss = 0.06929
Step 103920: loss = 0.22938
Step 103925: loss = 0.10374
Step 103930: loss = 0.35462
Step 103935: loss = 0.15815
Step 103940: loss = 0.06156
Step 103945: loss = 0.17917
Step 103950: loss = 0.21139
Step 103955: loss = 0.12813
Step 103960: loss = 0.16679
Step 103965: loss = 0.15440
Step 103970: loss = 0.13375
Step 103975: loss = 0.07682
Step 103980: loss = 0.14874
Step 103985: loss = 0.12497
Step 103990: loss = 0.22905
Step 103995: loss = 0.24578
Step 104000: loss = 0.11300
Training Data Eval:
  Num examples: 50000, Num correct: 47315, Precision @ 1: 0.9463
('Testing Data Eval: EPOCH->', 105)
  Num examples: 10000, Num correct: 6560, Precision @ 1: 0.6560
Step 104005: loss = 0.13316
Step 104010: loss = 0.09607
Step 104015: loss = 0.12967
Step 104020: loss = 0.44587
Step 104025: loss = 0.09372
Step 104030: loss = 0.31527
Step 104035: loss = 0.05656
Step 104040: loss = 0.07999
Step 104045: loss = 0.09449
Step 104050: loss = 0.06890
Step 104055: loss = 0.23328
Step 104060: loss = 0.09747
Step 104065: loss = 0.08286
Step 104070: loss = 0.09326
Step 104075: loss = 0.20222
Step 104080: loss = 0.08305
Step 104085: loss = 0.10815
Step 104090: loss = 0.16402
Step 104095: loss = 0.22463
Step 104100: loss = 0.17747
Step 104105: loss = 0.11077
Step 104110: loss = 0.18248
Step 104115: loss = 0.25320
Step 104120: loss = 0.10951
Step 104125: loss = 0.20353
Step 104130: loss = 0.13129
Step 104135: loss = 0.14753
Step 104140: loss = 0.20808
Step 104145: loss = 0.10103
Step 104150: loss = 0.07726
Step 104155: loss = 0.15026
Step 104160: loss = 0.27982
Step 104165: loss = 0.15506
Step 104170: loss = 0.11519
Step 104175: loss = 0.36897
Step 104180: loss = 0.13763
Step 104185: loss = 0.18270
Step 104190: loss = 0.14457
Step 104195: loss = 0.29080
Step 104200: loss = 0.26475
Step 104205: loss = 0.33611
Step 104210: loss = 0.19902
Step 104215: loss = 0.14414
Step 104220: loss = 0.08892
Step 104225: loss = 0.11411
Step 104230: loss = 0.22706
Step 104235: loss = 0.23698
Step 104240: loss = 0.16028
Step 104245: loss = 0.22540
Step 104250: loss = 0.14666
Step 104255: loss = 0.10679
Step 104260: loss = 0.24027
Step 104265: loss = 0.15116
Step 104270: loss = 0.18021
Step 104275: loss = 0.12254
Step 104280: loss = 0.17307
Step 104285: loss = 0.21274
Step 104290: loss = 0.16700
Step 104295: loss = 0.21709
Step 104300: loss = 0.20538
Step 104305: loss = 0.12953
Step 104310: loss = 0.35396
Step 104315: loss = 0.16760
Step 104320: loss = 0.07391
Step 104325: loss = 0.13094
Step 104330: loss = 0.28157
Step 104335: loss = 0.16970
Step 104340: loss = 0.12460
Step 104345: loss = 0.07344
Step 104350: loss = 0.08599
Step 104355: loss = 0.12864
Step 104360: loss = 0.13239
Step 104365: loss = 0.18119
Step 104370: loss = 0.14934
Step 104375: loss = 0.12340
Step 104380: loss = 0.05875
Step 104385: loss = 0.06233
Step 104390: loss = 0.10875
Step 104395: loss = 0.10966
Step 104400: loss = 0.12394
Step 104405: loss = 0.09987
Step 104410: loss = 0.37852
Step 104415: loss = 0.09579
Step 104420: loss = 0.07180
Step 104425: loss = 0.10960
Step 104430: loss = 0.06666
Step 104435: loss = 0.18164
Step 104440: loss = 0.10767
Step 104445: loss = 0.03891
Step 104450: loss = 0.18517
Step 104455: loss = 0.11578
Step 104460: loss = 0.35703
Step 104465: loss = 0.04899
Step 104470: loss = 0.11345
Step 104475: loss = 0.21721
Step 104480: loss = 0.23687
Step 104485: loss = 0.18884
Step 104490: loss = 0.03207
Step 104495: loss = 0.09509
Step 104500: loss = 0.14990
Step 104505: loss = 0.23513
Step 104510: loss = 0.05279
Step 104515: loss = 0.19093
Step 104520: loss = 0.03848
Step 104525: loss = 0.08871
Step 104530: loss = 0.10986
Step 104535: loss = 0.14256
Step 104540: loss = 0.12997
Step 104545: loss = 0.09018
Step 104550: loss = 0.12896
Step 104555: loss = 0.04992
Step 104560: loss = 0.21936
Step 104565: loss = 0.13749
Step 104570: loss = 0.35954
Step 104575: loss = 0.10954
Step 104580: loss = 0.11380
Step 104585: loss = 0.12992
Step 104590: loss = 0.10807
Step 104595: loss = 0.33388
Step 104600: loss = 0.11800
Step 104605: loss = 0.11692
Step 104610: loss = 0.05014
Step 104615: loss = 0.27176
Step 104620: loss = 0.16830
Step 104625: loss = 0.03043
Step 104630: loss = 0.14980
Step 104635: loss = 0.10066
Step 104640: loss = 0.09794
Step 104645: loss = 0.20963
Step 104650: loss = 0.18858
Step 104655: loss = 0.37739
Step 104660: loss = 0.14470
Step 104665: loss = 0.08160
Step 104670: loss = 0.04322
Step 104675: loss = 0.73295
Step 104680: loss = 0.28545
Step 104685: loss = 0.07803
Step 104690: loss = 0.18143
Step 104695: loss = 0.13631
Step 104700: loss = 0.21458
Step 104705: loss = 0.20160
Step 104710: loss = 0.13872
Step 104715: loss = 0.21629
Step 104720: loss = 0.20144
Step 104725: loss = 0.13523
Step 104730: loss = 0.18108
Step 104735: loss = 0.09602
Step 104740: loss = 0.42179
Step 104745: loss = 0.19096
Step 104750: loss = 0.22507
Step 104755: loss = 0.23007
Step 104760: loss = 0.14621
Step 104765: loss = 0.33253
Step 104770: loss = 0.13442
Step 104775: loss = 0.06839
Step 104780: loss = 0.21077
Step 104785: loss = 0.11638
Step 104790: loss = 0.16271
Step 104795: loss = 0.26120
Step 104800: loss = 0.20574
Step 104805: loss = 0.23926
Step 104810: loss = 0.10389
Step 104815: loss = 0.11910
Step 104820: loss = 0.11543
Step 104825: loss = 0.17333
Step 104830: loss = 0.13107
Step 104835: loss = 0.09534
Step 104840: loss = 0.17381
Step 104845: loss = 0.06462
Step 104850: loss = 0.08385
Step 104855: loss = 0.09287
Step 104860: loss = 0.14471
Step 104865: loss = 0.23905
Step 104870: loss = 0.06942
Step 104875: loss = 0.26986
Step 104880: loss = 0.10546
Step 104885: loss = 0.10377
Step 104890: loss = 0.10845
Step 104895: loss = 0.22071
Step 104900: loss = 0.15426
Step 104905: loss = 0.26026
Step 104910: loss = 0.04326
Step 104915: loss = 0.13940
Step 104920: loss = 0.33379
Step 104925: loss = 0.21797
Step 104930: loss = 0.09603
Step 104935: loss = 0.37838
Step 104940: loss = 0.09360
Step 104945: loss = 0.12644
Step 104950: loss = 0.12075
Step 104955: loss = 0.44763
Step 104960: loss = 0.11419
Step 104965: loss = 0.21745
Step 104970: loss = 0.10302
Step 104975: loss = 0.09704
Step 104980: loss = 0.18532
Step 104985: loss = 0.18970
Step 104990: loss = 0.17350
Step 104995: loss = 0.12450
Step 105000: loss = 0.18539
Training Data Eval:
  Num examples: 50000, Num correct: 47280, Precision @ 1: 0.9456
('Testing Data Eval: EPOCH->', 106)
  Num examples: 10000, Num correct: 6649, Precision @ 1: 0.6649
Step 105005: loss = 0.15969
Step 105010: loss = 0.11467
Step 105015: loss = 0.21419
Step 105020: loss = 0.01632
Step 105025: loss = 0.12295
Step 105030: loss = 0.18565
Step 105035: loss = 0.22160
Step 105040: loss = 0.06899
Step 105045: loss = 0.12904
Step 105050: loss = 0.14204
Step 105055: loss = 0.12291
Step 105060: loss = 0.32775
Step 105065: loss = 0.10179
Step 105070: loss = 0.26932
Step 105075: loss = 0.11787
Step 105080: loss = 0.07703
Step 105085: loss = 0.06701
Step 105090: loss = 0.05099
Step 105095: loss = 0.13786
Step 105100: loss = 0.25987
Step 105105: loss = 0.20226
Step 105110: loss = 0.19017
Step 105115: loss = 0.25365
Step 105120: loss = 0.13436
Step 105125: loss = 0.09061
Step 105130: loss = 0.08112
Step 105135: loss = 0.11562
Step 105140: loss = 0.07716
Step 105145: loss = 0.08886
Step 105150: loss = 0.06240
Step 105155: loss = 0.14186
Step 105160: loss = 0.07907
Step 105165: loss = 0.15093
Step 105170: loss = 0.07120
Step 105175: loss = 0.08925
Step 105180: loss = 0.09869
Step 105185: loss = 0.12985
Step 105190: loss = 0.04979
Step 105195: loss = 0.12732
Step 105200: loss = 0.13242
Step 105205: loss = 0.12485
Step 105210: loss = 0.32411
Step 105215: loss = 0.14808
Step 105220: loss = 0.23413
Step 105225: loss = 0.09730
Step 105230: loss = 0.16661
Step 105235: loss = 0.11756
Step 105240: loss = 0.19628
Step 105245: loss = 0.11659
Step 105250: loss = 0.08299
Step 105255: loss = 0.08821
Step 105260: loss = 0.16037
Step 105265: loss = 0.14333
Step 105270: loss = 0.29700
Step 105275: loss = 0.08205
Step 105280: loss = 0.08516
Step 105285: loss = 0.21882
Step 105290: loss = 0.13146
Step 105295: loss = 0.02673
Step 105300: loss = 0.17307
Step 105305: loss = 0.09814
Step 105310: loss = 0.14483
Step 105315: loss = 0.27209
Step 105320: loss = 0.18730
Step 105325: loss = 0.07262
Step 105330: loss = 0.33050
Step 105335: loss = 0.19909
Step 105340: loss = 0.24035
Step 105345: loss = 0.05193
Step 105350: loss = 0.07080
Step 105355: loss = 0.12690
Step 105360: loss = 0.10631
Step 105365: loss = 0.14549
Step 105370: loss = 0.38314
Step 105375: loss = 0.34034
Step 105380: loss = 0.04871
Step 105385: loss = 0.10812
Step 105390: loss = 0.21172
Step 105395: loss = 0.11834
Step 105400: loss = 0.11824
Step 105405: loss = 0.02430
Step 105410: loss = 0.32651
Step 105415: loss = 0.11682
Step 105420: loss = 0.34181
Step 105425: loss = 0.16852
Step 105430: loss = 0.05133
Step 105435: loss = 0.14461
Step 105440: loss = 0.12278
Step 105445: loss = 0.15246
Step 105450: loss = 0.25420
Step 105455: loss = 0.16708
Step 105460: loss = 0.09767
Step 105465: loss = 0.14242
Step 105470: loss = 0.29796
Step 105475: loss = 0.32699
Step 105480: loss = 0.27305
Step 105485: loss = 0.11317
Step 105490: loss = 0.09097
Step 105495: loss = 0.13096
Step 105500: loss = 0.11522
Step 105505: loss = 0.15349
Step 105510: loss = 0.07603
Step 105515: loss = 0.19872
Step 105520: loss = 0.18533
Step 105525: loss = 0.13538
Step 105530: loss = 0.15362
Step 105535: loss = 0.15757
Step 105540: loss = 0.05843
Step 105545: loss = 0.26872
Step 105550: loss = 0.06111
Step 105555: loss = 0.13885
Step 105560: loss = 0.27315
Step 105565: loss = 0.04353
Step 105570: loss = 0.11892
Step 105575: loss = 0.05230
Step 105580: loss = 0.20307
Step 105585: loss = 0.10140
Step 105590: loss = 0.06680
Step 105595: loss = 0.09807
Step 105600: loss = 0.04128
Step 105605: loss = 0.29265
Step 105610: loss = 0.24144
Step 105615: loss = 0.15189
Step 105620: loss = 0.33295
Step 105625: loss = 0.21497
Step 105630: loss = 0.07952
Step 105635: loss = 0.23890
Step 105640: loss = 0.06199
Step 105645: loss = 0.27209
Step 105650: loss = 0.27875
Step 105655: loss = 0.11783
Step 105660: loss = 0.21465
Step 105665: loss = 0.14838
Step 105670: loss = 0.14846
Step 105675: loss = 0.08261
Step 105680: loss = 0.10016
Step 105685: loss = 0.21574
Step 105690: loss = 0.48734
Step 105695: loss = 0.06115
Step 105700: loss = 0.12121
Step 105705: loss = 0.19992
Step 105710: loss = 0.07237
Step 105715: loss = 0.14827
Step 105720: loss = 0.29334
Step 105725: loss = 0.24378
Step 105730: loss = 0.13081
Step 105735: loss = 0.05953
Step 105740: loss = 0.25338
Step 105745: loss = 0.45630
Step 105750: loss = 0.26979
Step 105755: loss = 0.14469
Step 105760: loss = 0.45893
Step 105765: loss = 0.28843
Step 105770: loss = 0.33005
Step 105775: loss = 0.10704
Step 105780: loss = 0.16200
Step 105785: loss = 0.22629
Step 105790: loss = 0.20405
Step 105795: loss = 0.20146
Step 105800: loss = 0.06909
Step 105805: loss = 0.17545
Step 105810: loss = 0.13744
Step 105815: loss = 0.19679
Step 105820: loss = 0.29541
Step 105825: loss = 0.20410
Step 105830: loss = 0.22512
Step 105835: loss = 0.27224
Step 105840: loss = 0.17637
Step 105845: loss = 0.08749
Step 105850: loss = 0.09244
Step 105855: loss = 0.09077
Step 105860: loss = 0.12827
Step 105865: loss = 0.10006
Step 105870: loss = 0.12658
Step 105875: loss = 0.08564
Step 105880: loss = 0.05268
Step 105885: loss = 0.16664
Step 105890: loss = 0.31616
Step 105895: loss = 0.06347
Step 105900: loss = 0.06524
Step 105905: loss = 0.26359
Step 105910: loss = 0.11316
Step 105915: loss = 0.11344
Step 105920: loss = 0.12507
Step 105925: loss = 0.15784
Step 105930: loss = 0.09341
Step 105935: loss = 0.38203
Step 105940: loss = 0.10821
Step 105945: loss = 0.10443
Step 105950: loss = 0.12848
Step 105955: loss = 0.27778
Step 105960: loss = 0.07555
Step 105965: loss = 0.22493
Step 105970: loss = 0.14668
Step 105975: loss = 0.07820
Step 105980: loss = 0.21774
Step 105985: loss = 0.21380
Step 105990: loss = 0.31020
Step 105995: loss = 0.04165
Step 106000: loss = 0.09140
Training Data Eval:
  Num examples: 50000, Num correct: 47359, Precision @ 1: 0.9472
('Testing Data Eval: EPOCH->', 107)
  Num examples: 10000, Num correct: 6589, Precision @ 1: 0.6589
Step 106005: loss = 0.23340
Step 106010: loss = 0.26117
Step 106015: loss = 0.06031
Step 106020: loss = 0.09343
Step 106025: loss = 0.09811
Step 106030: loss = 0.11455
Step 106035: loss = 0.18882
Step 106040: loss = 0.17646
Step 106045: loss = 0.13989
Step 106050: loss = 0.05858
Step 106055: loss = 0.28792
Step 106060: loss = 0.17491
Step 106065: loss = 0.19999
Step 106070: loss = 0.23770
Step 106075: loss = 0.24149
Step 106080: loss = 0.04810
Step 106085: loss = 0.12187
Step 106090: loss = 0.10779
Step 106095: loss = 0.18416
Step 106100: loss = 0.16449
Step 106105: loss = 0.26064
Step 106110: loss = 0.08480
Step 106115: loss = 0.08631
Step 106120: loss = 0.21772
Step 106125: loss = 0.17938
Step 106130: loss = 0.51494
Step 106135: loss = 0.21658
Step 106140: loss = 0.18874
Step 106145: loss = 0.15570
Step 106150: loss = 0.22202
Step 106155: loss = 0.11834
Step 106160: loss = 0.13582
Step 106165: loss = 0.12446
Step 106170: loss = 0.07316
Step 106175: loss = 0.19910
Step 106180: loss = 0.04314
Step 106185: loss = 0.15954
Step 106190: loss = 0.17701
Step 106195: loss = 0.08580
Step 106200: loss = 0.09445
Step 106205: loss = 0.09592
Step 106210: loss = 0.38283
Step 106215: loss = 0.12514
Step 106220: loss = 0.09074
Step 106225: loss = 0.09203
Step 106230: loss = 0.12519
Step 106235: loss = 0.18846
Step 106240: loss = 0.15780
Step 106245: loss = 0.09913
Step 106250: loss = 0.14918
Step 106255: loss = 0.21499
Step 106260: loss = 0.18726
Step 106265: loss = 0.11241
Step 106270: loss = 0.16888
Step 106275: loss = 0.18759
Step 106280: loss = 0.25718
Step 106285: loss = 0.06621
Step 106290: loss = 0.04825
Step 106295: loss = 0.13918
Step 106300: loss = 0.20230
Step 106305: loss = 0.06961
Step 106310: loss = 0.08821
Step 106315: loss = 0.19768
Step 106320: loss = 0.13255
Step 106325: loss = 0.06055
Step 106330: loss = 0.16673
Step 106335: loss = 0.28102
Step 106340: loss = 0.17528
Step 106345: loss = 0.16482
Step 106350: loss = 0.17948
Step 106355: loss = 0.06034
Step 106360: loss = 0.16338
Step 106365: loss = 0.07602
Step 106370: loss = 0.21165
Step 106375: loss = 0.08237
Step 106380: loss = 0.10428
Step 106385: loss = 0.22281
Step 106390: loss = 0.26823
Step 106395: loss = 0.26598
Step 106400: loss = 0.16124
Step 106405: loss = 0.13978
Step 106410: loss = 0.13837
Step 106415: loss = 0.02609
Step 106420: loss = 0.13244
Step 106425: loss = 0.20835
Step 106430: loss = 0.28411
Step 106435: loss = 0.08146
Step 106440: loss = 0.13166
Step 106445: loss = 0.18405
Step 106450: loss = 0.17163
Step 106455: loss = 0.09632
Step 106460: loss = 0.19606
Step 106465: loss = 0.14787
Step 106470: loss = 0.26778
Step 106475: loss = 0.23720
Step 106480: loss = 0.08631
Step 106485: loss = 0.13712
Step 106490: loss = 0.32943
Step 106495: loss = 0.08344
Step 106500: loss = 0.14154
Step 106505: loss = 0.18199
Step 106510: loss = 0.11243
Step 106515: loss = 0.11200
Step 106520: loss = 0.10458
Step 106525: loss = 0.10464
Step 106530: loss = 0.08495
Step 106535: loss = 0.37822
Step 106540: loss = 0.10571
Step 106545: loss = 0.53581
Step 106550: loss = 0.06758
Step 106555: loss = 0.05786
Step 106560: loss = 0.12749
Step 106565: loss = 0.24105
Step 106570: loss = 0.11485
Step 106575: loss = 0.07295
Step 106580: loss = 0.16624
Step 106585: loss = 0.09021
Step 106590: loss = 0.07748
Step 106595: loss = 0.19361
Step 106600: loss = 0.03181
Step 106605: loss = 0.07720
Step 106610: loss = 0.19405
Step 106615: loss = 0.10784
Step 106620: loss = 0.09206
Step 106625: loss = 0.16818
Step 106630: loss = 0.08063
Step 106635: loss = 0.17040
Step 106640: loss = 0.08115
Step 106645: loss = 0.15352
Step 106650: loss = 0.10537
Step 106655: loss = 0.08367
Step 106660: loss = 0.08023
Step 106665: loss = 0.27850
Step 106670: loss = 0.21322
Step 106675: loss = 0.09382
Step 106680: loss = 0.06080
Step 106685: loss = 0.40033
Step 106690: loss = 0.13643
Step 106695: loss = 0.17058
Step 106700: loss = 0.19478
Step 106705: loss = 0.17095
Step 106710: loss = 0.11773
Step 106715: loss = 0.08255
Step 106720: loss = 0.26336
Step 106725: loss = 0.08783
Step 106730: loss = 0.10034
Step 106735: loss = 0.13725
Step 106740: loss = 0.11213
Step 106745: loss = 0.15054
Step 106750: loss = 0.23985
Step 106755: loss = 0.08081
Step 106760: loss = 0.13974
Step 106765: loss = 0.21446
Step 106770: loss = 0.07434
Step 106775: loss = 0.18344
Step 106780: loss = 0.02605
Step 106785: loss = 0.14150
Step 106790: loss = 0.32555
Step 106795: loss = 0.30157
Step 106800: loss = 0.22935
Step 106805: loss = 0.14788
Step 106810: loss = 0.29299
Step 106815: loss = 0.04981
Step 106820: loss = 0.10771
Step 106825: loss = 0.10040
Step 106830: loss = 0.08605
Step 106835: loss = 0.07153
Step 106840: loss = 0.30648
Step 106845: loss = 0.03640
Step 106850: loss = 0.38714
Step 106855: loss = 0.10972
Step 106860: loss = 0.31628
Step 106865: loss = 0.09416
Step 106870: loss = 0.17459
Step 106875: loss = 0.19567
Step 106880: loss = 0.09325
Step 106885: loss = 0.18667
Step 106890: loss = 0.17669
Step 106895: loss = 0.08435
Step 106900: loss = 0.20346
Step 106905: loss = 0.10821
Step 106910: loss = 0.19013
Step 106915: loss = 0.13639
Step 106920: loss = 0.18069
Step 106925: loss = 0.07404
Step 106930: loss = 0.20723
Step 106935: loss = 0.15701
Step 106940: loss = 0.09709
Step 106945: loss = 0.31027
Step 106950: loss = 0.09555
Step 106955: loss = 0.07458
Step 106960: loss = 0.13983
Step 106965: loss = 0.36648
Step 106970: loss = 0.07106
Step 106975: loss = 0.20819
Step 106980: loss = 0.09142
Step 106985: loss = 0.10572
Step 106990: loss = 0.14900
Step 106995: loss = 0.12539
Step 107000: loss = 0.15825
Training Data Eval:
  Num examples: 50000, Num correct: 47237, Precision @ 1: 0.9447
('Testing Data Eval: EPOCH->', 108)
  Num examples: 10000, Num correct: 6591, Precision @ 1: 0.6591
Step 107005: loss = 0.29770
Step 107010: loss = 0.10466
Step 107015: loss = 0.07271
Step 107020: loss = 0.26745
Step 107025: loss = 0.12422
Step 107030: loss = 0.28518
Step 107035: loss = 0.09800
Step 107040: loss = 0.24848
Step 107045: loss = 0.05954
Step 107050: loss = 0.27002
Step 107055: loss = 0.26990
Step 107060: loss = 0.18108
Step 107065: loss = 0.25622
Step 107070: loss = 0.06662
Step 107075: loss = 0.20354
Step 107080: loss = 0.15949
Step 107085: loss = 0.04397
Step 107090: loss = 0.13525
Step 107095: loss = 0.31934
Step 107100: loss = 0.22621
Step 107105: loss = 0.21786
Step 107110: loss = 0.42168
Step 107115: loss = 0.06775
Step 107120: loss = 0.37234
Step 107125: loss = 0.41493
Step 107130: loss = 0.15659
Step 107135: loss = 0.04636
Step 107140: loss = 0.06171
Step 107145: loss = 0.15080
Step 107150: loss = 0.28216
Step 107155: loss = 0.34576
Step 107160: loss = 0.14430
Step 107165: loss = 0.22130
Step 107170: loss = 0.11135
Step 107175: loss = 0.37646
Step 107180: loss = 0.20565
Step 107185: loss = 0.13209
Step 107190: loss = 0.10536
Step 107195: loss = 0.25449
Step 107200: loss = 0.07231
Step 107205: loss = 0.17808
Step 107210: loss = 0.21320
Step 107215: loss = 0.16470
Step 107220: loss = 0.14104
Step 107225: loss = 0.04122
Step 107230: loss = 0.14374
Step 107235: loss = 0.16910
Step 107240: loss = 0.07590
Step 107245: loss = 0.06562
Step 107250: loss = 0.19621
Step 107255: loss = 0.11872
Step 107260: loss = 0.30686
Step 107265: loss = 0.14516
Step 107270: loss = 0.04936
Step 107275: loss = 0.07321
Step 107280: loss = 0.09421
Step 107285: loss = 0.14700
Step 107290: loss = 0.08026
Step 107295: loss = 0.05541
Step 107300: loss = 0.13133
Step 107305: loss = 0.17518
Step 107310: loss = 0.07076
Step 107315: loss = 0.55277
Step 107320: loss = 0.24675
Step 107325: loss = 0.05957
Step 107330: loss = 0.05557
Step 107335: loss = 0.07401
Step 107340: loss = 0.27610
Step 107345: loss = 0.14443
Step 107350: loss = 0.09063
Step 107355: loss = 0.04754
Step 107360: loss = 0.26059
Step 107365: loss = 0.05347
Step 107370: loss = 0.25998
Step 107375: loss = 0.10081
Step 107380: loss = 0.10397
Step 107385: loss = 0.10596
Step 107390: loss = 0.25841
Step 107395: loss = 0.07963
Step 107400: loss = 0.21205
Step 107405: loss = 0.14130
Step 107410: loss = 0.25448
Step 107415: loss = 0.35633
Step 107420: loss = 0.09462
Step 107425: loss = 0.11523
Step 107430: loss = 0.12909
Step 107435: loss = 0.07770
Step 107440: loss = 0.21016
Step 107445: loss = 0.17832
Step 107450: loss = 0.08562
Step 107455: loss = 0.11664
Step 107460: loss = 0.15455
Step 107465: loss = 0.11819
Step 107470: loss = 0.11265
Step 107475: loss = 0.27521
Step 107480: loss = 0.12645
Step 107485: loss = 0.21950
Step 107490: loss = 0.26345
Step 107495: loss = 0.18066
Step 107500: loss = 0.17599
Step 107505: loss = 0.16460
Step 107510: loss = 0.12280
Step 107515: loss = 0.09813
Step 107520: loss = 0.23335
Step 107525: loss = 0.15865
Step 107530: loss = 0.14151
Step 107535: loss = 0.04839
Step 107540: loss = 0.12541
Step 107545: loss = 0.12624
Step 107550: loss = 0.15741
Step 107555: loss = 0.05395
Step 107560: loss = 0.18081
Step 107565: loss = 0.15538
Step 107570: loss = 0.22097
Step 107575: loss = 0.17445
Step 107580: loss = 0.13913
Step 107585: loss = 0.36933
Step 107590: loss = 0.02758
Step 107595: loss = 0.18743
Step 107600: loss = 0.21275
Step 107605: loss = 0.16777
Step 107610: loss = 0.11500
Step 107615: loss = 0.20207
Step 107620: loss = 0.09667
Step 107625: loss = 0.07854
Step 107630: loss = 0.21338
Step 107635: loss = 0.09415
Step 107640: loss = 0.05100
Step 107645: loss = 0.09340
Step 107650: loss = 0.36128
Step 107655: loss = 0.16115
Step 107660: loss = 0.20290
Step 107665: loss = 0.09268
Step 107670: loss = 0.07262
Step 107675: loss = 0.08196
Step 107680: loss = 0.28258
Step 107685: loss = 0.23269
Step 107690: loss = 0.06126
Step 107695: loss = 0.09758
Step 107700: loss = 0.21032
Step 107705: loss = 0.07706
Step 107710: loss = 0.18582
Step 107715: loss = 0.09613
Step 107720: loss = 0.09822
Step 107725: loss = 0.12611
Step 107730: loss = 0.13462
Step 107735: loss = 0.12741
Step 107740: loss = 0.14757
Step 107745: loss = 0.17455
Step 107750: loss = 0.14757
Step 107755: loss = 0.15047
Step 107760: loss = 0.30714
Step 107765: loss = 0.08311
Step 107770: loss = 0.13194
Step 107775: loss = 0.06616
Step 107780: loss = 0.15518
Step 107785: loss = 0.11231
Step 107790: loss = 0.14605
Step 107795: loss = 0.10588
Step 107800: loss = 0.10090
Step 107805: loss = 0.25156
Step 107810: loss = 0.15539
Step 107815: loss = 0.28225
Step 107820: loss = 0.28162
Step 107825: loss = 0.13789
Step 107830: loss = 0.05636
Step 107835: loss = 0.25230
Step 107840: loss = 0.06426
Step 107845: loss = 0.08746
Step 107850: loss = 0.18741
Step 107855: loss = 0.09226
Step 107860: loss = 0.14243
Step 107865: loss = 0.19698
Step 107870: loss = 0.07928
Step 107875: loss = 0.23662
Step 107880: loss = 0.31279
Step 107885: loss = 0.15793
Step 107890: loss = 0.09874
Step 107895: loss = 0.14325
Step 107900: loss = 0.27725
Step 107905: loss = 0.24024
Step 107910: loss = 0.06192
Step 107915: loss = 0.09269
Step 107920: loss = 0.06075
Step 107925: loss = 0.35893
Step 107930: loss = 0.07092
Step 107935: loss = 0.07122
Step 107940: loss = 0.26416
Step 107945: loss = 0.25249
Step 107950: loss = 0.19074
Step 107955: loss = 0.38544
Step 107960: loss = 0.12236
Step 107965: loss = 0.20695
Step 107970: loss = 0.29365
Step 107975: loss = 0.13068
Step 107980: loss = 0.20796
Step 107985: loss = 0.08027
Step 107990: loss = 0.26437
Step 107995: loss = 0.44624
Step 108000: loss = 0.33718
Training Data Eval:
  Num examples: 50000, Num correct: 47129, Precision @ 1: 0.9426
('Testing Data Eval: EPOCH->', 109)
  Num examples: 10000, Num correct: 6551, Precision @ 1: 0.6551
Step 108005: loss = 0.13893
Step 108010: loss = 0.41066
Step 108015: loss = 0.02770
Step 108020: loss = 0.04578
Step 108025: loss = 0.46469
Step 108030: loss = 0.03889
Step 108035: loss = 0.16047
Step 108040: loss = 0.08415
Step 108045: loss = 0.23358
Step 108050: loss = 0.13602
Step 108055: loss = 0.14218
Step 108060: loss = 0.04217
Step 108065: loss = 0.23632
Step 108070: loss = 0.10714
Step 108075: loss = 0.08123
Step 108080: loss = 0.26704
Step 108085: loss = 0.21824
Step 108090: loss = 0.22463
Step 108095: loss = 0.11815
Step 108100: loss = 0.14816
Step 108105: loss = 0.37513
Step 108110: loss = 0.05518
Step 108115: loss = 0.20326
Step 108120: loss = 0.34784
Step 108125: loss = 0.35030
Step 108130: loss = 0.21261
Step 108135: loss = 0.10905
Step 108140: loss = 0.08579
Step 108145: loss = 0.12176
Step 108150: loss = 0.12045
Step 108155: loss = 0.22030
Step 108160: loss = 0.10631
Step 108165: loss = 0.11412
Step 108170: loss = 0.15756
Step 108175: loss = 0.16679
Step 108180: loss = 0.44055
Step 108185: loss = 0.12319
Step 108190: loss = 0.21591
Step 108195: loss = 0.04577
Step 108200: loss = 0.15690
Step 108205: loss = 0.22747
Step 108210: loss = 0.26687
Step 108215: loss = 0.12552
Step 108220: loss = 0.03401
Step 108225: loss = 0.36995
Step 108230: loss = 0.06510
Step 108235: loss = 0.21391
Step 108240: loss = 0.19634
Step 108245: loss = 0.08151
Step 108250: loss = 0.08198
Step 108255: loss = 0.11683
Step 108260: loss = 0.08916
Step 108265: loss = 0.15002
Step 108270: loss = 0.12506
Step 108275: loss = 0.11157
Step 108280: loss = 0.29992
Step 108285: loss = 0.09697
Step 108290: loss = 0.23882
Step 108295: loss = 0.06635
Step 108300: loss = 0.14939
Step 108305: loss = 0.20391
Step 108310: loss = 0.18114
Step 108315: loss = 0.27782
Step 108320: loss = 0.23917
Step 108325: loss = 0.17703
Step 108330: loss = 0.16830
Step 108335: loss = 0.23500
Step 108340: loss = 0.21221
Step 108345: loss = 0.08981
Step 108350: loss = 0.28623
Step 108355: loss = 0.21285
Step 108360: loss = 0.07331
Step 108365: loss = 0.35479
Step 108370: loss = 0.13601
Step 108375: loss = 0.13494
Step 108380: loss = 0.18115
Step 108385: loss = 0.08726
Step 108390: loss = 0.21770
Step 108395: loss = 0.15124
Step 108400: loss = 0.05374
Step 108405: loss = 0.09008
Step 108410: loss = 0.01826
Step 108415: loss = 0.05154
Step 108420: loss = 0.27951
Step 108425: loss = 0.13482
Step 108430: loss = 0.30187
Step 108435: loss = 0.09051
Step 108440: loss = 0.27103
Step 108445: loss = 0.06207
Step 108450: loss = 0.24708
Step 108455: loss = 0.10894
Step 108460: loss = 0.08486
Step 108465: loss = 0.16310
Step 108470: loss = 0.14038
Step 108475: loss = 0.39748
Step 108480: loss = 0.21457
Step 108485: loss = 0.15083
Step 108490: loss = 0.11556
Step 108495: loss = 0.14766
Step 108500: loss = 0.04073
Step 108505: loss = 0.11201
Step 108510: loss = 0.12770
Step 108515: loss = 0.09213
Step 108520: loss = 0.13475
Step 108525: loss = 0.10619
Step 108530: loss = 0.05940
Step 108535: loss = 0.29063
Step 108540: loss = 0.04843
Step 108545: loss = 0.13972
Step 108550: loss = 0.07397
Step 108555: loss = 0.29324
Step 108560: loss = 0.09592
Step 108565: loss = 0.20056
Step 108570: loss = 0.28623
Step 108575: loss = 0.14937
Step 108580: loss = 0.21207
Step 108585: loss = 0.05300
Step 108590: loss = 0.43883
Step 108595: loss = 0.22968
Step 108600: loss = 0.08784
Step 108605: loss = 0.13827
Step 108610: loss = 0.16423
Step 108615: loss = 0.15070
Step 108620: loss = 0.10691
Step 108625: loss = 0.08033
Step 108630: loss = 0.08867
Step 108635: loss = 0.11535
Step 108640: loss = 0.26254
Step 108645: loss = 0.12830
Step 108650: loss = 0.18972
Step 108655: loss = 0.10681
Step 108660: loss = 0.19564
Step 108665: loss = 0.14562
Step 108670: loss = 0.15797
Step 108675: loss = 0.10690
Step 108680: loss = 0.14513
Step 108685: loss = 0.15354
Step 108690: loss = 0.05773
Step 108695: loss = 0.21048
Step 108700: loss = 0.11039
Step 108705: loss = 0.13410
Step 108710: loss = 0.38688
Step 108715: loss = 0.10806
Step 108720: loss = 0.22345
Step 108725: loss = 0.19496
Step 108730: loss = 0.44254
Step 108735: loss = 0.18498
Step 108740: loss = 0.09507
Step 108745: loss = 0.11669
Step 108750: loss = 0.18421
Step 108755: loss = 0.07667
Step 108760: loss = 0.26334
Step 108765: loss = 0.15907
Step 108770: loss = 0.22593
Step 108775: loss = 0.11869
Step 108780: loss = 0.14678
Step 108785: loss = 0.06349
Step 108790: loss = 0.07476
Step 108795: loss = 0.27266
Step 108800: loss = 0.03910
Step 108805: loss = 0.08245
Step 108810: loss = 0.22690
Step 108815: loss = 0.09781
Step 108820: loss = 0.11132
Step 108825: loss = 0.17893
Step 108830: loss = 0.09132
Step 108835: loss = 0.15464
Step 108840: loss = 0.11504
Step 108845: loss = 0.06697
Step 108850: loss = 0.06102
Step 108855: loss = 0.38636
Step 108860: loss = 0.19254
Step 108865: loss = 0.14059
Step 108870: loss = 0.05933
Step 108875: loss = 0.15117
Step 108880: loss = 0.12322
Step 108885: loss = 0.08296
Step 108890: loss = 0.09510
Step 108895: loss = 0.06016
Step 108900: loss = 0.11853
Step 108905: loss = 0.07341
Step 108910: loss = 0.09033
Step 108915: loss = 0.26017
Step 108920: loss = 0.12165
Step 108925: loss = 0.06740
Step 108930: loss = 0.09173
Step 108935: loss = 0.15780
Step 108940: loss = 0.32542
Step 108945: loss = 0.19416
Step 108950: loss = 0.22148
Step 108955: loss = 0.15544
Step 108960: loss = 0.11774
Step 108965: loss = 0.17397
Step 108970: loss = 0.15838
Step 108975: loss = 0.08136
Step 108980: loss = 0.13068
Step 108985: loss = 0.20862
Step 108990: loss = 0.12129
Step 108995: loss = 0.12418
Step 109000: loss = 0.10040
Training Data Eval:
  Num examples: 50000, Num correct: 47133, Precision @ 1: 0.9427
('Testing Data Eval: EPOCH->', 110)
  Num examples: 10000, Num correct: 6508, Precision @ 1: 0.6508
Step 109005: loss = 0.11350
Step 109010: loss = 0.22313
Step 109015: loss = 0.29914
Step 109020: loss = 0.09208
Step 109025: loss = 0.16342
Step 109030: loss = 0.24223
Step 109035: loss = 0.19656
Step 109040: loss = 0.07030
Step 109045: loss = 0.38069
Step 109050: loss = 0.13166
Step 109055: loss = 0.23552
Step 109060: loss = 0.12269
Step 109065: loss = 0.08392
Step 109070: loss = 0.20713
Step 109075: loss = 0.17596
Step 109080: loss = 0.12747
Step 109085: loss = 0.06442
Step 109090: loss = 0.08602
Step 109095: loss = 0.03813
Step 109100: loss = 0.12504
Step 109105: loss = 0.16754
Step 109110: loss = 0.21106
Step 109115: loss = 0.17654
Step 109120: loss = 0.22630
Step 109125: loss = 0.05634
Step 109130: loss = 0.08636
Step 109135: loss = 0.11888
Step 109140: loss = 0.24848
Step 109145: loss = 0.23210
Step 109150: loss = 0.12993
Step 109155: loss = 0.13864
Step 109160: loss = 0.11904
Step 109165: loss = 0.09273
Step 109170: loss = 0.21953
Step 109175: loss = 0.11107
Step 109180: loss = 0.12636
Step 109185: loss = 0.13668
Step 109190: loss = 0.09244
Step 109195: loss = 0.05002
Step 109200: loss = 0.30010
Step 109205: loss = 0.07278
Step 109210: loss = 0.25073
Step 109215: loss = 0.15571
Step 109220: loss = 0.27100
Step 109225: loss = 0.21444
Step 109230: loss = 0.06569
Step 109235: loss = 0.29201
Step 109240: loss = 0.19196
Step 109245: loss = 0.20301
Step 109250: loss = 0.13127
Step 109255: loss = 0.21850
Step 109260: loss = 0.20820
Step 109265: loss = 0.35111
Step 109270: loss = 0.03077
Step 109275: loss = 0.29074
Step 109280: loss = 0.18566
Step 109285: loss = 0.18066
Step 109290: loss = 0.18426
Step 109295: loss = 0.15829
Step 109300: loss = 0.18526
Step 109305: loss = 0.20454
Step 109310: loss = 0.15982
Step 109315: loss = 0.18993
Step 109320: loss = 0.08025
Step 109325: loss = 0.12435
Step 109330: loss = 0.07849
Step 109335: loss = 0.28524
Step 109340: loss = 0.11633
Step 109345: loss = 0.09925
Step 109350: loss = 0.04594
Step 109355: loss = 0.30532
Step 109360: loss = 0.07853
Step 109365: loss = 0.06562
Step 109370: loss = 0.17008
Step 109375: loss = 0.12126
Step 109380: loss = 0.30581
Step 109385: loss = 0.19941
Step 109390: loss = 0.16971
Step 109395: loss = 0.09726
Step 109400: loss = 0.11510
Step 109405: loss = 0.27558
Step 109410: loss = 0.09886
Step 109415: loss = 0.16232
Step 109420: loss = 0.05595
Step 109425: loss = 0.08979
Step 109430: loss = 0.16328
Step 109435: loss = 0.19285
Step 109440: loss = 0.21859
Step 109445: loss = 0.31429
Step 109450: loss = 0.03144
Step 109455: loss = 0.16425
Step 109460: loss = 0.15744
Step 109465: loss = 0.10902
Step 109470: loss = 0.33581
Step 109475: loss = 0.15697
Step 109480: loss = 0.19637
Step 109485: loss = 0.10056
Step 109490: loss = 0.14234
Step 109495: loss = 0.21451
Step 109500: loss = 0.34862
Step 109505: loss = 0.19353
Step 109510: loss = 0.06950
Step 109515: loss = 0.04273
Step 109520: loss = 0.10086
Step 109525: loss = 0.15707
Step 109530: loss = 0.27723
Step 109535: loss = 0.16383
Step 109540: loss = 0.12057
Step 109545: loss = 0.23653
Step 109550: loss = 0.10548
Step 109555: loss = 0.08148
Step 109560: loss = 0.29523
Step 109565: loss = 0.17518
Step 109570: loss = 0.19796
Step 109575: loss = 0.07545
Step 109580: loss = 0.23642
Step 109585: loss = 0.11097
Step 109590: loss = 0.11064
Step 109595: loss = 0.09656
Step 109600: loss = 0.11272
Step 109605: loss = 0.07852
Step 109610: loss = 0.03601
Step 109615: loss = 0.19292
Step 109620: loss = 0.12007
Step 109625: loss = 0.10354
Step 109630: loss = 0.03088
Step 109635: loss = 0.08369
Step 109640: loss = 0.20582
Step 109645: loss = 0.17375
Step 109650: loss = 0.16189
Step 109655: loss = 0.16504
Step 109660: loss = 0.14741
Step 109665: loss = 0.17595
Step 109670: loss = 0.34048
Step 109675: loss = 0.13247
Step 109680: loss = 0.15270
Step 109685: loss = 0.17024
Step 109690: loss = 0.17175
Step 109695: loss = 0.05967
Step 109700: loss = 0.10776
Step 109705: loss = 0.22327
Step 109710: loss = 0.17969
Step 109715: loss = 0.23316
Step 109720: loss = 0.11873
Step 109725: loss = 0.11158
Step 109730: loss = 0.25689
Step 109735: loss = 0.25923
Step 109740: loss = 0.12109
Step 109745: loss = 0.10080
Step 109750: loss = 0.05626
Step 109755: loss = 0.19531
Step 109760: loss = 0.23518
Step 109765: loss = 0.21030
Step 109770: loss = 0.04987
Step 109775: loss = 0.14678
Step 109780: loss = 0.17968
Step 109785: loss = 0.39824
Step 109790: loss = 0.10073
Step 109795: loss = 0.06254
Step 109800: loss = 0.24898
Step 109805: loss = 0.33720
Step 109810: loss = 0.11613
Step 109815: loss = 0.20530
Step 109820: loss = 0.20011
Step 109825: loss = 0.18636
Step 109830: loss = 0.16163
Step 109835: loss = 0.36453
Step 109840: loss = 0.49519
Step 109845: loss = 0.06884
Step 109850: loss = 0.21015
Step 109855: loss = 0.17233
Step 109860: loss = 0.21148
Step 109865: loss = 0.11077
Step 109870: loss = 0.28435
Step 109875: loss = 0.16266
Step 109880: loss = 0.05381
Step 109885: loss = 0.34726
Step 109890: loss = 0.26652
Step 109895: loss = 0.23529
Step 109900: loss = 0.09952
Step 109905: loss = 0.11886
Step 109910: loss = 0.17526
Step 109915: loss = 0.18432
Step 109920: loss = 0.09732
Step 109925: loss = 0.07618
Step 109930: loss = 0.22956
Step 109935: loss = 0.24872
Step 109940: loss = 0.06567
Step 109945: loss = 0.13621
Step 109950: loss = 0.23647
Step 109955: loss = 0.32955
Step 109960: loss = 0.09317
Step 109965: loss = 0.19953
Step 109970: loss = 0.27246
Step 109975: loss = 0.33974
Step 109980: loss = 0.10482
Step 109985: loss = 0.12218
Step 109990: loss = 0.11895
Step 109995: loss = 0.15154
Step 110000: loss = 0.26045
Training Data Eval:
  Num examples: 50000, Num correct: 47195, Precision @ 1: 0.9439
('Testing Data Eval: EPOCH->', 111)
  Num examples: 10000, Num correct: 6641, Precision @ 1: 0.6641
Step 110005: loss = 0.21999
Step 110010: loss = 0.15014
Step 110015: loss = 0.13443
Step 110020: loss = 0.17297
Step 110025: loss = 0.22253
Step 110030: loss = 0.06736
Step 110035: loss = 0.25292
Step 110040: loss = 0.17675
Step 110045: loss = 0.24406
Step 110050: loss = 0.16077
Step 110055: loss = 0.14528
Step 110060: loss = 0.16012
Step 110065: loss = 0.32710
Step 110070: loss = 0.10800
Step 110075: loss = 0.12431
Step 110080: loss = 0.24864
Step 110085: loss = 0.13745
Step 110090: loss = 0.27928
Step 110095: loss = 0.11983
Step 110100: loss = 0.09354
Step 110105: loss = 0.14687
Step 110110: loss = 0.10102
Step 110115: loss = 0.08017
Step 110120: loss = 0.09057
Step 110125: loss = 0.09508
Step 110130: loss = 0.12820
Step 110135: loss = 0.16604
Step 110140: loss = 0.05111
Step 110145: loss = 0.22609
Step 110150: loss = 0.12041
Step 110155: loss = 0.10735
Step 110160: loss = 0.27951
Step 110165: loss = 0.09566
Step 110170: loss = 0.19860
Step 110175: loss = 0.26350
Step 110180: loss = 0.09450
Step 110185: loss = 0.22718
Step 110190: loss = 0.19722
Step 110195: loss = 0.04085
Step 110200: loss = 0.22700
Step 110205: loss = 0.32433
Step 110210: loss = 0.08695
Step 110215: loss = 0.07364
Step 110220: loss = 0.07481
Step 110225: loss = 0.16604
Step 110230: loss = 0.05317
Step 110235: loss = 0.10682
Step 110240: loss = 0.06981
Step 110245: loss = 0.09132
Step 110250: loss = 0.25017
Step 110255: loss = 0.13197
Step 110260: loss = 0.13949
Step 110265: loss = 0.04316
Step 110270: loss = 0.11379
Step 110275: loss = 0.19697
Step 110280: loss = 0.18138
Step 110285: loss = 0.06640
Step 110290: loss = 0.09427
Step 110295: loss = 0.10305
Step 110300: loss = 0.13747
Step 110305: loss = 0.09778
Step 110310: loss = 0.17670
Step 110315: loss = 0.56788
Step 110320: loss = 0.10155
Step 110325: loss = 0.17364
Step 110330: loss = 0.35126
Step 110335: loss = 0.16396
Step 110340: loss = 0.09477
Step 110345: loss = 0.09115
Step 110350: loss = 0.35740
Step 110355: loss = 0.38253
Step 110360: loss = 0.08950
Step 110365: loss = 0.07498
Step 110370: loss = 0.15872
Step 110375: loss = 0.13731
Step 110380: loss = 0.15340
Step 110385: loss = 0.26225
Step 110390: loss = 0.10953
Step 110395: loss = 0.39779
Step 110400: loss = 0.11579
Step 110405: loss = 0.15538
Step 110410: loss = 0.08217
Step 110415: loss = 0.25117
Step 110420: loss = 0.10177
Step 110425: loss = 0.18378
Step 110430: loss = 0.38661
Step 110435: loss = 0.44050
Step 110440: loss = 0.10140
Step 110445: loss = 0.24504
Step 110450: loss = 0.11409
Step 110455: loss = 0.15656
Step 110460: loss = 0.10064
Step 110465: loss = 0.27308
Step 110470: loss = 0.08612
Step 110475: loss = 0.28916
Step 110480: loss = 0.20498
Step 110485: loss = 0.20227
Step 110490: loss = 0.11258
Step 110495: loss = 0.07897
Step 110500: loss = 0.15149
Step 110505: loss = 0.11919
Step 110510: loss = 0.27812
Step 110515: loss = 0.09180
Step 110520: loss = 0.08230
Step 110525: loss = 0.11572
Step 110530: loss = 0.15048
Step 110535: loss = 0.27645
Step 110540: loss = 0.19655
Step 110545: loss = 0.23347
Step 110550: loss = 0.10105
Step 110555: loss = 0.32206
Step 110560: loss = 0.05008
Step 110565: loss = 0.16485
Step 110570: loss = 0.12721
Step 110575: loss = 0.04906
Step 110580: loss = 0.05911
Step 110585: loss = 0.19018
Step 110590: loss = 0.19261
Step 110595: loss = 0.10085
Step 110600: loss = 0.41220
Step 110605: loss = 0.17912
Step 110610: loss = 0.06230
Step 110615: loss = 0.05367
Step 110620: loss = 0.18466
Step 110625: loss = 0.10024
Step 110630: loss = 0.07241
Step 110635: loss = 0.04806
Step 110640: loss = 0.13081
Step 110645: loss = 0.18123
Step 110650: loss = 0.12902
Step 110655: loss = 0.13778
Step 110660: loss = 0.21093
Step 110665: loss = 0.47368
Step 110670: loss = 0.40481
Step 110675: loss = 0.19119
Step 110680: loss = 0.25911
Step 110685: loss = 0.07872
Step 110690: loss = 0.13235
Step 110695: loss = 0.18472
Step 110700: loss = 0.08575
Step 110705: loss = 0.14225
Step 110710: loss = 0.11715
Step 110715: loss = 0.12993
Step 110720: loss = 0.14991
Step 110725: loss = 0.39779
Step 110730: loss = 0.33133
Step 110735: loss = 0.11693
Step 110740: loss = 0.13461
Step 110745: loss = 0.44721
Step 110750: loss = 0.16565
Step 110755: loss = 0.14252
Step 110760: loss = 0.17595
Step 110765: loss = 0.36731
Step 110770: loss = 0.22411
Step 110775: loss = 0.13541
Step 110780: loss = 0.16863
Step 110785: loss = 0.20361
Step 110790: loss = 0.10734
Step 110795: loss = 0.30465
Step 110800: loss = 0.30102
Step 110805: loss = 0.29565
Step 110810: loss = 0.05574
Step 110815: loss = 0.09181
Step 110820: loss = 0.13355
Step 110825: loss = 0.15436
Step 110830: loss = 0.15587
Step 110835: loss = 0.09281
Step 110840: loss = 0.12925
Step 110845: loss = 0.29156
Step 110850: loss = 0.19900
Step 110855: loss = 0.34830
Step 110860: loss = 0.32567
Step 110865: loss = 0.07104
Step 110870: loss = 0.15805
Step 110875: loss = 0.20362
Step 110880: loss = 0.07875
Step 110885: loss = 0.25185
Step 110890: loss = 0.15237
Step 110895: loss = 0.08278
Step 110900: loss = 0.15703
Step 110905: loss = 0.17286
Step 110910: loss = 0.14142
Step 110915: loss = 0.08034
Step 110920: loss = 0.18279
Step 110925: loss = 0.04600
Step 110930: loss = 0.20000
Step 110935: loss = 0.15400
Step 110940: loss = 0.15836
Step 110945: loss = 0.21089
Step 110950: loss = 0.18924
Step 110955: loss = 0.30591
Step 110960: loss = 0.23740
Step 110965: loss = 0.22494
Step 110970: loss = 0.09426
Step 110975: loss = 0.09537
Step 110980: loss = 0.31956
Step 110985: loss = 0.09898
Step 110990: loss = 0.22038
Step 110995: loss = 0.24679
Step 111000: loss = 0.08730
Training Data Eval:
  Num examples: 50000, Num correct: 47293, Precision @ 1: 0.9459
('Testing Data Eval: EPOCH->', 112)
  Num examples: 10000, Num correct: 6623, Precision @ 1: 0.6623
Step 111005: loss = 0.18070
Step 111010: loss = 0.21235
Step 111015: loss = 0.20341
Step 111020: loss = 0.15051
Step 111025: loss = 0.16422
Step 111030: loss = 0.12718
Step 111035: loss = 0.11740
Step 111040: loss = 0.05864
Step 111045: loss = 0.14650
Step 111050: loss = 0.16564
Step 111055: loss = 0.18944
Step 111060: loss = 0.22350
Step 111065: loss = 0.06146
Step 111070: loss = 0.49488
Step 111075: loss = 0.09441
Step 111080: loss = 0.10390
Step 111085: loss = 0.04642
Step 111090: loss = 0.16106
Step 111095: loss = 0.25173
Step 111100: loss = 0.26723
Step 111105: loss = 0.16679
Step 111110: loss = 0.15767
Step 111115: loss = 0.28469
Step 111120: loss = 0.17510
Step 111125: loss = 0.20982
Step 111130: loss = 0.31275
Step 111135: loss = 0.11087
Step 111140: loss = 0.09186
Step 111145: loss = 0.19017
Step 111150: loss = 0.12951
Step 111155: loss = 0.11821
Step 111160: loss = 0.18429
Step 111165: loss = 0.10831
Step 111170: loss = 0.21284
Step 111175: loss = 0.13020
Step 111180: loss = 0.12771
Step 111185: loss = 0.16259
Step 111190: loss = 0.32272
Step 111195: loss = 0.28319
Step 111200: loss = 0.03227
Step 111205: loss = 0.04846
Step 111210: loss = 0.11443
Step 111215: loss = 0.26020
Step 111220: loss = 0.44361
Step 111225: loss = 0.07738
Step 111230: loss = 0.08684
Step 111235: loss = 0.30954
Step 111240: loss = 0.10979
Step 111245: loss = 0.28776
Step 111250: loss = 0.05422
Step 111255: loss = 0.13943
Step 111260: loss = 0.05845
Step 111265: loss = 0.07441
Step 111270: loss = 0.02327
Step 111275: loss = 0.29273
Step 111280: loss = 0.12784
Step 111285: loss = 0.17235
Step 111290: loss = 0.13126
Step 111295: loss = 0.06777
Step 111300: loss = 0.10896
Step 111305: loss = 0.21177
Step 111310: loss = 0.15111
Step 111315: loss = 0.11276
Step 111320: loss = 0.21924
Step 111325: loss = 0.16703
Step 111330: loss = 0.11776
Step 111335: loss = 0.11242
Step 111340: loss = 0.19935
Step 111345: loss = 0.11139
Step 111350: loss = 0.31232
Step 111355: loss = 0.15195
Step 111360: loss = 0.24333
Step 111365: loss = 0.32907
Step 111370: loss = 0.22332
Step 111375: loss = 0.24028
Step 111380: loss = 0.17393
Step 111385: loss = 0.20194
Step 111390: loss = 0.05348
Step 111395: loss = 0.08683
Step 111400: loss = 0.27353
Step 111405: loss = 0.09609
Step 111410: loss = 0.15285
Step 111415: loss = 0.14032
Step 111420: loss = 0.30218
Step 111425: loss = 0.08455
Step 111430: loss = 0.08908
Step 111435: loss = 0.03763
Step 111440: loss = 0.14377
Step 111445: loss = 0.12236
Step 111450: loss = 0.40857
Step 111455: loss = 0.26769
Step 111460: loss = 0.04703
Step 111465: loss = 0.27614
Step 111470: loss = 0.53959
Step 111475: loss = 0.14007
Step 111480: loss = 0.03724
Step 111485: loss = 0.24660
Step 111490: loss = 0.18821
Step 111495: loss = 0.11642
Step 111500: loss = 0.08165
Step 111505: loss = 0.38094
Step 111510: loss = 0.46355
Step 111515: loss = 0.14120
Step 111520: loss = 0.05377
Step 111525: loss = 0.03126
Step 111530: loss = 0.08387
Step 111535: loss = 0.07191
Step 111540: loss = 0.05958
Step 111545: loss = 0.12172
Step 111550: loss = 0.21628
Step 111555: loss = 0.20629
Step 111560: loss = 0.09558
Step 111565: loss = 0.24808
Step 111570: loss = 0.15951
Step 111575: loss = 0.05542
Step 111580: loss = 0.21926
Step 111585: loss = 0.28711
Step 111590: loss = 0.14685
Step 111595: loss = 0.05400
Step 111600: loss = 0.05215
Step 111605: loss = 0.04520
Step 111610: loss = 0.08212
Step 111615: loss = 0.08881
Step 111620: loss = 0.12323
Step 111625: loss = 0.06160
Step 111630: loss = 0.15166
Step 111635: loss = 0.07595
Step 111640: loss = 0.27099
Step 111645: loss = 0.07584
Step 111650: loss = 0.21005
Step 111655: loss = 0.04238
Step 111660: loss = 0.08000
Step 111665: loss = 0.03262
Step 111670: loss = 0.02666
Step 111675: loss = 0.20950
Step 111680: loss = 0.13691
Step 111685: loss = 0.05562
Step 111690: loss = 0.16725
Step 111695: loss = 0.05290
Step 111700: loss = 0.07147
Step 111705: loss = 0.17038
Step 111710: loss = 0.27999
Step 111715: loss = 0.14923
Step 111720: loss = 0.12943
Step 111725: loss = 0.22386
Step 111730: loss = 0.10764
Step 111735: loss = 0.30280
Step 111740: loss = 0.09683
Step 111745: loss = 0.12581
Step 111750: loss = 0.19333
Step 111755: loss = 0.24676
Step 111760: loss = 0.17504
Step 111765: loss = 0.07878
Step 111770: loss = 0.08903
Step 111775: loss = 0.16802
Step 111780: loss = 0.06287
Step 111785: loss = 0.07694
Step 111790: loss = 0.10850
Step 111795: loss = 0.18152
Step 111800: loss = 0.17363
Step 111805: loss = 0.09896
Step 111810: loss = 0.18789
Step 111815: loss = 0.11072
Step 111820: loss = 0.15151
Step 111825: loss = 0.07021
Step 111830: loss = 0.15653
Step 111835: loss = 0.22412
Step 111840: loss = 0.14934
Step 111845: loss = 0.11523
Step 111850: loss = 0.16344
Step 111855: loss = 0.16329
Step 111860: loss = 0.23804
Step 111865: loss = 0.07832
Step 111870: loss = 0.22365
Step 111875: loss = 0.14329
Step 111880: loss = 0.22915
Step 111885: loss = 0.21784
Step 111890: loss = 0.16603
Step 111895: loss = 0.21052
Step 111900: loss = 0.07411
Step 111905: loss = 0.23381
Step 111910: loss = 0.15078
Step 111915: loss = 0.18340
Step 111920: loss = 0.18038
Step 111925: loss = 0.23092
Step 111930: loss = 0.16704
Step 111935: loss = 0.07514
Step 111940: loss = 0.15552
Step 111945: loss = 0.09686
Step 111950: loss = 0.15988
Step 111955: loss = 0.11067
Step 111960: loss = 0.17539
Step 111965: loss = 0.31420
Step 111970: loss = 0.17295
Step 111975: loss = 0.14216
Step 111980: loss = 0.11993
Step 111985: loss = 0.12411
Step 111990: loss = 0.19371
Step 111995: loss = 0.08897
Step 112000: loss = 0.04793
Training Data Eval:
  Num examples: 50000, Num correct: 47099, Precision @ 1: 0.9420
('Testing Data Eval: EPOCH->', 113)
  Num examples: 10000, Num correct: 6506, Precision @ 1: 0.6506
Step 112005: loss = 0.24302
Step 112010: loss = 0.12018
Step 112015: loss = 0.16515
Step 112020: loss = 0.34186
Step 112025: loss = 0.23803
Step 112030: loss = 0.08361
Step 112035: loss = 0.08699
Step 112040: loss = 0.25461
Step 112045: loss = 0.34464
Step 112050: loss = 0.08134
Step 112055: loss = 0.16611
Step 112060: loss = 0.06482
Step 112065: loss = 0.03734
Step 112070: loss = 0.32811
Step 112075: loss = 0.08399
Step 112080: loss = 0.27749
Step 112085: loss = 0.11487
Step 112090: loss = 0.14159
Step 112095: loss = 0.14296
Step 112100: loss = 0.20982
Step 112105: loss = 0.13065
Step 112110: loss = 0.19896
Step 112115: loss = 0.09563
Step 112120: loss = 0.18940
Step 112125: loss = 0.14073
Step 112130: loss = 0.17493
Step 112135: loss = 0.39070
Step 112140: loss = 0.08237
Step 112145: loss = 0.16562
Step 112150: loss = 0.20526
Step 112155: loss = 0.26918
Step 112160: loss = 0.18301
Step 112165: loss = 0.14336
Step 112170: loss = 0.09409
Step 112175: loss = 0.28936
Step 112180: loss = 0.19051
Step 112185: loss = 0.16471
Step 112190: loss = 0.13583
Step 112195: loss = 0.18263
Step 112200: loss = 0.14473
Step 112205: loss = 0.28589
Step 112210: loss = 0.16601
Step 112215: loss = 0.48513
Step 112220: loss = 0.05508
Step 112225: loss = 0.08655
Step 112230: loss = 0.04968
Step 112235: loss = 0.06800
Step 112240: loss = 0.18691
Step 112245: loss = 0.07764
Step 112250: loss = 0.26049
Step 112255: loss = 0.09088
Step 112260: loss = 0.14829
Step 112265: loss = 0.08154
Step 112270: loss = 0.16075
Step 112275: loss = 0.12029
Step 112280: loss = 0.08769
Step 112285: loss = 0.10090
Step 112290: loss = 0.21436
Step 112295: loss = 0.12106
Step 112300: loss = 0.17852
Step 112305: loss = 0.10573
Step 112310: loss = 0.17787
Step 112315: loss = 0.27220
Step 112320: loss = 0.21224
Step 112325: loss = 0.20077
Step 112330: loss = 0.04873
Step 112335: loss = 0.23198
Step 112340: loss = 0.11655
Step 112345: loss = 0.06840
Step 112350: loss = 0.04868
Step 112355: loss = 0.15696
Step 112360: loss = 0.16025
Step 112365: loss = 0.23114
Step 112370: loss = 0.35414
Step 112375: loss = 0.17308
Step 112380: loss = 0.16138
Step 112385: loss = 0.17502
Step 112390: loss = 0.11215
Step 112395: loss = 0.07065
Step 112400: loss = 0.31239
Step 112405: loss = 0.12661
Step 112410: loss = 0.21188
Step 112415: loss = 0.25460
Step 112420: loss = 0.19759
Step 112425: loss = 0.17569
Step 112430: loss = 0.22269
Step 112435: loss = 0.20055
Step 112440: loss = 0.07461
Step 112445: loss = 0.08269
Step 112450: loss = 0.11693
Step 112455: loss = 0.18168
Step 112460: loss = 0.08834
Step 112465: loss = 0.21578
Step 112470: loss = 0.08520
Step 112475: loss = 0.28947
Step 112480: loss = 0.31069
Step 112485: loss = 0.18337
Step 112490: loss = 0.27401
Step 112495: loss = 0.10078
Step 112500: loss = 0.09930
Step 112505: loss = 0.13848
Step 112510: loss = 0.05679
Step 112515: loss = 0.11582
Step 112520: loss = 0.25464
Step 112525: loss = 0.36182
Step 112530: loss = 0.07630
Step 112535: loss = 0.20001
Step 112540: loss = 0.04115
Step 112545: loss = 0.11499
Step 112550: loss = 0.08595
Step 112555: loss = 0.11058
Step 112560: loss = 0.17111
Step 112565: loss = 0.09979
Step 112570: loss = 0.11090
Step 112575: loss = 0.16722
Step 112580: loss = 0.13819
Step 112585: loss = 0.15188
Step 112590: loss = 0.47370
Step 112595: loss = 0.14253
Step 112600: loss = 0.25445
Step 112605: loss = 0.21863
Step 112610: loss = 0.08331
Step 112615: loss = 0.04763
Step 112620: loss = 0.25665
Step 112625: loss = 0.18270
Step 112630: loss = 0.16145
Step 112635: loss = 0.14604
Step 112640: loss = 0.13220
Step 112645: loss = 0.15481
Step 112650: loss = 0.08168
Step 112655: loss = 0.08621
Step 112660: loss = 0.12320
Step 112665: loss = 0.19644
Step 112670: loss = 0.19280
Step 112675: loss = 0.15466
Step 112680: loss = 0.13277
Step 112685: loss = 0.16308
Step 112690: loss = 0.15658
Step 112695: loss = 0.11709
Step 112700: loss = 0.12845
Step 112705: loss = 0.37262
Step 112710: loss = 0.10939
Step 112715: loss = 0.10669
Step 112720: loss = 0.07576
Step 112725: loss = 0.11034
Step 112730: loss = 0.11570
Step 112735: loss = 0.18962
Step 112740: loss = 0.05830
Step 112745: loss = 0.18576
Step 112750: loss = 0.11325
Step 112755: loss = 0.05992
Step 112760: loss = 0.35083
Step 112765: loss = 0.10311
Step 112770: loss = 0.20705
Step 112775: loss = 0.23346
Step 112780: loss = 0.51685
Step 112785: loss = 0.17656
Step 112790: loss = 0.07958
Step 112795: loss = 0.12606
Step 112800: loss = 0.09830
Step 112805: loss = 0.23489
Step 112810: loss = 0.21504
Step 112815: loss = 0.03954
Step 112820: loss = 0.16086
Step 112825: loss = 0.18609
Step 112830: loss = 0.10041
Step 112835: loss = 0.19129
Step 112840: loss = 0.06834
Step 112845: loss = 0.19341
Step 112850: loss = 0.14187
Step 112855: loss = 0.16415
Step 112860: loss = 0.11538
Step 112865: loss = 0.30013
Step 112870: loss = 0.24735
Step 112875: loss = 0.09413
Step 112880: loss = 0.20921
Step 112885: loss = 0.08473
Step 112890: loss = 0.05798
Step 112895: loss = 0.37646
Step 112900: loss = 0.13033
Step 112905: loss = 0.06033
Step 112910: loss = 0.22947
Step 112915: loss = 0.08658
Step 112920: loss = 0.07236
Step 112925: loss = 0.17846
Step 112930: loss = 0.14048
Step 112935: loss = 0.14429
Step 112940: loss = 0.17133
Step 112945: loss = 0.26010
Step 112950: loss = 0.19736
Step 112955: loss = 0.14496
Step 112960: loss = 0.11318
Step 112965: loss = 0.16400
Step 112970: loss = 0.06909
Step 112975: loss = 0.04885
Step 112980: loss = 0.30185
Step 112985: loss = 0.06960
Step 112990: loss = 0.14181
Step 112995: loss = 0.09545
Step 113000: loss = 0.12635
Training Data Eval:
  Num examples: 50000, Num correct: 47376, Precision @ 1: 0.9475
('Testing Data Eval: EPOCH->', 114)
  Num examples: 10000, Num correct: 6591, Precision @ 1: 0.6591
Step 113005: loss = 0.18382
Step 113010: loss = 0.13086
Step 113015: loss = 0.29453
Step 113020: loss = 0.09578
Step 113025: loss = 0.23010
Step 113030: loss = 0.14022
Step 113035: loss = 0.05936
Step 113040: loss = 0.06487
Step 113045: loss = 0.10345
Step 113050: loss = 0.08010
Step 113055: loss = 0.30391
Step 113060: loss = 0.07129
Step 113065: loss = 0.23316
Step 113070: loss = 0.05109
Step 113075: loss = 0.16659
Step 113080: loss = 0.22543
Step 113085: loss = 0.07569
Step 113090: loss = 0.08810
Step 113095: loss = 0.12464
Step 113100: loss = 0.42008
Step 113105: loss = 0.18061
Step 113110: loss = 0.07717
Step 113115: loss = 0.05115
Step 113120: loss = 0.27548
Step 113125: loss = 0.24731
Step 113130: loss = 0.13974
Step 113135: loss = 0.10874
Step 113140: loss = 0.04559
Step 113145: loss = 0.03213
Step 113150: loss = 0.09743
Step 113155: loss = 0.36551
Step 113160: loss = 0.16049
Step 113165: loss = 0.11384
Step 113170: loss = 0.11979
Step 113175: loss = 0.10959
Step 113180: loss = 0.04598
Step 113185: loss = 0.12102
Step 113190: loss = 0.12379
Step 113195: loss = 0.28764
Step 113200: loss = 0.21704
Step 113205: loss = 0.16166
Step 113210: loss = 0.18558
Step 113215: loss = 0.08343
Step 113220: loss = 0.22246
Step 113225: loss = 0.12938
Step 113230: loss = 0.29322
Step 113235: loss = 0.17066
Step 113240: loss = 0.42830
Step 113245: loss = 0.24607
Step 113250: loss = 0.07069
Step 113255: loss = 0.09278
Step 113260: loss = 0.11260
Step 113265: loss = 0.24513
Step 113270: loss = 0.06351
Step 113275: loss = 0.10305
Step 113280: loss = 0.24984
Step 113285: loss = 0.47653
Step 113290: loss = 0.19387
Step 113295: loss = 0.11835
Step 113300: loss = 0.31135
Step 113305: loss = 0.12472
Step 113310: loss = 0.05709
Step 113315: loss = 0.16032
Step 113320: loss = 0.10000
Step 113325: loss = 0.24988
Step 113330: loss = 0.11010
Step 113335: loss = 0.22836
Step 113340: loss = 0.30428
Step 113345: loss = 0.34068
Step 113350: loss = 0.07420
Step 113355: loss = 0.15135
Step 113360: loss = 0.11622
Step 113365: loss = 0.08448
Step 113370: loss = 0.22306
Step 113375: loss = 0.15628
Step 113380: loss = 0.16252
Step 113385: loss = 0.25519
Step 113390: loss = 0.10354
Step 113395: loss = 0.07664
Step 113400: loss = 0.19644
Step 113405: loss = 0.17674
Step 113410: loss = 0.37860
Step 113415: loss = 0.22326
Step 113420: loss = 0.18090
Step 113425: loss = 0.08124
Step 113430: loss = 0.18044
Step 113435: loss = 0.12568
Step 113440: loss = 0.09472
Step 113445: loss = 0.28327
Step 113450: loss = 0.05822
Step 113455: loss = 0.05106
Step 113460: loss = 0.12078
Step 113465: loss = 0.08993
Step 113470: loss = 0.28955
Step 113475: loss = 0.07253
Step 113480: loss = 0.16750
Step 113485: loss = 0.23351
Step 113490: loss = 0.12373
Step 113495: loss = 0.12228
Step 113500: loss = 0.15689
Step 113505: loss = 0.10832
Step 113510: loss = 0.18737
Step 113515: loss = 0.09417
Step 113520: loss = 0.15057
Step 113525: loss = 0.08710
Step 113530: loss = 0.16368
Step 113535: loss = 0.33609
Step 113540: loss = 0.10958
Step 113545: loss = 0.26387
Step 113550: loss = 0.07257
Step 113555: loss = 0.14935
Step 113560: loss = 0.49657
Step 113565: loss = 0.24443
Step 113570: loss = 0.26216
Step 113575: loss = 0.09324
Step 113580: loss = 0.21035
Step 113585: loss = 0.14175
Step 113590: loss = 0.16134
Step 113595: loss = 0.07984
Step 113600: loss = 0.11031
Step 113605: loss = 0.10841
Step 113610: loss = 0.08834
Step 113615: loss = 0.28769
Step 113620: loss = 0.29809
Step 113625: loss = 0.25569
Step 113630: loss = 0.18120
Step 113635: loss = 0.12654
Step 113640: loss = 0.31489
Step 113645: loss = 0.32541
Step 113650: loss = 0.19329
Step 113655: loss = 0.13842
Step 113660: loss = 0.13707
Step 113665: loss = 0.18783
Step 113670: loss = 0.16698
Step 113675: loss = 0.16845
Step 113680: loss = 0.08930
Step 113685: loss = 0.15654
Step 113690: loss = 0.13557
Step 113695: loss = 0.17582
Step 113700: loss = 0.51786
Step 113705: loss = 0.14801
Step 113710: loss = 0.11716
Step 113715: loss = 0.13636
Step 113720: loss = 0.10148
Step 113725: loss = 0.13361
Step 113730: loss = 0.33852
Step 113735: loss = 0.12107
Step 113740: loss = 0.12040
Step 113745: loss = 0.15288
Step 113750: loss = 0.12165
Step 113755: loss = 0.10316
Step 113760: loss = 0.09318
Step 113765: loss = 0.30442
Step 113770: loss = 0.18356
Step 113775: loss = 0.09073
Step 113780: loss = 0.13987
Step 113785: loss = 0.11713
Step 113790: loss = 0.11347
Step 113795: loss = 0.26432
Step 113800: loss = 0.12980
Step 113805: loss = 0.18081
Step 113810: loss = 0.13371
Step 113815: loss = 0.41510
Step 113820: loss = 0.25019
Step 113825: loss = 0.09213
Step 113830: loss = 0.30559
Step 113835: loss = 0.09397
Step 113840: loss = 0.12111
Step 113845: loss = 0.25021
Step 113850: loss = 0.10116
Step 113855: loss = 0.11195
Step 113860: loss = 0.19164
Step 113865: loss = 0.10889
Step 113870: loss = 0.10149
Step 113875: loss = 0.18803
Step 113880: loss = 0.17070
Step 113885: loss = 0.18168
Step 113890: loss = 0.28398
Step 113895: loss = 0.09646
Step 113900: loss = 0.12234
Step 113905: loss = 0.05988
Step 113910: loss = 0.15455
Step 113915: loss = 0.09477
Step 113920: loss = 0.23842
Step 113925: loss = 0.32666
Step 113930: loss = 0.16938
Step 113935: loss = 0.27468
Step 113940: loss = 0.13818
Step 113945: loss = 0.16722
Step 113950: loss = 0.25297
Step 113955: loss = 0.08878
Step 113960: loss = 0.07185
Step 113965: loss = 0.11640
Step 113970: loss = 0.18024
Step 113975: loss = 0.06268
Step 113980: loss = 0.06021
Step 113985: loss = 0.09010
Step 113990: loss = 0.11239
Step 113995: loss = 0.08560
Step 114000: loss = 0.22539
Training Data Eval:
  Num examples: 50000, Num correct: 47623, Precision @ 1: 0.9525
('Testing Data Eval: EPOCH->', 115)
  Num examples: 10000, Num correct: 6604, Precision @ 1: 0.6604
Step 114005: loss = 0.21052
Step 114010: loss = 0.06207
Step 114015: loss = 0.13251
Step 114020: loss = 0.06640
Step 114025: loss = 0.11066
Step 114030: loss = 0.10539
Step 114035: loss = 0.19812
Step 114040: loss = 0.07547
Step 114045: loss = 0.15535
Step 114050: loss = 0.16504
Step 114055: loss = 0.11210
Step 114060: loss = 0.07949
Step 114065: loss = 0.19360
Step 114070: loss = 0.16573
Step 114075: loss = 0.05025
Step 114080: loss = 0.12090
Step 114085: loss = 0.11164
Step 114090: loss = 0.40623
Step 114095: loss = 0.11782
Step 114100: loss = 0.16287
Step 114105: loss = 0.03705
Step 114110: loss = 0.09407
Step 114115: loss = 0.09702
Step 114120: loss = 0.07508
Step 114125: loss = 0.12516
Step 114130: loss = 0.03339
Step 114135: loss = 0.26933
Step 114140: loss = 0.04735
Step 114145: loss = 0.15893
Step 114150: loss = 0.15757
Step 114155: loss = 0.48874
Step 114160: loss = 0.19715
Step 114165: loss = 0.03571
Step 114170: loss = 0.48182
Step 114175: loss = 0.08090
Step 114180: loss = 0.10420
Step 114185: loss = 0.24204
Step 114190: loss = 0.20768
Step 114195: loss = 0.17730
Step 114200: loss = 0.25957
Step 114205: loss = 0.20515
Step 114210: loss = 0.23850
Step 114215: loss = 0.22884
Step 114220: loss = 0.15175
Step 114225: loss = 0.03566
Step 114230: loss = 0.46158
Step 114235: loss = 0.11674
Step 114240: loss = 0.20487
Step 114245: loss = 0.11997
Step 114250: loss = 0.26100
Step 114255: loss = 0.09199
Step 114260: loss = 0.07818
Step 114265: loss = 0.10651
Step 114270: loss = 0.09802
Step 114275: loss = 0.24460
Step 114280: loss = 0.37553
Step 114285: loss = 0.17401
Step 114290: loss = 0.20225
Step 114295: loss = 0.21690
Step 114300: loss = 0.33445
Step 114305: loss = 0.12629
Step 114310: loss = 0.22550
Step 114315: loss = 0.13263
Step 114320: loss = 0.18502
Step 114325: loss = 0.19374
Step 114330: loss = 0.14065
Step 114335: loss = 0.08519
Step 114340: loss = 0.13695
Step 114345: loss = 0.30662
Step 114350: loss = 0.18594
Step 114355: loss = 0.42626
Step 114360: loss = 0.31758
Step 114365: loss = 0.09328
Step 114370: loss = 0.12891
Step 114375: loss = 0.13718
Step 114380: loss = 0.20924
Step 114385: loss = 0.11676
Step 114390: loss = 0.18053
Step 114395: loss = 0.06860
Step 114400: loss = 0.09996
Step 114405: loss = 0.15062
Step 114410: loss = 0.10089
Step 114415: loss = 0.25786
Step 114420: loss = 0.11175
Step 114425: loss = 0.08002
Step 114430: loss = 0.18892
Step 114435: loss = 0.23674
Step 114440: loss = 0.15837
Step 114445: loss = 0.13834
Step 114450: loss = 0.18195
Step 114455: loss = 0.27082
Step 114460: loss = 0.11245
Step 114465: loss = 0.05107
Step 114470: loss = 0.19172
Step 114475: loss = 0.12675
Step 114480: loss = 0.06400
Step 114485: loss = 0.21843
Step 114490: loss = 0.38516
Step 114495: loss = 0.14277
Step 114500: loss = 0.17488
Step 114505: loss = 0.07888
Step 114510: loss = 0.12919
Step 114515: loss = 0.11136
Step 114520: loss = 0.03478
Step 114525: loss = 0.19380
Step 114530: loss = 0.15419
Step 114535: loss = 0.25150
Step 114540: loss = 0.41147
Step 114545: loss = 0.34839
Step 114550: loss = 0.23834
Step 114555: loss = 0.07998
Step 114560: loss = 0.06568
Step 114565: loss = 0.13191
Step 114570: loss = 0.17041
Step 114575: loss = 0.03465
Step 114580: loss = 0.20150
Step 114585: loss = 0.05718
Step 114590: loss = 0.11909
Step 114595: loss = 0.07983
Step 114600: loss = 0.03758
Step 114605: loss = 0.13075
Step 114610: loss = 0.07962
Step 114615: loss = 0.10340
Step 114620: loss = 0.29387
Step 114625: loss = 0.06029
Step 114630: loss = 0.12073
Step 114635: loss = 0.21925
Step 114640: loss = 0.13213
Step 114645: loss = 0.19177
Step 114650: loss = 0.13720
Step 114655: loss = 0.17115
Step 114660: loss = 0.12895
Step 114665: loss = 0.10258
Step 114670: loss = 0.29351
Step 114675: loss = 0.04922
Step 114680: loss = 0.12073
Step 114685: loss = 0.12233
Step 114690: loss = 0.02019
Step 114695: loss = 0.10803
Step 114700: loss = 0.07949
Step 114705: loss = 0.17871
Step 114710: loss = 0.13718
Step 114715: loss = 0.22953
Step 114720: loss = 0.11491
Step 114725: loss = 0.11505
Step 114730: loss = 0.06921
Step 114735: loss = 0.35616
Step 114740: loss = 0.19753
Step 114745: loss = 0.21467
Step 114750: loss = 0.16499
Step 114755: loss = 0.28807
Step 114760: loss = 0.07342
Step 114765: loss = 0.28298
Step 114770: loss = 0.47882
Step 114775: loss = 0.15464
Step 114780: loss = 0.38433
Step 114785: loss = 0.46601
Step 114790: loss = 0.13636
Step 114795: loss = 0.20140
Step 114800: loss = 0.14424
Step 114805: loss = 0.18748
Step 114810: loss = 0.20902
Step 114815: loss = 0.19254
Step 114820: loss = 0.29272
Step 114825: loss = 0.29214
Step 114830: loss = 0.40972
Step 114835: loss = 0.13897
Step 114840: loss = 0.13323
Step 114845: loss = 0.15395
Step 114850: loss = 0.34789
Step 114855: loss = 0.10697
Step 114860: loss = 0.07215
Step 114865: loss = 0.14639
Step 114870: loss = 0.20895
Step 114875: loss = 0.08635
Step 114880: loss = 0.05782
Step 114885: loss = 0.14618
Step 114890: loss = 0.03824
Step 114895: loss = 0.07338
Step 114900: loss = 0.20312
Step 114905: loss = 0.25945
Step 114910: loss = 0.08324
Step 114915: loss = 0.30366
Step 114920: loss = 0.15208
Step 114925: loss = 0.12132
Step 114930: loss = 0.22464
Step 114935: loss = 0.16469
Step 114940: loss = 0.19474
Step 114945: loss = 0.37294
Step 114950: loss = 0.14753
Step 114955: loss = 0.09255
Step 114960: loss = 0.14086
Step 114965: loss = 0.18710
Step 114970: loss = 0.15763
Step 114975: loss = 0.29697
Step 114980: loss = 0.09302
Step 114985: loss = 0.13943
Step 114990: loss = 0.21976
Step 114995: loss = 0.10234
Step 115000: loss = 0.11141
Training Data Eval:
  Num examples: 50000, Num correct: 47214, Precision @ 1: 0.9443
('Testing Data Eval: EPOCH->', 116)
  Num examples: 10000, Num correct: 6478, Precision @ 1: 0.6478
Step 115005: loss = 0.20204
Step 115010: loss = 0.12399
Step 115015: loss = 0.34553
Step 115020: loss = 0.24030
Step 115025: loss = 0.08872
Step 115030: loss = 0.15147
Step 115035: loss = 0.12471
Step 115040: loss = 0.27604
Step 115045: loss = 0.14672
Step 115050: loss = 0.15966
Step 115055: loss = 0.40385
Step 115060: loss = 0.20681
Step 115065: loss = 0.27418
Step 115070: loss = 0.02460
Step 115075: loss = 0.08873
Step 115080: loss = 0.20055
Step 115085: loss = 0.02275
Step 115090: loss = 0.37835
Step 115095: loss = 0.03527
Step 115100: loss = 0.06815
Step 115105: loss = 0.12383
Step 115110: loss = 0.19509
Step 115115: loss = 0.17145
Step 115120: loss = 0.16874
Step 115125: loss = 0.02403
Step 115130: loss = 0.10281
Step 115135: loss = 0.16154
Step 115140: loss = 0.23356
Step 115145: loss = 0.13332
Step 115150: loss = 0.06585
Step 115155: loss = 0.07516
Step 115160: loss = 0.19984
Step 115165: loss = 0.10994
Step 115170: loss = 0.22840
Step 115175: loss = 0.23960
Step 115180: loss = 0.15119
Step 115185: loss = 0.12896
Step 115190: loss = 0.16626
Step 115195: loss = 0.09323
Step 115200: loss = 0.08094
Step 115205: loss = 0.31396
Step 115210: loss = 0.33887
Step 115215: loss = 0.13575
Step 115220: loss = 0.05539
Step 115225: loss = 0.05541
Step 115230: loss = 0.06651
Step 115235: loss = 0.09799
Step 115240: loss = 0.11542
Step 115245: loss = 0.11312
Step 115250: loss = 0.18157
Step 115255: loss = 0.37787
Step 115260: loss = 0.16691
Step 115265: loss = 0.10843
Step 115270: loss = 0.14671
Step 115275: loss = 0.17993
Step 115280: loss = 0.21953
Step 115285: loss = 0.04408
Step 115290: loss = 0.21532
Step 115295: loss = 0.18843
Step 115300: loss = 0.26509
Step 115305: loss = 0.16924
Step 115310: loss = 0.29769
Step 115315: loss = 0.13320
Step 115320: loss = 0.11207
Step 115325: loss = 0.15031
Step 115330: loss = 0.09522
Step 115335: loss = 0.06603
Step 115340: loss = 0.20787
Step 115345: loss = 0.11086
Step 115350: loss = 0.25983
Step 115355: loss = 0.15758
Step 115360: loss = 0.13915
Step 115365: loss = 0.19308
Step 115370: loss = 0.05188
Step 115375: loss = 0.03851
Step 115380: loss = 0.33653
Step 115385: loss = 0.18580
Step 115390: loss = 0.27623
Step 115395: loss = 0.33589
Step 115400: loss = 0.07255
Step 115405: loss = 0.33907
Step 115410: loss = 0.22370
Step 115415: loss = 0.12333
Step 115420: loss = 0.38098
Step 115425: loss = 0.12066
Step 115430: loss = 0.04668
Step 115435: loss = 0.19085
Step 115440: loss = 0.17110
Step 115445: loss = 0.17178
Step 115450: loss = 0.14517
Step 115455: loss = 0.16741
Step 115460: loss = 0.17188
Step 115465: loss = 0.10410
Step 115470: loss = 0.23197
Step 115475: loss = 0.12704
Step 115480: loss = 0.10453
Step 115485: loss = 0.06387
Step 115490: loss = 0.35885
Step 115495: loss = 0.02669
Step 115500: loss = 0.13860
Step 115505: loss = 0.07548
Step 115510: loss = 0.21777
Step 115515: loss = 0.12055
Step 115520: loss = 0.17760
Step 115525: loss = 0.15364
Step 115530: loss = 0.22456
Step 115535: loss = 0.15615
Step 115540: loss = 0.37457
Step 115545: loss = 0.15288
Step 115550: loss = 0.13196
Step 115555: loss = 0.18016
Step 115560: loss = 0.12619
Step 115565: loss = 0.08542
Step 115570: loss = 0.09666
Step 115575: loss = 0.15285
Step 115580: loss = 0.16912
Step 115585: loss = 0.18688
Step 115590: loss = 0.08673
Step 115595: loss = 0.06644
Step 115600: loss = 0.13556
Step 115605: loss = 0.18008
Step 115610: loss = 0.06656
Step 115615: loss = 0.17926
Step 115620: loss = 0.08380
Step 115625: loss = 0.10900
Step 115630: loss = 0.06736
Step 115635: loss = 0.27084
Step 115640: loss = 0.21768
Step 115645: loss = 0.11533
Step 115650: loss = 0.14410
Step 115655: loss = 0.28218
Step 115660: loss = 0.13059
Step 115665: loss = 0.09908
Step 115670: loss = 0.13193
Step 115675: loss = 0.21809
Step 115680: loss = 0.20425
Step 115685: loss = 0.15127
Step 115690: loss = 0.27921
Step 115695: loss = 0.27509
Step 115700: loss = 0.20124
Step 115705: loss = 0.06605
Step 115710: loss = 0.10027
Step 115715: loss = 0.08260
Step 115720: loss = 0.37535
Step 115725: loss = 0.19014
Step 115730: loss = 0.14649
Step 115735: loss = 0.09704
Step 115740: loss = 0.20443
Step 115745: loss = 0.29515
Step 115750: loss = 0.18100
Step 115755: loss = 0.11260
Step 115760: loss = 0.13147
Step 115765: loss = 0.20501
Step 115770: loss = 0.09421
Step 115775: loss = 0.22053
Step 115780: loss = 0.14810
Step 115785: loss = 0.10991
Step 115790: loss = 0.13544
Step 115795: loss = 0.06755
Step 115800: loss = 0.20761
Step 115805: loss = 0.19461
Step 115810: loss = 0.12369
Step 115815: loss = 0.11844
Step 115820: loss = 0.15612
Step 115825: loss = 0.14804
Step 115830: loss = 0.05424
Step 115835: loss = 0.12699
Step 115840: loss = 0.08681
Step 115845: loss = 0.29866
Step 115850: loss = 0.09544
Step 115855: loss = 0.17144
Step 115860: loss = 0.19515
Step 115865: loss = 0.13727
Step 115870: loss = 0.11818
Step 115875: loss = 0.08491
Step 115880: loss = 0.16510
Step 115885: loss = 0.12389
Step 115890: loss = 0.43206
Step 115895: loss = 0.10082
Step 115900: loss = 0.13819
Step 115905: loss = 0.11156
Step 115910: loss = 0.15004
Step 115915: loss = 0.17158
Step 115920: loss = 0.36004
Step 115925: loss = 0.11873
Step 115930: loss = 0.12644
Step 115935: loss = 0.06050
Step 115940: loss = 0.10664
Step 115945: loss = 0.07280
Step 115950: loss = 0.17256
Step 115955: loss = 0.16750
Step 115960: loss = 0.21341
Step 115965: loss = 0.13116
Step 115970: loss = 0.13119
Step 115975: loss = 0.12036
Step 115980: loss = 0.17982
Step 115985: loss = 0.08377
Step 115990: loss = 0.05255
Step 115995: loss = 0.09871
Step 116000: loss = 0.45199
Training Data Eval:
  Num examples: 50000, Num correct: 47368, Precision @ 1: 0.9474
('Testing Data Eval: EPOCH->', 117)
  Num examples: 10000, Num correct: 6606, Precision @ 1: 0.6606
Step 116005: loss = 0.54018
Step 116010: loss = 0.08231
Step 116015: loss = 0.08461
Step 116020: loss = 0.15069
Step 116025: loss = 0.31806
Step 116030: loss = 0.11018
Step 116035: loss = 0.19296
Step 116040: loss = 0.05705
Step 116045: loss = 0.18704
Step 116050: loss = 0.15416
Step 116055: loss = 0.09091
Step 116060: loss = 0.34084
Step 116065: loss = 0.34076
Step 116070: loss = 0.34428
Step 116075: loss = 0.14748
Step 116080: loss = 0.16589
Step 116085: loss = 0.08114
Step 116090: loss = 0.04666
Step 116095: loss = 0.13592
Step 116100: loss = 0.14047
Step 116105: loss = 0.08132
Step 116110: loss = 0.20373
Step 116115: loss = 0.15300
Step 116120: loss = 0.20517
Step 116125: loss = 0.35159
Step 116130: loss = 0.15742
Step 116135: loss = 0.14432
Step 116140: loss = 0.34656
Step 116145: loss = 0.16217
Step 116150: loss = 0.33125
Step 116155: loss = 0.02647
Step 116160: loss = 0.20312
Step 116165: loss = 0.26450
Step 116170: loss = 0.15347
Step 116175: loss = 0.07632
Step 116180: loss = 0.07949
Step 116185: loss = 0.09918
Step 116190: loss = 0.11800
Step 116195: loss = 0.16640
Step 116200: loss = 0.08071
Step 116205: loss = 0.09051
Step 116210: loss = 0.16198
Step 116215: loss = 0.08241
Step 116220: loss = 0.06022
Step 116225: loss = 0.17463
Step 116230: loss = 0.13366
Step 116235: loss = 0.25050
Step 116240: loss = 0.31578
Step 116245: loss = 0.12079
Step 116250: loss = 0.21829
Step 116255: loss = 0.04135
Step 116260: loss = 0.04508
Step 116265: loss = 0.09624
Step 116270: loss = 0.04835
Step 116275: loss = 0.18289
Step 116280: loss = 0.43496
Step 116285: loss = 0.22239
Step 116290: loss = 0.05661
Step 116295: loss = 0.04513
Step 116300: loss = 0.18979
Step 116305: loss = 0.21902
Step 116310: loss = 0.07426
Step 116315: loss = 0.06800
Step 116320: loss = 0.15549
Step 116325: loss = 0.24559
Step 116330: loss = 0.18209
Step 116335: loss = 0.25214
Step 116340: loss = 0.09275
Step 116345: loss = 0.18534
Step 116350: loss = 0.27651
Step 116355: loss = 0.20163
Step 116360: loss = 0.07024
Step 116365: loss = 0.09942
Step 116370: loss = 0.20854
Step 116375: loss = 0.24398
Step 116380: loss = 0.13323
Step 116385: loss = 0.08848
Step 116390: loss = 0.29976
Step 116395: loss = 0.08966
Step 116400: loss = 0.19480
Step 116405: loss = 0.14675
Step 116410: loss = 0.14468
Step 116415: loss = 0.11371
Step 116420: loss = 0.22929
Step 116425: loss = 0.09966
Step 116430: loss = 0.22790
Step 116435: loss = 0.27700
Step 116440: loss = 0.07134
Step 116445: loss = 0.04260
Step 116450: loss = 0.21948
Step 116455: loss = 0.23053
Step 116460: loss = 0.13672
Step 116465: loss = 0.11337
Step 116470: loss = 0.11127
Step 116475: loss = 0.17251
Step 116480: loss = 0.18932
Step 116485: loss = 0.09834
Step 116490: loss = 0.10120
Step 116495: loss = 0.22595
Step 116500: loss = 0.05670
Step 116505: loss = 0.07947
Step 116510: loss = 0.06588
Step 116515: loss = 0.14555
Step 116520: loss = 0.14802
Step 116525: loss = 0.10655
Step 116530: loss = 0.37890
Step 116535: loss = 0.11289
Step 116540: loss = 0.25985
Step 116545: loss = 0.24892
Step 116550: loss = 0.07226
Step 116555: loss = 0.26001
Step 116560: loss = 0.21145
Step 116565: loss = 0.14040
Step 116570: loss = 0.16033
Step 116575: loss = 0.05391
Step 116580: loss = 0.20806
Step 116585: loss = 0.12602
Step 116590: loss = 0.17732
Step 116595: loss = 0.09860
Step 116600: loss = 0.12780
Step 116605: loss = 0.16911
Step 116610: loss = 0.05332
Step 116615: loss = 0.04914
Step 116620: loss = 0.06543
Step 116625: loss = 0.10790
Step 116630: loss = 0.11910
Step 116635: loss = 0.21226
Step 116640: loss = 0.10777
Step 116645: loss = 0.05678
Step 116650: loss = 0.12110
Step 116655: loss = 0.04763
Step 116660: loss = 0.13813
Step 116665: loss = 0.12606
Step 116670: loss = 0.24957
Step 116675: loss = 0.06767
Step 116680: loss = 0.15132
Step 116685: loss = 0.28656
Step 116690: loss = 0.15402
Step 116695: loss = 0.06771
Step 116700: loss = 0.13544
Step 116705: loss = 0.06041
Step 116710: loss = 0.36219
Step 116715: loss = 0.06625
Step 116720: loss = 0.21772
Step 116725: loss = 0.15504
Step 116730: loss = 0.08943
Step 116735: loss = 0.09254
Step 116740: loss = 0.09873
Step 116745: loss = 0.13293
Step 116750: loss = 0.08747
Step 116755: loss = 0.15484
Step 116760: loss = 0.33859
Step 116765: loss = 0.12512
Step 116770: loss = 0.25869
Step 116775: loss = 0.10413
Step 116780: loss = 0.30517
Step 116785: loss = 0.42268
Step 116790: loss = 0.16514
Step 116795: loss = 0.06610
Step 116800: loss = 0.23360
Step 116805: loss = 0.16820
Step 116810: loss = 0.09379
Step 116815: loss = 0.13134
Step 116820: loss = 0.09010
Step 116825: loss = 0.14335
Step 116830: loss = 0.11421
Step 116835: loss = 0.04806
Step 116840: loss = 0.14515
Step 116845: loss = 0.41177
Step 116850: loss = 0.19201
Step 116855: loss = 0.18432
Step 116860: loss = 0.18668
Step 116865: loss = 0.11792
Step 116870: loss = 0.09199
Step 116875: loss = 0.28177
Step 116880: loss = 0.29650
Step 116885: loss = 0.25431
Step 116890: loss = 0.08027
Step 116895: loss = 0.14866
Step 116900: loss = 0.05900
Step 116905: loss = 0.43418
Step 116910: loss = 0.17450
Step 116915: loss = 0.09592
Step 116920: loss = 0.22699
Step 116925: loss = 0.08471
Step 116930: loss = 0.10242
Step 116935: loss = 0.10130
Step 116940: loss = 0.10961
Step 116945: loss = 0.10002
Step 116950: loss = 0.08484
Step 116955: loss = 0.14022
Step 116960: loss = 0.13959
Step 116965: loss = 0.08318
Step 116970: loss = 0.20490
Step 116975: loss = 0.17050
Step 116980: loss = 0.14073
Step 116985: loss = 0.18505
Step 116990: loss = 0.21076
Step 116995: loss = 0.10687
Step 117000: loss = 0.09088
Training Data Eval:
  Num examples: 50000, Num correct: 47225, Precision @ 1: 0.9445
('Testing Data Eval: EPOCH->', 118)
  Num examples: 10000, Num correct: 6608, Precision @ 1: 0.6608
Step 117005: loss = 0.20777
Step 117010: loss = 0.15348
Step 117015: loss = 0.30643
Step 117020: loss = 0.07170
Step 117025: loss = 0.27785
Step 117030: loss = 0.12907
Step 117035: loss = 0.05195
Step 117040: loss = 0.13312
Step 117045: loss = 0.22464
Step 117050: loss = 0.26384
Step 117055: loss = 0.26727
Step 117060: loss = 0.35904
Step 117065: loss = 0.12738
Step 117070: loss = 0.18064
Step 117075: loss = 0.14204
Step 117080: loss = 0.21509
Step 117085: loss = 0.10258
Step 117090: loss = 0.11199
Step 117095: loss = 0.23705
Step 117100: loss = 0.05944
Step 117105: loss = 0.12406
Step 117110: loss = 0.12078
Step 117115: loss = 0.19760
Step 117120: loss = 0.18488
Step 117125: loss = 0.08601
Step 117130: loss = 0.31538
Step 117135: loss = 0.09421
Step 117140: loss = 0.14037
Step 117145: loss = 0.08694
Step 117150: loss = 0.03073
Step 117155: loss = 0.11437
Step 117160: loss = 0.17914
Step 117165: loss = 0.04037
Step 117170: loss = 0.06350
Step 117175: loss = 0.10850
Step 117180: loss = 0.21447
Step 117185: loss = 0.05716
Step 117190: loss = 0.13490
Step 117195: loss = 0.09514
Step 117200: loss = 0.20486
Step 117205: loss = 0.28023
Step 117210: loss = 0.28824
Step 117215: loss = 0.31208
Step 117220: loss = 0.13902
Step 117225: loss = 0.15579
Step 117230: loss = 0.16123
Step 117235: loss = 0.11372
Step 117240: loss = 0.14750
Step 117245: loss = 0.08830
Step 117250: loss = 0.40342
Step 117255: loss = 0.13540
Step 117260: loss = 0.11040
Step 117265: loss = 0.09654
Step 117270: loss = 0.25695
Step 117275: loss = 0.06726
Step 117280: loss = 0.54180
Step 117285: loss = 0.18480
Step 117290: loss = 0.14234
Step 117295: loss = 0.27173
Step 117300: loss = 0.03577
Step 117305: loss = 0.03567
Step 117310: loss = 0.04950
Step 117315: loss = 0.24432
Step 117320: loss = 0.10160
Step 117325: loss = 0.13025
Step 117330: loss = 0.13905
Step 117335: loss = 0.23275
Step 117340: loss = 0.13224
Step 117345: loss = 0.15052
Step 117350: loss = 0.10164
Step 117355: loss = 0.08013
Step 117360: loss = 0.28238
Step 117365: loss = 0.10785
Step 117370: loss = 0.11611
Step 117375: loss = 0.12477
Step 117380: loss = 0.18735
Step 117385: loss = 0.22885
Step 117390: loss = 0.13513
Step 117395: loss = 0.09206
Step 117400: loss = 0.14067
Step 117405: loss = 0.12440
Step 117410: loss = 0.08909
Step 117415: loss = 0.10747
Step 117420: loss = 0.09170
Step 117425: loss = 0.15524
Step 117430: loss = 0.15577
Step 117435: loss = 0.38528
Step 117440: loss = 0.20779
Step 117445: loss = 0.12018
Step 117450: loss = 0.19864
Step 117455: loss = 0.10944
Step 117460: loss = 0.07171
Step 117465: loss = 0.10320
Step 117470: loss = 0.13110
Step 117475: loss = 0.16588
Step 117480: loss = 0.12980
Step 117485: loss = 0.16017
Step 117490: loss = 0.15224
Step 117495: loss = 0.05077
Step 117500: loss = 0.16129
Step 117505: loss = 0.05991
Step 117510: loss = 0.15263
Step 117515: loss = 0.16766
Step 117520: loss = 0.16071
Step 117525: loss = 0.17381
Step 117530: loss = 0.14327
Step 117535: loss = 0.18354
Step 117540: loss = 0.13224
Step 117545: loss = 0.30434
Step 117550: loss = 0.16966
Step 117555: loss = 0.10956
Step 117560: loss = 0.07641
Step 117565: loss = 0.09634
Step 117570: loss = 0.04311
Step 117575: loss = 0.10504
Step 117580: loss = 0.06759
Step 117585: loss = 0.07012
Step 117590: loss = 0.19315
Step 117595: loss = 0.05756
Step 117600: loss = 0.06926
Step 117605: loss = 0.22826
Step 117610: loss = 0.05087
Step 117615: loss = 0.07910
Step 117620: loss = 0.16298
Step 117625: loss = 0.09908
Step 117630: loss = 0.12970
Step 117635: loss = 0.20076
Step 117640: loss = 0.14808
Step 117645: loss = 0.05473
Step 117650: loss = 0.24352
Step 117655: loss = 0.05618
Step 117660: loss = 0.04141
Step 117665: loss = 0.03802
Step 117670: loss = 0.11334
Step 117675: loss = 0.22855
Step 117680: loss = 0.03665
Step 117685: loss = 0.11173
Step 117690: loss = 0.09602
Step 117695: loss = 0.09263
Step 117700: loss = 0.19536
Step 117705: loss = 0.25802
Step 117710: loss = 0.13189
Step 117715: loss = 0.31226
Step 117720: loss = 0.22078
Step 117725: loss = 0.15293
Step 117730: loss = 0.04893
Step 117735: loss = 0.26652
Step 117740: loss = 0.18381
Step 117745: loss = 0.09640
Step 117750: loss = 0.05810
Step 117755: loss = 0.14725
Step 117760: loss = 0.24263
Step 117765: loss = 0.41749
Step 117770: loss = 0.23579
Step 117775: loss = 0.10933
Step 117780: loss = 0.28540
Step 117785: loss = 0.10228
Step 117790: loss = 0.08537
Step 117795: loss = 0.29188
Step 117800: loss = 0.08697
Step 117805: loss = 0.07520
Step 117810: loss = 0.22042
Step 117815: loss = 0.31735
Step 117820: loss = 0.05945
Step 117825: loss = 0.10266
Step 117830: loss = 0.14783
Step 117835: loss = 0.16230
Step 117840: loss = 0.05286
Step 117845: loss = 0.20524
Step 117850: loss = 0.07459
Step 117855: loss = 0.03132
Step 117860: loss = 0.08598
Step 117865: loss = 0.08504
Step 117870: loss = 0.12551
Step 117875: loss = 0.09161
Step 117880: loss = 0.25029
Step 117885: loss = 0.10224
Step 117890: loss = 0.08554
Step 117895: loss = 0.05677
Step 117900: loss = 0.18769
Step 117905: loss = 0.32699
Step 117910: loss = 0.12038
Step 117915: loss = 0.12563
Step 117920: loss = 0.12596
Step 117925: loss = 0.06316
Step 117930: loss = 0.09113
Step 117935: loss = 0.14163
Step 117940: loss = 0.13551
Step 117945: loss = 0.05979
Step 117950: loss = 0.18977
Step 117955: loss = 0.09345
Step 117960: loss = 0.11768
Step 117965: loss = 0.05685
Step 117970: loss = 0.14445
Step 117975: loss = 0.06463
Step 117980: loss = 0.08960
Step 117985: loss = 0.03647
Step 117990: loss = 0.24941
Step 117995: loss = 0.08268
Step 118000: loss = 0.04179
Training Data Eval:
  Num examples: 50000, Num correct: 47354, Precision @ 1: 0.9471
('Testing Data Eval: EPOCH->', 119)
  Num examples: 10000, Num correct: 6650, Precision @ 1: 0.6650
Step 118005: loss = 0.23515
Step 118010: loss = 0.14313
Step 118015: loss = 0.13898
Step 118020: loss = 0.10629
Step 118025: loss = 0.20048
Step 118030: loss = 0.46051
Step 118035: loss = 0.11746
Step 118040: loss = 0.11392
Step 118045: loss = 0.16377
Step 118050: loss = 0.05481
Step 118055: loss = 0.18169
Step 118060: loss = 0.15018
Step 118065: loss = 0.16540
Step 118070: loss = 0.14654
Step 118075: loss = 0.16088
Step 118080: loss = 0.13955
Step 118085: loss = 0.08004
Step 118090: loss = 0.13553
Step 118095: loss = 0.20446
Step 118100: loss = 0.33364
Step 118105: loss = 0.42931
Step 118110: loss = 0.05751
Step 118115: loss = 0.25007
Step 118120: loss = 0.26011
Step 118125: loss = 0.09434
Step 118130: loss = 0.24526
Step 118135: loss = 0.07505
Step 118140: loss = 0.17171
Step 118145: loss = 0.03708
Step 118150: loss = 0.33873
Step 118155: loss = 0.31490
Step 118160: loss = 0.30052
Step 118165: loss = 0.07048
Step 118170: loss = 0.07480
Step 118175: loss = 0.20080
Step 118180: loss = 0.19880
Step 118185: loss = 0.12587
Step 118190: loss = 0.08414
Step 118195: loss = 0.11908
Step 118200: loss = 0.09794
Step 118205: loss = 0.09927
Step 118210: loss = 0.15328
Step 118215: loss = 0.07842
Step 118220: loss = 0.08696
Step 118225: loss = 0.35808
Step 118230: loss = 0.12802
Step 118235: loss = 0.12362
Step 118240: loss = 0.33693
Step 118245: loss = 0.22903
Step 118250: loss = 0.12334
Step 118255: loss = 0.09909
Step 118260: loss = 0.20140
Step 118265: loss = 0.09523
Step 118270: loss = 0.15681
Step 118275: loss = 0.06555
Step 118280: loss = 0.27416
Step 118285: loss = 0.18730
Step 118290: loss = 0.13754
Step 118295: loss = 0.13293
Step 118300: loss = 0.07680
Step 118305: loss = 0.18359
Step 118310: loss = 0.11450
Step 118315: loss = 0.14450
Step 118320: loss = 0.10403
Step 118325: loss = 0.13216
Step 118330: loss = 0.23169
Step 118335: loss = 0.05168
Step 118340: loss = 0.25835
Step 118345: loss = 0.17031
Step 118350: loss = 0.07789
Step 118355: loss = 0.10076
Step 118360: loss = 0.27162
Step 118365: loss = 0.12725
Step 118370: loss = 0.10855
Step 118375: loss = 0.17707
Step 118380: loss = 0.09464
Step 118385: loss = 0.19860
Step 118390: loss = 0.23785
Step 118395: loss = 0.11202
Step 118400: loss = 0.04578
Step 118405: loss = 0.15699
Step 118410: loss = 0.20224
Step 118415: loss = 0.09743
Step 118420: loss = 0.20379
Step 118425: loss = 0.21300
Step 118430: loss = 0.13527
Step 118435: loss = 0.05650
Step 118440: loss = 0.43597
Step 118445: loss = 0.08074
Step 118450: loss = 0.14342
Step 118455: loss = 0.14232
Step 118460: loss = 0.17106
Step 118465: loss = 0.10135
Step 118470: loss = 0.08994
Step 118475: loss = 0.35841
Step 118480: loss = 0.12694
Step 118485: loss = 0.12438
Step 118490: loss = 0.07262
Step 118495: loss = 0.13958
Step 118500: loss = 0.16090
Step 118505: loss = 0.24891
Step 118510: loss = 0.17273
Step 118515: loss = 0.13034
Step 118520: loss = 0.26249
Step 118525: loss = 0.09395
Step 118530: loss = 0.07797
Step 118535: loss = 0.13114
Step 118540: loss = 0.28622
Step 118545: loss = 0.18830
Step 118550: loss = 0.22381
Step 118555: loss = 0.08220
Step 118560: loss = 0.11326
Step 118565: loss = 0.25050
Step 118570: loss = 0.23871
Step 118575: loss = 0.23607
Step 118580: loss = 0.10834
Step 118585: loss = 0.16488
Step 118590: loss = 0.16676
Step 118595: loss = 0.16848
Step 118600: loss = 0.09320
Step 118605: loss = 0.21658
Step 118610: loss = 0.32990
Step 118615: loss = 0.12518
Step 118620: loss = 0.08378
Step 118625: loss = 0.06753
Step 118630: loss = 0.09767
Step 118635: loss = 0.12603
Step 118640: loss = 0.06480
Step 118645: loss = 0.13551
Step 118650: loss = 0.09397
Step 118655: loss = 0.07980
Step 118660: loss = 0.05891
Step 118665: loss = 0.17537
Step 118670: loss = 0.19033
Step 118675: loss = 0.20804
Step 118680: loss = 0.08169
Step 118685: loss = 0.11486
Step 118690: loss = 0.20289
Step 118695: loss = 0.41665
Step 118700: loss = 0.23719
Step 118705: loss = 0.36968
Step 118710: loss = 0.16015
Step 118715: loss = 0.10276
Step 118720: loss = 0.18917
Step 118725: loss = 0.14112
Step 118730: loss = 0.18218
Step 118735: loss = 0.31792
Step 118740: loss = 0.65652
Step 118745: loss = 0.07285
Step 118750: loss = 0.14696
Step 118755: loss = 0.34260
Step 118760: loss = 0.23287
Step 118765: loss = 0.16222
Step 118770: loss = 0.11165
Step 118775: loss = 0.06555
Step 118780: loss = 0.27643
Step 118785: loss = 0.33839
Step 118790: loss = 0.12310
Step 118795: loss = 0.13045
Step 118800: loss = 0.07517
Step 118805: loss = 0.09952
Step 118810: loss = 0.16633
Step 118815: loss = 0.06050
Step 118820: loss = 0.09456
Step 118825: loss = 0.15766
Step 118830: loss = 0.12941
Step 118835: loss = 0.21741
Step 118840: loss = 0.11676
Step 118845: loss = 0.14698
Step 118850: loss = 0.24665
Step 118855: loss = 0.10260
Step 118860: loss = 0.12588
Step 118865: loss = 0.17892
Step 118870: loss = 0.15306
Step 118875: loss = 0.25357
Step 118880: loss = 0.19210
Step 118885: loss = 0.07952
Step 118890: loss = 0.11504
Step 118895: loss = 0.18061
Step 118900: loss = 0.09325
Step 118905: loss = 0.21870
Step 118910: loss = 0.06444
Step 118915: loss = 0.04719
Step 118920: loss = 0.13936
Step 118925: loss = 0.22336
Step 118930: loss = 0.09033
Step 118935: loss = 0.15430
Step 118940: loss = 0.11335
Step 118945: loss = 0.18976
Step 118950: loss = 0.27062
Step 118955: loss = 0.17529
Step 118960: loss = 0.07388
Step 118965: loss = 0.13350
Step 118970: loss = 0.09903
Step 118975: loss = 0.20969
Step 118980: loss = 0.09039
Step 118985: loss = 0.38070
Step 118990: loss = 0.16075
Step 118995: loss = 0.46076
Step 119000: loss = 0.13846
Training Data Eval:
  Num examples: 50000, Num correct: 47457, Precision @ 1: 0.9491
('Testing Data Eval: EPOCH->', 120)
  Num examples: 10000, Num correct: 6648, Precision @ 1: 0.6648
Step 119005: loss = 0.13008
Step 119010: loss = 0.12300
Step 119015: loss = 0.19943
Step 119020: loss = 0.05141
Step 119025: loss = 0.12294
Step 119030: loss = 0.19493
Step 119035: loss = 0.14356
Step 119040: loss = 0.29007
Step 119045: loss = 0.12148
Step 119050: loss = 0.14704
Step 119055: loss = 0.15580
Step 119060: loss = 0.20375
Step 119065: loss = 0.10077
Step 119070: loss = 0.36597
Step 119075: loss = 0.37527
Step 119080: loss = 0.08490
Step 119085: loss = 0.18959
Step 119090: loss = 0.24855
Step 119095: loss = 0.30371
Step 119100: loss = 0.26064
Step 119105: loss = 0.06545
Step 119110: loss = 0.12490
Step 119115: loss = 0.10991
Step 119120: loss = 0.08893
Step 119125: loss = 0.14326
Step 119130: loss = 0.04311
Step 119135: loss = 0.05609
Step 119140: loss = 0.45932
Step 119145: loss = 0.05281
Step 119150: loss = 0.14087
Step 119155: loss = 0.33753
Step 119160: loss = 0.11239
Step 119165: loss = 0.32402
Step 119170: loss = 0.12281
Step 119175: loss = 0.28427
Step 119180: loss = 0.11833
Step 119185: loss = 0.15866
Step 119190: loss = 0.18953
Step 119195: loss = 0.11337
Step 119200: loss = 0.04468
Step 119205: loss = 0.01780
Step 119210: loss = 0.02952
Step 119215: loss = 0.18378
Step 119220: loss = 0.11980
Step 119225: loss = 0.19732
Step 119230: loss = 0.07100
Step 119235: loss = 0.14066
Step 119240: loss = 0.16254
Step 119245: loss = 0.20424
Step 119250: loss = 0.33671
Step 119255: loss = 0.12129
Step 119260: loss = 0.19137
Step 119265: loss = 0.13915
Step 119270: loss = 0.20640
Step 119275: loss = 0.13560
Step 119280: loss = 0.07709
Step 119285: loss = 0.17580
Step 119290: loss = 0.31345
Step 119295: loss = 0.14750
Step 119300: loss = 0.17309
Step 119305: loss = 0.13571
Step 119310: loss = 0.04695
Step 119315: loss = 0.20290
Step 119320: loss = 0.15630
Step 119325: loss = 0.14603
Step 119330: loss = 0.05065
Step 119335: loss = 0.03865
Step 119340: loss = 0.17161
Step 119345: loss = 0.04505
Step 119350: loss = 0.07238
Step 119355: loss = 0.05170
Step 119360: loss = 0.10988
Step 119365: loss = 0.10205
Step 119370: loss = 0.09910
Step 119375: loss = 0.12641
Step 119380: loss = 0.09920
Step 119385: loss = 0.02001
Step 119390: loss = 0.22360
Step 119395: loss = 0.14471
Step 119400: loss = 0.06447
Step 119405: loss = 0.14314
Step 119410: loss = 0.20944
Step 119415: loss = 0.15953
Step 119420: loss = 0.21879
Step 119425: loss = 0.10468
Step 119430: loss = 0.36091
Step 119435: loss = 0.11426
Step 119440: loss = 0.05610
Step 119445: loss = 0.22488
Step 119450: loss = 0.10437
Step 119455: loss = 0.25588
Step 119460: loss = 0.36193
Step 119465: loss = 0.04052
Step 119470: loss = 0.14453
Step 119475: loss = 0.07496
Step 119480: loss = 0.15433
Step 119485: loss = 0.15318
Step 119490: loss = 0.16567
Step 119495: loss = 0.13563
Step 119500: loss = 0.33454
Step 119505: loss = 0.17176
Step 119510: loss = 0.11656
Step 119515: loss = 0.07681
Step 119520: loss = 0.46258
Step 119525: loss = 0.10084
Step 119530: loss = 0.14905
Step 119535: loss = 0.14487
Step 119540: loss = 0.14904
Step 119545: loss = 0.14350
Step 119550: loss = 0.16909
Step 119555: loss = 0.15101
Step 119560: loss = 0.08149
Step 119565: loss = 0.08058
Step 119570: loss = 0.12122
Step 119575: loss = 0.09131
Step 119580: loss = 0.05261
Step 119585: loss = 0.14603
Step 119590: loss = 0.09712
Step 119595: loss = 0.12111
Step 119600: loss = 0.05333
Step 119605: loss = 0.23836
Step 119610: loss = 0.11302
Step 119615: loss = 0.06218
Step 119620: loss = 0.41431
Step 119625: loss = 0.10061
Step 119630: loss = 0.10484
Step 119635: loss = 0.17625
Step 119640: loss = 0.22985
Step 119645: loss = 0.09215
Step 119650: loss = 0.27816
Step 119655: loss = 0.13449
Step 119660: loss = 0.05178
Step 119665: loss = 0.13101
Step 119670: loss = 0.07519
Step 119675: loss = 0.07012
Step 119680: loss = 0.23258
Step 119685: loss = 0.19374
Step 119690: loss = 0.10035
Step 119695: loss = 0.15986
Step 119700: loss = 0.08398
Step 119705: loss = 0.13130
Step 119710: loss = 0.10727
Step 119715: loss = 0.14648
Step 119720: loss = 0.20801
Step 119725: loss = 0.09940
Step 119730: loss = 0.11929
Step 119735: loss = 0.33220
Step 119740: loss = 0.13470
Step 119745: loss = 0.15826
Step 119750: loss = 0.09940
Step 119755: loss = 0.10852
Step 119760: loss = 0.21074
Step 119765: loss = 0.18024
Step 119770: loss = 0.04468
Step 119775: loss = 0.15066
Step 119780: loss = 0.19836
Step 119785: loss = 0.07092
Step 119790: loss = 0.07556
Step 119795: loss = 0.22259
Step 119800: loss = 0.01943
Step 119805: loss = 0.16142
Step 119810: loss = 0.18894
Step 119815: loss = 0.28434
Step 119820: loss = 0.11337
Step 119825: loss = 0.09103
Step 119830: loss = 0.20241
Step 119835: loss = 0.16369
Step 119840: loss = 0.32860
Step 119845: loss = 0.06722
Step 119850: loss = 0.11068
Step 119855: loss = 0.12002
Step 119860: loss = 0.11546
Step 119865: loss = 0.42507
Step 119870: loss = 0.13594
Step 119875: loss = 0.09928
Step 119880: loss = 0.15254
Step 119885: loss = 0.13302
Step 119890: loss = 0.13377
Step 119895: loss = 0.27739
Step 119900: loss = 0.45966
Step 119905: loss = 0.09699
Step 119910: loss = 0.17150
Step 119915: loss = 0.23445
Step 119920: loss = 0.20616
Step 119925: loss = 0.12787
Step 119930: loss = 0.10379
Step 119935: loss = 0.15169
Step 119940: loss = 0.08998
Step 119945: loss = 0.22774
Step 119950: loss = 0.30770
Step 119955: loss = 0.06514
Step 119960: loss = 0.21427
Step 119965: loss = 0.21886
Step 119970: loss = 0.10513
Step 119975: loss = 0.10585
Step 119980: loss = 0.20970
Step 119985: loss = 0.10497
Step 119990: loss = 0.09665
Step 119995: loss = 0.05305
Step 120000: loss = 0.12835
Training Data Eval:
  Num examples: 50000, Num correct: 47536, Precision @ 1: 0.9507
('Testing Data Eval: EPOCH->', 121)
  Num examples: 10000, Num correct: 6620, Precision @ 1: 0.6620
Step 120005: loss = 0.09855
Step 120010: loss = 0.23410
Step 120015: loss = 0.24955
Step 120020: loss = 0.19154
Step 120025: loss = 0.12963
Step 120030: loss = 0.14443
Step 120035: loss = 0.10655
Step 120040: loss = 0.26156
Step 120045: loss = 0.13589
Step 120050: loss = 0.11615
Step 120055: loss = 0.10252
Step 120060: loss = 0.10694
Step 120065: loss = 0.05100
Step 120070: loss = 0.06362
Step 120075: loss = 0.17529
Step 120080: loss = 0.25610
Step 120085: loss = 0.17666
Step 120090: loss = 0.19946
Step 120095: loss = 0.14491
Step 120100: loss = 0.05186
Step 120105: loss = 0.33662
Step 120110: loss = 0.42328
Step 120115: loss = 0.21718
Step 120120: loss = 0.31600
Step 120125: loss = 0.14824
Step 120130: loss = 0.24485
Step 120135: loss = 0.28567
Step 120140: loss = 0.07138
Step 120145: loss = 0.14012
Step 120150: loss = 0.14490
Step 120155: loss = 0.09936
Step 120160: loss = 0.11228
Step 120165: loss = 0.20870
Step 120170: loss = 0.14295
Step 120175: loss = 0.12261
Step 120180: loss = 0.09418
Step 120185: loss = 0.16996
Step 120190: loss = 0.09578
Step 120195: loss = 0.10076
Step 120200: loss = 0.04747
Step 120205: loss = 0.24088
Step 120210: loss = 0.12633
Step 120215: loss = 0.13736
Step 120220: loss = 0.14405
Step 120225: loss = 0.24615
Step 120230: loss = 0.12745
Step 120235: loss = 0.05004
Step 120240: loss = 0.25922
Step 120245: loss = 0.11619
Step 120250: loss = 0.26636
Step 120255: loss = 0.16467
Step 120260: loss = 0.32710
Step 120265: loss = 0.10689
Step 120270: loss = 0.14240
Step 120275: loss = 0.10545
Step 120280: loss = 0.05050
Step 120285: loss = 0.35205
Step 120290: loss = 0.10920
Step 120295: loss = 0.07381
Step 120300: loss = 0.11645
Step 120305: loss = 0.27489
Step 120310: loss = 0.20720
Step 120315: loss = 0.12160
Step 120320: loss = 0.19448
Step 120325: loss = 0.06745
Step 120330: loss = 0.17303
Step 120335: loss = 0.02910
Step 120340: loss = 0.25191
Step 120345: loss = 0.04672
Step 120350: loss = 0.11919
Step 120355: loss = 0.15707
Step 120360: loss = 0.20093
Step 120365: loss = 0.08065
Step 120370: loss = 0.26847
Step 120375: loss = 0.07957
Step 120380: loss = 0.10871
Step 120385: loss = 0.14325
Step 120390: loss = 0.10217
Step 120395: loss = 0.19924
Step 120400: loss = 0.08999
Step 120405: loss = 0.20862
Step 120410: loss = 0.25883
Step 120415: loss = 0.18171
Step 120420: loss = 0.11205
Step 120425: loss = 0.09657
Step 120430: loss = 0.13457
Step 120435: loss = 0.21930
Step 120440: loss = 0.09760
Step 120445: loss = 0.16388
Step 120450: loss = 0.13455
Step 120455: loss = 0.14507
Step 120460: loss = 0.23898
Step 120465: loss = 0.04420
Step 120470: loss = 0.14633
Step 120475: loss = 0.14307
Step 120480: loss = 0.13794
Step 120485: loss = 0.12080
Step 120490: loss = 0.07096
Step 120495: loss = 0.31742
Step 120500: loss = 0.16367
Step 120505: loss = 0.30252
Step 120510: loss = 0.24831
Step 120515: loss = 0.48182
Step 120520: loss = 0.21720
Step 120525: loss = 0.04459
Step 120530: loss = 0.16606
Step 120535: loss = 0.21619
Step 120540: loss = 0.18553
Step 120545: loss = 0.14886
Step 120550: loss = 0.17246
Step 120555: loss = 0.13060
Step 120560: loss = 0.12509
Step 120565: loss = 0.14843
Step 120570: loss = 0.15732
Step 120575: loss = 0.11924
Step 120580: loss = 0.10989
Step 120585: loss = 0.15007
Step 120590: loss = 0.20074
Step 120595: loss = 0.17826
Step 120600: loss = 0.06611
Step 120605: loss = 0.11667
Step 120610: loss = 0.15581
Step 120615: loss = 0.36537
Step 120620: loss = 0.29205
Step 120625: loss = 0.13438
Step 120630: loss = 0.38865
Step 120635: loss = 0.14927
Step 120640: loss = 0.13943
Step 120645: loss = 0.16477
Step 120650: loss = 0.09980
Step 120655: loss = 0.04136
Step 120660: loss = 0.23309
Step 120665: loss = 0.11796
Step 120670: loss = 0.11507
Step 120675: loss = 0.07684
Step 120680: loss = 0.07085
Step 120685: loss = 0.31393
Step 120690: loss = 0.04920
Step 120695: loss = 0.07412
Step 120700: loss = 0.09104
Step 120705: loss = 0.27972
Step 120710: loss = 0.29641
Step 120715: loss = 0.10176
Step 120720: loss = 0.09851
Step 120725: loss = 0.13012
Step 120730: loss = 0.14736
Step 120735: loss = 0.24509
Step 120740: loss = 0.20664
Step 120745: loss = 0.07677
Step 120750: loss = 0.25282
Step 120755: loss = 0.05576
Step 120760: loss = 0.09849
Step 120765: loss = 0.31872
Step 120770: loss = 0.12348
Step 120775: loss = 0.20471
Step 120780: loss = 0.11565
Step 120785: loss = 0.06886
Step 120790: loss = 0.29030
Step 120795: loss = 0.26850
Step 120800: loss = 0.09900
Step 120805: loss = 0.08182
Step 120810: loss = 0.17322
Step 120815: loss = 0.16968
Step 120820: loss = 0.37255
Step 120825: loss = 0.24052
Step 120830: loss = 0.10727
Step 120835: loss = 0.04188
Step 120840: loss = 0.15874
Step 120845: loss = 0.16731
Step 120850: loss = 0.31043
Step 120855: loss = 0.12849
Step 120860: loss = 0.17369
Step 120865: loss = 0.12661
Step 120870: loss = 0.21328
Step 120875: loss = 0.01324
Step 120880: loss = 0.38595
Step 120885: loss = 0.15212
Step 120890: loss = 0.06108
Step 120895: loss = 0.17441
Step 120900: loss = 0.09052
Step 120905: loss = 0.21143
Step 120910: loss = 0.09858
Step 120915: loss = 0.08889
Step 120920: loss = 0.16982
Step 120925: loss = 0.12239
Step 120930: loss = 0.34130
Step 120935: loss = 0.09529
Step 120940: loss = 0.09870
Step 120945: loss = 0.11649
Step 120950: loss = 0.26233
Step 120955: loss = 0.27688
Step 120960: loss = 0.22255
Step 120965: loss = 0.36238
Step 120970: loss = 0.09296
Step 120975: loss = 0.07583
Step 120980: loss = 0.13205
Step 120985: loss = 0.34803
Step 120990: loss = 0.08128
Step 120995: loss = 0.04659
Step 121000: loss = 0.15591
Training Data Eval:
  Num examples: 50000, Num correct: 47665, Precision @ 1: 0.9533
('Testing Data Eval: EPOCH->', 122)
  Num examples: 10000, Num correct: 6698, Precision @ 1: 0.6698
Step 121005: loss = 0.06557
Step 121010: loss = 0.10251
Step 121015: loss = 0.17802
Step 121020: loss = 0.24805
Step 121025: loss = 0.11059
Step 121030: loss = 0.15849
Step 121035: loss = 0.07846
Step 121040: loss = 0.07036
Step 121045: loss = 0.13796
Step 121050: loss = 0.03959
Step 121055: loss = 0.08520
Step 121060: loss = 0.14208
Step 121065: loss = 0.27166
Step 121070: loss = 0.11786
Step 121075: loss = 0.13819
Step 121080: loss = 0.18873
Step 121085: loss = 0.15520
Step 121090: loss = 0.13822
Step 121095: loss = 0.18825
Step 121100: loss = 0.13102
Step 121105: loss = 0.23839
Step 121110: loss = 0.13926
Step 121115: loss = 0.18480
Step 121120: loss = 0.09957
Step 121125: loss = 0.09478
Step 121130: loss = 0.13865
Step 121135: loss = 0.19290
Step 121140: loss = 0.07900
Step 121145: loss = 0.09681
Step 121150: loss = 0.16548
Step 121155: loss = 0.23806
Step 121160: loss = 0.21062
Step 121165: loss = 0.41992
Step 121170: loss = 0.13037
Step 121175: loss = 0.10217
Step 121180: loss = 0.08532
Step 121185: loss = 0.07575
Step 121190: loss = 0.04744
Step 121195: loss = 0.42178
Step 121200: loss = 0.05281
Step 121205: loss = 0.08540
Step 121210: loss = 0.05020
Step 121215: loss = 0.09433
Step 121220: loss = 0.31372
Step 121225: loss = 0.03714
Step 121230: loss = 0.12323
Step 121235: loss = 0.05428
Step 121240: loss = 0.17535
Step 121245: loss = 0.18519
Step 121250: loss = 0.09234
Step 121255: loss = 0.06617
Step 121260: loss = 0.06405
Step 121265: loss = 0.16034
Step 121270: loss = 0.10730
Step 121275: loss = 0.12757
Step 121280: loss = 0.12706
Step 121285: loss = 0.12680
Step 121290: loss = 0.09310
Step 121295: loss = 0.31773
Step 121300: loss = 0.03977
Step 121305: loss = 0.03191
Step 121310: loss = 0.21958
Step 121315: loss = 0.02596
Step 121320: loss = 0.11778
Step 121325: loss = 0.07627
Step 121330: loss = 0.14387
Step 121335: loss = 0.28049
Step 121340: loss = 0.04545
Step 121345: loss = 0.01844
Step 121350: loss = 0.13786
Step 121355: loss = 0.10402
Step 121360: loss = 0.10614
Step 121365: loss = 0.07037
Step 121370: loss = 0.08628
Step 121375: loss = 0.16086
Step 121380: loss = 0.12621
Step 121385: loss = 0.08678
Step 121390: loss = 0.08180
Step 121395: loss = 0.19066
Step 121400: loss = 0.07962
Step 121405: loss = 0.08999
Step 121410: loss = 0.18031
Step 121415: loss = 0.07040
Step 121420: loss = 0.13234
Step 121425: loss = 0.10914
Step 121430: loss = 0.20285
Step 121435: loss = 0.22920
Step 121440: loss = 0.16170
Step 121445: loss = 0.32702
Step 121450: loss = 0.08888
Step 121455: loss = 0.07005
Step 121460: loss = 0.30439
Step 121465: loss = 0.04180
Step 121470: loss = 0.36551
Step 121475: loss = 0.04398
Step 121480: loss = 0.11978
Step 121485: loss = 0.18004
Step 121490: loss = 0.20527
Step 121495: loss = 0.14874
Step 121500: loss = 0.20615
Step 121505: loss = 0.12032
Step 121510: loss = 0.16152
Step 121515: loss = 0.18625
Step 121520: loss = 0.13513
Step 121525: loss = 0.13023
Step 121530: loss = 0.17253
Step 121535: loss = 0.32720
Step 121540: loss = 0.13359
Step 121545: loss = 0.24816
Step 121550: loss = 0.17005
Step 121555: loss = 0.05525
Step 121560: loss = 0.09504
Step 121565: loss = 0.09034
Step 121570: loss = 0.03683
Step 121575: loss = 0.21857
Step 121580: loss = 0.05514
Step 121585: loss = 0.12894
Step 121590: loss = 0.25433
Step 121595: loss = 0.21748
Step 121600: loss = 0.07708
Step 121605: loss = 0.19009
Step 121610: loss = 0.25979
Step 121615: loss = 0.21075
Step 121620: loss = 0.12410
Step 121625: loss = 0.12547
Step 121630: loss = 0.10953
Step 121635: loss = 0.05817
Step 121640: loss = 0.08551
Step 121645: loss = 0.25610
Step 121650: loss = 0.10038
Step 121655: loss = 0.04945
Step 121660: loss = 0.09200
Step 121665: loss = 0.10997
Step 121670: loss = 0.06313
Step 121675: loss = 0.23821
Step 121680: loss = 0.21962
Step 121685: loss = 0.18121
Step 121690: loss = 0.12941
Step 121695: loss = 0.09336
Step 121700: loss = 0.20857
Step 121705: loss = 0.12129
Step 121710: loss = 0.33505
Step 121715: loss = 0.02847
Step 121720: loss = 0.23555
Step 121725: loss = 0.11179
Step 121730: loss = 0.19271
Step 121735: loss = 0.09961
Step 121740: loss = 0.28452
Step 121745: loss = 0.33771
Step 121750: loss = 0.04214
Step 121755: loss = 0.05400
Step 121760: loss = 0.17319
Step 121765: loss = 0.17632
Step 121770: loss = 0.11856
Step 121775: loss = 0.26886
Step 121780: loss = 0.08350
Step 121785: loss = 0.13918
Step 121790: loss = 0.21085
Step 121795: loss = 0.14683
Step 121800: loss = 0.16260
Step 121805: loss = 0.10440
Step 121810: loss = 0.17922
Step 121815: loss = 0.13695
Step 121820: loss = 0.09692
Step 121825: loss = 0.15209
Step 121830: loss = 0.27975
Step 121835: loss = 0.11133
Step 121840: loss = 0.31141
Step 121845: loss = 0.13510
Step 121850: loss = 0.23629
Step 121855: loss = 0.12032
Step 121860: loss = 0.21136
Step 121865: loss = 0.23519
Step 121870: loss = 0.08171
Step 121875: loss = 0.18094
Step 121880: loss = 0.21413
Step 121885: loss = 0.06847
Step 121890: loss = 0.14505
Step 121895: loss = 0.17255
Step 121900: loss = 0.05959
Step 121905: loss = 0.09215
Step 121910: loss = 0.10088
Step 121915: loss = 0.19226
Step 121920: loss = 0.15949
Step 121925: loss = 0.15988
Step 121930: loss = 0.13559
Step 121935: loss = 0.15643
Step 121940: loss = 0.38246
Step 121945: loss = 0.25791
Step 121950: loss = 0.20103
Step 121955: loss = 0.02717
Step 121960: loss = 0.13852
Step 121965: loss = 0.26496
Step 121970: loss = 0.11005
Step 121975: loss = 0.08599
Step 121980: loss = 0.09863
Step 121985: loss = 0.17736
Step 121990: loss = 0.18846
Step 121995: loss = 0.08894
Step 122000: loss = 0.07530
Training Data Eval:
  Num examples: 50000, Num correct: 47547, Precision @ 1: 0.9509
('Testing Data Eval: EPOCH->', 123)
  Num examples: 10000, Num correct: 6652, Precision @ 1: 0.6652
Step 122005: loss = 0.06340
Step 122010: loss = 0.24365
Step 122015: loss = 0.12077
Step 122020: loss = 0.06403
Step 122025: loss = 0.14686
Step 122030: loss = 0.06602
Step 122035: loss = 0.14008
Step 122040: loss = 0.04957
Step 122045: loss = 0.23072
Step 122050: loss = 0.14181
Step 122055: loss = 0.19722
Step 122060: loss = 0.11584
Step 122065: loss = 0.13857
Step 122070: loss = 0.09250
Step 122075: loss = 0.13232
Step 122080: loss = 0.07469
Step 122085: loss = 0.11305
Step 122090: loss = 0.19071
Step 122095: loss = 0.14430
Step 122100: loss = 0.08307
Step 122105: loss = 0.15129
Step 122110: loss = 0.10026
Step 122115: loss = 0.15428
Step 122120: loss = 0.06847
Step 122125: loss = 0.18661
Step 122130: loss = 0.10653
Step 122135: loss = 0.13466
Step 122140: loss = 0.08382
Step 122145: loss = 0.08279
Step 122150: loss = 0.14032
Step 122155: loss = 0.09751
Step 122160: loss = 0.09791
Step 122165: loss = 0.08927
Step 122170: loss = 0.04813
Step 122175: loss = 0.08150
Step 122180: loss = 0.11783
Step 122185: loss = 0.12710
Step 122190: loss = 0.03207
Step 122195: loss = 0.27290
Step 122200: loss = 0.12346
Step 122205: loss = 0.15894
Step 122210: loss = 0.12106
Step 122215: loss = 0.14889
Step 122220: loss = 0.15514
Step 122225: loss = 0.04162
Step 122230: loss = 0.12157
Step 122235: loss = 0.12597
Step 122240: loss = 0.23207
Step 122245: loss = 0.18573
Step 122250: loss = 0.32423
Step 122255: loss = 0.23742
Step 122260: loss = 0.21632
Step 122265: loss = 0.04073
Step 122270: loss = 0.15932
Step 122275: loss = 0.16225
Step 122280: loss = 0.18326
Step 122285: loss = 0.18899
Step 122290: loss = 0.13418
Step 122295: loss = 0.05968
Step 122300: loss = 0.12302
Step 122305: loss = 0.03773
Step 122310: loss = 0.09590
Step 122315: loss = 0.13425
Step 122320: loss = 0.04075
Step 122325: loss = 0.14872
Step 122330: loss = 0.07489
Step 122335: loss = 0.13987
Step 122340: loss = 0.01889
Step 122345: loss = 0.06546
Step 122350: loss = 0.14070
Step 122355: loss = 0.14428
Step 122360: loss = 0.05618
Step 122365: loss = 0.05664
Step 122370: loss = 0.05224
Step 122375: loss = 0.19473
Step 122380: loss = 0.03281
Step 122385: loss = 0.16005
Step 122390: loss = 0.08143
Step 122395: loss = 0.22117
Step 122400: loss = 0.19025
Step 122405: loss = 0.10146
Step 122410: loss = 0.05585
Step 122415: loss = 0.09835
Step 122420: loss = 0.12481
Step 122425: loss = 0.10660
Step 122430: loss = 0.10723
Step 122435: loss = 0.13358
Step 122440: loss = 0.14428
Step 122445: loss = 0.18284
Step 122450: loss = 0.17234
Step 122455: loss = 0.08597
Step 122460: loss = 0.05824
Step 122465: loss = 0.30553
Step 122470: loss = 0.07621
Step 122475: loss = 0.30218
Step 122480: loss = 0.16324
Step 122485: loss = 0.09898
Step 122490: loss = 0.11498
Step 122495: loss = 0.21986
Step 122500: loss = 0.24240
Step 122505: loss = 0.19696
Step 122510: loss = 0.09443
Step 122515: loss = 0.22917
Step 122520: loss = 0.06919
Step 122525: loss = 0.04292
Step 122530: loss = 0.06703
Step 122535: loss = 0.11837
Step 122540: loss = 0.18776
Step 122545: loss = 0.15953
Step 122550: loss = 0.13390
Step 122555: loss = 0.22367
Step 122560: loss = 0.18888
Step 122565: loss = 0.28230
Step 122570: loss = 0.32475
Step 122575: loss = 0.34131
Step 122580: loss = 0.12639
Step 122585: loss = 0.16143
Step 122590: loss = 0.22023
Step 122595: loss = 0.73808
Step 122600: loss = 0.23947
Step 122605: loss = 0.10732
Step 122610: loss = 0.14771
Step 122615: loss = 0.26732
Step 122620: loss = 0.30246
Step 122625: loss = 0.10177
Step 122630: loss = 0.06557
Step 122635: loss = 0.16344
Step 122640: loss = 0.22831
Step 122645: loss = 0.21583
Step 122650: loss = 0.07826
Step 122655: loss = 0.18849
Step 122660: loss = 0.11878
Step 122665: loss = 0.08652
Step 122670: loss = 0.06571
Step 122675: loss = 0.21097
Step 122680: loss = 0.04819
Step 122685: loss = 0.04112
Step 122690: loss = 0.19045
Step 122695: loss = 0.19873
Step 122700: loss = 0.11581
Step 122705: loss = 0.18763
Step 122710: loss = 0.20180
Step 122715: loss = 0.16440
Step 122720: loss = 0.18355
Step 122725: loss = 0.16406
Step 122730: loss = 0.09082
Step 122735: loss = 0.13785
Step 122740: loss = 0.39407
Step 122745: loss = 0.08994
Step 122750: loss = 0.31325
Step 122755: loss = 0.13239
Step 122760: loss = 0.36493
Step 122765: loss = 0.05608
Step 122770: loss = 0.13806
Step 122775: loss = 0.12759
Step 122780: loss = 0.06504
Step 122785: loss = 0.23283
Step 122790: loss = 0.16788
Step 122795: loss = 0.07896
Step 122800: loss = 0.24025
Step 122805: loss = 0.12995
Step 122810: loss = 0.11987
Step 122815: loss = 0.10711
Step 122820: loss = 0.08822
Step 122825: loss = 0.21122
Step 122830: loss = 0.14625
Step 122835: loss = 0.10601
Step 122840: loss = 0.15731
Step 122845: loss = 0.15284
Step 122850: loss = 0.04376
Step 122855: loss = 0.12910
Step 122860: loss = 0.11595
Step 122865: loss = 0.16783
Step 122870: loss = 0.15185
Step 122875: loss = 0.18029
Step 122880: loss = 0.08162
Step 122885: loss = 0.09332
Step 122890: loss = 0.45954
Step 122895: loss = 0.14541
Step 122900: loss = 0.12359
Step 122905: loss = 0.14374
Step 122910: loss = 0.26710
Step 122915: loss = 0.20956
Step 122920: loss = 0.15040
Step 122925: loss = 0.10650
Step 122930: loss = 0.09277
Step 122935: loss = 0.21170
Step 122940: loss = 0.12119
Step 122945: loss = 0.17307
Step 122950: loss = 0.12697
Step 122955: loss = 0.10415
Step 122960: loss = 0.11106
Step 122965: loss = 0.01719
Step 122970: loss = 0.24003
Step 122975: loss = 0.10088
Step 122980: loss = 0.12199
Step 122985: loss = 0.06519
Step 122990: loss = 0.31673
Step 122995: loss = 0.47980
Step 123000: loss = 0.11415
Training Data Eval:
  Num examples: 50000, Num correct: 47620, Precision @ 1: 0.9524
('Testing Data Eval: EPOCH->', 124)
  Num examples: 10000, Num correct: 6675, Precision @ 1: 0.6675
Step 123005: loss = 0.12452
Step 123010: loss = 0.08887
Step 123015: loss = 0.13224
Step 123020: loss = 0.09883
Step 123025: loss = 0.06133
Step 123030: loss = 0.12964
Step 123035: loss = 0.15809
Step 123040: loss = 0.09695
Step 123045: loss = 0.10458
Step 123050: loss = 0.07211
Step 123055: loss = 0.06130
Step 123060: loss = 0.08581
Step 123065: loss = 0.16796
Step 123070: loss = 0.13086
Step 123075: loss = 0.13481
Step 123080: loss = 0.06875
Step 123085: loss = 0.16472
Step 123090: loss = 0.06695
Step 123095: loss = 0.08473
Step 123100: loss = 0.13659
Step 123105: loss = 0.12067
Step 123110: loss = 0.19549
Step 123115: loss = 0.25294
Step 123120: loss = 0.30351
Step 123125: loss = 0.04826
Step 123130: loss = 0.03674
Step 123135: loss = 0.21148
Step 123140: loss = 0.11612
Step 123145: loss = 0.06578
Step 123150: loss = 0.10879
Step 123155: loss = 0.15025
Step 123160: loss = 0.11514
Step 123165: loss = 0.09891
Step 123170: loss = 0.12745
Step 123175: loss = 0.09265
Step 123180: loss = 0.12710
Step 123185: loss = 0.22790
Step 123190: loss = 0.62236
Step 123195: loss = 0.11400
Step 123200: loss = 0.06375
Step 123205: loss = 0.29493
Step 123210: loss = 0.09588
Step 123215: loss = 0.03605
Step 123220: loss = 0.09845
Step 123225: loss = 0.11473
Step 123230: loss = 0.08222
Step 123235: loss = 0.04616
Step 123240: loss = 0.01957
Step 123245: loss = 0.18266
Step 123250: loss = 0.09776
Step 123255: loss = 0.04952
Step 123260: loss = 0.06197
Step 123265: loss = 0.31213
Step 123270: loss = 0.11493
Step 123275: loss = 0.04944
Step 123280: loss = 0.12901
Step 123285: loss = 0.04785
Step 123290: loss = 0.18298
Step 123295: loss = 0.03341
Step 123300: loss = 0.10635
Step 123305: loss = 0.53783
Step 123310: loss = 0.16297
Step 123315: loss = 0.09889
Step 123320: loss = 0.15849
Step 123325: loss = 0.17100
Step 123330: loss = 0.18193
Step 123335: loss = 0.10105
Step 123340: loss = 0.02099
Step 123345: loss = 0.03566
Step 123350: loss = 0.23255
Step 123355: loss = 0.64936
Step 123360: loss = 0.07154
Step 123365: loss = 0.17191
Step 123370: loss = 0.16217
Step 123375: loss = 0.24362
Step 123380: loss = 0.12654
Step 123385: loss = 0.25848
Step 123390: loss = 0.10108
Step 123395: loss = 0.16563
Step 123400: loss = 0.08267
Step 123405: loss = 0.07322
Step 123410: loss = 0.20917
Step 123415: loss = 0.07401
Step 123420: loss = 0.12864
Step 123425: loss = 0.19958
Step 123430: loss = 0.13573
Step 123435: loss = 0.20502
Step 123440: loss = 0.26234
Step 123445: loss = 0.21074
Step 123450: loss = 0.22560
Step 123455: loss = 0.12882
Step 123460: loss = 0.19964
Step 123465: loss = 0.22486
Step 123470: loss = 0.14541
Step 123475: loss = 0.10762
Step 123480: loss = 0.06426
Step 123485: loss = 0.04616
Step 123490: loss = 0.04841
Step 123495: loss = 0.06106
Step 123500: loss = 0.06095
Step 123505: loss = 0.25835
Step 123510: loss = 0.05891
Step 123515: loss = 0.07466
Step 123520: loss = 0.08647
Step 123525: loss = 0.10879
Step 123530: loss = 0.12182
Step 123535: loss = 0.15461
Step 123540: loss = 0.05760
Step 123545: loss = 0.13063
Step 123550: loss = 0.15008
Step 123555: loss = 0.25985
Step 123560: loss = 0.01576
Step 123565: loss = 0.07186
Step 123570: loss = 0.09206
Step 123575: loss = 0.10923
Step 123580: loss = 0.08414
Step 123585: loss = 0.03770
Step 123590: loss = 0.16905
Step 123595: loss = 0.11326
Step 123600: loss = 0.12451
Step 123605: loss = 0.29352
Step 123610: loss = 0.32611
Step 123615: loss = 0.17230
Step 123620: loss = 0.10412
Step 123625: loss = 0.17225
Step 123630: loss = 0.11651
Step 123635: loss = 0.09185
Step 123640: loss = 0.17215
Step 123645: loss = 0.07624
Step 123650: loss = 0.09633
Step 123655: loss = 0.16624
Step 123660: loss = 0.25310
Step 123665: loss = 0.14825
Step 123670: loss = 0.14815
Step 123675: loss = 0.08359
Step 123680: loss = 0.05194
Step 123685: loss = 0.12775
Step 123690: loss = 0.24400
Step 123695: loss = 0.39994
Step 123700: loss = 0.26397
Step 123705: loss = 0.13521
Step 123710: loss = 0.06792
Step 123715: loss = 0.04698
Step 123720: loss = 0.05834
Step 123725: loss = 0.03997
Step 123730: loss = 0.13432
Step 123735: loss = 0.23658
Step 123740: loss = 0.17060
Step 123745: loss = 0.16721
Step 123750: loss = 0.11077
Step 123755: loss = 0.11351
Step 123760: loss = 0.04659
Step 123765: loss = 0.11941
Step 123770: loss = 0.03965
Step 123775: loss = 0.23673
Step 123780: loss = 0.08551
Step 123785: loss = 0.10537
Step 123790: loss = 0.23720
Step 123795: loss = 0.11562
Step 123800: loss = 0.17142
Step 123805: loss = 0.12233
Step 123810: loss = 0.31995
Step 123815: loss = 0.10738
Step 123820: loss = 0.56610
Step 123825: loss = 0.28371
Step 123830: loss = 0.19125
Step 123835: loss = 0.23895
Step 123840: loss = 0.07008
Step 123845: loss = 0.12191
Step 123850: loss = 0.26141
Step 123855: loss = 0.14878
Step 123860: loss = 0.13282
Step 123865: loss = 0.08360
Step 123870: loss = 0.19468
Step 123875: loss = 0.06185
Step 123880: loss = 0.08148
Step 123885: loss = 0.12796
Step 123890: loss = 0.22048
Step 123895: loss = 0.14421
Step 123900: loss = 0.05828
Step 123905: loss = 0.10527
Step 123910: loss = 0.11584
Step 123915: loss = 0.03689
Step 123920: loss = 0.09038
Step 123925: loss = 0.17486
Step 123930: loss = 0.23779
Step 123935: loss = 0.37645
Step 123940: loss = 0.13163
Step 123945: loss = 0.19776
Step 123950: loss = 0.10339
Step 123955: loss = 0.05829
Step 123960: loss = 0.06218
Step 123965: loss = 0.16532
Step 123970: loss = 0.13353
Step 123975: loss = 0.12578
Step 123980: loss = 0.07635
Step 123985: loss = 0.25021
Step 123990: loss = 0.17994
Step 123995: loss = 0.10080
Step 124000: loss = 0.14024
Training Data Eval:
  Num examples: 50000, Num correct: 47516, Precision @ 1: 0.9503
('Testing Data Eval: EPOCH->', 125)
  Num examples: 10000, Num correct: 6637, Precision @ 1: 0.6637
Step 124005: loss = 0.23138
Step 124010: loss = 0.19340
Step 124015: loss = 0.18063
Step 124020: loss = 0.11105
Step 124025: loss = 0.05932
Step 124030: loss = 0.09227
Step 124035: loss = 0.06072
Step 124040: loss = 0.08005
Step 124045: loss = 0.10638
Step 124050: loss = 0.22025
Step 124055: loss = 0.04407
Step 124060: loss = 0.16601
Step 124065: loss = 0.09478
Step 124070: loss = 0.15917
Step 124075: loss = 0.08440
Step 124080: loss = 0.10025
Step 124085: loss = 0.08509
Step 124090: loss = 0.08115
Step 124095: loss = 0.07705
Step 124100: loss = 0.12363
Step 124105: loss = 0.06502
Step 124110: loss = 0.09840
Step 124115: loss = 0.03355
Step 124120: loss = 0.08814
Step 124125: loss = 0.06620
Step 124130: loss = 0.12239
Step 124135: loss = 0.10053
Step 124140: loss = 0.13140
Step 124145: loss = 0.25379
Step 124150: loss = 0.13875
Step 124155: loss = 0.05589
Step 124160: loss = 0.16598
Step 124165: loss = 0.07395
Step 124170: loss = 0.27209
Step 124175: loss = 0.32270
Step 124180: loss = 0.15109
Step 124185: loss = 0.08465
Step 124190: loss = 0.12742
Step 124195: loss = 0.17730
Step 124200: loss = 0.09099
Step 124205: loss = 0.23230
Step 124210: loss = 0.19486
Step 124215: loss = 0.07773
Step 124220: loss = 0.08990
Step 124225: loss = 0.04992
Step 124230: loss = 0.08988
Step 124235: loss = 0.44952
Step 124240: loss = 0.11475
Step 124245: loss = 0.38580
Step 124250: loss = 0.11809
Step 124255: loss = 0.05401
Step 124260: loss = 0.19238
Step 124265: loss = 0.15308
Step 124270: loss = 0.15932
Step 124275: loss = 0.06765
Step 124280: loss = 0.07380
Step 124285: loss = 0.15088
Step 124290: loss = 0.09988
Step 124295: loss = 0.15192
Step 124300: loss = 0.06679
Step 124305: loss = 0.21136
Step 124310: loss = 0.26626
Step 124315: loss = 0.14754
Step 124320: loss = 0.23786
Step 124325: loss = 0.20041
Step 124330: loss = 0.12339
Step 124335: loss = 0.10439
Step 124340: loss = 0.11444
Step 124345: loss = 0.13117
Step 124350: loss = 0.06461
Step 124355: loss = 0.32149
Step 124360: loss = 0.16498
Step 124365: loss = 0.13189
Step 124370: loss = 0.13239
Step 124375: loss = 0.09758
Step 124380: loss = 0.33894
Step 124385: loss = 0.16195
Step 124390: loss = 0.13352
Step 124395: loss = 0.09672
Step 124400: loss = 0.33718
Step 124405: loss = 0.08786
Step 124410: loss = 0.08970
Step 124415: loss = 0.08722
Step 124420: loss = 0.19836
Step 124425: loss = 0.13078
Step 124430: loss = 0.13950
Step 124435: loss = 0.08707
Step 124440: loss = 0.26394
Step 124445: loss = 0.35535
Step 124450: loss = 0.04195
Step 124455: loss = 0.19950
Step 124460: loss = 0.13566
Step 124465: loss = 0.12984
Step 124470: loss = 0.09177
Step 124475: loss = 0.12222
Step 124480: loss = 0.17144
Step 124485: loss = 0.15236
Step 124490: loss = 0.12031
Step 124495: loss = 0.04173
Step 124500: loss = 0.16080
Step 124505: loss = 0.17557
Step 124510: loss = 0.02774
Step 124515: loss = 0.07911
Step 124520: loss = 0.13114
Step 124525: loss = 0.28027
Step 124530: loss = 0.17219
Step 124535: loss = 0.07094
Step 124540: loss = 0.22162
Step 124545: loss = 0.03057
Step 124550: loss = 0.23694
Step 124555: loss = 0.15760
Step 124560: loss = 0.30612
Step 124565: loss = 0.19095
Step 124570: loss = 0.18585
Step 124575: loss = 0.15549
Step 124580: loss = 0.39193
Step 124585: loss = 0.06590
Step 124590: loss = 0.05729
Step 124595: loss = 0.38972
Step 124600: loss = 0.07702
Step 124605: loss = 0.17918
Step 124610: loss = 0.12300
Step 124615: loss = 0.17656
Step 124620: loss = 0.10944
Step 124625: loss = 0.16123
Step 124630: loss = 0.24746
Step 124635: loss = 0.12796
Step 124640: loss = 0.10768
Step 124645: loss = 0.11223
Step 124650: loss = 0.27642
Step 124655: loss = 0.10488
Step 124660: loss = 0.07622
Step 124665: loss = 0.09785
Step 124670: loss = 0.23689
Step 124675: loss = 0.15143
Step 124680: loss = 0.17934
Step 124685: loss = 0.15693
Step 124690: loss = 0.07641
Step 124695: loss = 0.18334
Step 124700: loss = 0.09853
Step 124705: loss = 0.07842
Step 124710: loss = 0.10195
Step 124715: loss = 0.09150
Step 124720: loss = 0.12743
Step 124725: loss = 0.08086
Step 124730: loss = 0.05650
Step 124735: loss = 0.12366
Step 124740: loss = 0.04588
Step 124745: loss = 0.08554
Step 124750: loss = 0.13773
Step 124755: loss = 0.19240
Step 124760: loss = 0.19407
Step 124765: loss = 0.22178
Step 124770: loss = 0.11510
Step 124775: loss = 0.06087
Step 124780: loss = 0.19661
Step 124785: loss = 0.07360
Step 124790: loss = 0.07827
Step 124795: loss = 0.09471
Step 124800: loss = 0.26000
Step 124805: loss = 0.09813
Step 124810: loss = 0.23205
Step 124815: loss = 0.20859
Step 124820: loss = 0.09311
Step 124825: loss = 0.06153
Step 124830: loss = 0.19806
Step 124835: loss = 0.09250
Step 124840: loss = 0.21203
Step 124845: loss = 0.16918
Step 124850: loss = 0.29796
Step 124855: loss = 0.10301
Step 124860: loss = 0.15533
Step 124865: loss = 0.10209
Step 124870: loss = 0.12241
Step 124875: loss = 0.18563
Step 124880: loss = 0.16660
Step 124885: loss = 0.07566
Step 124890: loss = 0.04244
Step 124895: loss = 0.06877
Step 124900: loss = 0.09552
Step 124905: loss = 0.04536
Step 124910: loss = 0.09503
Step 124915: loss = 0.14313
Step 124920: loss = 0.03859
Step 124925: loss = 0.06701
Step 124930: loss = 0.12145
Step 124935: loss = 0.15219
Step 124940: loss = 0.16477
Step 124945: loss = 0.14866
Step 124950: loss = 0.08861
Step 124955: loss = 0.14176
Step 124960: loss = 0.03564
Step 124965: loss = 0.23258
Step 124970: loss = 0.26155
Step 124975: loss = 0.25110
Step 124980: loss = 0.28272
Step 124985: loss = 0.21025
Step 124990: loss = 0.12249
Step 124995: loss = 0.11528
Step 125000: loss = 0.10836
Training Data Eval:
  Num examples: 50000, Num correct: 47426, Precision @ 1: 0.9485
('Testing Data Eval: EPOCH->', 126)
  Num examples: 10000, Num correct: 6603, Precision @ 1: 0.6603
Step 125005: loss = 0.12599
Step 125010: loss = 0.07039
Step 125015: loss = 0.09695
Step 125020: loss = 0.10383
Step 125025: loss = 0.07504
Step 125030: loss = 0.05493
Step 125035: loss = 0.05925
Step 125040: loss = 0.35498
Step 125045: loss = 0.09598
Step 125050: loss = 0.15170
Step 125055: loss = 0.26531
Step 125060: loss = 0.11985
Step 125065: loss = 0.41573
Step 125070: loss = 0.13695
Step 125075: loss = 0.23824
Step 125080: loss = 0.12387
Step 125085: loss = 0.24462
Step 125090: loss = 0.18335
Step 125095: loss = 0.10296
Step 125100: loss = 0.09455
Step 125105: loss = 0.11505
Step 125110: loss = 0.15396
Step 125115: loss = 0.06162
Step 125120: loss = 0.21159
Step 125125: loss = 0.07917
Step 125130: loss = 0.24577
Step 125135: loss = 0.25799
Step 125140: loss = 0.17746
Step 125145: loss = 0.17190
Step 125150: loss = 0.20328
Step 125155: loss = 0.15399
Step 125160: loss = 0.09498
Step 125165: loss = 0.14568
Step 125170: loss = 0.16305
Step 125175: loss = 0.13202
Step 125180: loss = 0.27181
Step 125185: loss = 0.09775
Step 125190: loss = 0.16205
Step 125195: loss = 0.12899
Step 125200: loss = 0.20241
Step 125205: loss = 0.08450
Step 125210: loss = 0.33207
Step 125215: loss = 0.20580
Step 125220: loss = 0.17807
Step 125225: loss = 0.04911
Step 125230: loss = 0.07591
Step 125235: loss = 0.17881
Step 125240: loss = 0.13277
Step 125245: loss = 0.21055
Step 125250: loss = 0.11800
Step 125255: loss = 0.04915
Step 125260: loss = 0.31541
Step 125265: loss = 0.21101
Step 125270: loss = 0.26724
Step 125275: loss = 0.07295
Step 125280: loss = 0.36242
Step 125285: loss = 0.06807
Step 125290: loss = 0.07222
Step 125295: loss = 0.19436
Step 125300: loss = 0.15047
Step 125305: loss = 0.17299
Step 125310: loss = 0.11858
Step 125315: loss = 0.16014
Step 125320: loss = 0.14157
Step 125325: loss = 0.24165
Step 125330: loss = 0.13458
Step 125335: loss = 0.04589
Step 125340: loss = 0.05187
Step 125345: loss = 0.06379
Step 125350: loss = 0.15480
Step 125355: loss = 0.07348
Step 125360: loss = 0.18171
Step 125365: loss = 0.26069
Step 125370: loss = 0.25197
Step 125375: loss = 0.11412
Step 125380: loss = 0.06211
Step 125385: loss = 0.09533
Step 125390: loss = 0.11981
Step 125395: loss = 0.14942
Step 125400: loss = 0.16780
Step 125405: loss = 0.10957
Step 125410: loss = 0.12042
Step 125415: loss = 0.04090
Step 125420: loss = 0.11801
Step 125425: loss = 0.10243
Step 125430: loss = 0.16933
Step 125435: loss = 0.21109
Step 125440: loss = 0.07574
Step 125445: loss = 0.08556
Step 125450: loss = 0.18159
Step 125455: loss = 0.17221
Step 125460: loss = 0.13029
Step 125465: loss = 0.03374
Step 125470: loss = 0.11998
Step 125475: loss = 0.16338
Step 125480: loss = 0.16386
Step 125485: loss = 0.09764
Step 125490: loss = 0.25927
Step 125495: loss = 0.19912
Step 125500: loss = 0.20365
Step 125505: loss = 0.09554
Step 125510: loss = 0.19658
Step 125515: loss = 0.19471
Step 125520: loss = 0.08597
Step 125525: loss = 0.11362
Step 125530: loss = 0.07512
Step 125535: loss = 0.13935
Step 125540: loss = 0.12880
Step 125545: loss = 0.10489
Step 125550: loss = 0.06104
Step 125555: loss = 0.16410
Step 125560: loss = 0.23942
Step 125565: loss = 0.08450
Step 125570: loss = 0.06081
Step 125575: loss = 0.08774
Step 125580: loss = 0.16209
Step 125585: loss = 0.13553
Step 125590: loss = 0.15297
Step 125595: loss = 0.13712
Step 125600: loss = 0.13515
Step 125605: loss = 0.13857
Step 125610: loss = 0.12713
Step 125615: loss = 0.09921
Step 125620: loss = 0.09113
Step 125625: loss = 0.18646
Step 125630: loss = 0.34878
Step 125635: loss = 0.17455
Step 125640: loss = 0.08431
Step 125645: loss = 0.13903
Step 125650: loss = 0.10463
Step 125655: loss = 0.09658
Step 125660: loss = 0.08832
Step 125665: loss = 0.22997
Step 125670: loss = 0.07938
Step 125675: loss = 0.37638
Step 125680: loss = 0.16360
Step 125685: loss = 0.07423
Step 125690: loss = 0.18578
Step 125695: loss = 0.24139
Step 125700: loss = 0.24617
Step 125705: loss = 0.13024
Step 125710: loss = 0.07998
Step 125715: loss = 0.05712
Step 125720: loss = 0.17838
Step 125725: loss = 0.07957
Step 125730: loss = 0.09374
Step 125735: loss = 0.17230
Step 125740: loss = 0.25403
Step 125745: loss = 0.22475
Step 125750: loss = 0.10261
Step 125755: loss = 0.10689
Step 125760: loss = 0.17326
Step 125765: loss = 0.06464
Step 125770: loss = 0.26066
Step 125775: loss = 0.15508
Step 125780: loss = 0.27548
Step 125785: loss = 0.20598
Step 125790: loss = 0.04258
Step 125795: loss = 0.26490
Step 125800: loss = 0.09137
Step 125805: loss = 0.07395
Step 125810: loss = 0.07990
Step 125815: loss = 0.02684
Step 125820: loss = 0.15154
Step 125825: loss = 0.14951
Step 125830: loss = 0.06384
Step 125835: loss = 0.20945
Step 125840: loss = 0.07181
Step 125845: loss = 0.05178
Step 125850: loss = 0.26859
Step 125855: loss = 0.09651
Step 125860: loss = 0.13024
Step 125865: loss = 0.05839
Step 125870: loss = 0.22916
Step 125875: loss = 0.19371
Step 125880: loss = 0.12681
Step 125885: loss = 0.12491
Step 125890: loss = 0.03798
Step 125895: loss = 0.09220
Step 125900: loss = 0.17901
Step 125905: loss = 0.05937
Step 125910: loss = 0.05208
Step 125915: loss = 0.13858
Step 125920: loss = 0.16620
Step 125925: loss = 0.08799
Step 125930: loss = 0.12176
Step 125935: loss = 0.19090
Step 125940: loss = 0.19431
Step 125945: loss = 0.19088
Step 125950: loss = 0.50777
Step 125955: loss = 0.11263
Step 125960: loss = 0.07067
Step 125965: loss = 0.15985
Step 125970: loss = 0.06144
Step 125975: loss = 0.02845
Step 125980: loss = 0.18117
Step 125985: loss = 0.11761
Step 125990: loss = 0.13497
Step 125995: loss = 0.56393
Step 126000: loss = 0.07960
Training Data Eval:
  Num examples: 50000, Num correct: 47712, Precision @ 1: 0.9542
('Testing Data Eval: EPOCH->', 127)
  Num examples: 10000, Num correct: 6605, Precision @ 1: 0.6605
Step 126005: loss = 0.09798
Step 126010: loss = 0.20938
Step 126015: loss = 0.19969
Step 126020: loss = 0.07320
Step 126025: loss = 0.16188
Step 126030: loss = 0.06781
Step 126035: loss = 0.24272
Step 126040: loss = 0.10933
Step 126045: loss = 0.08646
Step 126050: loss = 0.08098
Step 126055: loss = 0.22586
Step 126060: loss = 0.14091
Step 126065: loss = 0.05338
Step 126070: loss = 0.09266
Step 126075: loss = 0.05635
Step 126080: loss = 0.24430
Step 126085: loss = 0.10312
Step 126090: loss = 0.03046
Step 126095: loss = 0.09446
Step 126100: loss = 0.17065
Step 126105: loss = 0.11819
Step 126110: loss = 0.04430
Step 126115: loss = 0.08900
Step 126120: loss = 0.14902
Step 126125: loss = 0.11107
Step 126130: loss = 0.22291
Step 126135: loss = 0.07852
Step 126140: loss = 0.29009
Step 126145: loss = 0.04055
Step 126150: loss = 0.12071
Step 126155: loss = 0.13601
Step 126160: loss = 0.22474
Step 126165: loss = 0.13200
Step 126170: loss = 0.08900
Step 126175: loss = 0.15483
Step 126180: loss = 0.27646
Step 126185: loss = 0.12129
Step 126190: loss = 0.15777
Step 126195: loss = 0.07456
Step 126200: loss = 0.03674
Step 126205: loss = 0.25527
Step 126210: loss = 0.20196
Step 126215: loss = 0.08024
Step 126220: loss = 0.06429
Step 126225: loss = 0.18571
Step 126230: loss = 0.05308
Step 126235: loss = 0.05349
Step 126240: loss = 0.08675
Step 126245: loss = 0.30687
Step 126250: loss = 0.17284
Step 126255: loss = 0.31923
Step 126260: loss = 0.10146
Step 126265: loss = 0.15347
Step 126270: loss = 0.08639
Step 126275: loss = 0.16562
Step 126280: loss = 0.07164
Step 126285: loss = 0.08954
Step 126290: loss = 0.21335
Step 126295: loss = 0.07289
Step 126300: loss = 0.14185
Step 126305: loss = 0.34411
Step 126310: loss = 0.04906
Step 126315: loss = 0.06592
Step 126320: loss = 0.14163
Step 126325: loss = 0.03861
Step 126330: loss = 0.14365
Step 126335: loss = 0.10797
Step 126340: loss = 0.20048
Step 126345: loss = 0.08110
Step 126350: loss = 0.06772
Step 126355: loss = 0.13681
Step 126360: loss = 0.07640
Step 126365: loss = 0.10277
Step 126370: loss = 0.06531
Step 126375: loss = 0.10704
Step 126380: loss = 0.22602
Step 126385: loss = 0.08855
Step 126390: loss = 0.13670
Step 126395: loss = 0.17009
Step 126400: loss = 0.10839
Step 126405: loss = 0.12869
Step 126410: loss = 0.03760
Step 126415: loss = 0.08235
Step 126420: loss = 0.08927
Step 126425: loss = 0.23837
Step 126430: loss = 0.10487
Step 126435: loss = 0.07140
Step 126440: loss = 0.09338
Step 126445: loss = 0.03728
Step 126450: loss = 0.21328
Step 126455: loss = 0.10549
Step 126460: loss = 0.10262
Step 126465: loss = 0.11850
Step 126470: loss = 0.07515
Step 126475: loss = 0.13338
Step 126480: loss = 0.19547
Step 126485: loss = 0.13894
Step 126490: loss = 0.15491
Step 126495: loss = 0.21551
Step 126500: loss = 0.12195
Step 126505: loss = 0.06464
Step 126510: loss = 0.05964
Step 126515: loss = 0.09174
Step 126520: loss = 0.10203
Step 126525: loss = 0.28032
Step 126530: loss = 0.15853
Step 126535: loss = 0.12695
Step 126540: loss = 0.08734
Step 126545: loss = 0.10674
Step 126550: loss = 0.31675
Step 126555: loss = 0.17262
Step 126560: loss = 0.18181
Step 126565: loss = 0.28209
Step 126570: loss = 0.15429
Step 126575: loss = 0.29224
Step 126580: loss = 0.11176
Step 126585: loss = 0.17662
Step 126590: loss = 0.13988
Step 126595: loss = 0.11809
Step 126600: loss = 0.27442
Step 126605: loss = 0.10011
Step 126610: loss = 0.35396
Step 126615: loss = 0.15211
Step 126620: loss = 0.14023
Step 126625: loss = 0.15722
Step 126630: loss = 0.25383
Step 126635: loss = 0.11185
Step 126640: loss = 0.03623
Step 126645: loss = 0.07154
Step 126650: loss = 0.14187
Step 126655: loss = 0.09833
Step 126660: loss = 0.07577
Step 126665: loss = 0.04424
Step 126670: loss = 0.20009
Step 126675: loss = 0.19770
Step 126680: loss = 0.16930
Step 126685: loss = 0.08727
Step 126690: loss = 0.09073
Step 126695: loss = 0.11620
Step 126700: loss = 0.14597
Step 126705: loss = 0.18031
Step 126710: loss = 0.34799
Step 126715: loss = 0.23185
Step 126720: loss = 0.06139
Step 126725: loss = 0.10920
Step 126730: loss = 0.16642
Step 126735: loss = 0.09414
Step 126740: loss = 0.18925
Step 126745: loss = 0.14706
Step 126750: loss = 0.14716
Step 126755: loss = 0.08028
Step 126760: loss = 0.10306
Step 126765: loss = 0.08484
Step 126770: loss = 0.28228
Step 126775: loss = 0.12739
Step 126780: loss = 0.05499
Step 126785: loss = 0.09814
Step 126790: loss = 0.02604
Step 126795: loss = 0.18664
Step 126800: loss = 0.22692
Step 126805: loss = 0.16670
Step 126810: loss = 0.21458
Step 126815: loss = 0.29873
Step 126820: loss = 0.04300
Step 126825: loss = 0.10200
Step 126830: loss = 0.14764
Step 126835: loss = 0.11084
Step 126840: loss = 0.08700
Step 126845: loss = 0.25838
Step 126850: loss = 0.27910
Step 126855: loss = 0.39396
Step 126860: loss = 0.06074
Step 126865: loss = 0.19703
Step 126870: loss = 0.02136
Step 126875: loss = 0.13603
Step 126880: loss = 0.09862
Step 126885: loss = 0.06256
Step 126890: loss = 0.21205
Step 126895: loss = 0.11463
Step 126900: loss = 0.10868
Step 126905: loss = 0.10355
Step 126910: loss = 0.27617
Step 126915: loss = 0.06969
Step 126920: loss = 0.16269
Step 126925: loss = 0.09191
Step 126930: loss = 0.09730
Step 126935: loss = 0.03043
Step 126940: loss = 0.11271
Step 126945: loss = 0.08997
Step 126950: loss = 0.06126
Step 126955: loss = 0.12568
Step 126960: loss = 0.14002
Step 126965: loss = 0.10038
Step 126970: loss = 0.18595
Step 126975: loss = 0.24208
Step 126980: loss = 0.16251
Step 126985: loss = 0.10953
Step 126990: loss = 0.10907
Step 126995: loss = 0.07334
Step 127000: loss = 0.22289
Training Data Eval:
  Num examples: 50000, Num correct: 47629, Precision @ 1: 0.9526
('Testing Data Eval: EPOCH->', 128)
  Num examples: 10000, Num correct: 6635, Precision @ 1: 0.6635
Step 127005: loss = 0.06836
Step 127010: loss = 0.07778
Step 127015: loss = 0.09280
Step 127020: loss = 0.11935
Step 127025: loss = 0.15696
Step 127030: loss = 0.03613
Step 127035: loss = 0.08816
Step 127040: loss = 0.11753
Step 127045: loss = 0.19269
Step 127050: loss = 0.10743
Step 127055: loss = 0.22929
Step 127060: loss = 0.19805
Step 127065: loss = 0.12169
Step 127070: loss = 0.19836
Step 127075: loss = 0.19713
Step 127080: loss = 0.12132
Step 127085: loss = 0.08002
Step 127090: loss = 0.23339
Step 127095: loss = 0.09965
Step 127100: loss = 0.14529
Step 127105: loss = 0.23239
Step 127110: loss = 0.14844
Step 127115: loss = 0.06159
Step 127120: loss = 0.12282
Step 127125: loss = 0.22595
Step 127130: loss = 0.07036
Step 127135: loss = 0.08630
Step 127140: loss = 0.07230
Step 127145: loss = 0.24602
Step 127150: loss = 0.10715
Step 127155: loss = 0.17063
Step 127160: loss = 0.13197
Step 127165: loss = 0.17086
Step 127170: loss = 0.18614
Step 127175: loss = 0.13811
Step 127180: loss = 0.31480
Step 127185: loss = 0.17076
Step 127190: loss = 0.05324
Step 127195: loss = 0.18831
Step 127200: loss = 0.09961
Step 127205: loss = 0.06029
Step 127210: loss = 0.14822
Step 127215: loss = 0.13940
Step 127220: loss = 0.06933
Step 127225: loss = 0.07125
Step 127230: loss = 0.06157
Step 127235: loss = 0.36657
Step 127240: loss = 0.06839
Step 127245: loss = 0.08623
Step 127250: loss = 0.23096
Step 127255: loss = 0.18511
Step 127260: loss = 0.22056
Step 127265: loss = 0.05143
Step 127270: loss = 0.14796
Step 127275: loss = 0.15933
Step 127280: loss = 0.24718
Step 127285: loss = 0.13541
Step 127290: loss = 0.13846
Step 127295: loss = 0.22700
Step 127300: loss = 0.10470
Step 127305: loss = 0.09310
Step 127310: loss = 0.08519
Step 127315: loss = 0.05377
Step 127320: loss = 0.08077
Step 127325: loss = 0.13997
Step 127330: loss = 0.11446
Step 127335: loss = 0.03837
Step 127340: loss = 0.14786
Step 127345: loss = 0.10665
Step 127350: loss = 0.10722
Step 127355: loss = 0.04602
Step 127360: loss = 0.04746
Step 127365: loss = 0.13276
Step 127370: loss = 0.22708
Step 127375: loss = 0.30429
Step 127380: loss = 0.11753
Step 127385: loss = 0.13652
Step 127390: loss = 0.11387
Step 127395: loss = 0.06485
Step 127400: loss = 0.16124
Step 127405: loss = 0.11625
Step 127410: loss = 0.02400
Step 127415: loss = 0.08388
Step 127420: loss = 0.10331
Step 127425: loss = 0.05785
Step 127430: loss = 0.09747
Step 127435: loss = 0.10580
Step 127440: loss = 0.30884
Step 127445: loss = 0.13432
Step 127450: loss = 0.11084
Step 127455: loss = 0.17594
Step 127460: loss = 0.14033
Step 127465: loss = 0.21944
Step 127470: loss = 0.34935
Step 127475: loss = 0.28028
Step 127480: loss = 0.14417
Step 127485: loss = 0.15731
Step 127490: loss = 0.28093
Step 127495: loss = 0.18291
Step 127500: loss = 0.25793
Step 127505: loss = 0.02512
Step 127510: loss = 0.05511
Step 127515: loss = 0.21556
Step 127520: loss = 0.23805
Step 127525: loss = 0.12419
Step 127530: loss = 0.08421
Step 127535: loss = 0.06803
Step 127540: loss = 0.04399
Step 127545: loss = 0.14920
Step 127550: loss = 0.14210
Step 127555: loss = 0.16845
Step 127560: loss = 0.06400
Step 127565: loss = 0.28723
Step 127570: loss = 0.11655
Step 127575: loss = 0.08709
Step 127580: loss = 0.17816
Step 127585: loss = 0.07669
Step 127590: loss = 0.16430
Step 127595: loss = 0.04912
Step 127600: loss = 0.17604
Step 127605: loss = 0.11812
Step 127610: loss = 0.03369
Step 127615: loss = 0.06766
Step 127620: loss = 0.28091
Step 127625: loss = 0.31257
Step 127630: loss = 0.17698
Step 127635: loss = 0.06960
Step 127640: loss = 0.08522
Step 127645: loss = 0.10769
Step 127650: loss = 0.12643
Step 127655: loss = 0.09478
Step 127660: loss = 0.07546
Step 127665: loss = 0.16978
Step 127670: loss = 0.20478
Step 127675: loss = 0.21670
Step 127680: loss = 0.31316
Step 127685: loss = 0.17166
Step 127690: loss = 0.10929
Step 127695: loss = 0.09449
Step 127700: loss = 0.07898
Step 127705: loss = 0.08427
Step 127710: loss = 0.17766
Step 127715: loss = 0.12214
Step 127720: loss = 0.11092
Step 127725: loss = 0.26515
Step 127730: loss = 0.10115
Step 127735: loss = 0.13824
Step 127740: loss = 0.28552
Step 127745: loss = 0.04791
Step 127750: loss = 0.06870
Step 127755: loss = 0.31231
Step 127760: loss = 0.10080
Step 127765: loss = 0.05850
Step 127770: loss = 0.05011
Step 127775: loss = 0.23376
Step 127780: loss = 0.14811
Step 127785: loss = 0.21232
Step 127790: loss = 0.09968
Step 127795: loss = 0.11155
Step 127800: loss = 0.05915
Step 127805: loss = 0.06052
Step 127810: loss = 0.08742
Step 127815: loss = 0.09209
Step 127820: loss = 0.11516
Step 127825: loss = 0.13113
Step 127830: loss = 0.05554
Step 127835: loss = 0.21786
Step 127840: loss = 0.20696
Step 127845: loss = 0.21096
Step 127850: loss = 0.06865
Step 127855: loss = 0.26660
Step 127860: loss = 0.18756
Step 127865: loss = 0.13618
Step 127870: loss = 0.17881
Step 127875: loss = 0.10024
Step 127880: loss = 0.18716
Step 127885: loss = 0.22229
Step 127890: loss = 0.08361
Step 127895: loss = 0.32129
Step 127900: loss = 0.19174
Step 127905: loss = 0.18117
Step 127910: loss = 0.15975
Step 127915: loss = 0.06942
Step 127920: loss = 0.12560
Step 127925: loss = 0.24277
Step 127930: loss = 0.09646
Step 127935: loss = 0.09171
Step 127940: loss = 0.08013
Step 127945: loss = 0.11787
Step 127950: loss = 0.11376
Step 127955: loss = 0.09518
Step 127960: loss = 0.05489
Step 127965: loss = 0.05289
Step 127970: loss = 0.18531
Step 127975: loss = 0.08335
Step 127980: loss = 0.12349
Step 127985: loss = 0.12403
Step 127990: loss = 0.21083
Step 127995: loss = 0.16633
Step 128000: loss = 0.16036
Training Data Eval:
  Num examples: 50000, Num correct: 47627, Precision @ 1: 0.9525
('Testing Data Eval: EPOCH->', 129)
  Num examples: 10000, Num correct: 6581, Precision @ 1: 0.6581
Step 128005: loss = 0.06978
Step 128010: loss = 0.03438
Step 128015: loss = 0.09963
Step 128020: loss = 0.13517
Step 128025: loss = 0.29730
Step 128030: loss = 0.21974
Step 128035: loss = 0.07402
Step 128040: loss = 0.08616
Step 128045: loss = 0.20494
Step 128050: loss = 0.13930
Step 128055: loss = 0.07244
Step 128060: loss = 0.28660
Step 128065: loss = 0.12466
Step 128070: loss = 0.21917
Step 128075: loss = 0.15739
Step 128080: loss = 0.16655
Step 128085: loss = 0.07363
Step 128090: loss = 0.20534
Step 128095: loss = 0.27878
Step 128100: loss = 0.04519
Step 128105: loss = 0.13302
Step 128110: loss = 0.09774
Step 128115: loss = 0.11952
Step 128120: loss = 0.31064
Step 128125: loss = 0.13668
Step 128130: loss = 0.03352
Step 128135: loss = 0.07160
Step 128140: loss = 0.25371
Step 128145: loss = 0.43354
Step 128150: loss = 0.10845
Step 128155: loss = 0.09594
Step 128160: loss = 0.04531
Step 128165: loss = 0.08037
Step 128170: loss = 0.15885
Step 128175: loss = 0.10888
Step 128180: loss = 0.29619
Step 128185: loss = 0.15289
Step 128190: loss = 0.15478
Step 128195: loss = 0.31481
Step 128200: loss = 0.08364
Step 128205: loss = 0.06059
Step 128210: loss = 0.07923
Step 128215: loss = 0.24987
Step 128220: loss = 0.13510
Step 128225: loss = 0.05451
Step 128230: loss = 0.18715
Step 128235: loss = 0.41918
Step 128240: loss = 0.06931
Step 128245: loss = 0.20322
Step 128250: loss = 0.15899
Step 128255: loss = 0.20382
Step 128260: loss = 0.04689
Step 128265: loss = 0.02533
Step 128270: loss = 0.11116
Step 128275: loss = 0.27008
Step 128280: loss = 0.08589
Step 128285: loss = 0.14890
Step 128290: loss = 0.14631
Step 128295: loss = 0.13573
Step 128300: loss = 0.18602
Step 128305: loss = 0.16290
Step 128310: loss = 0.19949
Step 128315: loss = 0.05938
Step 128320: loss = 0.10758
Step 128325: loss = 0.11439
Step 128330: loss = 0.06755
Step 128335: loss = 0.38334
Step 128340: loss = 0.08577
Step 128345: loss = 0.25641
Step 128350: loss = 0.19533
Step 128355: loss = 0.11070
Step 128360: loss = 0.05641
Step 128365: loss = 0.21625
Step 128370: loss = 0.09887
Step 128375: loss = 0.13141
Step 128380: loss = 0.07866
Step 128385: loss = 0.08987
Step 128390: loss = 0.13268
Step 128395: loss = 0.08575
Step 128400: loss = 0.11526
Step 128405: loss = 0.08731
Step 128410: loss = 0.11849
Step 128415: loss = 0.11290
Step 128420: loss = 0.23638
Step 128425: loss = 0.45005
Step 128430: loss = 0.03007
Step 128435: loss = 0.06921
Step 128440: loss = 0.14898
Step 128445: loss = 0.01847
Step 128450: loss = 0.09578
Step 128455: loss = 0.19237
Step 128460: loss = 0.18359
Step 128465: loss = 0.17761
Step 128470: loss = 0.14537
Step 128475: loss = 0.12119
Step 128480: loss = 0.08922
Step 128485: loss = 0.04043
Step 128490: loss = 0.29767
Step 128495: loss = 0.24224
Step 128500: loss = 0.08921
Step 128505: loss = 0.12256
Step 128510: loss = 0.11861
Step 128515: loss = 0.20763
Step 128520: loss = 0.19874
Step 128525: loss = 0.31998
Step 128530: loss = 0.16648
Step 128535: loss = 0.06198
Step 128540: loss = 0.22846
Step 128545: loss = 0.05987
Step 128550: loss = 0.34626
Step 128555: loss = 0.03124
Step 128560: loss = 0.17178
Step 128565: loss = 0.04945
Step 128570: loss = 0.03868
Step 128575: loss = 0.09568
Step 128580: loss = 0.14175
Step 128585: loss = 0.06943
Step 128590: loss = 0.03609
Step 128595: loss = 0.25348
Step 128600: loss = 0.07236
Step 128605: loss = 0.15379
Step 128610: loss = 0.15948
Step 128615: loss = 0.16164
Step 128620: loss = 0.12219
Step 128625: loss = 0.44124
Step 128630: loss = 0.09821
Step 128635: loss = 0.11614
Step 128640: loss = 0.22015
Step 128645: loss = 0.06176
Step 128650: loss = 0.09297
Step 128655: loss = 0.10179
Step 128660: loss = 0.09411
Step 128665: loss = 0.23593
Step 128670: loss = 0.10031
Step 128675: loss = 0.23630
Step 128680: loss = 0.16646
Step 128685: loss = 0.16880
Step 128690: loss = 0.05890
Step 128695: loss = 0.09436
Step 128700: loss = 0.15948
Step 128705: loss = 0.12920
Step 128710: loss = 0.05171
Step 128715: loss = 0.07240
Step 128720: loss = 0.08135
Step 128725: loss = 0.20356
Step 128730: loss = 0.09611
Step 128735: loss = 0.02793
Step 128740: loss = 0.21718
Step 128745: loss = 0.09715
Step 128750: loss = 0.05415
Step 128755: loss = 0.02459
Step 128760: loss = 0.23777
Step 128765: loss = 0.07308
Step 128770: loss = 0.22937
Step 128775: loss = 0.22597
Step 128780: loss = 0.10255
Step 128785: loss = 0.08107
Step 128790: loss = 0.08962
Step 128795: loss = 0.22874
Step 128800: loss = 0.11902
Step 128805: loss = 0.10351
Step 128810: loss = 0.10498
Step 128815: loss = 0.07288
Step 128820: loss = 0.17960
Step 128825: loss = 0.06616
Step 128830: loss = 0.13627
Step 128835: loss = 0.08227
Step 128840: loss = 0.04121
Step 128845: loss = 0.08597
Step 128850: loss = 0.04403
Step 128855: loss = 0.23295
Step 128860: loss = 0.08697
Step 128865: loss = 0.11528
Step 128870: loss = 0.05328
Step 128875: loss = 0.11694
Step 128880: loss = 0.14240
Step 128885: loss = 0.36972
Step 128890: loss = 0.25615
Step 128895: loss = 0.02502
Step 128900: loss = 0.18264
Step 128905: loss = 0.02818
Step 128910: loss = 0.13483
Step 128915: loss = 0.03761
Step 128920: loss = 0.14587
Step 128925: loss = 0.09914
Step 128930: loss = 0.28203
Step 128935: loss = 0.04657
Step 128940: loss = 0.14309
Step 128945: loss = 0.15555
Step 128950: loss = 0.08531
Step 128955: loss = 0.21934
Step 128960: loss = 0.24586
Step 128965: loss = 0.09377
Step 128970: loss = 0.08391
Step 128975: loss = 0.10390
Step 128980: loss = 0.25520
Step 128985: loss = 0.03368
Step 128990: loss = 0.37102
Step 128995: loss = 0.49327
Step 129000: loss = 0.10436
Training Data Eval:
  Num examples: 50000, Num correct: 47585, Precision @ 1: 0.9517
('Testing Data Eval: EPOCH->', 130)
  Num examples: 10000, Num correct: 6727, Precision @ 1: 0.6727
Step 129005: loss = 0.04632
Step 129010: loss = 0.15528
Step 129015: loss = 0.10464
Step 129020: loss = 0.28148
Step 129025: loss = 0.17430
Step 129030: loss = 0.09912
Step 129035: loss = 0.05950
Step 129040: loss = 0.26910
Step 129045: loss = 0.06048
Step 129050: loss = 0.10054
Step 129055: loss = 0.30613
Step 129060: loss = 0.14989
Step 129065: loss = 0.07526
Step 129070: loss = 0.10308
Step 129075: loss = 0.07138
Step 129080: loss = 0.08630
Step 129085: loss = 0.15214
Step 129090: loss = 0.08119
Step 129095: loss = 0.03983
Step 129100: loss = 0.12310
Step 129105: loss = 0.22273
Step 129110: loss = 0.08704
Step 129115: loss = 0.09347
Step 129120: loss = 0.24458
Step 129125: loss = 0.16161
Step 129130: loss = 0.11917
Step 129135: loss = 0.22234
Step 129140: loss = 0.07926
Step 129145: loss = 0.04432
Step 129150: loss = 0.10660
Step 129155: loss = 0.21571
Step 129160: loss = 0.10368
Step 129165: loss = 0.12387
Step 129170: loss = 0.08750
Step 129175: loss = 0.09729
Step 129180: loss = 0.07107
Step 129185: loss = 0.05065
Step 129190: loss = 0.23873
Step 129195: loss = 0.03854
Step 129200: loss = 0.09448
Step 129205: loss = 0.06211
Step 129210: loss = 0.16749
Step 129215: loss = 0.04915
Step 129220: loss = 0.08469
Step 129225: loss = 0.05160
Step 129230: loss = 0.03916
Step 129235: loss = 0.23975
Step 129240: loss = 0.14070
Step 129245: loss = 0.06867
Step 129250: loss = 0.14347
Step 129255: loss = 0.17237
Step 129260: loss = 0.08911
Step 129265: loss = 0.14714
Step 129270: loss = 0.07191
Step 129275: loss = 0.11588
Step 129280: loss = 0.10027
Step 129285: loss = 0.13046
Step 129290: loss = 0.37525
Step 129295: loss = 0.14279
Step 129300: loss = 0.08712
Step 129305: loss = 0.12967
Step 129310: loss = 0.06460
Step 129315: loss = 0.15415
Step 129320: loss = 0.04213
Step 129325: loss = 0.04166
Step 129330: loss = 0.03738
Step 129335: loss = 0.31698
Step 129340: loss = 0.32076
Step 129345: loss = 0.24785
Step 129350: loss = 0.20927
Step 129355: loss = 0.22094
Step 129360: loss = 0.20542
Step 129365: loss = 0.03353
Step 129370: loss = 0.21411
Step 129375: loss = 0.23894
Step 129380: loss = 0.06299
Step 129385: loss = 0.13602
Step 129390: loss = 0.17157
Step 129395: loss = 0.11066
Step 129400: loss = 0.14917
Step 129405: loss = 0.08624
Step 129410: loss = 0.21988
Step 129415: loss = 0.04826
Step 129420: loss = 0.06038
Step 129425: loss = 0.19732
Step 129430: loss = 0.31287
Step 129435: loss = 0.31844
Step 129440: loss = 0.03968
Step 129445: loss = 0.07840
Step 129450: loss = 0.08720
Step 129455: loss = 0.28478
Step 129460: loss = 0.16056
Step 129465: loss = 0.24183
Step 129470: loss = 0.06503
Step 129475: loss = 0.26654
Step 129480: loss = 0.17947
Step 129485: loss = 0.13398
Step 129490: loss = 0.09309
Step 129495: loss = 0.12687
Step 129500: loss = 0.17386
Step 129505: loss = 0.20963
Step 129510: loss = 0.09535
Step 129515: loss = 0.19057
Step 129520: loss = 0.08556
Step 129525: loss = 0.13966
Step 129530: loss = 0.11100
Step 129535: loss = 0.32893
Step 129540: loss = 0.17503
Step 129545: loss = 0.28610
Step 129550: loss = 0.12014
Step 129555: loss = 0.16048
Step 129560: loss = 0.18874
Step 129565: loss = 0.16674
Step 129570: loss = 0.12674
Step 129575: loss = 0.04490
Step 129580: loss = 0.21638
Step 129585: loss = 0.20141
Step 129590: loss = 0.10043
Step 129595: loss = 0.24816
Step 129600: loss = 0.11078
Step 129605: loss = 0.17904
Step 129610: loss = 0.11557
Step 129615: loss = 0.13433
Step 129620: loss = 0.08105
Step 129625: loss = 0.05630
Step 129630: loss = 0.06336
Step 129635: loss = 0.10113
Step 129640: loss = 0.47904
Step 129645: loss = 0.03498
Step 129650: loss = 0.08438
Step 129655: loss = 0.11497
Step 129660: loss = 0.07544
Step 129665: loss = 0.05314
Step 129670: loss = 0.09580
Step 129675: loss = 0.21463
Step 129680: loss = 0.11237
Step 129685: loss = 0.08860
Step 129690: loss = 0.18176
Step 129695: loss = 0.12173
Step 129700: loss = 0.17237
Step 129705: loss = 0.03705
Step 129710: loss = 0.05581
Step 129715: loss = 0.17528
Step 129720: loss = 0.10911
Step 129725: loss = 0.13408
Step 129730: loss = 0.08886
Step 129735: loss = 0.48346
Step 129740: loss = 0.21556
Step 129745: loss = 0.19005
Step 129750: loss = 0.15288
Step 129755: loss = 0.07311
Step 129760: loss = 0.29117
Step 129765: loss = 0.23774
Step 129770: loss = 0.18302
Step 129775: loss = 0.26626
Step 129780: loss = 0.13233
Step 129785: loss = 0.13418
Step 129790: loss = 0.21518
Step 129795: loss = 0.17429
Step 129800: loss = 0.04464
Step 129805: loss = 0.16711
Step 129810: loss = 0.07997
Step 129815: loss = 0.07831
Step 129820: loss = 0.13081
Step 129825: loss = 0.09462
Step 129830: loss = 0.12476
Step 129835: loss = 0.11210
Step 129840: loss = 0.18187
Step 129845: loss = 0.05555
Step 129850: loss = 0.07130
Step 129855: loss = 0.15040
Step 129860: loss = 0.08103
Step 129865: loss = 0.21741
Step 129870: loss = 0.04532
Step 129875: loss = 0.25844
Step 129880: loss = 0.06827
Step 129885: loss = 0.13153
Step 129890: loss = 0.22537
Step 129895: loss = 0.08250
Step 129900: loss = 0.08417
Step 129905: loss = 0.40897
Step 129910: loss = 0.15914
Step 129915: loss = 0.08533
Step 129920: loss = 0.22324
Step 129925: loss = 0.06019
Step 129930: loss = 0.17247
Step 129935: loss = 0.16579
Step 129940: loss = 0.04383
Step 129945: loss = 0.05934
Step 129950: loss = 0.08913
Step 129955: loss = 0.21413
Step 129960: loss = 0.19126
Step 129965: loss = 0.09894
Step 129970: loss = 0.10598
Step 129975: loss = 0.10878
Step 129980: loss = 0.04932
Step 129985: loss = 0.09083
Step 129990: loss = 0.11287
Step 129995: loss = 0.06694
Step 130000: loss = 0.10549
Training Data Eval:
  Num examples: 50000, Num correct: 47793, Precision @ 1: 0.9559
('Testing Data Eval: EPOCH->', 131)
  Num examples: 10000, Num correct: 6671, Precision @ 1: 0.6671
Step 130005: loss = 0.36092
Step 130010: loss = 0.03304
Step 130015: loss = 0.11374
Step 130020: loss = 0.05557
Step 130025: loss = 0.03661
Step 130030: loss = 0.12901
Step 130035: loss = 0.09481
Step 130040: loss = 0.15344
Step 130045: loss = 0.38247
Step 130050: loss = 0.18437
Step 130055: loss = 0.25954
Step 130060: loss = 0.04302
Step 130065: loss = 0.13125
Step 130070: loss = 0.47404
Step 130075: loss = 0.06882
Step 130080: loss = 0.04947
Step 130085: loss = 0.12796
Step 130090: loss = 0.09697
Step 130095: loss = 0.02318
Step 130100: loss = 0.08629
Step 130105: loss = 0.09915
Step 130110: loss = 0.15692
Step 130115: loss = 0.09923
Step 130120: loss = 0.06816
Step 130125: loss = 0.13921
Step 130130: loss = 0.16089
Step 130135: loss = 0.12446
Step 130140: loss = 0.07882
Step 130145: loss = 0.11926
Step 130150: loss = 0.07244
Step 130155: loss = 0.14915
Step 130160: loss = 0.10614
Step 130165: loss = 0.26135
Step 130170: loss = 0.05749
Step 130175: loss = 0.10279
Step 130180: loss = 0.17561
Step 130185: loss = 0.07584
Step 130190: loss = 0.25934
Step 130195: loss = 0.11844
Step 130200: loss = 0.38392
Step 130205: loss = 0.12845
Step 130210: loss = 0.02999
Step 130215: loss = 0.08604
Step 130220: loss = 0.06678
Step 130225: loss = 0.06448
Step 130230: loss = 0.05414
Step 130235: loss = 0.05442
Step 130240: loss = 0.05241
Step 130245: loss = 0.13320
Step 130250: loss = 0.14213
Step 130255: loss = 0.31850
Step 130260: loss = 0.20225
Step 130265: loss = 0.12239
Step 130270: loss = 0.03462
Step 130275: loss = 0.03558
Step 130280: loss = 0.07915
Step 130285: loss = 0.12421
Step 130290: loss = 0.14367
Step 130295: loss = 0.04245
Step 130300: loss = 0.05421
Step 130305: loss = 0.16142
Step 130310: loss = 0.09433
Step 130315: loss = 0.10047
Step 130320: loss = 0.22589
Step 130325: loss = 0.09045
Step 130330: loss = 0.05829
Step 130335: loss = 0.11722
Step 130340: loss = 0.09338
Step 130345: loss = 0.07902
Step 130350: loss = 0.13399
Step 130355: loss = 0.08014
Step 130360: loss = 0.12843
Step 130365: loss = 0.43140
Step 130370: loss = 0.39085
Step 130375: loss = 0.04567
Step 130380: loss = 0.10638
Step 130385: loss = 0.19858
Step 130390: loss = 0.19299
Step 130395: loss = 0.07162
Step 130400: loss = 0.10092
Step 130405: loss = 0.11518
Step 130410: loss = 0.23065
Step 130415: loss = 0.14455
Step 130420: loss = 0.18187
Step 130425: loss = 0.14083
Step 130430: loss = 0.10425
Step 130435: loss = 0.32518
Step 130440: loss = 0.10950
Step 130445: loss = 0.09713
Step 130450: loss = 0.20759
Step 130455: loss = 0.19375
Step 130460: loss = 0.07162
Step 130465: loss = 0.02812
Step 130470: loss = 0.17388
Step 130475: loss = 0.08961
Step 130480: loss = 0.30425
Step 130485: loss = 0.21263
Step 130490: loss = 0.12467
Step 130495: loss = 0.08411
Step 130500: loss = 0.15370
Step 130505: loss = 0.20164
Step 130510: loss = 0.08742
Step 130515: loss = 0.05440
Step 130520: loss = 0.07959
Step 130525: loss = 0.11192
Step 130530: loss = 0.04690
Step 130535: loss = 0.06996
Step 130540: loss = 0.06752
Step 130545: loss = 0.10864
Step 130550: loss = 0.12631
Step 130555: loss = 0.12460
Step 130560: loss = 0.35342
Step 130565: loss = 0.19616
Step 130570: loss = 0.05082
Step 130575: loss = 0.08569
Step 130580: loss = 0.06788
Step 130585: loss = 0.07021
Step 130590: loss = 0.13311
Step 130595: loss = 0.05017
Step 130600: loss = 0.91695
Step 130605: loss = 0.09080
Step 130610: loss = 0.24493
Step 130615: loss = 0.19105
Step 130620: loss = 0.25327
Step 130625: loss = 0.11562
Step 130630: loss = 0.31417
Step 130635: loss = 0.14351
Step 130640: loss = 0.19870
Step 130645: loss = 0.30315
Step 130650: loss = 0.05476
Step 130655: loss = 0.13336
Step 130660: loss = 0.27132
Step 130665: loss = 0.09358
Step 130670: loss = 0.26512
Step 130675: loss = 0.22512
Step 130680: loss = 0.08762
Step 130685: loss = 0.20884
Step 130690: loss = 0.22157
Step 130695: loss = 0.09289
Step 130700: loss = 0.09804
Step 130705: loss = 0.13005
Step 130710: loss = 0.27205
Step 130715: loss = 0.08985
Step 130720: loss = 0.04458
Step 130725: loss = 0.06696
Step 130730: loss = 0.11892
Step 130735: loss = 0.07394
Step 130740: loss = 0.18371
Step 130745: loss = 0.06797
Step 130750: loss = 0.07545
Step 130755: loss = 0.08917
Step 130760: loss = 0.04324
Step 130765: loss = 0.06426
Step 130770: loss = 0.12597
Step 130775: loss = 0.03659
Step 130780: loss = 0.20360
Step 130785: loss = 0.14489
Step 130790: loss = 0.09821
Step 130795: loss = 0.08472
Step 130800: loss = 0.09692
Step 130805: loss = 0.18358
Step 130810: loss = 0.14636
Step 130815: loss = 0.13369
Step 130820: loss = 0.08220
Step 130825: loss = 0.05946
Step 130830: loss = 0.15440
Step 130835: loss = 0.17022
Step 130840: loss = 0.22495
Step 130845: loss = 0.03140
Step 130850: loss = 0.11994
Step 130855: loss = 0.32416
Step 130860: loss = 0.07863
Step 130865: loss = 0.15874
Step 130870: loss = 0.10299
Step 130875: loss = 0.11264
Step 130880: loss = 0.07128
Step 130885: loss = 0.27579
Step 130890: loss = 0.21173
Step 130895: loss = 0.31693
Step 130900: loss = 0.10323
Step 130905: loss = 0.14111
Step 130910: loss = 0.13703
Step 130915: loss = 0.35446
Step 130920: loss = 0.17279
Step 130925: loss = 0.15197
Step 130930: loss = 0.21180
Step 130935: loss = 0.20334
Step 130940: loss = 0.10827
Step 130945: loss = 0.12247
Step 130950: loss = 0.24446
Step 130955: loss = 0.09351
Step 130960: loss = 0.20043
Step 130965: loss = 0.25431
Step 130970: loss = 0.17104
Step 130975: loss = 0.11284
Step 130980: loss = 0.08187
Step 130985: loss = 0.14323
Step 130990: loss = 0.33793
Step 130995: loss = 0.04554
Step 131000: loss = 0.08029
Training Data Eval:
  Num examples: 50000, Num correct: 47579, Precision @ 1: 0.9516
('Testing Data Eval: EPOCH->', 132)
  Num examples: 10000, Num correct: 6710, Precision @ 1: 0.6710
Step 131005: loss = 0.07666
Step 131010: loss = 0.26155
Step 131015: loss = 0.27691
Step 131020: loss = 0.04084
Step 131025: loss = 0.11379
Step 131030: loss = 0.10902
Step 131035: loss = 0.09144
Step 131040: loss = 0.03996
Step 131045: loss = 0.07024
Step 131050: loss = 0.09055
Step 131055: loss = 0.08426
Step 131060: loss = 0.02731
Step 131065: loss = 0.21544
Step 131070: loss = 0.12199
Step 131075: loss = 0.07429
Step 131080: loss = 0.29343
Step 131085: loss = 0.17874
Step 131090: loss = 0.06554
Step 131095: loss = 0.10569
Step 131100: loss = 0.09922
Step 131105: loss = 0.02564
Step 131110: loss = 0.12584
Step 131115: loss = 0.15318
Step 131120: loss = 0.10107
Step 131125: loss = 0.02899
Step 131130: loss = 0.07273
Step 131135: loss = 0.13384
Step 131140: loss = 0.15029
Step 131145: loss = 0.15285
Step 131150: loss = 0.20268
Step 131155: loss = 0.42338
Step 131160: loss = 0.11385
Step 131165: loss = 0.03680
Step 131170: loss = 0.53562
Step 131175: loss = 0.05417
Step 131180: loss = 0.02944
Step 131185: loss = 0.04367
Step 131190: loss = 0.10645
Step 131195: loss = 0.41045
Step 131200: loss = 0.04550
Step 131205: loss = 0.05935
Step 131210: loss = 0.10332
Step 131215: loss = 0.36814
Step 131220: loss = 0.09777
Step 131225: loss = 0.11970
Step 131230: loss = 0.08439
Step 131235: loss = 0.09019
Step 131240: loss = 0.17389
Step 131245: loss = 0.12460
Step 131250: loss = 0.11891
Step 131255: loss = 0.14346
Step 131260: loss = 0.18462
Step 131265: loss = 0.04972
Step 131270: loss = 0.17014
Step 131275: loss = 0.08271
Step 131280: loss = 0.06911
Step 131285: loss = 0.10789
Step 131290: loss = 0.39053
Step 131295: loss = 0.05720
Step 131300: loss = 0.37400
Step 131305: loss = 0.18559
Step 131310: loss = 0.11481
Step 131315: loss = 0.07519
Step 131320: loss = 0.40636
Step 131325: loss = 0.08894
Step 131330: loss = 0.07406
Step 131335: loss = 0.08639
Step 131340: loss = 0.20858
Step 131345: loss = 0.05307
Step 131350: loss = 0.20144
Step 131355: loss = 0.11988
Step 131360: loss = 0.18674
Step 131365: loss = 0.12727
Step 131370: loss = 0.06615
Step 131375: loss = 0.17469
Step 131380: loss = 0.11871
Step 131385: loss = 0.11943
Step 131390: loss = 0.09304
Step 131395: loss = 0.11724
Step 131400: loss = 0.12175
Step 131405: loss = 0.10598
Step 131410: loss = 0.09444
Step 131415: loss = 0.16367
Step 131420: loss = 0.06298
Step 131425: loss = 0.18346
Step 131430: loss = 0.36296
Step 131435: loss = 0.24224
Step 131440: loss = 0.05848
Step 131445: loss = 0.19415
Step 131450: loss = 0.04909
Step 131455: loss = 0.19695
Step 131460: loss = 0.02190
Step 131465: loss = 0.13325
Step 131470: loss = 0.09421
Step 131475: loss = 0.25910
Step 131480: loss = 0.42079
Step 131485: loss = 0.02705
Step 131490: loss = 0.22690
Step 131495: loss = 0.05441
Step 131500: loss = 0.10373
Step 131505: loss = 0.07034
Step 131510: loss = 0.10906
Step 131515: loss = 0.13182
Step 131520: loss = 0.25382
Step 131525: loss = 0.16027
Step 131530: loss = 0.05873
Step 131535: loss = 0.11080
Step 131540: loss = 0.06422
Step 131545: loss = 0.08850
Step 131550: loss = 0.35910
Step 131555: loss = 0.07815
Step 131560: loss = 0.11217
Step 131565: loss = 0.12225
Step 131570: loss = 0.06759
Step 131575: loss = 0.15932
Step 131580: loss = 0.04302
Step 131585: loss = 0.15715
Step 131590: loss = 0.27559
Step 131595: loss = 0.07798
Step 131600: loss = 0.16248
Step 131605: loss = 0.16821
Step 131610: loss = 0.10366
Step 131615: loss = 0.12497
Step 131620: loss = 0.38210
Step 131625: loss = 0.10522
Step 131630: loss = 0.23470
Step 131635: loss = 0.47607
Step 131640: loss = 0.18956
Step 131645: loss = 0.14812
Step 131650: loss = 0.02826
Step 131655: loss = 0.15511
Step 131660: loss = 0.07926
Step 131665: loss = 0.14022
Step 131670: loss = 0.08435
Step 131675: loss = 0.08957
Step 131680: loss = 0.17152
Step 131685: loss = 0.18931
Step 131690: loss = 0.15073
Step 131695: loss = 0.09960
Step 131700: loss = 0.02572
Step 131705: loss = 0.18127
Step 131710: loss = 0.12158
Step 131715: loss = 0.24412
Step 131720: loss = 0.09429
Step 131725: loss = 0.08059
Step 131730: loss = 0.13915
Step 131735: loss = 0.25627
Step 131740: loss = 0.07823
Step 131745: loss = 0.03035
Step 131750: loss = 0.14270
Step 131755: loss = 0.34392
Step 131760: loss = 0.18328
Step 131765: loss = 0.10539
Step 131770: loss = 0.08312
Step 131775: loss = 0.40185
Step 131780: loss = 0.10925
Step 131785: loss = 0.07820
Step 131790: loss = 0.30807
Step 131795: loss = 0.14163
Step 131800: loss = 0.17903
Step 131805: loss = 0.06166
Step 131810: loss = 0.26025
Step 131815: loss = 0.04948
Step 131820: loss = 0.10742
Step 131825: loss = 0.22969
Step 131830: loss = 0.16441
Step 131835: loss = 0.09993
Step 131840: loss = 0.14330
Step 131845: loss = 0.20830
Step 131850: loss = 0.08451
Step 131855: loss = 0.08520
Step 131860: loss = 0.11623
Step 131865: loss = 0.12009
Step 131870: loss = 0.06534
Step 131875: loss = 0.34906
Step 131880: loss = 0.07788
Step 131885: loss = 0.06600
Step 131890: loss = 0.06139
Step 131895: loss = 0.10371
Step 131900: loss = 0.21350
Step 131905: loss = 0.08290
Step 131910: loss = 0.19737
Step 131915: loss = 0.24845
Step 131920: loss = 0.09304
Step 131925: loss = 0.28706
Step 131930: loss = 0.12436
Step 131935: loss = 0.35306
Step 131940: loss = 0.12558
Step 131945: loss = 0.06259
Step 131950: loss = 0.25065
Step 131955: loss = 0.06868
Step 131960: loss = 0.07797
Step 131965: loss = 0.15589
Step 131970: loss = 0.08298
Step 131975: loss = 0.13324
Step 131980: loss = 0.15682
Step 131985: loss = 0.04626
Step 131990: loss = 0.07997
Step 131995: loss = 0.10473
Step 132000: loss = 0.11384
Training Data Eval:
  Num examples: 50000, Num correct: 47414, Precision @ 1: 0.9483
('Testing Data Eval: EPOCH->', 133)
  Num examples: 10000, Num correct: 6587, Precision @ 1: 0.6587
Step 132005: loss = 0.08122
Step 132010: loss = 0.07369
Step 132015: loss = 0.09301
Step 132020: loss = 0.05653
Step 132025: loss = 0.08105
Step 132030: loss = 0.36703
Step 132035: loss = 0.28578
Step 132040: loss = 0.29122
Step 132045: loss = 0.20186
Step 132050: loss = 0.17862
Step 132055: loss = 0.12578
Step 132060: loss = 0.11485
Step 132065: loss = 0.14764
Step 132070: loss = 0.06518
Step 132075: loss = 0.10749
Step 132080: loss = 0.08495
Step 132085: loss = 0.67587
Step 132090: loss = 0.07014
Step 132095: loss = 0.12548
Step 132100: loss = 0.09183
Step 132105: loss = 0.23765
Step 132110: loss = 0.10136
Step 132115: loss = 0.25006
Step 132120: loss = 0.20386
Step 132125: loss = 0.02211
Step 132130: loss = 0.14378
Step 132135: loss = 0.14874
Step 132140: loss = 0.17597
Step 132145: loss = 0.14451
Step 132150: loss = 0.05208
Step 132155: loss = 0.09951
Step 132160: loss = 0.33638
Step 132165: loss = 0.23750
Step 132170: loss = 0.22530
Step 132175: loss = 0.18028
Step 132180: loss = 0.15821
Step 132185: loss = 0.11321
Step 132190: loss = 0.08175
Step 132195: loss = 0.19740
Step 132200: loss = 0.24149
Step 132205: loss = 0.24763
Step 132210: loss = 0.07087
Step 132215: loss = 0.09537
Step 132220: loss = 0.07287
Step 132225: loss = 0.06277
Step 132230: loss = 0.12239
Step 132235: loss = 0.23046
Step 132240: loss = 0.16068
Step 132245: loss = 0.36927
Step 132250: loss = 0.21112
Step 132255: loss = 0.14057
Step 132260: loss = 0.07639
Step 132265: loss = 0.07179
Step 132270: loss = 0.14524
Step 132275: loss = 0.12290
Step 132280: loss = 0.09104
Step 132285: loss = 0.06003
Step 132290: loss = 0.10580
Step 132295: loss = 0.11249
Step 132300: loss = 0.05022
Step 132305: loss = 0.11025
Step 132310: loss = 0.10103
Step 132315: loss = 0.15170
Step 132320: loss = 0.15556
Step 132325: loss = 0.15854
Step 132330: loss = 0.08921
Step 132335: loss = 0.08512
Step 132340: loss = 0.17390
Step 132345: loss = 0.05256
Step 132350: loss = 0.10234
Step 132355: loss = 0.15327
Step 132360: loss = 0.06961
Step 132365: loss = 0.33689
Step 132370: loss = 0.22767
Step 132375: loss = 0.07711
Step 132380: loss = 0.05184
Step 132385: loss = 0.07336
Step 132390: loss = 0.12398
Step 132395: loss = 0.05618
Step 132400: loss = 0.25600
Step 132405: loss = 0.04238
Step 132410: loss = 0.16075
Step 132415: loss = 0.03553
Step 132420: loss = 0.27694
Step 132425: loss = 0.05457
Step 132430: loss = 0.16638
Step 132435: loss = 0.04237
Step 132440: loss = 0.26236
Step 132445: loss = 0.03583
Step 132450: loss = 0.04635
Step 132455: loss = 0.16538
Step 132460: loss = 0.32943
Step 132465: loss = 0.20195
Step 132470: loss = 0.17582
Step 132475: loss = 0.06202
Step 132480: loss = 0.10740
Step 132485: loss = 0.24617
Step 132490: loss = 0.26223
Step 132495: loss = 0.05940
Step 132500: loss = 0.30953
Step 132505: loss = 0.15187
Step 132510: loss = 0.19878
Step 132515: loss = 0.05566
Step 132520: loss = 0.07726
Step 132525: loss = 0.14814
Step 132530: loss = 0.13341
Step 132535: loss = 0.21903
Step 132540: loss = 0.18076
Step 132545: loss = 0.28966
Step 132550: loss = 0.13952
Step 132555: loss = 0.09392
Step 132560: loss = 0.12461
Step 132565: loss = 0.22439
Step 132570: loss = 0.08492
Step 132575: loss = 0.23540
Step 132580: loss = 0.10920
Step 132585: loss = 0.16280
Step 132590: loss = 0.22755
Step 132595: loss = 0.04547
Step 132600: loss = 0.31048
Step 132605: loss = 0.09164
Step 132610: loss = 0.06674
Step 132615: loss = 0.12845
Step 132620: loss = 0.40540
Step 132625: loss = 0.16285
Step 132630: loss = 0.09579
Step 132635: loss = 0.31275
Step 132640: loss = 0.30309
Step 132645: loss = 0.06651
Step 132650: loss = 0.23038
Step 132655: loss = 0.06994
Step 132660: loss = 0.07912
Step 132665: loss = 0.05104
Step 132670: loss = 0.07802
Step 132675: loss = 0.53420
Step 132680: loss = 0.17722
Step 132685: loss = 0.20187
Step 132690: loss = 0.12747
Step 132695: loss = 0.07244
Step 132700: loss = 0.36373
Step 132705: loss = 0.10730
Step 132710: loss = 0.27538
Step 132715: loss = 0.08459
Step 132720: loss = 0.09505
Step 132725: loss = 0.15497
Step 132730: loss = 0.07458
Step 132735: loss = 0.19702
Step 132740: loss = 0.06235
Step 132745: loss = 0.13896
Step 132750: loss = 0.13305
Step 132755: loss = 0.23961
Step 132760: loss = 0.08111
Step 132765: loss = 0.20402
Step 132770: loss = 0.06763
Step 132775: loss = 0.03909
Step 132780: loss = 0.07393
Step 132785: loss = 0.10189
Step 132790: loss = 0.06889
Step 132795: loss = 0.13094
Step 132800: loss = 0.05417
Step 132805: loss = 0.22399
Step 132810: loss = 0.07935
Step 132815: loss = 0.13908
Step 132820: loss = 0.07384
Step 132825: loss = 0.07258
Step 132830: loss = 0.21633
Step 132835: loss = 0.14102
Step 132840: loss = 0.16366
Step 132845: loss = 0.04034
Step 132850: loss = 0.05730
Step 132855: loss = 0.29651
Step 132860: loss = 0.09338
Step 132865: loss = 0.03973
Step 132870: loss = 0.06595
Step 132875: loss = 0.13563
Step 132880: loss = 0.10452
Step 132885: loss = 0.07629
Step 132890: loss = 0.07712
Step 132895: loss = 0.06946
Step 132900: loss = 0.12296
Step 132905: loss = 0.04178
Step 132910: loss = 0.39227
Step 132915: loss = 0.07704
Step 132920: loss = 0.10659
Step 132925: loss = 0.21613
Step 132930: loss = 0.19109
Step 132935: loss = 0.14728
Step 132940: loss = 0.07507
Step 132945: loss = 0.20038
Step 132950: loss = 0.05298
Step 132955: loss = 0.06669
Step 132960: loss = 0.45860
Step 132965: loss = 0.18158
Step 132970: loss = 0.13553
Step 132975: loss = 0.05306
Step 132980: loss = 0.12723
Step 132985: loss = 0.15993
Step 132990: loss = 0.08000
Step 132995: loss = 0.22736
Step 133000: loss = 0.13620
Training Data Eval:
  Num examples: 50000, Num correct: 47396, Precision @ 1: 0.9479
('Testing Data Eval: EPOCH->', 134)
  Num examples: 10000, Num correct: 6614, Precision @ 1: 0.6614
Step 133005: loss = 0.23656
Step 133010: loss = 0.16745
Step 133015: loss = 0.05764
Step 133020: loss = 0.19871
Step 133025: loss = 0.25025
Step 133030: loss = 0.13543
Step 133035: loss = 0.07935
Step 133040: loss = 0.16398
Step 133045: loss = 0.10073
Step 133050: loss = 0.19331
Step 133055: loss = 0.12892
Step 133060: loss = 0.14201
Step 133065: loss = 0.04672
Step 133070: loss = 0.12743
Step 133075: loss = 0.22228
Step 133080: loss = 0.23954
Step 133085: loss = 0.10317
Step 133090: loss = 0.13676
Step 133095: loss = 0.12867
Step 133100: loss = 0.05942
Step 133105: loss = 0.13427
Step 133110: loss = 0.13461
Step 133115: loss = 0.12854
Step 133120: loss = 0.11995
Step 133125: loss = 0.07910
Step 133130: loss = 0.05212
Step 133135: loss = 0.20180
Step 133140: loss = 0.24422
Step 133145: loss = 0.05500
Step 133150: loss = 0.10222
Step 133155: loss = 0.14532
Step 133160: loss = 0.16915
Step 133165: loss = 0.22195
Step 133170: loss = 0.28163
Step 133175: loss = 0.19576
Step 133180: loss = 0.21554
Step 133185: loss = 0.15783
Step 133190: loss = 0.12575
Step 133195: loss = 0.09951
Step 133200: loss = 0.06628
Step 133205: loss = 0.14535
Step 133210: loss = 0.11328
Step 133215: loss = 0.12558
Step 133220: loss = 0.03452
Step 133225: loss = 0.04850
Step 133230: loss = 0.06153
Step 133235: loss = 0.06464
Step 133240: loss = 0.13435
Step 133245: loss = 0.09182
Step 133250: loss = 0.02712
Step 133255: loss = 0.23653
Step 133260: loss = 0.11132
Step 133265: loss = 0.07550
Step 133270: loss = 0.15716
Step 133275: loss = 0.19218
Step 133280: loss = 0.09127
Step 133285: loss = 0.24859
Step 133290: loss = 0.09263
Step 133295: loss = 0.15166
Step 133300: loss = 0.23245
Step 133305: loss = 0.27542
Step 133310: loss = 0.25449
Step 133315: loss = 0.09587
Step 133320: loss = 0.05865
Step 133325: loss = 0.20250
Step 133330: loss = 0.05266
Step 133335: loss = 0.04758
Step 133340: loss = 0.22161
Step 133345: loss = 0.16267
Step 133350: loss = 0.09196
Step 133355: loss = 0.06621
Step 133360: loss = 0.39595
Step 133365: loss = 0.03249
Step 133370: loss = 0.06381
Step 133375: loss = 0.07010
Step 133380: loss = 0.32686
Step 133385: loss = 0.10281
Step 133390: loss = 0.11336
Step 133395: loss = 0.20389
Step 133400: loss = 0.34810
Step 133405: loss = 0.16972
Step 133410: loss = 0.13568
Step 133415: loss = 0.15020
Step 133420: loss = 0.05143
Step 133425: loss = 0.18580
Step 133430: loss = 0.22557
Step 133435: loss = 0.06623
Step 133440: loss = 0.10855
Step 133445: loss = 0.16071
Step 133450: loss = 0.21012
Step 133455: loss = 0.20852
Step 133460: loss = 0.10687
Step 133465: loss = 0.03730
Step 133470: loss = 0.29260
Step 133475: loss = 0.04878
Step 133480: loss = 0.14241
Step 133485: loss = 0.04776
Step 133490: loss = 0.07468
Step 133495: loss = 0.12203
Step 133500: loss = 0.16458
Step 133505: loss = 0.04743
Step 133510: loss = 0.18313
Step 133515: loss = 0.05340
Step 133520: loss = 0.06426
Step 133525: loss = 0.30988
Step 133530: loss = 0.18660
Step 133535: loss = 0.14685
Step 133540: loss = 0.12033
Step 133545: loss = 0.26286
Step 133550: loss = 0.24538
Step 133555: loss = 0.12004
Step 133560: loss = 0.11434
Step 133565: loss = 0.12433
Step 133570: loss = 0.05575
Step 133575: loss = 0.05794
Step 133580: loss = 0.09133
Step 133585: loss = 0.12174
Step 133590: loss = 0.15045
Step 133595: loss = 0.27658
Step 133600: loss = 0.36323
Step 133605: loss = 0.10177
Step 133610: loss = 0.11916
Step 133615: loss = 0.07597
Step 133620: loss = 0.04650
Step 133625: loss = 0.19262
Step 133630: loss = 0.11936
Step 133635: loss = 0.17218
Step 133640: loss = 0.02937
Step 133645: loss = 0.16397
Step 133650: loss = 0.06689
Step 133655: loss = 0.22383
Step 133660: loss = 0.14033
Step 133665: loss = 0.06640
Step 133670: loss = 0.18853
Step 133675: loss = 0.35627
Step 133680: loss = 0.03685
Step 133685: loss = 0.13811
Step 133690: loss = 0.16174
Step 133695: loss = 0.09416
Step 133700: loss = 0.23501
Step 133705: loss = 0.05979
Step 133710: loss = 0.21028
Step 133715: loss = 0.07828
Step 133720: loss = 0.06195
Step 133725: loss = 0.14168
Step 133730: loss = 0.14221
Step 133735: loss = 0.08130
Step 133740: loss = 0.07779
Step 133745: loss = 0.20574
Step 133750: loss = 0.25096
Step 133755: loss = 0.06421
Step 133760: loss = 0.06994
Step 133765: loss = 0.11779
Step 133770: loss = 0.02160
Step 133775: loss = 0.16488
Step 133780: loss = 0.13980
Step 133785: loss = 0.14975
Step 133790: loss = 0.12592
Step 133795: loss = 0.07255
Step 133800: loss = 0.26004
Step 133805: loss = 0.17061
Step 133810: loss = 0.11894
Step 133815: loss = 0.14793
Step 133820: loss = 0.13631
Step 133825: loss = 0.07220
Step 133830: loss = 0.02634
Step 133835: loss = 0.25631
Step 133840: loss = 0.06976
Step 133845: loss = 0.04230
Step 133850: loss = 0.21185
Step 133855: loss = 0.18744
Step 133860: loss = 0.10990
Step 133865: loss = 0.07413
Step 133870: loss = 0.13416
Step 133875: loss = 0.19159
Step 133880: loss = 0.06539
Step 133885: loss = 0.02635
Step 133890: loss = 0.21615
Step 133895: loss = 0.06694
Step 133900: loss = 0.05570
Step 133905: loss = 0.10022
Step 133910: loss = 0.32989
Step 133915: loss = 0.21478
Step 133920: loss = 0.21091
Step 133925: loss = 0.12756
Step 133930: loss = 0.39345
Step 133935: loss = 0.20443
Step 133940: loss = 0.05335
Step 133945: loss = 0.08440
Step 133950: loss = 0.08063
Step 133955: loss = 0.33702
Step 133960: loss = 0.17857
Step 133965: loss = 0.14083
Step 133970: loss = 0.13504
Step 133975: loss = 0.09294
Step 133980: loss = 0.08310
Step 133985: loss = 0.17985
Step 133990: loss = 0.19040
Step 133995: loss = 0.11710
Step 134000: loss = 0.13043
Training Data Eval:
  Num examples: 50000, Num correct: 47833, Precision @ 1: 0.9567
('Testing Data Eval: EPOCH->', 135)
  Num examples: 10000, Num correct: 6687, Precision @ 1: 0.6687
Step 134005: loss = 0.08369
Step 134010: loss = 0.34521
Step 134015: loss = 0.07093
Step 134020: loss = 0.08220
Step 134025: loss = 0.09121
Step 134030: loss = 0.02532
Step 134035: loss = 0.02550
Step 134040: loss = 0.13780
Step 134045: loss = 0.18236
Step 134050: loss = 0.03663
Step 134055: loss = 0.23877
Step 134060: loss = 0.20181
Step 134065: loss = 0.12676
Step 134070: loss = 0.02418
Step 134075: loss = 0.17803
Step 134080: loss = 0.04963
Step 134085: loss = 0.13877
Step 134090: loss = 0.16744
Step 134095: loss = 0.04255
Step 134100: loss = 0.18786
Step 134105: loss = 0.26292
Step 134110: loss = 0.09346
Step 134115: loss = 0.12084
Step 134120: loss = 0.10035
Step 134125: loss = 0.27704
Step 134130: loss = 0.16390
Step 134135: loss = 0.03349
Step 134140: loss = 0.10284
Step 134145: loss = 0.16716
Step 134150: loss = 0.10661
Step 134155: loss = 0.06031
Step 134160: loss = 0.26853
Step 134165: loss = 0.10526
Step 134170: loss = 0.07018
Step 134175: loss = 0.14756
Step 134180: loss = 0.14852
Step 134185: loss = 0.03175
Step 134190: loss = 0.08241
Step 134195: loss = 0.21793
Step 134200: loss = 0.13552
Step 134205: loss = 0.19383
Step 134210: loss = 0.04964
Step 134215: loss = 0.11431
Step 134220: loss = 0.04866
Step 134225: loss = 0.10397
Step 134230: loss = 0.14549
Step 134235: loss = 0.16436
Step 134240: loss = 0.06774
Step 134245: loss = 0.11375
Step 134250: loss = 0.13857
Step 134255: loss = 0.05379
Step 134260: loss = 0.06847
Step 134265: loss = 0.05592
Step 134270: loss = 0.05773
Step 134275: loss = 0.15180
Step 134280: loss = 0.05353
Step 134285: loss = 0.06034
Step 134290: loss = 0.13234
Step 134295: loss = 0.11339
Step 134300: loss = 0.19780
Step 134305: loss = 0.14124
Step 134310: loss = 0.05381
Step 134315: loss = 0.19310
Step 134320: loss = 0.08555
Step 134325: loss = 0.09127
Step 134330: loss = 0.19105
Step 134335: loss = 0.06211
Step 134340: loss = 0.09363
Step 134345: loss = 0.12133
Step 134350: loss = 0.28844
Step 134355: loss = 0.21090
Step 134360: loss = 0.20184
Step 134365: loss = 0.06586
Step 134370: loss = 0.07041
Step 134375: loss = 0.04642
Step 134380: loss = 0.23392
Step 134385: loss = 0.17200
Step 134390: loss = 0.23367
Step 134395: loss = 0.09807
Step 134400: loss = 0.25237
Step 134405: loss = 0.05550
Step 134410: loss = 0.04846
Step 134415: loss = 0.54865
Step 134420: loss = 0.15067
Step 134425: loss = 0.08722
Step 134430: loss = 0.20630
Step 134435: loss = 0.34415
Step 134440: loss = 0.10168
Step 134445: loss = 0.07463
Step 134450: loss = 0.11164
Step 134455: loss = 0.07289
Step 134460: loss = 0.13350
Step 134465: loss = 0.06606
Step 134470: loss = 0.08255
Step 134475: loss = 0.20025
Step 134480: loss = 0.25297
Step 134485: loss = 0.11947
Step 134490: loss = 0.20722
Step 134495: loss = 0.14138
Step 134500: loss = 0.13965
Step 134505: loss = 0.18048
Step 134510: loss = 0.13530
Step 134515: loss = 0.08637
Step 134520: loss = 0.26998
Step 134525: loss = 0.08343
Step 134530: loss = 0.10404
Step 134535: loss = 0.27362
Step 134540: loss = 0.17527
Step 134545: loss = 0.15617
Step 134550: loss = 0.33003
Step 134555: loss = 0.15880
Step 134560: loss = 0.12806
Step 134565: loss = 0.13900
Step 134570: loss = 0.33696
Step 134575: loss = 0.17964
Step 134580: loss = 0.05932
Step 134585: loss = 0.09246
Step 134590: loss = 0.07893
Step 134595: loss = 0.04181
Step 134600: loss = 0.03503
Step 134605: loss = 0.14701
Step 134610: loss = 0.11792
Step 134615: loss = 0.06781
Step 134620: loss = 0.09646
Step 134625: loss = 0.16807
Step 134630: loss = 0.06352
Step 134635: loss = 0.05070
Step 134640: loss = 0.04070
Step 134645: loss = 0.06681
Step 134650: loss = 0.14950
Step 134655: loss = 0.16542
Step 134660: loss = 0.14880
Step 134665: loss = 0.14939
Step 134670: loss = 0.09168
Step 134675: loss = 0.08666
Step 134680: loss = 0.26130
Step 134685: loss = 0.27668
Step 134690: loss = 0.29331
Step 134695: loss = 0.10097
Step 134700: loss = 0.12995
Step 134705: loss = 0.22207
Step 134710: loss = 0.13684
Step 134715: loss = 0.08620
Step 134720: loss = 0.08178
Step 134725: loss = 0.22515
Step 134730: loss = 0.24745
Step 134735: loss = 0.11118
Step 134740: loss = 0.18092
Step 134745: loss = 0.14657
Step 134750: loss = 0.12583
Step 134755: loss = 0.07231
Step 134760: loss = 0.08682
Step 134765: loss = 0.03021
Step 134770: loss = 0.15638
Step 134775: loss = 0.21336
Step 134780: loss = 0.10075
Step 134785: loss = 0.08719
Step 134790: loss = 0.10212
Step 134795: loss = 0.11677
Step 134800: loss = 0.12464
Step 134805: loss = 0.08171
Step 134810: loss = 0.07183
Step 134815: loss = 0.11685
Step 134820: loss = 0.22382
Step 134825: loss = 0.21600
Step 134830: loss = 0.12331
Step 134835: loss = 0.26308
Step 134840: loss = 0.10242
Step 134845: loss = 0.24464
Step 134850: loss = 0.08219
Step 134855: loss = 0.14293
Step 134860: loss = 0.20841
Step 134865: loss = 0.31958
Step 134870: loss = 0.28786
Step 134875: loss = 0.12025
Step 134880: loss = 0.20879
Step 134885: loss = 0.04079
Step 134890: loss = 0.09260
Step 134895: loss = 0.38506
Step 134900: loss = 0.17621
Step 134905: loss = 0.08292
Step 134910: loss = 0.35796
Step 134915: loss = 0.16092
Step 134920: loss = 0.24660
Step 134925: loss = 0.09536
Step 134930: loss = 0.12783
Step 134935: loss = 0.12737
Step 134940: loss = 0.10835
Step 134945: loss = 0.38887
Step 134950: loss = 0.18582
Step 134955: loss = 0.04473
Step 134960: loss = 0.18665
Step 134965: loss = 0.13198
Step 134970: loss = 0.12103
Step 134975: loss = 0.19482
Step 134980: loss = 0.05819
Step 134985: loss = 0.15630
Step 134990: loss = 0.15027
Step 134995: loss = 0.14356
Step 135000: loss = 0.15504
Training Data Eval:
  Num examples: 50000, Num correct: 47649, Precision @ 1: 0.9530
('Testing Data Eval: EPOCH->', 136)
  Num examples: 10000, Num correct: 6741, Precision @ 1: 0.6741
Step 135005: loss = 0.10775
Step 135010: loss = 0.12919
Step 135015: loss = 0.17821
Step 135020: loss = 0.26808
Step 135025: loss = 0.13930
Step 135030: loss = 0.07774
Step 135035: loss = 0.07729
Step 135040: loss = 0.08997
Step 135045: loss = 0.11247
Step 135050: loss = 0.14771
Step 135055: loss = 0.10937
Step 135060: loss = 0.10777
Step 135065: loss = 0.17648
Step 135070: loss = 0.35144
Step 135075: loss = 0.04775
Step 135080: loss = 0.06797
Step 135085: loss = 0.04751
Step 135090: loss = 0.16121
Step 135095: loss = 0.07558
Step 135100: loss = 0.03424
Step 135105: loss = 0.12487
Step 135110: loss = 0.23139
Step 135115: loss = 0.18441
Step 135120: loss = 0.19218
Step 135125: loss = 0.05961
Step 135130: loss = 0.14430
Step 135135: loss = 0.20632
Step 135140: loss = 0.08075
Step 135145: loss = 0.08952
Step 135150: loss = 0.08510
Step 135155: loss = 0.08735
Step 135160: loss = 0.21246
Step 135165: loss = 0.06209
Step 135170: loss = 0.11929
Step 135175: loss = 0.02352
Step 135180: loss = 0.09068
Step 135185: loss = 0.04655
Step 135190: loss = 0.18609
Step 135195: loss = 0.03157
Step 135200: loss = 0.14206
Step 135205: loss = 0.45534
Step 135210: loss = 0.16661
Step 135215: loss = 0.18346
Step 135220: loss = 0.22400
Step 135225: loss = 0.13765
Step 135230: loss = 0.08409
Step 135235: loss = 0.06113
Step 135240: loss = 0.11083
Step 135245: loss = 0.09498
Step 135250: loss = 0.16269
Step 135255: loss = 0.21535
Step 135260: loss = 0.06587
Step 135265: loss = 0.16009
Step 135270: loss = 0.07044
Step 135275: loss = 0.29981
Step 135280: loss = 0.22198
Step 135285: loss = 0.13655
Step 135290: loss = 0.30313
Step 135295: loss = 0.13755
Step 135300: loss = 0.37386
Step 135305: loss = 0.14056
Step 135310: loss = 0.28725
Step 135315: loss = 0.20837
Step 135320: loss = 0.04732
Step 135325: loss = 0.31314
Step 135330: loss = 0.16231
Step 135335: loss = 0.31384
Step 135340: loss = 0.29589
Step 135345: loss = 0.16675
Step 135350: loss = 0.08370
Step 135355: loss = 0.07312
Step 135360: loss = 0.14777
Step 135365: loss = 0.10589
Step 135370: loss = 0.10418
Step 135375: loss = 0.26205
Step 135380: loss = 0.05935
Step 135385: loss = 0.38363
Step 135390: loss = 0.21678
Step 135395: loss = 0.02610
Step 135400: loss = 0.01251
Step 135405: loss = 0.15859
Step 135410: loss = 0.12703
Step 135415: loss = 0.04613
Step 135420: loss = 0.23374
Step 135425: loss = 0.46277
Step 135430: loss = 0.13514
Step 135435: loss = 0.06620
Step 135440: loss = 0.22176
Step 135445: loss = 0.10430
Step 135450: loss = 0.25417
Step 135455: loss = 0.29408
Step 135460: loss = 0.13278
Step 135465: loss = 0.29365
Step 135470: loss = 0.13554
Step 135475: loss = 0.07604
Step 135480: loss = 0.29346
Step 135485: loss = 0.11611
Step 135490: loss = 0.05442
Step 135495: loss = 0.11946
Step 135500: loss = 0.09072
Step 135505: loss = 0.14355
Step 135510: loss = 0.06726
Step 135515: loss = 0.22441
Step 135520: loss = 0.03303
Step 135525: loss = 0.06649
Step 135530: loss = 0.13014
Step 135535: loss = 0.19814
Step 135540: loss = 0.10474
Step 135545: loss = 0.13574
Step 135550: loss = 0.30634
Step 135555: loss = 0.10077
Step 135560: loss = 0.05789
Step 135565: loss = 0.14668
Step 135570: loss = 0.25136
Step 135575: loss = 0.22914
Step 135580: loss = 0.09577
Step 135585: loss = 0.07603
Step 135590: loss = 0.03723
Step 135595: loss = 0.02212
Step 135600: loss = 0.22210
Step 135605: loss = 0.09217
Step 135610: loss = 0.03652
Step 135615: loss = 0.07717
Step 135620: loss = 0.06582
Step 135625: loss = 0.05839
Step 135630: loss = 0.13549
Step 135635: loss = 0.29975
Step 135640: loss = 0.14214
Step 135645: loss = 0.11053
Step 135650: loss = 0.19056
Step 135655: loss = 0.12747
Step 135660: loss = 0.14748
Step 135665: loss = 0.18925
Step 135670: loss = 0.06034
Step 135675: loss = 0.10562
Step 135680: loss = 0.07821
Step 135685: loss = 0.20338
Step 135690: loss = 0.10156
Step 135695: loss = 0.15981
Step 135700: loss = 0.08028
Step 135705: loss = 0.18627
Step 135710: loss = 0.39199
Step 135715: loss = 0.14698
Step 135720: loss = 0.21492
Step 135725: loss = 0.10358
Step 135730: loss = 0.14431
Step 135735: loss = 0.09706
Step 135740: loss = 0.07438
Step 135745: loss = 0.24041
Step 135750: loss = 0.19708
Step 135755: loss = 0.26980
Step 135760: loss = 0.09114
Step 135765: loss = 0.04648
Step 135770: loss = 0.05352
Step 135775: loss = 0.08110
Step 135780: loss = 0.09803
Step 135785: loss = 0.05141
Step 135790: loss = 0.11681
Step 135795: loss = 0.06949
Step 135800: loss = 0.29528
Step 135805: loss = 0.12476
Step 135810: loss = 0.02960
Step 135815: loss = 0.07019
Step 135820: loss = 0.04506
Step 135825: loss = 0.08617
Step 135830: loss = 0.04830
Step 135835: loss = 0.08882
Step 135840: loss = 0.17268
Step 135845: loss = 0.06288
Step 135850: loss = 0.07048
Step 135855: loss = 0.07787
Step 135860: loss = 0.20654
Step 135865: loss = 0.05171
Step 135870: loss = 0.14528
Step 135875: loss = 0.04010
Step 135880: loss = 0.07596
Step 135885: loss = 0.13464
Step 135890: loss = 0.12037
Step 135895: loss = 0.11190
Step 135900: loss = 0.06962
Step 135905: loss = 0.37836
Step 135910: loss = 0.56874
Step 135915: loss = 0.11754
Step 135920: loss = 0.12812
Step 135925: loss = 0.04701
Step 135930: loss = 0.14460
Step 135935: loss = 0.23880
Step 135940: loss = 0.16895
Step 135945: loss = 0.11290
Step 135950: loss = 0.19847
Step 135955: loss = 0.09680
Step 135960: loss = 0.12843
Step 135965: loss = 0.05364
Step 135970: loss = 0.04862
Step 135975: loss = 0.07225
Step 135980: loss = 0.26280
Step 135985: loss = 0.22374
Step 135990: loss = 0.06838
Step 135995: loss = 0.24560
Step 136000: loss = 0.08218
Training Data Eval:
  Num examples: 50000, Num correct: 47583, Precision @ 1: 0.9517
('Testing Data Eval: EPOCH->', 137)
  Num examples: 10000, Num correct: 6652, Precision @ 1: 0.6652
Step 136005: loss = 0.08891
Step 136010: loss = 0.10899
Step 136015: loss = 0.04402
Step 136020: loss = 0.08781
Step 136025: loss = 0.24164
Step 136030: loss = 0.15356
Step 136035: loss = 0.26133
Step 136040: loss = 0.15195
Step 136045: loss = 0.09361
Step 136050: loss = 0.13248
Step 136055: loss = 0.09055
Step 136060: loss = 0.33363
Step 136065: loss = 0.17194
Step 136070: loss = 0.13494
Step 136075: loss = 0.14161
Step 136080: loss = 0.10517
Step 136085: loss = 0.16346
Step 136090: loss = 0.19506
Step 136095: loss = 0.08892
Step 136100: loss = 0.10055
Step 136105: loss = 0.04617
Step 136110: loss = 0.12947
Step 136115: loss = 0.29902
Step 136120: loss = 0.03186
Step 136125: loss = 0.07427
Step 136130: loss = 0.22104
Step 136135: loss = 0.23713
Step 136140: loss = 0.09769
Step 136145: loss = 0.09006
Step 136150: loss = 0.12747
Step 136155: loss = 0.15006
Step 136160: loss = 0.03918
Step 136165: loss = 0.07574
Step 136170: loss = 0.13591
Step 136175: loss = 0.23002
Step 136180: loss = 0.09193
Step 136185: loss = 0.07659
Step 136190: loss = 0.14760
Step 136195: loss = 0.22038
Step 136200: loss = 0.10713
Step 136205: loss = 0.18593
Step 136210: loss = 0.10559
Step 136215: loss = 0.12602
Step 136220: loss = 0.11614
Step 136225: loss = 0.19001
Step 136230: loss = 0.08125
Step 136235: loss = 0.04051
Step 136240: loss = 0.09381
Step 136245: loss = 0.06928
Step 136250: loss = 0.09499
Step 136255: loss = 0.19563
Step 136260: loss = 0.12436
Step 136265: loss = 0.12200
Step 136270: loss = 0.28623
Step 136275: loss = 0.14040
Step 136280: loss = 0.21155
Step 136285: loss = 0.11074
Step 136290: loss = 0.45902
Step 136295: loss = 0.19486
Step 136300: loss = 0.17608
Step 136305: loss = 0.13821
Step 136310: loss = 0.07872
Step 136315: loss = 0.28579
Step 136320: loss = 0.15866
Step 136325: loss = 0.18992
Step 136330: loss = 0.13503
Step 136335: loss = 0.07400
Step 136340: loss = 0.06570
Step 136345: loss = 0.11149
Step 136350: loss = 0.15633
Step 136355: loss = 0.24660
Step 136360: loss = 0.10804
Step 136365: loss = 0.15522
Step 136370: loss = 0.13946
Step 136375: loss = 0.26958
Step 136380: loss = 0.12809
Step 136385: loss = 0.17770
Step 136390: loss = 0.22857
Step 136395: loss = 0.21416
Step 136400: loss = 0.06538
Step 136405: loss = 0.17097
Step 136410: loss = 0.13131
Step 136415: loss = 0.28221
Step 136420: loss = 0.13354
Step 136425: loss = 0.24528
Step 136430: loss = 0.40447
Step 136435: loss = 0.19766
Step 136440: loss = 0.12169
Step 136445: loss = 0.24315
Step 136450: loss = 0.10184
Step 136455: loss = 0.19772
Step 136460: loss = 0.08010
Step 136465: loss = 0.31375
Step 136470: loss = 0.08351
Step 136475: loss = 0.28422
Step 136480: loss = 0.11947
Step 136485: loss = 0.10194
Step 136490: loss = 0.21211
Step 136495: loss = 0.24961
Step 136500: loss = 0.15561
Step 136505: loss = 0.05120
Step 136510: loss = 0.32504
Step 136515: loss = 0.11835
Step 136520: loss = 0.28031
Step 136525: loss = 0.06058
Step 136530: loss = 0.24701
Step 136535: loss = 0.11800
Step 136540: loss = 0.18647
Step 136545: loss = 0.05942
Step 136550: loss = 0.10947
Step 136555: loss = 0.16327
Step 136560: loss = 0.02986
Step 136565: loss = 0.07832
Step 136570: loss = 0.25432
Step 136575: loss = 0.23982
Step 136580: loss = 0.13623
Step 136585: loss = 0.22241
Step 136590: loss = 0.05433
Step 136595: loss = 0.03681
Step 136600: loss = 0.09098
Step 136605: loss = 0.12555
Step 136610: loss = 0.08436
Step 136615: loss = 0.08636
Step 136620: loss = 0.03838
Step 136625: loss = 0.07133
Step 136630: loss = 0.17903
Step 136635: loss = 0.11669
Step 136640: loss = 0.15071
Step 136645: loss = 0.15156
Step 136650: loss = 0.15005
Step 136655: loss = 0.10811
Step 136660: loss = 0.24310
Step 136665: loss = 0.07650
Step 136670: loss = 0.21619
Step 136675: loss = 0.20934
Step 136680: loss = 0.04177
Step 136685: loss = 0.14885
Step 136690: loss = 0.16298
Step 136695: loss = 0.08916
Step 136700: loss = 0.06154
Step 136705: loss = 0.26708
Step 136710: loss = 0.05634
Step 136715: loss = 0.16037
Step 136720: loss = 0.12804
Step 136725: loss = 0.11465
Step 136730: loss = 0.17249
Step 136735: loss = 0.18847
Step 136740: loss = 0.07592
Step 136745: loss = 0.12353
Step 136750: loss = 0.03197
Step 136755: loss = 0.04940
Step 136760: loss = 0.14940
Step 136765: loss = 0.04571
Step 136770: loss = 0.07861
Step 136775: loss = 0.15227
Step 136780: loss = 0.08663
Step 136785: loss = 0.07221
Step 136790: loss = 0.12318
Step 136795: loss = 0.12721
Step 136800: loss = 0.07922
Step 136805: loss = 0.07915
Step 136810: loss = 0.17376
Step 136815: loss = 0.11753
Step 136820: loss = 0.15370
Step 136825: loss = 0.26711
Step 136830: loss = 0.11387
Step 136835: loss = 0.13178
Step 136840: loss = 0.13463
Step 136845: loss = 0.09525
Step 136850: loss = 0.16952
Step 136855: loss = 0.12178
Step 136860: loss = 0.08663
Step 136865: loss = 0.05880
Step 136870: loss = 0.22664
Step 136875: loss = 0.04901
Step 136880: loss = 0.12776
Step 136885: loss = 0.27078
Step 136890: loss = 0.06570
Step 136895: loss = 0.22901
Step 136900: loss = 0.10192
Step 136905: loss = 0.18806
Step 136910: loss = 0.13327
Step 136915: loss = 0.06777
Step 136920: loss = 0.23853
Step 136925: loss = 0.08867
Step 136930: loss = 0.22567
Step 136935: loss = 0.18250
Step 136940: loss = 0.26884
Step 136945: loss = 0.17963
Step 136950: loss = 0.19803
Step 136955: loss = 0.09418
Step 136960: loss = 0.17362
Step 136965: loss = 0.12932
Step 136970: loss = 0.23143
Step 136975: loss = 0.16947
Step 136980: loss = 0.19983
Step 136985: loss = 0.13246
Step 136990: loss = 0.13691
Step 136995: loss = 0.21798
Step 137000: loss = 0.12236
Training Data Eval:
  Num examples: 50000, Num correct: 47618, Precision @ 1: 0.9524
('Testing Data Eval: EPOCH->', 138)
  Num examples: 10000, Num correct: 6609, Precision @ 1: 0.6609
Step 137005: loss = 0.03980
Step 137010: loss = 0.18705
Step 137015: loss = 0.17184
Step 137020: loss = 0.34451
Step 137025: loss = 0.17508
Step 137030: loss = 0.21259
Step 137035: loss = 0.06933
Step 137040: loss = 0.23717
Step 137045: loss = 0.13464
Step 137050: loss = 0.14183
Step 137055: loss = 0.09551
Step 137060: loss = 0.03919
Step 137065: loss = 0.14229
Step 137070: loss = 0.06374
Step 137075: loss = 0.09515
Step 137080: loss = 0.06669
Step 137085: loss = 0.09809
Step 137090: loss = 0.15945
Step 137095: loss = 0.05923
Step 137100: loss = 0.27500
Step 137105: loss = 0.07976
Step 137110: loss = 0.14913
Step 137115: loss = 0.04775
Step 137120: loss = 0.15459
Step 137125: loss = 0.11788
Step 137130: loss = 0.20263
Step 137135: loss = 0.12118
Step 137140: loss = 0.11368
Step 137145: loss = 0.13191
Step 137150: loss = 0.05852
Step 137155: loss = 0.17429
Step 137160: loss = 0.06418
Step 137165: loss = 0.07730
Step 137170: loss = 0.14032
Step 137175: loss = 0.11633
Step 137180: loss = 0.08507
Step 137185: loss = 0.12887
Step 137190: loss = 0.15097
Step 137195: loss = 0.26804
Step 137200: loss = 0.62504
Step 137205: loss = 0.02945
Step 137210: loss = 0.09335
Step 137215: loss = 0.09426
Step 137220: loss = 0.19552
Step 137225: loss = 0.16082
Step 137230: loss = 0.03272
Step 137235: loss = 0.05907
Step 137240: loss = 0.03125
Step 137245: loss = 0.08043
Step 137250: loss = 0.14409
Step 137255: loss = 0.02482
Step 137260: loss = 0.19207
Step 137265: loss = 0.07616
Step 137270: loss = 0.22029
Step 137275: loss = 0.18556
Step 137280: loss = 0.23254
Step 137285: loss = 0.24659
Step 137290: loss = 0.17543
Step 137295: loss = 0.25361
Step 137300: loss = 0.06179
Step 137305: loss = 0.13362
Step 137310: loss = 0.11905
Step 137315: loss = 0.18851
Step 137320: loss = 0.46259
Step 137325: loss = 0.12018
Step 137330: loss = 0.18838
Step 137335: loss = 0.25666
Step 137340: loss = 0.16577
Step 137345: loss = 0.05294
Step 137350: loss = 0.30849
Step 137355: loss = 0.34551
Step 137360: loss = 0.22367
Step 137365: loss = 0.10585
Step 137370: loss = 0.06417
Step 137375: loss = 0.08874
Step 137380: loss = 0.16210
Step 137385: loss = 0.19398
Step 137390: loss = 0.10839
Step 137395: loss = 0.17743
Step 137400: loss = 0.34124
Step 137405: loss = 0.04426
Step 137410: loss = 0.10005
Step 137415: loss = 0.10479
Step 137420: loss = 0.09187
Step 137425: loss = 0.36026
Step 137430: loss = 0.10770
Step 137435: loss = 0.15439
Step 137440: loss = 0.12126
Step 137445: loss = 0.20938
Step 137450: loss = 0.08185
Step 137455: loss = 0.12032
Step 137460: loss = 0.05050
Step 137465: loss = 0.13286
Step 137470: loss = 0.08379
Step 137475: loss = 0.09872
Step 137480: loss = 0.13639
Step 137485: loss = 0.11972
Step 137490: loss = 0.04298
Step 137495: loss = 0.12837
Step 137500: loss = 0.09658
Step 137505: loss = 0.07929
Step 137510: loss = 0.12105
Step 137515: loss = 0.21318
Step 137520: loss = 0.42346
Step 137525: loss = 0.13394
Step 137530: loss = 0.06241
Step 137535: loss = 0.14125
Step 137540: loss = 0.03559
Step 137545: loss = 0.13164
Step 137550: loss = 0.06960
Step 137555: loss = 0.20115
Step 137560: loss = 0.06711
Step 137565: loss = 0.17734
Step 137570: loss = 0.18001
Step 137575: loss = 0.19494
Step 137580: loss = 0.17483
Step 137585: loss = 0.11908
Step 137590: loss = 0.06545
Step 137595: loss = 0.08619
Step 137600: loss = 0.14835
Step 137605: loss = 0.04550
Step 137610: loss = 0.16238
Step 137615: loss = 0.30146
Step 137620: loss = 0.12920
Step 137625: loss = 0.15112
Step 137630: loss = 0.18934
Step 137635: loss = 0.04679
Step 137640: loss = 0.07618
Step 137645: loss = 0.05819
Step 137650: loss = 0.02802
Step 137655: loss = 0.05045
Step 137660: loss = 0.03731
Step 137665: loss = 0.03802
Step 137670: loss = 0.43107
Step 137675: loss = 0.16008
Step 137680: loss = 0.18167
Step 137685: loss = 0.10381
Step 137690: loss = 0.11478
Step 137695: loss = 0.19598
Step 137700: loss = 0.09921
Step 137705: loss = 0.18911
Step 137710: loss = 0.03732
Step 137715: loss = 0.17672
Step 137720: loss = 0.02334
Step 137725: loss = 0.17557
Step 137730: loss = 0.15260
Step 137735: loss = 0.15088
Step 137740: loss = 0.19748
Step 137745: loss = 0.06190
Step 137750: loss = 0.07814
Step 137755: loss = 0.11918
Step 137760: loss = 0.04472
Step 137765: loss = 0.14116
Step 137770: loss = 0.07365
Step 137775: loss = 0.28294
Step 137780: loss = 0.13412
Step 137785: loss = 0.12282
Step 137790: loss = 0.06422
Step 137795: loss = 0.15120
Step 137800: loss = 0.32601
Step 137805: loss = 0.13086
Step 137810: loss = 0.16391
Step 137815: loss = 0.13444
Step 137820: loss = 0.05470
Step 137825: loss = 0.12447
Step 137830: loss = 0.32765
Step 137835: loss = 0.11331
Step 137840: loss = 0.29057
Step 137845: loss = 0.08002
Step 137850: loss = 0.25809
Step 137855: loss = 0.07977
Step 137860: loss = 0.09173
Step 137865: loss = 0.36346
Step 137870: loss = 0.05704
Step 137875: loss = 0.10148
Step 137880: loss = 0.20739
Step 137885: loss = 0.10976
Step 137890: loss = 0.23251
Step 137895: loss = 0.21790
Step 137900: loss = 0.15283
Step 137905: loss = 0.18389
Step 137910: loss = 0.14085
Step 137915: loss = 0.26591
Step 137920: loss = 0.24434
Step 137925: loss = 0.24778
Step 137930: loss = 0.10259
Step 137935: loss = 0.12591
Step 137940: loss = 0.09162
Step 137945: loss = 0.22202
Step 137950: loss = 0.05587
Step 137955: loss = 0.05703
Step 137960: loss = 0.14762
Step 137965: loss = 0.08616
Step 137970: loss = 0.29600
Step 137975: loss = 0.08031
Step 137980: loss = 0.23395
Step 137985: loss = 0.24490
Step 137990: loss = 0.14497
Step 137995: loss = 0.14187
Step 138000: loss = 0.06661
Training Data Eval:
  Num examples: 50000, Num correct: 47550, Precision @ 1: 0.9510
('Testing Data Eval: EPOCH->', 139)
  Num examples: 10000, Num correct: 6598, Precision @ 1: 0.6598
Step 138005: loss = 0.05475
Step 138010: loss = 0.13585
Step 138015: loss = 0.11157
Step 138020: loss = 0.17286
Step 138025: loss = 0.13649
Step 138030: loss = 0.33087
Step 138035: loss = 0.32262
Step 138040: loss = 0.22136
Step 138045: loss = 0.11325
Step 138050: loss = 0.08019
Step 138055: loss = 0.22221
Step 138060: loss = 0.04986
Step 138065: loss = 0.32150
Step 138070: loss = 0.12176
Step 138075: loss = 0.15486
Step 138080: loss = 0.09894
Step 138085: loss = 0.22486
Step 138090: loss = 0.09709
Step 138095: loss = 0.07447
Step 138100: loss = 0.14455
Step 138105: loss = 0.14065
Step 138110: loss = 0.04291
Step 138115: loss = 0.14282
Step 138120: loss = 0.08682
Step 138125: loss = 0.19462
Step 138130: loss = 0.08614
Step 138135: loss = 0.04823
Step 138140: loss = 0.29119
Step 138145: loss = 0.06864
Step 138150: loss = 0.16448
Step 138155: loss = 0.12987
Step 138160: loss = 0.14631
Step 138165: loss = 0.09498
Step 138170: loss = 0.31834
Step 138175: loss = 0.16425
Step 138180: loss = 0.24098
Step 138185: loss = 0.13122
Step 138190: loss = 0.02792
Step 138195: loss = 0.03402
Step 138200: loss = 0.31651
Step 138205: loss = 0.07773
Step 138210: loss = 0.07655
Step 138215: loss = 0.21892
Step 138220: loss = 0.15693
Step 138225: loss = 0.17779
Step 138230: loss = 0.05952
Step 138235: loss = 0.16727
Step 138240: loss = 0.11272
Step 138245: loss = 0.12615
Step 138250: loss = 0.19029
Step 138255: loss = 0.07968
Step 138260: loss = 0.14147
Step 138265: loss = 0.16342
Step 138270: loss = 0.19963
Step 138275: loss = 0.14627
Step 138280: loss = 0.19780
Step 138285: loss = 0.15426
Step 138290: loss = 0.08025
Step 138295: loss = 0.08636
Step 138300: loss = 0.19483
Step 138305: loss = 0.09375
Step 138310: loss = 0.12465
Step 138315: loss = 0.28552
Step 138320: loss = 0.15917
Step 138325: loss = 0.20534
Step 138330: loss = 0.52848
Step 138335: loss = 0.27736
Step 138340: loss = 0.15217
Step 138345: loss = 0.20204
Step 138350: loss = 0.11899
Step 138355: loss = 0.25260
Step 138360: loss = 0.17197
Step 138365: loss = 0.42597
Step 138370: loss = 0.14092
Step 138375: loss = 0.23741
Step 138380: loss = 0.09569
Step 138385: loss = 0.18327
Step 138390: loss = 0.45544
Step 138395: loss = 0.15516
Step 138400: loss = 0.08126
Step 138405: loss = 0.24584
Step 138410: loss = 0.28307
Step 138415: loss = 0.10236
Step 138420: loss = 0.15272
Step 138425: loss = 0.29978
Step 138430: loss = 0.17149
Step 138435: loss = 0.05821
Step 138440: loss = 0.05776
Step 138445: loss = 0.36639
Step 138450: loss = 0.19369
Step 138455: loss = 0.27488
Step 138460: loss = 0.13052
Step 138465: loss = 0.20124
Step 138470: loss = 0.17381
Step 138475: loss = 0.13298
Step 138480: loss = 0.19352
Step 138485: loss = 0.11840
Step 138490: loss = 0.08458
Step 138495: loss = 0.11231
Step 138500: loss = 0.14444
Step 138505: loss = 0.16666
Step 138510: loss = 0.30594
Step 138515: loss = 0.19617
Step 138520: loss = 0.11953
Step 138525: loss = 0.19633
Step 138530: loss = 0.17352
Step 138535: loss = 0.21563
Step 138540: loss = 0.37388
Step 138545: loss = 0.28230
Step 138550: loss = 0.22054
Step 138555: loss = 0.18522
Step 138560: loss = 0.18701
Step 138565: loss = 0.33580
Step 138570: loss = 0.26132
Step 138575: loss = 0.20162
Step 138580: loss = 0.17061
Step 138585: loss = 0.10008
Step 138590: loss = 0.09988
Step 138595: loss = 0.18052
Step 138600: loss = 0.12348
Step 138605: loss = 0.12244
Step 138610: loss = 0.05445
Step 138615: loss = 0.13372
Step 138620: loss = 0.16897
Step 138625: loss = 0.44459
Step 138630: loss = 0.02177
Step 138635: loss = 0.16276
Step 138640: loss = 0.13285
Step 138645: loss = 0.09369
Step 138650: loss = 0.07022
Step 138655: loss = 0.05254
Step 138660: loss = 0.24347
Step 138665: loss = 0.24963
Step 138670: loss = 0.32859
Step 138675: loss = 0.17129
Step 138680: loss = 0.21754
Step 138685: loss = 0.11261
Step 138690: loss = 0.13129
Step 138695: loss = 0.10310
Step 138700: loss = 0.15979
Step 138705: loss = 0.18969
Step 138710: loss = 0.12302
Step 138715: loss = 0.12261
Step 138720: loss = 0.09669
Step 138725: loss = 0.05882
Step 138730: loss = 0.12301
Step 138735: loss = 0.28279
Step 138740: loss = 0.40873
Step 138745: loss = 0.05957
Step 138750: loss = 0.04253
Step 138755: loss = 0.15013
Step 138760: loss = 0.15231
Step 138765: loss = 0.19667
Step 138770: loss = 0.13096
Step 138775: loss = 0.12494
Step 138780: loss = 0.12218
Step 138785: loss = 0.23839
Step 138790: loss = 0.27863
Step 138795: loss = 0.17411
Step 138800: loss = 0.10592
Step 138805: loss = 0.03242
Step 138810: loss = 0.08622
Step 138815: loss = 0.07311
Step 138820: loss = 0.07890
Step 138825: loss = 0.10741
Step 138830: loss = 0.05962
Step 138835: loss = 0.06337
Step 138840: loss = 0.06018
Step 138845: loss = 0.09522
Step 138850: loss = 0.14122
Step 138855: loss = 0.15609
Step 138860: loss = 0.04655
Step 138865: loss = 0.02744
Step 138870: loss = 0.06845
Step 138875: loss = 0.10064
Step 138880: loss = 0.19329
Step 138885: loss = 0.36955
Step 138890: loss = 0.35775
Step 138895: loss = 0.29101
Step 138900: loss = 0.15230
Step 138905: loss = 0.09763
Step 138910: loss = 0.05782
Step 138915: loss = 0.12900
Step 138920: loss = 0.27259
Step 138925: loss = 0.29633
Step 138930: loss = 0.20825
Step 138935: loss = 0.37180
Step 138940: loss = 0.07533
Step 138945: loss = 0.19293
Step 138950: loss = 0.35021
Step 138955: loss = 0.24836
Step 138960: loss = 0.04717
Step 138965: loss = 0.37147
Step 138970: loss = 0.04843
Step 138975: loss = 0.10088
Step 138980: loss = 0.02376
Step 138985: loss = 0.12328
Step 138990: loss = 0.13171
Step 138995: loss = 0.31684
Step 139000: loss = 0.09763
Training Data Eval:
  Num examples: 50000, Num correct: 47619, Precision @ 1: 0.9524
('Testing Data Eval: EPOCH->', 140)
  Num examples: 10000, Num correct: 6690, Precision @ 1: 0.6690
Step 139005: loss = 0.21978
Step 139010: loss = 0.17057
Step 139015: loss = 0.11467
Step 139020: loss = 0.08786
Step 139025: loss = 0.19520
Step 139030: loss = 0.05105
Step 139035: loss = 0.20917
Step 139040: loss = 0.22843
Step 139045: loss = 0.10146
Step 139050: loss = 0.17005
Step 139055: loss = 0.19221
Step 139060: loss = 0.26985
Step 139065: loss = 0.22863
Step 139070: loss = 0.08657
Step 139075: loss = 0.10506
Step 139080: loss = 0.26059
Step 139085: loss = 0.12966
Step 139090: loss = 0.09052
Step 139095: loss = 0.16015
Step 139100: loss = 0.04065
Step 139105: loss = 0.25863
Step 139110: loss = 0.22919
Step 139115: loss = 0.15947
Step 139120: loss = 0.13748
Step 139125: loss = 0.18944
Step 139130: loss = 0.08936
Step 139135: loss = 0.06080
Step 139140: loss = 0.12988
Step 139145: loss = 0.06956
Step 139150: loss = 0.15764
Step 139155: loss = 0.15126
Step 139160: loss = 0.05072
Step 139165: loss = 0.04977
Step 139170: loss = 0.06231
Step 139175: loss = 0.36447
Step 139180: loss = 0.21574
Step 139185: loss = 0.11594
Step 139190: loss = 0.18964
Step 139195: loss = 0.11759
Step 139200: loss = 0.29342
Step 139205: loss = 0.23972
Step 139210: loss = 0.23710
Step 139215: loss = 0.20402
Step 139220: loss = 0.03689
Step 139225: loss = 0.10158
Step 139230: loss = 0.12983
Step 139235: loss = 0.08254
Step 139240: loss = 0.04255
Step 139245: loss = 0.07478
Step 139250: loss = 0.15904
Step 139255: loss = 0.09440
Step 139260: loss = 0.18447
Step 139265: loss = 0.14865
Step 139270: loss = 0.14280
Step 139275: loss = 0.10394
Step 139280: loss = 0.06494
Step 139285: loss = 0.13794
Step 139290: loss = 0.13802
Step 139295: loss = 0.14571
Step 139300: loss = 0.08342
Step 139305: loss = 0.19489
Step 139310: loss = 0.08987
Step 139315: loss = 0.21060
Step 139320: loss = 0.10921
Step 139325: loss = 0.03243
Step 139330: loss = 0.07212
Step 139335: loss = 0.11778
Step 139340: loss = 0.16519
Step 139345: loss = 0.16030
Step 139350: loss = 0.12862
Step 139355: loss = 0.11731
Step 139360: loss = 0.31613
Step 139365: loss = 0.14101
Step 139370: loss = 0.12792
Step 139375: loss = 0.29541
Step 139380: loss = 0.11600
Step 139385: loss = 0.23392
Step 139390: loss = 0.07956
Step 139395: loss = 0.26424
Step 139400: loss = 0.03698
Step 139405: loss = 0.22479
Step 139410: loss = 0.05240
Step 139415: loss = 0.11738
Step 139420: loss = 0.14724
Step 139425: loss = 0.24545
Step 139430: loss = 0.23741
Step 139435: loss = 0.21043
Step 139440: loss = 0.05397
Step 139445: loss = 0.09644
Step 139450: loss = 0.15832
Step 139455: loss = 0.30467
Step 139460: loss = 0.19064
Step 139465: loss = 0.08598
Step 139470: loss = 0.04997
Step 139475: loss = 0.11613
Step 139480: loss = 0.21461
Step 139485: loss = 0.25157
Step 139490: loss = 0.22590
Step 139495: loss = 0.12592
Step 139500: loss = 0.10283
Step 139505: loss = 0.16812
Step 139510: loss = 0.20498
Step 139515: loss = 0.02982
Step 139520: loss = 0.20491
Step 139525: loss = 0.18750
Step 139530: loss = 0.13654
Step 139535: loss = 0.14690
Step 139540: loss = 0.27795
Step 139545: loss = 0.10971
Step 139550: loss = 0.05418
Step 139555: loss = 0.13357
Step 139560: loss = 0.10820
Step 139565: loss = 0.20085
Step 139570: loss = 0.12103
Step 139575: loss = 0.08820
Step 139580: loss = 0.10192
Step 139585: loss = 0.06953
Step 139590: loss = 0.41481
Step 139595: loss = 0.21324
Step 139600: loss = 0.03733
Step 139605: loss = 0.08522
Step 139610: loss = 0.06617
Step 139615: loss = 0.13886
Step 139620: loss = 0.08678
Step 139625: loss = 0.06010
Step 139630: loss = 0.11378
Step 139635: loss = 0.07525
Step 139640: loss = 0.20802
Step 139645: loss = 0.05888
Step 139650: loss = 0.08872
Step 139655: loss = 0.08095
Step 139660: loss = 0.17519
Step 139665: loss = 0.22467
Step 139670: loss = 0.19122
Step 139675: loss = 0.08803
Step 139680: loss = 0.27561
Step 139685: loss = 0.33121
Step 139690: loss = 0.04399
Step 139695: loss = 0.04393
Step 139700: loss = 0.26056
Step 139705: loss = 0.06689
Step 139710: loss = 0.12091
Step 139715: loss = 0.15235
Step 139720: loss = 0.02819
Step 139725: loss = 0.09533
Step 139730: loss = 0.28423
Step 139735: loss = 0.06355
Step 139740: loss = 0.13153
Step 139745: loss = 0.06484
Step 139750: loss = 0.15543
Step 139755: loss = 0.03213
Step 139760: loss = 0.24721
Step 139765: loss = 0.22697
Step 139770: loss = 0.10565
Step 139775: loss = 0.15701
Step 139780: loss = 0.13942
Step 139785: loss = 0.12251
Step 139790: loss = 0.02695
Step 139795: loss = 0.16431
Step 139800: loss = 0.12828
Step 139805: loss = 0.10768
Step 139810: loss = 0.15547
Step 139815: loss = 0.08586
Step 139820: loss = 0.22140
Step 139825: loss = 0.05749
Step 139830: loss = 0.13035
Step 139835: loss = 0.03969
Step 139840: loss = 0.11906
Step 139845: loss = 0.07192
Step 139850: loss = 0.03090
Step 139855: loss = 0.13925
Step 139860: loss = 0.08194
Step 139865: loss = 0.10610
Step 139870: loss = 0.20889
Step 139875: loss = 0.13535
Step 139880: loss = 0.13293
Step 139885: loss = 0.01860
Step 139890: loss = 0.13179
Step 139895: loss = 0.06945
Step 139900: loss = 0.26336
Step 139905: loss = 0.06954
Step 139910: loss = 0.16121
Step 139915: loss = 0.08181
Step 139920: loss = 0.10705
Step 139925: loss = 0.14405
Step 139930: loss = 0.20872
Step 139935: loss = 0.13776
Step 139940: loss = 0.12143
Step 139945: loss = 0.07360
Step 139950: loss = 0.29576
Step 139955: loss = 0.08415
Step 139960: loss = 0.27634
Step 139965: loss = 0.19056
Step 139970: loss = 0.03232
Step 139975: loss = 0.13138
Step 139980: loss = 0.24352
Step 139985: loss = 0.04790
Step 139990: loss = 0.18648
Step 139995: loss = 0.25410
Step 140000: loss = 0.16676
Training Data Eval:
  Num examples: 50000, Num correct: 47700, Precision @ 1: 0.9540
('Testing Data Eval: EPOCH->', 141)
  Num examples: 10000, Num correct: 6554, Precision @ 1: 0.6554
Step 140005: loss = 0.11795
Step 140010: loss = 0.25080
Step 140015: loss = 0.06654
Step 140020: loss = 0.09752
Step 140025: loss = 0.08483
Step 140030: loss = 0.06509
Step 140035: loss = 0.08386
Step 140040: loss = 0.10480
Step 140045: loss = 0.04899
Step 140050: loss = 0.15663
Step 140055: loss = 0.04641
Step 140060: loss = 0.02522
Step 140065: loss = 0.21089
Step 140070: loss = 0.09066
Step 140075: loss = 0.12811
Step 140080: loss = 0.04991
Step 140085: loss = 0.10703
Step 140090: loss = 0.23136
Step 140095: loss = 0.30283
Step 140100: loss = 0.03658
Step 140105: loss = 0.18087
Step 140110: loss = 0.07492
Step 140115: loss = 0.04060
Step 140120: loss = 0.15094
Step 140125: loss = 0.09767
Step 140130: loss = 0.22988
Step 140135: loss = 0.14347
Step 140140: loss = 0.05029
Step 140145: loss = 0.14051
Step 140150: loss = 0.25667
Step 140155: loss = 0.09371
Step 140160: loss = 0.08200
Step 140165: loss = 0.05379
Step 140170: loss = 0.75122
Step 140175: loss = 0.14337
Step 140180: loss = 0.04658
Step 140185: loss = 0.14069
Step 140190: loss = 0.17553
Step 140195: loss = 0.17666
Step 140200: loss = 0.10831
Step 140205: loss = 0.09023
Step 140210: loss = 0.17374
Step 140215: loss = 0.21605
Step 140220: loss = 0.16120
Step 140225: loss = 0.03499
Step 140230: loss = 0.06088
Step 140235: loss = 0.19241
Step 140240: loss = 0.08054
Step 140245: loss = 0.19985
Step 140250: loss = 0.23046
Step 140255: loss = 0.12298
Step 140260: loss = 0.16250
Step 140265: loss = 0.03324
Step 140270: loss = 0.18625
Step 140275: loss = 0.06551
Step 140280: loss = 0.03472
Step 140285: loss = 0.09646
Step 140290: loss = 0.11539
Step 140295: loss = 0.10023
Step 140300: loss = 0.07194
Step 140305: loss = 0.06859
Step 140310: loss = 0.09787
Step 140315: loss = 0.14474
Step 140320: loss = 0.19884
Step 140325: loss = 0.15571
Step 140330: loss = 0.07310
Step 140335: loss = 0.19687
Step 140340: loss = 0.14880
Step 140345: loss = 0.06654
Step 140350: loss = 0.08622
Step 140355: loss = 0.29768
Step 140360: loss = 0.27049
Step 140365: loss = 0.09554
Step 140370: loss = 0.08629
Step 140375: loss = 0.18078
Step 140380: loss = 0.03509
Step 140385: loss = 0.21545
Step 140390: loss = 0.11173
Step 140395: loss = 0.02595
Step 140400: loss = 0.12343
Step 140405: loss = 0.05040
Step 140410: loss = 0.11233
Step 140415: loss = 0.05429
Step 140420: loss = 0.03720
Step 140425: loss = 0.01515
Step 140430: loss = 0.10644
Step 140435: loss = 0.05912
Step 140440: loss = 0.03233
Step 140445: loss = 0.06997
Step 140450: loss = 0.11481
Step 140455: loss = 0.21351
Step 140460: loss = 0.14515
Step 140465: loss = 0.22989
Step 140470: loss = 0.08856
Step 140475: loss = 0.17912
Step 140480: loss = 0.08014
Step 140485: loss = 0.23917
Step 140490: loss = 0.33200
Step 140495: loss = 0.09639
Step 140500: loss = 0.17155
Step 140505: loss = 0.14739
Step 140510: loss = 0.36569
Step 140515: loss = 0.17232
Step 140520: loss = 0.18430
Step 140525: loss = 0.10006
Step 140530: loss = 0.20215
Step 140535: loss = 0.07912
Step 140540: loss = 0.15892
Step 140545: loss = 0.14129
Step 140550: loss = 0.16278
Step 140555: loss = 0.17007
Step 140560: loss = 0.09840
Step 140565: loss = 0.11991
Step 140570: loss = 0.27071
Step 140575: loss = 0.05007
Step 140580: loss = 0.03854
Step 140585: loss = 0.24700
Step 140590: loss = 0.28618
Step 140595: loss = 0.03450
Step 140600: loss = 0.17886
Step 140605: loss = 0.25074
Step 140610: loss = 0.03807
Step 140615: loss = 0.05159
Step 140620: loss = 0.17425
Step 140625: loss = 0.17463
Step 140630: loss = 0.13779
Step 140635: loss = 0.28614
Step 140640: loss = 0.08514
Step 140645: loss = 0.13005
Step 140650: loss = 0.12379
Step 140655: loss = 0.05063
Step 140660: loss = 0.14638
Step 140665: loss = 0.13493
Step 140670: loss = 0.23068
Step 140675: loss = 0.21802
Step 140680: loss = 0.04604
Step 140685: loss = 0.12039
Step 140690: loss = 0.10649
Step 140695: loss = 0.07605
Step 140700: loss = 0.08598
Step 140705: loss = 0.13693
Step 140710: loss = 0.04242
Step 140715: loss = 0.09386
Step 140720: loss = 0.27137
Step 140725: loss = 0.18651
Step 140730: loss = 0.15600
Step 140735: loss = 0.06523
Step 140740: loss = 0.21565
Step 140745: loss = 0.23556
Step 140750: loss = 0.06254
Step 140755: loss = 0.09420
Step 140760: loss = 0.16431
Step 140765: loss = 0.06839
Step 140770: loss = 0.05102
Step 140775: loss = 0.12570
Step 140780: loss = 0.12804
Step 140785: loss = 0.08665
Step 140790: loss = 0.16146
Step 140795: loss = 0.33603
Step 140800: loss = 0.07602
Step 140805: loss = 0.07415
Step 140810: loss = 0.08100
Step 140815: loss = 0.05166
Step 140820: loss = 0.11256
Step 140825: loss = 0.07507
Step 140830: loss = 0.10276
Step 140835: loss = 0.15666
Step 140840: loss = 0.03817
Step 140845: loss = 0.44974
Step 140850: loss = 0.05826
Step 140855: loss = 0.10297
Step 140860: loss = 0.12335
Step 140865: loss = 0.08889
Step 140870: loss = 0.19803
Step 140875: loss = 0.15244
Step 140880: loss = 0.07953
Step 140885: loss = 0.05524
Step 140890: loss = 0.09473
Step 140895: loss = 0.06811
Step 140900: loss = 0.20198
Step 140905: loss = 0.05086
Step 140910: loss = 0.28749
Step 140915: loss = 0.07104
Step 140920: loss = 0.04207
Step 140925: loss = 0.01489
Step 140930: loss = 0.12319
Step 140935: loss = 0.30693
Step 140940: loss = 0.11453
Step 140945: loss = 0.09938
Step 140950: loss = 0.12200
Step 140955: loss = 0.15887
Step 140960: loss = 0.17169
Step 140965: loss = 0.09875
Step 140970: loss = 0.25023
Step 140975: loss = 0.12489
Step 140980: loss = 0.10643
Step 140985: loss = 0.09873
Step 140990: loss = 0.20649
Step 140995: loss = 0.17686
Step 141000: loss = 0.13808
Training Data Eval:
  Num examples: 50000, Num correct: 47696, Precision @ 1: 0.9539
('Testing Data Eval: EPOCH->', 142)
  Num examples: 10000, Num correct: 6576, Precision @ 1: 0.6576
Step 141005: loss = 0.19437
Step 141010: loss = 0.16376
Step 141015: loss = 0.13150
Step 141020: loss = 0.29630
Step 141025: loss = 0.14995
Step 141030: loss = 0.13217
Step 141035: loss = 0.11209
Step 141040: loss = 0.06562
Step 141045: loss = 0.13615
Step 141050: loss = 0.21031
Step 141055: loss = 0.19380
Step 141060: loss = 0.10232
Step 141065: loss = 0.03569
Step 141070: loss = 0.06134
Step 141075: loss = 0.30777
Step 141080: loss = 0.08892
Step 141085: loss = 0.15028
Step 141090: loss = 0.06042
Step 141095: loss = 0.04282
Step 141100: loss = 0.40825
Step 141105: loss = 0.11014
Step 141110: loss = 0.08920
Step 141115: loss = 0.16495
Step 141120: loss = 0.16204
Step 141125: loss = 0.11052
Step 141130: loss = 0.08940
Step 141135: loss = 0.08675
Step 141140: loss = 0.14127
Step 141145: loss = 0.05501
Step 141150: loss = 0.24637
Step 141155: loss = 0.11223
Step 141160: loss = 0.18693
Step 141165: loss = 0.03221
Step 141170: loss = 0.16118
Step 141175: loss = 0.08267
Step 141180: loss = 0.05622
Step 141185: loss = 0.13456
Step 141190: loss = 0.12784
Step 141195: loss = 0.11270
Step 141200: loss = 0.07940
Step 141205: loss = 0.06542
Step 141210: loss = 0.10605
Step 141215: loss = 0.18814
Step 141220: loss = 0.08423
Step 141225: loss = 0.10707
Step 141230: loss = 0.05442
Step 141235: loss = 0.22821
Step 141240: loss = 0.06114
Step 141245: loss = 0.09436
Step 141250: loss = 0.05746
Step 141255: loss = 0.22139
Step 141260: loss = 0.12663
Step 141265: loss = 0.12161
Step 141270: loss = 0.07456
Step 141275: loss = 0.15673
Step 141280: loss = 0.04911
Step 141285: loss = 0.19213
Step 141290: loss = 0.23923
Step 141295: loss = 0.26747
Step 141300: loss = 0.10980
Step 141305: loss = 0.05500
Step 141310: loss = 0.07922
Step 141315: loss = 0.17142
Step 141320: loss = 0.26279
Step 141325: loss = 0.07573
Step 141330: loss = 0.04652
Step 141335: loss = 0.08965
Step 141340: loss = 0.12146
Step 141345: loss = 0.09750
Step 141350: loss = 0.16015
Step 141355: loss = 0.11594
Step 141360: loss = 0.11276
Step 141365: loss = 0.18224
Step 141370: loss = 0.08961
Step 141375: loss = 0.05995
Step 141380: loss = 0.18899
Step 141385: loss = 0.13850
Step 141390: loss = 0.07813
Step 141395: loss = 0.03407
Step 141400: loss = 0.12001
Step 141405: loss = 0.02983
Step 141410: loss = 0.11632
Step 141415: loss = 0.06095
Step 141420: loss = 0.09582
Step 141425: loss = 0.20016
Step 141430: loss = 0.16387
Step 141435: loss = 0.16562
Step 141440: loss = 0.03127
Step 141445: loss = 0.12265
Step 141450: loss = 0.21503
Step 141455: loss = 0.06062
Step 141460: loss = 0.09703
Step 141465: loss = 0.45337
Step 141470: loss = 0.34155
Step 141475: loss = 0.12168
Step 141480: loss = 0.07860
Step 141485: loss = 0.21933
Step 141490: loss = 0.09449
Step 141495: loss = 0.11587
Step 141500: loss = 0.16039
Step 141505: loss = 0.28642
Step 141510: loss = 0.12224
Step 141515: loss = 0.08445
Step 141520: loss = 0.07951
Step 141525: loss = 0.16415
Step 141530: loss = 0.03248
Step 141535: loss = 0.05743
Step 141540: loss = 0.22205
Step 141545: loss = 0.15342
Step 141550: loss = 0.20740
Step 141555: loss = 0.06249
Step 141560: loss = 0.15378
Step 141565: loss = 0.04971
Step 141570: loss = 0.07324
Step 141575: loss = 0.08215
Step 141580: loss = 0.03854
Step 141585: loss = 0.23837
Step 141590: loss = 0.12693
Step 141595: loss = 0.17230
Step 141600: loss = 0.13544
Step 141605: loss = 0.12826
Step 141610: loss = 0.15624
Step 141615: loss = 0.03907
Step 141620: loss = 0.03837
Step 141625: loss = 0.05183
Step 141630: loss = 0.24289
Step 141635: loss = 0.24396
Step 141640: loss = 0.20267
Step 141645: loss = 0.03786
Step 141650: loss = 0.09311
Step 141655: loss = 0.20133
Step 141660: loss = 0.26501
Step 141665: loss = 0.30643
Step 141670: loss = 0.04903
Step 141675: loss = 0.06583
Step 141680: loss = 0.21218
Step 141685: loss = 0.04150
Step 141690: loss = 0.22682
Step 141695: loss = 0.08709
Step 141700: loss = 0.15240
Step 141705: loss = 0.18297
Step 141710: loss = 0.10889
Step 141715: loss = 0.11063
Step 141720: loss = 0.16017
Step 141725: loss = 0.16042
Step 141730: loss = 0.08263
Step 141735: loss = 0.16628
Step 141740: loss = 0.13333
Step 141745: loss = 0.11019
Step 141750: loss = 0.20172
Step 141755: loss = 0.10529
Step 141760: loss = 0.11348
Step 141765: loss = 0.24240
Step 141770: loss = 0.16922
Step 141775: loss = 0.14557
Step 141780: loss = 0.08395
Step 141785: loss = 0.34967
Step 141790: loss = 0.11423
Step 141795: loss = 0.07157
Step 141800: loss = 0.29879
Step 141805: loss = 0.10872
Step 141810: loss = 0.05208
Step 141815: loss = 0.28593
Step 141820: loss = 0.13635
Step 141825: loss = 0.10893
Step 141830: loss = 0.08497
Step 141835: loss = 0.06665
Step 141840: loss = 0.27201
Step 141845: loss = 0.29876
Step 141850: loss = 0.21619
Step 141855: loss = 0.12099
Step 141860: loss = 0.13321
Step 141865: loss = 0.07006
Step 141870: loss = 0.08644
Step 141875: loss = 0.13476
Step 141880: loss = 0.10878
Step 141885: loss = 0.26509
Step 141890: loss = 0.08588
Step 141895: loss = 0.05566
Step 141900: loss = 0.03678
Step 141905: loss = 0.15580
Step 141910: loss = 0.11244
Step 141915: loss = 0.15731
Step 141920: loss = 0.07450
Step 141925: loss = 0.18789
Step 141930: loss = 0.03629
Step 141935: loss = 0.15213
Step 141940: loss = 0.13595
Step 141945: loss = 0.03847
Step 141950: loss = 0.13742
Step 141955: loss = 0.06328
Step 141960: loss = 0.10023
Step 141965: loss = 0.14382
Step 141970: loss = 0.11172
Step 141975: loss = 0.40834
Step 141980: loss = 0.06068
Step 141985: loss = 0.09158
Step 141990: loss = 0.23927
Step 141995: loss = 0.05779
Step 142000: loss = 0.07806
Training Data Eval:
  Num examples: 50000, Num correct: 48069, Precision @ 1: 0.9614
('Testing Data Eval: EPOCH->', 143)
  Num examples: 10000, Num correct: 6708, Precision @ 1: 0.6708
Step 142005: loss = 0.07359
Step 142010: loss = 0.17942
Step 142015: loss = 0.11799
Step 142020: loss = 0.05789
Step 142025: loss = 0.09614
Step 142030: loss = 0.13786
Step 142035: loss = 0.05988
Step 142040: loss = 0.06549
Step 142045: loss = 0.08500
Step 142050: loss = 0.10424
Step 142055: loss = 0.28455
Step 142060: loss = 0.13785
Step 142065: loss = 0.06369
Step 142070: loss = 0.07373
Step 142075: loss = 0.05751
Step 142080: loss = 0.14742
Step 142085: loss = 0.07775
Step 142090: loss = 0.06502
Step 142095: loss = 0.10910
Step 142100: loss = 0.07437
Step 142105: loss = 0.04861
Step 142110: loss = 0.16949
Step 142115: loss = 0.24215
Step 142120: loss = 0.02973
Step 142125: loss = 0.02296
Step 142130: loss = 0.15714
Step 142135: loss = 0.06864
Step 142140: loss = 0.12515
Step 142145: loss = 0.05428
Step 142150: loss = 0.10283
Step 142155: loss = 0.10938
Step 142160: loss = 0.05240
Step 142165: loss = 0.11192
Step 142170: loss = 0.13363
Step 142175: loss = 0.11222
Step 142180: loss = 0.26300
Step 142185: loss = 0.05121
Step 142190: loss = 0.12060
Step 142195: loss = 0.17805
Step 142200: loss = 0.10227
Step 142205: loss = 0.15295
Step 142210: loss = 0.04735
Step 142215: loss = 0.17004
Step 142220: loss = 0.14099
Step 142225: loss = 0.27439
Step 142230: loss = 0.16165
Step 142235: loss = 0.33371
Step 142240: loss = 0.12506
Step 142245: loss = 0.26503
Step 142250: loss = 0.16742
Step 142255: loss = 0.13141
Step 142260: loss = 0.10595
Step 142265: loss = 0.17407
Step 142270: loss = 0.05154
Step 142275: loss = 0.12007
Step 142280: loss = 0.41138
Step 142285: loss = 0.12855
Step 142290: loss = 0.33210
Step 142295: loss = 0.05647
Step 142300: loss = 0.06873
Step 142305: loss = 0.08826
Step 142310: loss = 0.20341
Step 142315: loss = 0.07734
Step 142320: loss = 0.05942
Step 142325: loss = 0.09013
Step 142330: loss = 0.24658
Step 142335: loss = 0.10037
Step 142340: loss = 0.09332
Step 142345: loss = 0.19523
Step 142350: loss = 0.23121
Step 142355: loss = 0.47140
Step 142360: loss = 0.17509
Step 142365: loss = 0.10089
Step 142370: loss = 0.69883
Step 142375: loss = 0.37735
Step 142380: loss = 0.10510
Step 142385: loss = 0.10876
Step 142390: loss = 0.19664
Step 142395: loss = 0.19369
Step 142400: loss = 0.21768
Step 142405: loss = 0.06755
Step 142410: loss = 0.12747
Step 142415: loss = 0.11238
Step 142420: loss = 0.10686
Step 142425: loss = 0.11446
Step 142430: loss = 0.15611
Step 142435: loss = 0.05706
Step 142440: loss = 0.19140
Step 142445: loss = 0.08556
Step 142450: loss = 0.08371
Step 142455: loss = 0.22157
Step 142460: loss = 0.16349
Step 142465: loss = 0.24062
Step 142470: loss = 0.19726
Step 142475: loss = 0.09256
Step 142480: loss = 0.20972
Step 142485: loss = 0.19484
Step 142490: loss = 0.22113
Step 142495: loss = 0.05585
Step 142500: loss = 0.11932
Step 142505: loss = 0.25078
Step 142510: loss = 0.02891
Step 142515: loss = 0.19614
Step 142520: loss = 0.07673
Step 142525: loss = 0.26745
Step 142530: loss = 0.05141
Step 142535: loss = 0.05351
Step 142540: loss = 0.06981
Step 142545: loss = 0.10365
Step 142550: loss = 0.09432
Step 142555: loss = 0.04798
Step 142560: loss = 0.11581
Step 142565: loss = 0.12090
Step 142570: loss = 0.18854
Step 142575: loss = 0.34241
Step 142580: loss = 0.22159
Step 142585: loss = 0.03613
Step 142590: loss = 0.25326
Step 142595: loss = 0.17195
Step 142600: loss = 0.22716
Step 142605: loss = 0.07866
Step 142610: loss = 0.18525
Step 142615: loss = 0.21217
Step 142620: loss = 0.04957
Step 142625: loss = 0.04207
Step 142630: loss = 0.02798
Step 142635: loss = 0.17600
Step 142640: loss = 0.07678
Step 142645: loss = 0.12284
Step 142650: loss = 0.23339
Step 142655: loss = 0.05930
Step 142660: loss = 0.06304
Step 142665: loss = 0.07404
Step 142670: loss = 0.14468
Step 142675: loss = 0.22419
Step 142680: loss = 0.06171
Step 142685: loss = 0.06590
Step 142690: loss = 0.11237
Step 142695: loss = 0.03334
Step 142700: loss = 0.09241
Step 142705: loss = 0.24058
Step 142710: loss = 0.14373
Step 142715: loss = 0.19206
Step 142720: loss = 0.02902
Step 142725: loss = 0.16259
Step 142730: loss = 0.18711
Step 142735: loss = 0.06478
Step 142740: loss = 0.15788
Step 142745: loss = 0.19194
Step 142750: loss = 0.09220
Step 142755: loss = 0.03580
Step 142760: loss = 0.10319
Step 142765: loss = 0.11216
Step 142770: loss = 0.11399
Step 142775: loss = 0.32213
Step 142780: loss = 0.07436
Step 142785: loss = 0.12015
Step 142790: loss = 0.13771
Step 142795: loss = 0.04004
Step 142800: loss = 0.50630
Step 142805: loss = 0.11937
Step 142810: loss = 0.05378
Step 142815: loss = 0.16519
Step 142820: loss = 0.14105
Step 142825: loss = 0.04834
Step 142830: loss = 0.08531
Step 142835: loss = 0.10962
Step 142840: loss = 0.05003
Step 142845: loss = 0.13616
Step 142850: loss = 0.14423
Step 142855: loss = 0.11896
Step 142860: loss = 0.04281
Step 142865: loss = 0.19679
Step 142870: loss = 0.05751
Step 142875: loss = 0.11897
Step 142880: loss = 0.15297
Step 142885: loss = 0.22216
Step 142890: loss = 0.16407
Step 142895: loss = 0.05214
Step 142900: loss = 0.19725
Step 142905: loss = 0.18380
Step 142910: loss = 0.07778
Step 142915: loss = 0.11327
Step 142920: loss = 0.04786
Step 142925: loss = 0.06547
Step 142930: loss = 0.06388
Step 142935: loss = 0.16506
Step 142940: loss = 0.11566
Step 142945: loss = 0.13564
Step 142950: loss = 0.03598
Step 142955: loss = 0.23193
Step 142960: loss = 0.18412
Step 142965: loss = 0.15564
Step 142970: loss = 0.19684
Step 142975: loss = 0.05278
Step 142980: loss = 0.03307
Step 142985: loss = 0.19436
Step 142990: loss = 0.14106
Step 142995: loss = 0.07036
Step 143000: loss = 0.14084
Training Data Eval:
  Num examples: 50000, Num correct: 47853, Precision @ 1: 0.9571
('Testing Data Eval: EPOCH->', 144)
  Num examples: 10000, Num correct: 6620, Precision @ 1: 0.6620
Step 143005: loss = 0.05704
Step 143010: loss = 0.16960
Step 143015: loss = 0.10339
Step 143020: loss = 0.02869
Step 143025: loss = 0.11738
Step 143030: loss = 0.04889
Step 143035: loss = 0.40522
Step 143040: loss = 0.08330
Step 143045: loss = 0.03157
Step 143050: loss = 0.09956
Step 143055: loss = 0.11185
Step 143060: loss = 0.06324
Step 143065: loss = 0.10805
Step 143070: loss = 0.06392
Step 143075: loss = 0.13253
Step 143080: loss = 0.02208
Step 143085: loss = 0.08461
Step 143090: loss = 0.09337
Step 143095: loss = 0.03950
Step 143100: loss = 0.24770
Step 143105: loss = 0.04528
Step 143110: loss = 0.53681
Step 143115: loss = 0.12867
Step 143120: loss = 0.16061
Step 143125: loss = 0.06673
Step 143130: loss = 0.16418
Step 143135: loss = 0.10959
Step 143140: loss = 0.06895
Step 143145: loss = 0.10179
Step 143150: loss = 0.15418
Step 143155: loss = 0.25649
Step 143160: loss = 0.25057
Step 143165: loss = 0.20730
Step 143170: loss = 0.29250
Step 143175: loss = 0.03824
Step 143180: loss = 0.11834
Step 143185: loss = 0.22288
Step 143190: loss = 0.10292
Step 143195: loss = 0.30421
Step 143200: loss = 0.24887
Step 143205: loss = 0.09687
Step 143210: loss = 0.09690
Step 143215: loss = 0.19604
Step 143220: loss = 0.09133
Step 143225: loss = 0.07664
Step 143230: loss = 0.04207
Step 143235: loss = 0.07864
Step 143240: loss = 0.04931
Step 143245: loss = 0.41795
Step 143250: loss = 0.05599
Step 143255: loss = 0.11902
Step 143260: loss = 0.14495
Step 143265: loss = 0.08147
Step 143270: loss = 0.22763
Step 143275: loss = 0.08123
Step 143280: loss = 0.02262
Step 143285: loss = 0.07037
Step 143290: loss = 0.19807
Step 143295: loss = 0.02114
Step 143300: loss = 0.25164
Step 143305: loss = 0.54695
Step 143310: loss = 0.18447
Step 143315: loss = 0.01628
Step 143320: loss = 0.16371
Step 143325: loss = 0.12836
Step 143330: loss = 0.08904
Step 143335: loss = 0.07392
Step 143340: loss = 0.02105
Step 143345: loss = 0.11012
Step 143350: loss = 0.29060
Step 143355: loss = 0.15930
Step 143360: loss = 0.05381
Step 143365: loss = 0.24860
Step 143370: loss = 0.16342
Step 143375: loss = 0.12035
Step 143380: loss = 0.18412
Step 143385: loss = 0.05321
Step 143390: loss = 0.17878
Step 143395: loss = 0.03846
Step 143400: loss = 0.06843
Step 143405: loss = 0.14603
Step 143410: loss = 0.23869
Step 143415: loss = 0.12322
Step 143420: loss = 0.06047
Step 143425: loss = 0.05138
Step 143430: loss = 0.11174
Step 143435: loss = 0.10102
Step 143440: loss = 0.07052
Step 143445: loss = 0.30932
Step 143450: loss = 0.06155
Step 143455: loss = 0.29793
Step 143460: loss = 0.16931
Step 143465: loss = 0.12843
Step 143470: loss = 0.09937
Step 143475: loss = 0.23450
Step 143480: loss = 0.06586
Step 143485: loss = 0.18317
Step 143490: loss = 0.05108
Step 143495: loss = 0.37939
Step 143500: loss = 0.07185
Step 143505: loss = 0.18190
Step 143510: loss = 0.05190
Step 143515: loss = 0.05751
Step 143520: loss = 0.14575
Step 143525: loss = 0.08758
Step 143530: loss = 0.20953
Step 143535: loss = 0.14029
Step 143540: loss = 0.15481
Step 143545: loss = 0.13912
Step 143550: loss = 0.04001
Step 143555: loss = 0.04870
Step 143560: loss = 0.12464
Step 143565: loss = 0.06692
Step 143570: loss = 0.06576
Step 143575: loss = 0.07938
Step 143580: loss = 0.17696
Step 143585: loss = 0.04886
Step 143590: loss = 0.10215
Step 143595: loss = 0.04217
Step 143600: loss = 0.03835
Step 143605: loss = 0.08376
Step 143610: loss = 0.07228
Step 143615: loss = 0.14433
Step 143620: loss = 0.09951
Step 143625: loss = 0.15464
Step 143630: loss = 0.05709
Step 143635: loss = 0.04538
Step 143640: loss = 0.18111
Step 143645: loss = 0.15939
Step 143650: loss = 0.05295
Step 143655: loss = 0.21264
Step 143660: loss = 0.03755
Step 143665: loss = 0.19892
Step 143670: loss = 0.03969
Step 143675: loss = 0.18338
Step 143680: loss = 0.09858
Step 143685: loss = 0.25188
Step 143690: loss = 0.14379
Step 143695: loss = 0.15340
Step 143700: loss = 0.06499
Step 143705: loss = 0.40418
Step 143710: loss = 0.06469
Step 143715: loss = 0.11677
Step 143720: loss = 0.12739
Step 143725: loss = 0.03460
Step 143730: loss = 0.34258
Step 143735: loss = 0.11397
Step 143740: loss = 0.05301
Step 143745: loss = 0.24399
Step 143750: loss = 0.05266
Step 143755: loss = 0.03655
Step 143760: loss = 0.05486
Step 143765: loss = 0.18258
Step 143770: loss = 0.12811
Step 143775: loss = 0.01390
Step 143780: loss = 0.23035
Step 143785: loss = 0.14750
Step 143790: loss = 0.18480
Step 143795: loss = 0.04845
Step 143800: loss = 0.20524
Step 143805: loss = 0.30978
Step 143810: loss = 0.07487
Step 143815: loss = 0.04963
Step 143820: loss = 0.17515
Step 143825: loss = 0.10674
Step 143830: loss = 0.11776
Step 143835: loss = 0.09024
Step 143840: loss = 0.05349
Step 143845: loss = 0.24595
Step 143850: loss = 0.15660
Step 143855: loss = 0.16018
Step 143860: loss = 0.15209
Step 143865: loss = 0.12461
Step 143870: loss = 0.16206
Step 143875: loss = 0.09139
Step 143880: loss = 0.09259
Step 143885: loss = 0.03968
Step 143890: loss = 0.21596
Step 143895: loss = 0.13555
Step 143900: loss = 0.02774
Step 143905: loss = 0.14041
Step 143910: loss = 0.05357
Step 143915: loss = 0.05355
Step 143920: loss = 0.25434
Step 143925: loss = 0.12823
Step 143930: loss = 0.19128
Step 143935: loss = 0.20116
Step 143940: loss = 0.06655
Step 143945: loss = 0.22576
Step 143950: loss = 0.17943
Step 143955: loss = 0.17085
Step 143960: loss = 0.08101
Step 143965: loss = 0.14119
Step 143970: loss = 0.02913
Step 143975: loss = 0.04239
Step 143980: loss = 0.25441
Step 143985: loss = 0.17974
Step 143990: loss = 0.19145
Step 143995: loss = 0.23246
Step 144000: loss = 0.05967
Training Data Eval:
  Num examples: 50000, Num correct: 47564, Precision @ 1: 0.9513
('Testing Data Eval: EPOCH->', 145)
  Num examples: 10000, Num correct: 6506, Precision @ 1: 0.6506
Step 144005: loss = 0.15880
Step 144010: loss = 0.17484
Step 144015: loss = 0.13319
Step 144020: loss = 0.12389
Step 144025: loss = 0.12578
Step 144030: loss = 0.19849
Step 144035: loss = 0.17271
Step 144040: loss = 0.08601
Step 144045: loss = 0.06736
Step 144050: loss = 0.07368
Step 144055: loss = 0.07781
Step 144060: loss = 0.07764
Step 144065: loss = 0.09626
Step 144070: loss = 0.06226
Step 144075: loss = 0.09962
Step 144080: loss = 0.11134
Step 144085: loss = 0.02810
Step 144090: loss = 0.08891
Step 144095: loss = 0.23158
Step 144100: loss = 0.14725
Step 144105: loss = 0.02615
Step 144110: loss = 0.26625
Step 144115: loss = 0.13461
Step 144120: loss = 0.06252
Step 144125: loss = 0.27170
Step 144130: loss = 0.13019
Step 144135: loss = 0.23004
Step 144140: loss = 0.03187
Step 144145: loss = 0.01888
Step 144150: loss = 0.19906
Step 144155: loss = 0.07990
Step 144160: loss = 0.08249
Step 144165: loss = 0.10911
Step 144170: loss = 0.07542
Step 144175: loss = 0.18793
Step 144180: loss = 0.13914
Step 144185: loss = 0.26487
Step 144190: loss = 0.09273
Step 144195: loss = 0.12195
Step 144200: loss = 0.09463
Step 144205: loss = 0.54390
Step 144210: loss = 0.16831
Step 144215: loss = 0.11893
Step 144220: loss = 0.05664
Step 144225: loss = 0.23000
Step 144230: loss = 0.17716
Step 144235: loss = 0.25325
Step 144240: loss = 0.08939
Step 144245: loss = 0.03956
Step 144250: loss = 0.12865
Step 144255: loss = 0.03017
Step 144260: loss = 0.07419
Step 144265: loss = 0.07814
Step 144270: loss = 0.25081
Step 144275: loss = 0.13071
Step 144280: loss = 0.04541
Step 144285: loss = 0.03494
Step 144290: loss = 0.30387
Step 144295: loss = 0.39777
Step 144300: loss = 0.10894
Step 144305: loss = 0.11016
Step 144310: loss = 0.09087
Step 144315: loss = 0.07088
Step 144320: loss = 0.10754
Step 144325: loss = 0.20426
Step 144330: loss = 0.18753
Step 144335: loss = 0.04402
Step 144340: loss = 0.10129
Step 144345: loss = 0.14809
Step 144350: loss = 0.03334
Step 144355: loss = 0.09484
Step 144360: loss = 0.14030
Step 144365: loss = 0.04545
Step 144370: loss = 0.28086
Step 144375: loss = 0.11930
Step 144380: loss = 0.13617
Step 144385: loss = 0.32569
Step 144390: loss = 0.30325
Step 144395: loss = 0.08799
Step 144400: loss = 0.17208
Step 144405: loss = 0.08981
Step 144410: loss = 0.10739
Step 144415: loss = 0.09426
Step 144420: loss = 0.24556
Step 144425: loss = 0.20026
Step 144430: loss = 0.04319
Step 144435: loss = 0.13096
Step 144440: loss = 0.17087
Step 144445: loss = 0.24786
Step 144450: loss = 0.07718
Step 144455: loss = 0.10261
Step 144460: loss = 0.06843
Step 144465: loss = 0.15970
Step 144470: loss = 0.24490
Step 144475: loss = 0.05445
Step 144480: loss = 0.08186
Step 144485: loss = 0.05158
Step 144490: loss = 0.05780
Step 144495: loss = 0.26982
Step 144500: loss = 0.13231
Step 144505: loss = 0.19025
Step 144510: loss = 0.21436
Step 144515: loss = 0.19541
Step 144520: loss = 0.11677
Step 144525: loss = 0.10318
Step 144530: loss = 0.06393
Step 144535: loss = 0.04984
Step 144540: loss = 0.22766
Step 144545: loss = 0.04198
Step 144550: loss = 0.16029
Step 144555: loss = 0.17667
Step 144560: loss = 0.06097
Step 144565: loss = 0.06256
Step 144570: loss = 0.07056
Step 144575: loss = 0.21767
Step 144580: loss = 0.10977
Step 144585: loss = 0.09902
Step 144590: loss = 0.02897
Step 144595: loss = 0.05674
Step 144600: loss = 0.10193
Step 144605: loss = 0.19719
Step 144610: loss = 0.06545
Step 144615: loss = 0.11880
Step 144620: loss = 0.21965
Step 144625: loss = 0.07310
Step 144630: loss = 0.10023
Step 144635: loss = 0.05358
Step 144640: loss = 0.21372
Step 144645: loss = 0.06999
Step 144650: loss = 0.03487
Step 144655: loss = 0.10730
Step 144660: loss = 0.07473
Step 144665: loss = 0.17493
Step 144670: loss = 0.23876
Step 144675: loss = 0.14253
Step 144680: loss = 0.09015
Step 144685: loss = 0.06177
Step 144690: loss = 0.09378
Step 144695: loss = 0.34643
Step 144700: loss = 0.13012
Step 144705: loss = 0.05471
Step 144710: loss = 0.10524
Step 144715: loss = 0.06694
Step 144720: loss = 0.03479
Step 144725: loss = 0.19062
Step 144730: loss = 0.28440
Step 144735: loss = 0.15162
Step 144740: loss = 0.26065
Step 144745: loss = 0.16187
Step 144750: loss = 0.12462
Step 144755: loss = 0.25535
Step 144760: loss = 0.04260
Step 144765: loss = 0.20522
Step 144770: loss = 0.18021
Step 144775: loss = 0.12504
Step 144780: loss = 0.17805
Step 144785: loss = 0.10804
Step 144790: loss = 0.15528
Step 144795: loss = 0.14029
Step 144800: loss = 0.07227
Step 144805: loss = 0.20565
Step 144810: loss = 0.22422
Step 144815: loss = 0.24979
Step 144820: loss = 0.05603
Step 144825: loss = 0.04841
Step 144830: loss = 0.13194
Step 144835: loss = 0.29348
Step 144840: loss = 0.39493
Step 144845: loss = 0.05342
Step 144850: loss = 0.16996
Step 144855: loss = 0.17453
Step 144860: loss = 0.09468
Step 144865: loss = 0.19489
Step 144870: loss = 0.11084
Step 144875: loss = 0.37519
Step 144880: loss = 0.15977
Step 144885: loss = 0.24374
Step 144890: loss = 0.17862
Step 144895: loss = 0.04658
Step 144900: loss = 0.18138
Step 144905: loss = 0.12992
Step 144910: loss = 0.25332
Step 144915: loss = 0.14385
Step 144920: loss = 0.22498
Step 144925: loss = 0.15060
Step 144930: loss = 0.40832
Step 144935: loss = 0.09187
Step 144940: loss = 0.16040
Step 144945: loss = 0.29399
Step 144950: loss = 0.12811
Step 144955: loss = 0.13612
Step 144960: loss = 0.04266
Step 144965: loss = 0.02491
Step 144970: loss = 0.08107
Step 144975: loss = 0.09736
Step 144980: loss = 0.22700
Step 144985: loss = 0.08791
Step 144990: loss = 0.07177
Step 144995: loss = 0.09291
Step 145000: loss = 0.11837
Training Data Eval:
  Num examples: 50000, Num correct: 47811, Precision @ 1: 0.9562
('Testing Data Eval: EPOCH->', 146)
  Num examples: 10000, Num correct: 6644, Precision @ 1: 0.6644
Step 145005: loss = 0.17450
Step 145010: loss = 0.09359
Step 145015: loss = 0.08504
Step 145020: loss = 0.14706
Step 145025: loss = 0.33649
Step 145030: loss = 0.36327
Step 145035: loss = 0.14729
Step 145040: loss = 0.16124
Step 145045: loss = 0.16132
Step 145050: loss = 0.16689
Step 145055: loss = 0.13251
Step 145060: loss = 0.14597
Step 145065: loss = 0.09609
Step 145070: loss = 0.11527
Step 145075: loss = 0.10627
Step 145080: loss = 0.18843
Step 145085: loss = 0.06983
Step 145090: loss = 0.19513
Step 145095: loss = 0.02103
Step 145100: loss = 0.07884
Step 145105: loss = 0.21681
Step 145110: loss = 0.04158
Step 145115: loss = 0.08420
Step 145120: loss = 0.20383
Step 145125: loss = 0.06454
Step 145130: loss = 0.12344
Step 145135: loss = 0.07844
Step 145140: loss = 0.17908
Step 145145: loss = 0.04369
Step 145150: loss = 0.05599
Step 145155: loss = 0.04342
Step 145160: loss = 0.11841
Step 145165: loss = 0.03409
Step 145170: loss = 0.15764
Step 145175: loss = 0.11838
Step 145180: loss = 0.24844
Step 145185: loss = 0.07453
Step 145190: loss = 0.17552
Step 145195: loss = 0.13952
Step 145200: loss = 0.06012
Step 145205: loss = 0.12768
Step 145210: loss = 0.08861
Step 145215: loss = 0.12522
Step 145220: loss = 0.11421
Step 145225: loss = 0.11771
Step 145230: loss = 0.10635
Step 145235: loss = 0.24886
Step 145240: loss = 0.07047
Step 145245: loss = 0.14442
Step 145250: loss = 0.05699
Step 145255: loss = 0.04275
Step 145260: loss = 0.13755
Step 145265: loss = 0.10890
Step 145270: loss = 0.18344
Step 145275: loss = 0.18807
Step 145280: loss = 0.07505
Step 145285: loss = 0.27005
Step 145290: loss = 0.10705
Step 145295: loss = 0.24343
Step 145300: loss = 0.28432
Step 145305: loss = 0.14952
Step 145310: loss = 0.04079
Step 145315: loss = 0.34944
Step 145320: loss = 0.14458
Step 145325: loss = 0.09644
Step 145330: loss = 0.15218
Step 145335: loss = 0.02969
Step 145340: loss = 0.10836
Step 145345: loss = 0.20496
Step 145350: loss = 0.11007
Step 145355: loss = 0.17141
Step 145360: loss = 0.10492
Step 145365: loss = 0.11010
Step 145370: loss = 0.07268
Step 145375: loss = 0.15239
Step 145380: loss = 0.16515
Step 145385: loss = 0.04296
Step 145390: loss = 0.20980
Step 145395: loss = 0.09168
Step 145400: loss = 0.19278
Step 145405: loss = 0.11907
Step 145410: loss = 0.11346
Step 145415: loss = 0.05802
Step 145420: loss = 0.03178
Step 145425: loss = 0.03604
Step 145430: loss = 0.06803
Step 145435: loss = 0.15211
Step 145440: loss = 0.17685
Step 145445: loss = 0.08897
Step 145450: loss = 0.12984
Step 145455: loss = 0.20455
Step 145460: loss = 0.08934
Step 145465: loss = 0.13389
Step 145470: loss = 0.04428
Step 145475: loss = 0.15745
Step 145480: loss = 0.05335
Step 145485: loss = 0.23922
Step 145490: loss = 0.04773
Step 145495: loss = 0.17603
Step 145500: loss = 0.05246
Step 145505: loss = 0.32141
Step 145510: loss = 0.04085
Step 145515: loss = 0.16483
Step 145520: loss = 0.11306
Step 145525: loss = 0.16279
Step 145530: loss = 0.08797
Step 145535: loss = 0.05816
Step 145540: loss = 0.06747
Step 145545: loss = 0.02037
Step 145550: loss = 0.10294
Step 145555: loss = 0.16772
Step 145560: loss = 0.10817
Step 145565: loss = 0.06652
Step 145570: loss = 0.40096
Step 145575: loss = 0.19106
Step 145580: loss = 0.11568
Step 145585: loss = 0.38943
Step 145590: loss = 0.18512
Step 145595: loss = 0.06090
Step 145600: loss = 0.12996
Step 145605: loss = 0.08472
Step 145610: loss = 0.21706
Step 145615: loss = 0.21130
Step 145620: loss = 0.06323
Step 145625: loss = 0.11032
Step 145630: loss = 0.05410
Step 145635: loss = 0.17124
Step 145640: loss = 0.11677
Step 145645: loss = 0.14047
Step 145650: loss = 0.08218
Step 145655: loss = 0.16728
Step 145660: loss = 0.06123
Step 145665: loss = 0.05570
Step 145670: loss = 0.11942
Step 145675: loss = 0.09840
Step 145680: loss = 0.04159
Step 145685: loss = 0.15386
Step 145690: loss = 0.10278
Step 145695: loss = 0.03963
Step 145700: loss = 0.27088
Step 145705: loss = 0.11907
Step 145710: loss = 0.11919
Step 145715: loss = 0.35226
Step 145720: loss = 0.15527
Step 145725: loss = 0.16538
Step 145730: loss = 0.04307
Step 145735: loss = 0.13422
Step 145740: loss = 0.07977
Step 145745: loss = 0.23325
Step 145750: loss = 0.07192
Step 145755: loss = 0.09652
Step 145760: loss = 0.19256
Step 145765: loss = 0.32713
Step 145770: loss = 0.20586
Step 145775: loss = 0.03937
Step 145780: loss = 0.27156
Step 145785: loss = 0.16336
Step 145790: loss = 0.13868
Step 145795: loss = 0.24306
Step 145800: loss = 0.19774
Step 145805: loss = 0.21851
Step 145810: loss = 0.09631
Step 145815: loss = 0.04929
Step 145820: loss = 0.12307
Step 145825: loss = 0.16739
Step 145830: loss = 0.05232
Step 145835: loss = 0.13681
Step 145840: loss = 0.12779
Step 145845: loss = 0.12538
Step 145850: loss = 0.05942
Step 145855: loss = 0.03430
Step 145860: loss = 0.02926
Step 145865: loss = 0.20161
Step 145870: loss = 0.12118
Step 145875: loss = 0.01901
Step 145880: loss = 0.05520
Step 145885: loss = 0.05743
Step 145890: loss = 0.27980
Step 145895: loss = 0.12527
Step 145900: loss = 0.14878
Step 145905: loss = 0.08939
Step 145910: loss = 0.17551
Step 145915: loss = 0.08474
Step 145920: loss = 0.23826
Step 145925: loss = 0.12873
Step 145930: loss = 0.10015
Step 145935: loss = 0.08793
Step 145940: loss = 0.16332
Step 145945: loss = 0.11927
Step 145950: loss = 0.07381
Step 145955: loss = 0.02820
Step 145960: loss = 0.16676
Step 145965: loss = 0.08034
Step 145970: loss = 0.12770
Step 145975: loss = 0.10288
Step 145980: loss = 0.08099
Step 145985: loss = 0.17931
Step 145990: loss = 0.15424
Step 145995: loss = 0.05536
Step 146000: loss = 0.17152
Training Data Eval:
  Num examples: 50000, Num correct: 47810, Precision @ 1: 0.9562
('Testing Data Eval: EPOCH->', 147)
  Num examples: 10000, Num correct: 6657, Precision @ 1: 0.6657
Step 146005: loss = 0.04595
Step 146010: loss = 0.04752
Step 146015: loss = 0.08853
Step 146020: loss = 0.08212
Step 146025: loss = 0.17879
Step 146030: loss = 0.20087
Step 146035: loss = 0.07442
Step 146040: loss = 0.05931
Step 146045: loss = 0.05563
Step 146050: loss = 0.17498
Step 146055: loss = 0.04938
Step 146060: loss = 0.10334
Step 146065: loss = 0.05613
Step 146070: loss = 0.27816
Step 146075: loss = 0.08898
Step 146080: loss = 0.04757
Step 146085: loss = 0.12246
Step 146090: loss = 0.03356
Step 146095: loss = 0.13557
Step 146100: loss = 0.02350
Step 146105: loss = 0.09059
Step 146110: loss = 0.08133
Step 146115: loss = 0.09413
Step 146120: loss = 0.10463
Step 146125: loss = 0.06338
Step 146130: loss = 0.08004
Step 146135: loss = 0.18876
Step 146140: loss = 0.09790
Step 146145: loss = 0.21200
Step 146150: loss = 0.04028
Step 146155: loss = 0.10180
Step 146160: loss = 0.11611
Step 146165: loss = 0.25110
Step 146170: loss = 0.27094
Step 146175: loss = 0.11416
Step 146180: loss = 0.06923
Step 146185: loss = 0.25237
Step 146190: loss = 0.22910
Step 146195: loss = 0.11850
Step 146200: loss = 0.13729
Step 146205: loss = 0.31611
Step 146210: loss = 0.10638
Step 146215: loss = 0.15300
Step 146220: loss = 0.05230
Step 146225: loss = 0.12076
Step 146230: loss = 0.13245
Step 146235: loss = 0.15242
Step 146240: loss = 0.20349
Step 146245: loss = 0.11988
Step 146250: loss = 0.04558
Step 146255: loss = 0.05392
Step 146260: loss = 0.38038
Step 146265: loss = 0.08613
Step 146270: loss = 0.11740
Step 146275: loss = 0.05453
Step 146280: loss = 0.26741
Step 146285: loss = 0.08648
Step 146290: loss = 0.04286
Step 146295: loss = 0.06942
Step 146300: loss = 0.17301
Step 146305: loss = 0.14027
Step 146310: loss = 0.12100
Step 146315: loss = 0.28301
Step 146320: loss = 0.08401
Step 146325: loss = 0.20647
Step 146330: loss = 0.13013
Step 146335: loss = 0.14415
Step 146340: loss = 0.21253
Step 146345: loss = 0.12110
Step 146350: loss = 0.09575
Step 146355: loss = 0.22873
Step 146360: loss = 0.15933
Step 146365: loss = 0.03671
Step 146370: loss = 0.07830
Step 146375: loss = 0.13394
Step 146380: loss = 0.03820
Step 146385: loss = 0.05976
Step 146390: loss = 0.04424
Step 146395: loss = 0.26790
Step 146400: loss = 0.13661
Step 146405: loss = 0.10309
Step 146410: loss = 0.09260
Step 146415: loss = 0.12979
Step 146420: loss = 0.07303
Step 146425: loss = 0.18868
Step 146430: loss = 0.14273
Step 146435: loss = 0.28806
Step 146440: loss = 0.27757
Step 146445: loss = 0.22592
Step 146450: loss = 0.01972
Step 146455: loss = 0.04938
Step 146460: loss = 0.15993
Step 146465: loss = 0.23810
Step 146470: loss = 0.04597
Step 146475: loss = 0.18987
Step 146480: loss = 0.14334
Step 146485: loss = 0.07769
Step 146490: loss = 0.13983
Step 146495: loss = 0.08838
Step 146500: loss = 0.20838
Step 146505: loss = 0.07675
Step 146510: loss = 0.07512
Step 146515: loss = 0.03376
Step 146520: loss = 0.07775
Step 146525: loss = 0.13936
Step 146530: loss = 0.08209
Step 146535: loss = 0.09701
Step 146540: loss = 0.14665
Step 146545: loss = 0.09791
Step 146550: loss = 0.05578
Step 146555: loss = 0.24204
Step 146560: loss = 0.14830
Step 146565: loss = 0.05597
Step 146570: loss = 0.12378
Step 146575: loss = 0.41033
Step 146580: loss = 0.09277
Step 146585: loss = 0.17719
Step 146590: loss = 0.10850
Step 146595: loss = 0.11972
Step 146600: loss = 0.09972
Step 146605: loss = 0.06898
Step 146610: loss = 0.09518
Step 146615: loss = 0.18735
Step 146620: loss = 0.32098
Step 146625: loss = 0.34513
Step 146630: loss = 0.16079
Step 146635: loss = 0.13816
Step 146640: loss = 0.23431
Step 146645: loss = 0.06004
Step 146650: loss = 0.17412
Step 146655: loss = 0.03615
Step 146660: loss = 0.10863
Step 146665: loss = 0.10952
Step 146670: loss = 0.08227
Step 146675: loss = 0.10822
Step 146680: loss = 0.17136
Step 146685: loss = 0.37294
Step 146690: loss = 0.24752
Step 146695: loss = 0.09439
Step 146700: loss = 0.35933
Step 146705: loss = 0.10792
Step 146710: loss = 0.11065
Step 146715: loss = 0.04310
Step 146720: loss = 0.07721
Step 146725: loss = 0.16976
Step 146730: loss = 0.15365
Step 146735: loss = 0.07238
Step 146740: loss = 0.07082
Step 146745: loss = 0.15670
Step 146750: loss = 0.07196
Step 146755: loss = 0.20208
Step 146760: loss = 0.15957
Step 146765: loss = 0.14055
Step 146770: loss = 0.23007
Step 146775: loss = 0.07353
Step 146780: loss = 0.17305
Step 146785: loss = 0.05331
Step 146790: loss = 0.02867
Step 146795: loss = 0.14641
Step 146800: loss = 0.21709
Step 146805: loss = 0.06749
Step 146810: loss = 0.11246
Step 146815: loss = 0.07625
Step 146820: loss = 0.20263
Step 146825: loss = 0.09101
Step 146830: loss = 0.09126
Step 146835: loss = 0.14427
Step 146840: loss = 0.21732
Step 146845: loss = 0.23163
Step 146850: loss = 0.04714
Step 146855: loss = 0.34629
Step 146860: loss = 0.09150
Step 146865: loss = 0.25311
Step 146870: loss = 0.21019
Step 146875: loss = 0.09920
Step 146880: loss = 0.10768
Step 146885: loss = 0.03546
Step 146890: loss = 0.11157
Step 146895: loss = 0.11407
Step 146900: loss = 0.20165
Step 146905: loss = 0.05247
Step 146910: loss = 0.07808
Step 146915: loss = 0.10091
Step 146920: loss = 0.05755
Step 146925: loss = 0.17562
Step 146930: loss = 0.13580
Step 146935: loss = 0.11628
Step 146940: loss = 0.07076
Step 146945: loss = 0.06396
Step 146950: loss = 0.15484
Step 146955: loss = 0.16545
Step 146960: loss = 0.08274
Step 146965: loss = 0.08767
Step 146970: loss = 0.06407
Step 146975: loss = 0.22458
Step 146980: loss = 0.04373
Step 146985: loss = 0.06146
Step 146990: loss = 0.24682
Step 146995: loss = 0.09164
Step 147000: loss = 0.10303
Training Data Eval:
  Num examples: 50000, Num correct: 47805, Precision @ 1: 0.9561
('Testing Data Eval: EPOCH->', 148)
  Num examples: 10000, Num correct: 6620, Precision @ 1: 0.6620
Step 147005: loss = 0.11264
Step 147010: loss = 0.20176
Step 147015: loss = 0.12057
Step 147020: loss = 0.43497
Step 147025: loss = 0.07391
Step 147030: loss = 0.21224
Step 147035: loss = 0.11536
Step 147040: loss = 0.04865
Step 147045: loss = 0.21256
Step 147050: loss = 0.09591
Step 147055: loss = 0.09249
Step 147060: loss = 0.21654
Step 147065: loss = 0.18420
Step 147070: loss = 0.13474
Step 147075: loss = 0.16070
Step 147080: loss = 0.06882
Step 147085: loss = 0.09529
Step 147090: loss = 0.30915
Step 147095: loss = 0.10304
Step 147100: loss = 0.04501
Step 147105: loss = 0.29163
Step 147110: loss = 0.29366
Step 147115: loss = 0.05160
Step 147120: loss = 0.11362
Step 147125: loss = 0.15706
Step 147130: loss = 0.09095
Step 147135: loss = 0.04188
Step 147140: loss = 0.10261
Step 147145: loss = 0.05516
Step 147150: loss = 0.04311
Step 147155: loss = 0.09587
Step 147160: loss = 0.17095
Step 147165: loss = 0.16650
Step 147170: loss = 0.19290
Step 147175: loss = 0.05589
Step 147180: loss = 0.09141
Step 147185: loss = 0.04523
Step 147190: loss = 0.10762
Step 147195: loss = 0.12940
Step 147200: loss = 0.09991
Step 147205: loss = 0.06027
Step 147210: loss = 0.06662
Step 147215: loss = 0.14958
Step 147220: loss = 0.05618
Step 147225: loss = 0.05902
Step 147230: loss = 0.08668
Step 147235: loss = 0.27952
Step 147240: loss = 0.12293
Step 147245: loss = 0.08563
Step 147250: loss = 0.03755
Step 147255: loss = 0.05457
Step 147260: loss = 0.11613
Step 147265: loss = 0.08701
Step 147270: loss = 0.11179
Step 147275: loss = 0.11539
Step 147280: loss = 0.05485
Step 147285: loss = 0.15742
Step 147290: loss = 0.06459
Step 147295: loss = 0.15128
Step 147300: loss = 0.06197
Step 147305: loss = 0.07156
Step 147310: loss = 0.34210
Step 147315: loss = 0.11594
Step 147320: loss = 0.09562
Step 147325: loss = 0.13741
Step 147330: loss = 0.06469
Step 147335: loss = 0.13252
Step 147340: loss = 0.16675
Step 147345: loss = 0.12986
Step 147350: loss = 0.15410
Step 147355: loss = 0.19818
Step 147360: loss = 0.26139
Step 147365: loss = 0.07237
Step 147370: loss = 0.08746
Step 147375: loss = 0.05651
Step 147380: loss = 0.01859
Step 147385: loss = 0.15878
Step 147390: loss = 0.20984
Step 147395: loss = 0.09798
Step 147400: loss = 0.17061
Step 147405: loss = 0.08370
Step 147410: loss = 0.10922
Step 147415: loss = 0.04116
Step 147420: loss = 0.08779
Step 147425: loss = 0.12148
Step 147430: loss = 0.08986
Step 147435: loss = 0.10295
Step 147440: loss = 0.20654
Step 147445: loss = 0.10131
Step 147450: loss = 0.06480
Step 147455: loss = 0.05147
Step 147460: loss = 0.27199
Step 147465: loss = 0.53987
Step 147470: loss = 0.04706
Step 147475: loss = 0.30507
Step 147480: loss = 0.12331
Step 147485: loss = 0.08754
Step 147490: loss = 0.28518
Step 147495: loss = 0.14456
Step 147500: loss = 0.34469
Step 147505: loss = 0.04236
Step 147510: loss = 0.21059
Step 147515: loss = 0.05263
Step 147520: loss = 0.25684
Step 147525: loss = 0.08172
Step 147530: loss = 0.11995
Step 147535: loss = 0.22685
Step 147540: loss = 0.14990
Step 147545: loss = 0.06466
Step 147550: loss = 0.03047
Step 147555: loss = 0.07189
Step 147560: loss = 0.16300
Step 147565: loss = 0.13064
Step 147570: loss = 0.08480
Step 147575: loss = 0.05622
Step 147580: loss = 0.15566
Step 147585: loss = 0.18668
Step 147590: loss = 0.02949
Step 147595: loss = 0.04943
Step 147600: loss = 0.06516
Step 147605: loss = 0.06327
Step 147610: loss = 0.18401
Step 147615: loss = 0.17518
Step 147620: loss = 0.02609
Step 147625: loss = 0.14566
Step 147630: loss = 0.03652
Step 147635: loss = 0.16200
Step 147640: loss = 0.18811
Step 147645: loss = 0.31933
Step 147650: loss = 0.18068
Step 147655: loss = 0.16782
Step 147660: loss = 0.07045
Step 147665: loss = 0.10819
Step 147670: loss = 0.09041
Step 147675: loss = 0.05540
Step 147680: loss = 0.07470
Step 147685: loss = 0.09194
Step 147690: loss = 0.15507
Step 147695: loss = 0.20897
Step 147700: loss = 0.05755
Step 147705: loss = 0.08279
Step 147710: loss = 0.36948
Step 147715: loss = 0.03159
Step 147720: loss = 0.04523
Step 147725: loss = 0.31355
Step 147730: loss = 0.27628
Step 147735: loss = 0.09240
Step 147740: loss = 0.15260
Step 147745: loss = 0.26526
Step 147750: loss = 0.27823
Step 147755: loss = 0.16034
Step 147760: loss = 0.34181
Step 147765: loss = 0.04857
Step 147770: loss = 0.03608
Step 147775: loss = 0.38213
Step 147780: loss = 0.07429
Step 147785: loss = 0.17724
Step 147790: loss = 0.17778
Step 147795: loss = 0.12888
Step 147800: loss = 0.11003
Step 147805: loss = 0.24716
Step 147810: loss = 0.05772
Step 147815: loss = 0.07303
Step 147820: loss = 0.03095
Step 147825: loss = 0.08014
Step 147830: loss = 0.04245
Step 147835: loss = 0.18733
Step 147840: loss = 0.11491
Step 147845: loss = 0.31392
Step 147850: loss = 0.13249
Step 147855: loss = 0.15924
Step 147860: loss = 0.15514
Step 147865: loss = 0.06724
Step 147870: loss = 0.18124
Step 147875: loss = 0.06193
Step 147880: loss = 0.33286
Step 147885: loss = 0.05353
Step 147890: loss = 0.18402
Step 147895: loss = 0.13154
Step 147900: loss = 0.06358
Step 147905: loss = 0.15789
Step 147910: loss = 0.11733
Step 147915: loss = 0.04718
Step 147920: loss = 0.08740
Step 147925: loss = 0.01094
Step 147930: loss = 0.20657
Step 147935: loss = 0.17144
Step 147940: loss = 0.08454
Step 147945: loss = 0.07432
Step 147950: loss = 0.03419
Step 147955: loss = 0.12486
Step 147960: loss = 0.19999
Step 147965: loss = 0.04541
Step 147970: loss = 0.13184
Step 147975: loss = 0.04943
Step 147980: loss = 0.08774
Step 147985: loss = 0.16330
Step 147990: loss = 0.10040
Step 147995: loss = 0.06233
Step 148000: loss = 0.05323
Training Data Eval:
  Num examples: 50000, Num correct: 47898, Precision @ 1: 0.9580
('Testing Data Eval: EPOCH->', 149)
  Num examples: 10000, Num correct: 6725, Precision @ 1: 0.6725
Step 148005: loss = 0.11478
Step 148010: loss = 0.07170
Step 148015: loss = 0.17038
Step 148020: loss = 0.05936
Step 148025: loss = 0.12864
Step 148030: loss = 0.10278
Step 148035: loss = 0.06904
Step 148040: loss = 0.07990
Step 148045: loss = 0.04639
Step 148050: loss = 0.02999
Step 148055: loss = 0.09879
Step 148060: loss = 0.24600
Step 148065: loss = 0.21256
Step 148070: loss = 0.09489
Step 148075: loss = 0.17077
Step 148080: loss = 0.23613
Step 148085: loss = 0.10040
Step 148090: loss = 0.29467
Step 148095: loss = 0.33340
Step 148100: loss = 0.02593
Step 148105: loss = 0.06971
Step 148110: loss = 0.26294
Step 148115: loss = 0.06270
Step 148120: loss = 0.19265
Step 148125: loss = 0.06888
Step 148130: loss = 0.30888
Step 148135: loss = 0.48370
Step 148140: loss = 0.11174
Step 148145: loss = 0.19668
Step 148150: loss = 0.23624
Step 148155: loss = 0.07865
Step 148160: loss = 0.05541
Step 148165: loss = 0.14739
Step 148170: loss = 0.32580
Step 148175: loss = 0.10574
Step 148180: loss = 0.09503
Step 148185: loss = 0.05805
Step 148190: loss = 0.23441
Step 148195: loss = 0.08954
Step 148200: loss = 0.15020
Step 148205: loss = 0.15520
Step 148210: loss = 0.10208
Step 148215: loss = 0.07967
Step 148220: loss = 0.34184
Step 148225: loss = 0.31251
Step 148230: loss = 0.08546
Step 148235: loss = 0.17048
Step 148240: loss = 0.20290
Step 148245: loss = 0.20770
Step 148250: loss = 0.22281
Step 148255: loss = 0.07563
Step 148260: loss = 0.07678
Step 148265: loss = 0.07828
Step 148270: loss = 0.10803
Step 148275: loss = 0.24068
Step 148280: loss = 0.14211
Step 148285: loss = 0.04880
Step 148290: loss = 0.17464
Step 148295: loss = 0.11616
Step 148300: loss = 0.20182
Step 148305: loss = 0.09054
Step 148310: loss = 0.03999
Step 148315: loss = 0.10238
Step 148320: loss = 0.13760
Step 148325: loss = 0.17115
Step 148330: loss = 0.23505
Step 148335: loss = 0.07877
Step 148340: loss = 0.09296
Step 148345: loss = 0.04253
Step 148350: loss = 0.10477
Step 148355: loss = 0.26367
Step 148360: loss = 0.32537
Step 148365: loss = 0.29570
Step 148370: loss = 0.07617
Step 148375: loss = 0.16487
Step 148380: loss = 0.37985
Step 148385: loss = 0.03279
Step 148390: loss = 0.05315
Step 148395: loss = 0.01551
Step 148400: loss = 0.09897
Step 148405: loss = 0.07294
Step 148410: loss = 0.01986
Step 148415: loss = 0.33906
Step 148420: loss = 0.22735
Step 148425: loss = 0.05616
Step 148430: loss = 0.03701
Step 148435: loss = 0.09969
Step 148440: loss = 0.07809
Step 148445: loss = 0.09701
Step 148450: loss = 0.10615
Step 148455: loss = 0.18121
Step 148460: loss = 0.16477
Step 148465: loss = 0.17040
Step 148470: loss = 0.04757
Step 148475: loss = 0.11177
Step 148480: loss = 0.31713
Step 148485: loss = 0.03824
Step 148490: loss = 0.10855
Step 148495: loss = 0.34324
Step 148500: loss = 0.16948
Step 148505: loss = 0.06110
Step 148510: loss = 0.13027
Step 148515: loss = 0.04493
Step 148520: loss = 0.04844
Step 148525: loss = 0.14490
Step 148530: loss = 0.09850
Step 148535: loss = 0.15544
Step 148540: loss = 0.13482
Step 148545: loss = 0.09225
Step 148550: loss = 0.08127
Step 148555: loss = 0.24649
Step 148560: loss = 0.09644
Step 148565: loss = 0.11110
Step 148570: loss = 0.12271
Step 148575: loss = 0.07751
Step 148580: loss = 0.10083
Step 148585: loss = 0.04454
Step 148590: loss = 0.03531
Step 148595: loss = 0.35118
Step 148600: loss = 0.08370
Step 148605: loss = 0.05281
Step 148610: loss = 0.08226
Step 148615: loss = 0.14883
Step 148620: loss = 0.18401
Step 148625: loss = 0.04964
Step 148630: loss = 0.05436
Step 148635: loss = 0.08194
Step 148640: loss = 0.08650
Step 148645: loss = 0.02567
Step 148650: loss = 0.02596
Step 148655: loss = 0.07582
Step 148660: loss = 0.16312
Step 148665: loss = 0.21462
Step 148670: loss = 0.03057
Step 148675: loss = 0.15499
Step 148680: loss = 0.12831
Step 148685: loss = 0.16030
Step 148690: loss = 0.07919
Step 148695: loss = 0.04609
Step 148700: loss = 0.03180
Step 148705: loss = 0.10703
Step 148710: loss = 0.18069
Step 148715: loss = 0.11930
Step 148720: loss = 0.09143
Step 148725: loss = 0.11554
Step 148730: loss = 0.11198
Step 148735: loss = 0.03078
Step 148740: loss = 0.05175
Step 148745: loss = 0.08775
Step 148750: loss = 0.10825
Step 148755: loss = 0.06907
Step 148760: loss = 0.05575
Step 148765: loss = 0.06449
Step 148770: loss = 0.10579
Step 148775: loss = 0.08072
Step 148780: loss = 0.17045
Step 148785: loss = 0.20613
Step 148790: loss = 0.06014
Step 148795: loss = 0.11458
Step 148800: loss = 0.28437
Step 148805: loss = 0.11146
Step 148810: loss = 0.12581
Step 148815: loss = 0.12990
Step 148820: loss = 0.10574
Step 148825: loss = 0.08519
Step 148830: loss = 0.06243
Step 148835: loss = 0.11789
Step 148840: loss = 0.16044
Step 148845: loss = 0.12944
Step 148850: loss = 0.17073
Step 148855: loss = 0.16409
Step 148860: loss = 0.06166
Step 148865: loss = 0.12415
Step 148870: loss = 0.05949
Step 148875: loss = 0.14384
Step 148880: loss = 0.16365
Step 148885: loss = 0.13411
Step 148890: loss = 0.03774
Step 148895: loss = 0.10679
Step 148900: loss = 0.04239
Step 148905: loss = 0.09224
Step 148910: loss = 0.09516
Step 148915: loss = 0.19316
Step 148920: loss = 0.23141
Step 148925: loss = 0.19336
Step 148930: loss = 0.20966
Step 148935: loss = 0.15512
Step 148940: loss = 0.13446
Step 148945: loss = 0.06087
Step 148950: loss = 0.05990
Step 148955: loss = 0.09561
Step 148960: loss = 0.11820
Step 148965: loss = 0.22047
Step 148970: loss = 0.04272
Step 148975: loss = 0.16973
Step 148980: loss = 0.05994
Step 148985: loss = 0.07651
Step 148990: loss = 0.09321
Step 148995: loss = 0.10647
Step 149000: loss = 0.11006
Training Data Eval:
  Num examples: 50000, Num correct: 47724, Precision @ 1: 0.9545
('Testing Data Eval: EPOCH->', 150)
  Num examples: 10000, Num correct: 6721, Precision @ 1: 0.6721
Step 149005: loss = 0.16503
Step 149010: loss = 0.07375
Step 149015: loss = 0.03976
Step 149020: loss = 0.12229
Step 149025: loss = 0.03443
Step 149030: loss = 0.24294
Step 149035: loss = 0.16300
Step 149040: loss = 0.17929
Step 149045: loss = 0.32543
Step 149050: loss = 0.12194
Step 149055: loss = 0.02365
Step 149060: loss = 0.11889
Step 149065: loss = 0.16053
Step 149070: loss = 0.12145
Step 149075: loss = 0.07191
Step 149080: loss = 0.13201
Step 149085: loss = 0.10172
Step 149090: loss = 0.04750
Step 149095: loss = 0.17098
Step 149100: loss = 0.06924
Step 149105: loss = 0.16510
Step 149110: loss = 0.25557
Step 149115: loss = 0.04718
Step 149120: loss = 0.06620
Step 149125: loss = 0.16661
Step 149130: loss = 0.18211
Step 149135: loss = 0.03834
Step 149140: loss = 0.07877
Step 149145: loss = 0.18315
Step 149150: loss = 0.10767
Step 149155: loss = 0.11462
Step 149160: loss = 0.15362
Step 149165: loss = 0.10698
Step 149170: loss = 0.20427
Step 149175: loss = 0.10326
Step 149180: loss = 0.10699
Step 149185: loss = 0.37781
Step 149190: loss = 0.13100
Step 149195: loss = 0.13991
Step 149200: loss = 0.06093
Step 149205: loss = 0.11924
Step 149210: loss = 0.18113
Step 149215: loss = 0.10469
Step 149220: loss = 0.07583
Step 149225: loss = 0.11878
Step 149230: loss = 0.19718
Step 149235: loss = 0.34180
Step 149240: loss = 0.11315
Step 149245: loss = 0.24510
Step 149250: loss = 0.11972
Step 149255: loss = 0.10526
Step 149260: loss = 0.11381
Step 149265: loss = 0.17409
Step 149270: loss = 0.28432
Step 149275: loss = 0.05646
Step 149280: loss = 0.06364
Step 149285: loss = 0.03110
Step 149290: loss = 0.12075
Step 149295: loss = 0.03586
Step 149300: loss = 0.10265
Step 149305: loss = 0.12782
Step 149310: loss = 0.07450
Step 149315: loss = 0.04188
Step 149320: loss = 0.23215
Step 149325: loss = 0.08337
Step 149330: loss = 0.26435
Step 149335: loss = 0.09935
Step 149340: loss = 0.23371
Step 149345: loss = 0.13419
Step 149350: loss = 0.08458
Step 149355: loss = 0.27664
Step 149360: loss = 0.16846
Step 149365: loss = 0.06477
Step 149370: loss = 0.15760
Step 149375: loss = 0.21784
Step 149380: loss = 0.10435
Step 149385: loss = 0.07997
Step 149390: loss = 0.06374
Step 149395: loss = 0.04930
Step 149400: loss = 0.04263
Step 149405: loss = 0.18428
Step 149410: loss = 0.14464
Step 149415: loss = 0.10752
Step 149420: loss = 0.89778
Step 149425: loss = 0.09227
Step 149430: loss = 0.04560
Step 149435: loss = 0.07581
Step 149440: loss = 0.14562
Step 149445: loss = 0.12598
Step 149450: loss = 0.09636
Step 149455: loss = 0.05326
Step 149460: loss = 0.04464
Step 149465: loss = 0.06094
Step 149470: loss = 0.01854
Step 149475: loss = 0.12832
Step 149480: loss = 0.19757
Step 149485: loss = 0.23006
Step 149490: loss = 0.13024
Step 149495: loss = 0.24148
Step 149500: loss = 0.14197
Step 149505: loss = 0.22008
Step 149510: loss = 0.18838
Step 149515: loss = 0.13706
Step 149520: loss = 0.23797
Step 149525: loss = 0.14672
Step 149530: loss = 0.13739
Step 149535: loss = 0.05048
Step 149540: loss = 0.35251
Step 149545: loss = 0.12216
Step 149550: loss = 0.13205
Step 149555: loss = 0.02507
Step 149560: loss = 0.03101
Step 149565: loss = 0.17240
Step 149570: loss = 0.17781
Step 149575: loss = 0.15496
Step 149580: loss = 0.20260
Step 149585: loss = 0.24310
Step 149590: loss = 0.11143
Step 149595: loss = 0.04523
Step 149600: loss = 0.06226
Step 149605: loss = 0.09179
Step 149610: loss = 0.18538
Step 149615: loss = 0.17079
Step 149620: loss = 0.14229
Step 149625: loss = 0.19561
Step 149630: loss = 0.26984
Step 149635: loss = 0.29135
Step 149640: loss = 0.06721
Step 149645: loss = 0.10529
Step 149650: loss = 0.09775
Step 149655: loss = 0.11169
Step 149660: loss = 0.07496
Step 149665: loss = 0.08996
Step 149670: loss = 0.22695
Step 149675: loss = 0.22741
Step 149680: loss = 0.11856
Step 149685: loss = 0.23455
Step 149690: loss = 0.08597
Step 149695: loss = 0.13381
Step 149700: loss = 0.04900
Step 149705: loss = 0.16451
Step 149710: loss = 0.09432
Step 149715: loss = 0.07552
Step 149720: loss = 0.10319
Step 149725: loss = 0.03662
Step 149730: loss = 0.10366
Step 149735: loss = 0.10635
Step 149740: loss = 0.08001
Step 149745: loss = 0.11033
Step 149750: loss = 0.11056
Step 149755: loss = 0.06452
Step 149760: loss = 0.11657
Step 149765: loss = 0.22469
Step 149770: loss = 0.02144
Step 149775: loss = 0.10897
Step 149780: loss = 0.05478
Step 149785: loss = 0.16743
Step 149790: loss = 0.40958
Step 149795: loss = 0.11605
Step 149800: loss = 0.07090
Step 149805: loss = 0.04135
Step 149810: loss = 0.17208
Step 149815: loss = 0.16158
Step 149820: loss = 0.16668
Step 149825: loss = 0.22450
Step 149830: loss = 0.11228
Step 149835: loss = 0.18875
Step 149840: loss = 0.07662
Step 149845: loss = 0.03108
Step 149850: loss = 0.05155
Step 149855: loss = 0.12965
Step 149860: loss = 0.06588
Step 149865: loss = 0.07605
Step 149870: loss = 0.12239
Step 149875: loss = 0.15119
Step 149880: loss = 0.15221
Step 149885: loss = 0.27410
Step 149890: loss = 0.09143
Step 149895: loss = 0.15280
Step 149900: loss = 0.26966
Step 149905: loss = 0.08016
Step 149910: loss = 0.06895
Step 149915: loss = 0.04555
Step 149920: loss = 0.08127
Step 149925: loss = 0.16267
Step 149930: loss = 0.11640
Step 149935: loss = 0.07303
Step 149940: loss = 0.20504
Step 149945: loss = 0.06352
Step 149950: loss = 0.16298
Step 149955: loss = 0.10656
Step 149960: loss = 0.18105
Step 149965: loss = 0.23989
Step 149970: loss = 0.09491
Step 149975: loss = 0.06139
Step 149980: loss = 0.05945
Step 149985: loss = 0.10274
Step 149990: loss = 0.27726
Step 149995: loss = 0.20524
Step 150000: loss = 0.04729
Training Data Eval:
  Num examples: 50000, Num correct: 47810, Precision @ 1: 0.9562
('Testing Data Eval: EPOCH->', 151)
  Num examples: 10000, Num correct: 6672, Precision @ 1: 0.6672
Step 150005: loss = 0.19286
Step 150010: loss = 0.05192
Step 150015: loss = 0.06861
Step 150020: loss = 0.08136
Step 150025: loss = 0.15342
Step 150030: loss = 0.05247
Step 150035: loss = 0.07723
Step 150040: loss = 0.11125
Step 150045: loss = 0.05474
Step 150050: loss = 0.07875
Step 150055: loss = 0.09732
Step 150060: loss = 0.03644
Step 150065: loss = 0.08045
Step 150070: loss = 0.18337
Step 150075: loss = 0.07505
Step 150080: loss = 0.02394
Step 150085: loss = 0.09639
Step 150090: loss = 0.05047
Step 150095: loss = 0.04736
Step 150100: loss = 0.15042
Step 150105: loss = 0.13460
Step 150110: loss = 0.12008
Step 150115: loss = 0.16668
Step 150120: loss = 0.30383
Step 150125: loss = 0.02489
Step 150130: loss = 0.40556
Step 150135: loss = 0.11192
Step 150140: loss = 0.13477
Step 150145: loss = 0.07649
Step 150150: loss = 0.13587
Step 150155: loss = 0.22846
Step 150160: loss = 0.06567
Step 150165: loss = 0.02908
Step 150170: loss = 0.04466
Step 150175: loss = 0.14311
Step 150180: loss = 0.19717
Step 150185: loss = 0.10049
Step 150190: loss = 0.07798
Step 150195: loss = 0.17056
Step 150200: loss = 0.07977
Step 150205: loss = 0.12863
Step 150210: loss = 0.08894
Step 150215: loss = 0.30893
Step 150220: loss = 0.06218
Step 150225: loss = 0.12915
Step 150230: loss = 0.19900
Step 150235: loss = 0.02798
Step 150240: loss = 0.05577
Step 150245: loss = 0.42664
Step 150250: loss = 0.18755
Step 150255: loss = 0.08942
Step 150260: loss = 0.11237
Step 150265: loss = 0.34459
Step 150270: loss = 0.31736
Step 150275: loss = 0.10994
Step 150280: loss = 0.19224
Step 150285: loss = 0.08686
Step 150290: loss = 0.08010
Step 150295: loss = 0.04771
Step 150300: loss = 0.07742
Step 150305: loss = 0.09294
Step 150310: loss = 0.10591
Step 150315: loss = 0.07102
Step 150320: loss = 0.08898
Step 150325: loss = 0.13070
Step 150330: loss = 0.23358
Step 150335: loss = 0.54409
Step 150340: loss = 0.12253
Step 150345: loss = 0.11019
Step 150350: loss = 0.07702
Step 150355: loss = 0.24894
Step 150360: loss = 0.23372
Step 150365: loss = 0.15245
Step 150370: loss = 0.06387
Step 150375: loss = 0.19635
Step 150380: loss = 0.11825
Step 150385: loss = 0.15178
Step 150390: loss = 0.19206
Step 150395: loss = 0.04655
Step 150400: loss = 0.09016
Step 150405: loss = 0.11277
Step 150410: loss = 0.15631
Step 150415: loss = 0.07698
Step 150420: loss = 0.19720
Step 150425: loss = 0.17236
Step 150430: loss = 0.04806
Step 150435: loss = 0.07463
Step 150440: loss = 0.12140
Step 150445: loss = 0.16036
Step 150450: loss = 0.19947
Step 150455: loss = 0.08036
Step 150460: loss = 0.06273
Step 150465: loss = 0.16697
Step 150470: loss = 0.08105
Step 150475: loss = 0.17555
Step 150480: loss = 0.06165
Step 150485: loss = 0.13334
Step 150490: loss = 0.04489
Step 150495: loss = 0.09481
Step 150500: loss = 0.09168
Step 150505: loss = 0.30641
Step 150510: loss = 0.12588
Step 150515: loss = 0.24406
Step 150520: loss = 0.23516
Step 150525: loss = 0.11945
Step 150530: loss = 0.08375
Step 150535: loss = 0.06631
Step 150540: loss = 0.14141
Step 150545: loss = 0.17362
Step 150550: loss = 0.33372
Step 150555: loss = 0.06995
Step 150560: loss = 0.04248
Step 150565: loss = 0.23500
Step 150570: loss = 0.14237
Step 150575: loss = 0.03620
Step 150580: loss = 0.11925
Step 150585: loss = 0.14758
Step 150590: loss = 0.08965
Step 150595: loss = 0.04088
Step 150600: loss = 0.13921
Step 150605: loss = 0.05911
Step 150610: loss = 0.04440
Step 150615: loss = 0.10262
Step 150620: loss = 0.21323
Step 150625: loss = 0.05879
Step 150630: loss = 0.23348
Step 150635: loss = 0.31215
Step 150640: loss = 0.12559
Step 150645: loss = 0.05043
Step 150650: loss = 0.28406
Step 150655: loss = 0.05490
Step 150660: loss = 0.10185
Step 150665: loss = 0.04809
Step 150670: loss = 0.14180
Step 150675: loss = 0.05963
Step 150680: loss = 0.11301
Step 150685: loss = 0.06156
Step 150690: loss = 0.17394
Step 150695: loss = 0.07913
Step 150700: loss = 0.14346
Step 150705: loss = 0.14044
Step 150710: loss = 0.12570
Step 150715: loss = 0.11621
Step 150720: loss = 0.15579
Step 150725: loss = 0.15171
Step 150730: loss = 0.10331
Step 150735: loss = 0.08763
Step 150740: loss = 0.03229
Step 150745: loss = 0.06508
Step 150750: loss = 0.21118
Step 150755: loss = 0.36071
Step 150760: loss = 0.21243
Step 150765: loss = 0.16395
Step 150770: loss = 0.19277
Step 150775: loss = 0.08648
Step 150780: loss = 0.21415
Step 150785: loss = 0.09362
Step 150790: loss = 0.06309
Step 150795: loss = 0.02762
Step 150800: loss = 0.18006
Step 150805: loss = 0.22990
Step 150810: loss = 0.17640
Step 150815: loss = 0.31864
Step 150820: loss = 0.11146
Step 150825: loss = 0.09588
Step 150830: loss = 0.24609
Step 150835: loss = 0.10085
Step 150840: loss = 0.26505
Step 150845: loss = 0.20996
Step 150850: loss = 0.16173
Step 150855: loss = 0.27103
Step 150860: loss = 0.19664
Step 150865: loss = 0.17200
Step 150870: loss = 0.30230
Step 150875: loss = 0.34715
Step 150880: loss = 0.07085
Step 150885: loss = 0.14590
Step 150890: loss = 0.03297
Step 150895: loss = 0.12403
Step 150900: loss = 0.09946
Step 150905: loss = 0.23934
Step 150910: loss = 0.07727
Step 150915: loss = 0.08611
Step 150920: loss = 0.08495
Step 150925: loss = 0.11931
Step 150930: loss = 0.05514
Step 150935: loss = 0.16818
Step 150940: loss = 0.10925
Step 150945: loss = 0.14191
Step 150950: loss = 0.02964
Step 150955: loss = 0.19019
Step 150960: loss = 0.10410
Step 150965: loss = 0.12249
Step 150970: loss = 0.16305
Step 150975: loss = 0.16536
Step 150980: loss = 0.19125
Step 150985: loss = 0.16841
Step 150990: loss = 0.25053
Step 150995: loss = 0.18858
Step 151000: loss = 0.09632
Training Data Eval:
  Num examples: 50000, Num correct: 47748, Precision @ 1: 0.9550
('Testing Data Eval: EPOCH->', 152)
  Num examples: 10000, Num correct: 6622, Precision @ 1: 0.6622
Step 151005: loss = 0.08201
Step 151010: loss = 0.16474
Step 151015: loss = 0.06234
Step 151020: loss = 0.06909
Step 151025: loss = 0.17569
Step 151030: loss = 0.14476
Step 151035: loss = 0.16116
Step 151040: loss = 0.04400
Step 151045: loss = 0.17057
Step 151050: loss = 0.03532
Step 151055: loss = 0.06500
Step 151060: loss = 0.28453
Step 151065: loss = 0.23038
Step 151070: loss = 0.08010
Step 151075: loss = 0.17797
Step 151080: loss = 0.03202
Step 151085: loss = 0.11175
Step 151090: loss = 0.06429
Step 151095: loss = 0.11840
Step 151100: loss = 0.10498
Step 151105: loss = 0.33234
Step 151110: loss = 0.16251
Step 151115: loss = 0.19590
Step 151120: loss = 0.08826
Step 151125: loss = 0.06934
Step 151130: loss = 0.12194
Step 151135: loss = 0.06778
Step 151140: loss = 0.20099
Step 151145: loss = 0.05173
Step 151150: loss = 0.16351
Step 151155: loss = 0.11636
Step 151160: loss = 0.07251
Step 151165: loss = 0.11002
Step 151170: loss = 0.28338
Step 151175: loss = 0.27705
Step 151180: loss = 0.10340
Step 151185: loss = 0.13311
Step 151190: loss = 0.11717
Step 151195: loss = 0.21713
Step 151200: loss = 0.22967
Step 151205: loss = 0.13169
Step 151210: loss = 0.19519
Step 151215: loss = 0.04645
Step 151220: loss = 0.09448
Step 151225: loss = 0.10654
Step 151230: loss = 0.13614
Step 151235: loss = 0.09647
Step 151240: loss = 0.07573
Step 151245: loss = 0.20532
Step 151250: loss = 0.08598
Step 151255: loss = 0.07498
Step 151260: loss = 0.25686
Step 151265: loss = 0.17446
Step 151270: loss = 0.09900
Step 151275: loss = 0.23145
Step 151280: loss = 0.16887
Step 151285: loss = 0.03791
Step 151290: loss = 0.10113
Step 151295: loss = 0.15065
Step 151300: loss = 0.07546
Step 151305: loss = 0.13351
Step 151310: loss = 0.11817
Step 151315: loss = 0.12802
Step 151320: loss = 0.09418
Step 151325: loss = 0.18414
Step 151330: loss = 0.10859
Step 151335: loss = 0.09654
Step 151340: loss = 0.03535
Step 151345: loss = 0.05047
Step 151350: loss = 0.23454
Step 151355: loss = 0.24262
Step 151360: loss = 0.18722
Step 151365: loss = 0.05251
Step 151370: loss = 0.09517
Step 151375: loss = 0.05809
Step 151380: loss = 0.11688
Step 151385: loss = 0.05545
Step 151390: loss = 0.10738
Step 151395: loss = 0.08495
Step 151400: loss = 0.06972
Step 151405: loss = 0.03501
Step 151410: loss = 0.10252
Step 151415: loss = 0.06824
Step 151420: loss = 0.20059
Step 151425: loss = 0.11339
Step 151430: loss = 0.13313
Step 151435: loss = 0.20798
Step 151440: loss = 0.08493
Step 151445: loss = 0.04430
Step 151450: loss = 0.04571
Step 151455: loss = 0.14123
Step 151460: loss = 0.13636
Step 151465: loss = 0.05185
Step 151470: loss = 0.22377
Step 151475: loss = 0.07600
Step 151480: loss = 0.19864
Step 151485: loss = 0.20471
Step 151490: loss = 0.05814
Step 151495: loss = 0.04911
Step 151500: loss = 0.19065
Step 151505: loss = 0.15017
Step 151510: loss = 0.29594
Step 151515: loss = 0.19298
Step 151520: loss = 0.06897
Step 151525: loss = 0.13470
Step 151530: loss = 0.15227
Step 151535: loss = 0.07582
Step 151540: loss = 0.06288
Step 151545: loss = 0.07480
Step 151550: loss = 0.03331
Step 151555: loss = 0.20015
Step 151560: loss = 0.13081
Step 151565: loss = 0.20277
Step 151570: loss = 0.04918
Step 151575: loss = 0.19455
Step 151580: loss = 0.11777
Step 151585: loss = 0.05630
Step 151590: loss = 0.24318
Step 151595: loss = 0.06166
Step 151600: loss = 0.18027
Step 151605: loss = 0.17346
Step 151610: loss = 0.15031
Step 151615: loss = 0.18693
Step 151620: loss = 0.08862
Step 151625: loss = 0.06050
Step 151630: loss = 0.05568
Step 151635: loss = 0.09879
Step 151640: loss = 0.07734
Step 151645: loss = 0.23022
Step 151650: loss = 0.10188
Step 151655: loss = 0.09251
Step 151660: loss = 0.04540
Step 151665: loss = 0.03963
Step 151670: loss = 0.05402
Step 151675: loss = 0.13067
Step 151680: loss = 0.11535
Step 151685: loss = 0.18433
Step 151690: loss = 0.12708
Step 151695: loss = 0.11184
Step 151700: loss = 0.22622
Step 151705: loss = 0.16354
Step 151710: loss = 0.11300
Step 151715: loss = 0.10777
Step 151720: loss = 0.05500
Step 151725: loss = 0.05012
Step 151730: loss = 0.04447
Step 151735: loss = 0.07185
Step 151740: loss = 0.08485
Step 151745: loss = 0.21588
Step 151750: loss = 0.07796
Step 151755: loss = 0.14363
Step 151760: loss = 0.06342
Step 151765: loss = 0.11868
Step 151770: loss = 0.09780
Step 151775: loss = 0.07429
Step 151780: loss = 0.05192
Step 151785: loss = 0.13517
Step 151790: loss = 0.10283
Step 151795: loss = 0.14593
Step 151800: loss = 0.29941
Step 151805: loss = 0.05717
Step 151810: loss = 0.13374
Step 151815: loss = 0.13520
Step 151820: loss = 0.17466
Step 151825: loss = 0.15597
Step 151830: loss = 0.04403
Step 151835: loss = 0.12462
Step 151840: loss = 0.08599
Step 151845: loss = 0.11507
Step 151850: loss = 0.05475
Step 151855: loss = 0.13134
Step 151860: loss = 0.21801
Step 151865: loss = 0.08133
Step 151870: loss = 0.03018
Step 151875: loss = 0.04048
Step 151880: loss = 0.09979
Step 151885: loss = 0.08706
Step 151890: loss = 0.49916
Step 151895: loss = 0.13438
Step 151900: loss = 0.05950
Step 151905: loss = 0.10325
Step 151910: loss = 0.31305
Step 151915: loss = 0.05116
Step 151920: loss = 0.24189
Step 151925: loss = 0.24350
Step 151930: loss = 0.11040
Step 151935: loss = 0.15158
Step 151940: loss = 0.07303
Step 151945: loss = 0.06037
Step 151950: loss = 0.05491
Step 151955: loss = 0.10328
Step 151960: loss = 0.15155
Step 151965: loss = 0.13772
Step 151970: loss = 0.05887
Step 151975: loss = 0.06897
Step 151980: loss = 0.21191
Step 151985: loss = 0.19398
Step 151990: loss = 0.15502
Step 151995: loss = 0.23521
Step 152000: loss = 0.09417
Training Data Eval:
  Num examples: 50000, Num correct: 47649, Precision @ 1: 0.9530
('Testing Data Eval: EPOCH->', 153)
  Num examples: 10000, Num correct: 6645, Precision @ 1: 0.6645
Step 152005: loss = 0.06954
Step 152010: loss = 0.13872
Step 152015: loss = 0.16888
Step 152020: loss = 0.18012
Step 152025: loss = 0.03982
Step 152030: loss = 0.10264
Step 152035: loss = 0.15198
Step 152040: loss = 0.15465
Step 152045: loss = 0.07571
Step 152050: loss = 0.18442
Step 152055: loss = 0.10742
Step 152060: loss = 0.13053
Step 152065: loss = 0.11206
Step 152070: loss = 0.10696
Step 152075: loss = 0.29180
Step 152080: loss = 0.10650
Step 152085: loss = 0.22993
Step 152090: loss = 0.11290
Step 152095: loss = 0.13216
Step 152100: loss = 0.25953
Step 152105: loss = 0.23619
Step 152110: loss = 0.10552
Step 152115: loss = 0.12596
Step 152120: loss = 0.11164
Step 152125: loss = 0.09201
Step 152130: loss = 0.03793
Step 152135: loss = 0.17046
Step 152140: loss = 0.19722
Step 152145: loss = 0.16489
Step 152150: loss = 0.19618
Step 152155: loss = 0.08612
Step 152160: loss = 0.09228
Step 152165: loss = 0.23170
Step 152170: loss = 0.09776
Step 152175: loss = 0.13855
Step 152180: loss = 0.21247
Step 152185: loss = 0.04383
Step 152190: loss = 0.09466
Step 152195: loss = 0.02169
Step 152200: loss = 0.03985
Step 152205: loss = 0.09231
Step 152210: loss = 0.04961
Step 152215: loss = 0.24550
Step 152220: loss = 0.15522
Step 152225: loss = 0.07002
Step 152230: loss = 0.08339
Step 152235: loss = 0.03771
Step 152240: loss = 0.18004
Step 152245: loss = 0.18828
Step 152250: loss = 0.15812
Step 152255: loss = 0.05735
Step 152260: loss = 0.13543
Step 152265: loss = 0.11346
Step 152270: loss = 0.09763
Step 152275: loss = 0.11766
Step 152280: loss = 0.19702
Step 152285: loss = 0.07006
Step 152290: loss = 0.13279
Step 152295: loss = 0.17998
Step 152300: loss = 0.04393
Step 152305: loss = 0.15249
Step 152310: loss = 0.12115
Step 152315: loss = 0.08574
Step 152320: loss = 0.07206
Step 152325: loss = 0.13348
Step 152330: loss = 0.04365
Step 152335: loss = 0.17944
Step 152340: loss = 0.12134
Step 152345: loss = 0.23651
Step 152350: loss = 0.17522
Step 152355: loss = 0.17107
Step 152360: loss = 0.11272
Step 152365: loss = 0.04996
Step 152370: loss = 0.10253
Step 152375: loss = 0.32258
Step 152380: loss = 0.12340
Step 152385: loss = 0.07237
Step 152390: loss = 0.04603
Step 152395: loss = 0.21025
Step 152400: loss = 0.22367
Step 152405: loss = 0.11059
Step 152410: loss = 0.02659
Step 152415: loss = 0.05970
Step 152420: loss = 0.07472
Step 152425: loss = 0.09345
Step 152430: loss = 0.36777
Step 152435: loss = 0.05386
Step 152440: loss = 0.12812
Step 152445: loss = 0.12107
Step 152450: loss = 0.12703
Step 152455: loss = 0.30914
Step 152460: loss = 0.09311
Step 152465: loss = 0.09797
Step 152470: loss = 0.14110
Step 152475: loss = 0.11518
Step 152480: loss = 0.10714
Step 152485: loss = 0.10793
Step 152490: loss = 0.07536
Step 152495: loss = 0.04366
Step 152500: loss = 0.13065
Step 152505: loss = 0.16839
Step 152510: loss = 0.17244
Step 152515: loss = 0.22375
Step 152520: loss = 0.04859
Step 152525: loss = 0.11951
Step 152530: loss = 0.05443
Step 152535: loss = 0.24213
Step 152540: loss = 0.06016
Step 152545: loss = 0.06320
Step 152550: loss = 0.24773
Step 152555: loss = 0.15835
Step 152560: loss = 0.03700
Step 152565: loss = 0.17557
Step 152570: loss = 0.19391
Step 152575: loss = 0.23883
Step 152580: loss = 0.04994
Step 152585: loss = 0.26913
Step 152590: loss = 0.10312
Step 152595: loss = 0.28377
Step 152600: loss = 0.11977
Step 152605: loss = 0.09320
Step 152610: loss = 0.04780
Step 152615: loss = 0.10839
Step 152620: loss = 0.08009
Step 152625: loss = 0.12115
Step 152630: loss = 0.12810
Step 152635: loss = 0.20596
Step 152640: loss = 0.06862
Step 152645: loss = 0.03528
Step 152650: loss = 0.09076
Step 152655: loss = 0.09397
Step 152660: loss = 0.12586
Step 152665: loss = 0.08420
Step 152670: loss = 0.14582
Step 152675: loss = 0.25394
Step 152680: loss = 0.18871
Step 152685: loss = 0.08531
Step 152690: loss = 0.10374
Step 152695: loss = 0.11627
Step 152700: loss = 0.14912
Step 152705: loss = 0.03738
Step 152710: loss = 0.15000
Step 152715: loss = 0.24662
Step 152720: loss = 0.14311
Step 152725: loss = 0.20776
Step 152730: loss = 0.16124
Step 152735: loss = 0.05853
Step 152740: loss = 0.14943
Step 152745: loss = 0.10705
Step 152750: loss = 0.16684
Step 152755: loss = 0.05700
Step 152760: loss = 0.03592
Step 152765: loss = 0.03961
Step 152770: loss = 0.28079
Step 152775: loss = 0.10317
Step 152780: loss = 0.15452
Step 152785: loss = 0.23572
Step 152790: loss = 0.17614
Step 152795: loss = 0.10914
Step 152800: loss = 0.12605
Step 152805: loss = 0.09255
Step 152810: loss = 0.12510
Step 152815: loss = 0.07830
Step 152820: loss = 0.13142
Step 152825: loss = 0.03977
Step 152830: loss = 0.16528
Step 152835: loss = 0.14390
Step 152840: loss = 0.03466
Step 152845: loss = 0.05529
Step 152850: loss = 0.10619
Step 152855: loss = 0.09767
Step 152860: loss = 0.29705
Step 152865: loss = 0.05556
Step 152870: loss = 0.14477
Step 152875: loss = 0.07450
Step 152880: loss = 0.15776
Step 152885: loss = 0.10854
Step 152890: loss = 0.50738
Step 152895: loss = 0.14868
Step 152900: loss = 0.19993
Step 152905: loss = 0.03691
Step 152910: loss = 0.14804
Step 152915: loss = 0.17318
Step 152920: loss = 0.12902
Step 152925: loss = 0.06424
Step 152930: loss = 0.08675
Step 152935: loss = 0.12929
Step 152940: loss = 0.04825
Step 152945: loss = 0.30246
Step 152950: loss = 0.25726
Step 152955: loss = 0.06944
Step 152960: loss = 0.06638
Step 152965: loss = 0.08056
Step 152970: loss = 0.15794
Step 152975: loss = 0.08410
Step 152980: loss = 0.12432
Step 152985: loss = 0.02350
Step 152990: loss = 0.03883
Step 152995: loss = 0.21187
Step 153000: loss = 0.06527
Training Data Eval:
  Num examples: 50000, Num correct: 47923, Precision @ 1: 0.9585
('Testing Data Eval: EPOCH->', 154)
  Num examples: 10000, Num correct: 6643, Precision @ 1: 0.6643
Step 153005: loss = 0.05847
Step 153010: loss = 0.09199
Step 153015: loss = 0.08167
Step 153020: loss = 0.19794
Step 153025: loss = 0.04376
Step 153030: loss = 0.17256
Step 153035: loss = 0.15097
Step 153040: loss = 0.12064
Step 153045: loss = 0.08147
Step 153050: loss = 0.04635
Step 153055: loss = 0.18417
Step 153060: loss = 0.25387
Step 153065: loss = 0.09864
Step 153070: loss = 0.12089
Step 153075: loss = 0.27020
Step 153080: loss = 0.08476
Step 153085: loss = 0.25654
Step 153090: loss = 0.17911
Step 153095: loss = 0.26400
Step 153100: loss = 0.05958
Step 153105: loss = 0.10028
Step 153110: loss = 0.11624
Step 153115: loss = 0.42943
Step 153120: loss = 0.02584
Step 153125: loss = 0.06688
Step 153130: loss = 0.14175
Step 153135: loss = 0.07382
Step 153140: loss = 0.08853
Step 153145: loss = 0.05966
Step 153150: loss = 0.11257
Step 153155: loss = 0.05607
Step 153160: loss = 0.14440
Step 153165: loss = 0.15349
Step 153170: loss = 0.11205
Step 153175: loss = 0.19568
Step 153180: loss = 0.11643
Step 153185: loss = 0.04604
Step 153190: loss = 0.03488
Step 153195: loss = 0.31737
Step 153200: loss = 0.15742
Step 153205: loss = 0.04320
Step 153210: loss = 0.01573
Step 153215: loss = 0.08120
Step 153220: loss = 0.18094
Step 153225: loss = 0.10166
Step 153230: loss = 0.07019
Step 153235: loss = 0.24297
Step 153240: loss = 0.07564
Step 153245: loss = 0.09117
Step 153250: loss = 0.08240
Step 153255: loss = 0.15697
Step 153260: loss = 0.11113
Step 153265: loss = 0.04932
Step 153270: loss = 0.04954
Step 153275: loss = 0.09273
Step 153280: loss = 0.34200
Step 153285: loss = 0.19107
Step 153290: loss = 0.15195
Step 153295: loss = 0.02467
Step 153300: loss = 0.03944
Step 153305: loss = 0.08969
Step 153310: loss = 0.06936
Step 153315: loss = 0.15998
Step 153320: loss = 0.05346
Step 153325: loss = 0.04326
Step 153330: loss = 0.07021
Step 153335: loss = 0.07617
Step 153340: loss = 0.06611
Step 153345: loss = 0.07831
Step 153350: loss = 0.02052
Step 153355: loss = 0.14331
Step 153360: loss = 0.05256
Step 153365: loss = 0.04543
Step 153370: loss = 0.20712
Step 153375: loss = 0.10485
Step 153380: loss = 0.38842
Step 153385: loss = 0.03725
Step 153390: loss = 0.10788
Step 153395: loss = 0.11541
Step 153400: loss = 0.15672
Step 153405: loss = 0.12629
Step 153410: loss = 0.37372
Step 153415: loss = 0.27522
Step 153420: loss = 0.18421
Step 153425: loss = 0.21056
Step 153430: loss = 0.05669
Step 153435: loss = 0.04945
Step 153440: loss = 0.18575
Step 153445: loss = 0.04415
Step 153450: loss = 0.11668
Step 153455: loss = 0.04521
Step 153460: loss = 0.03880
Step 153465: loss = 0.40681
Step 153470: loss = 0.32675
Step 153475: loss = 0.24758
Step 153480: loss = 0.30379
Step 153485: loss = 0.22710
Step 153490: loss = 0.06163
Step 153495: loss = 0.18023
Step 153500: loss = 0.13719
Step 153505: loss = 0.04485
Step 153510: loss = 0.07635
Step 153515: loss = 0.23276
Step 153520: loss = 0.17959
Step 153525: loss = 0.18275
Step 153530: loss = 0.05925
Step 153535: loss = 0.19851
Step 153540: loss = 0.12453
Step 153545: loss = 0.14299
Step 153550: loss = 0.16282
Step 153555: loss = 0.17147
Step 153560: loss = 0.10720
Step 153565: loss = 0.14241
Step 153570: loss = 0.12220
Step 153575: loss = 0.07522
Step 153580: loss = 0.04866
Step 153585: loss = 0.19655
Step 153590: loss = 0.04118
Step 153595: loss = 0.04630
Step 153600: loss = 0.18720
Step 153605: loss = 0.10961
Step 153610: loss = 0.12554
Step 153615: loss = 0.16210
Step 153620: loss = 0.06250
Step 153625: loss = 0.03396
Step 153630: loss = 0.18424
Step 153635: loss = 0.09255
Step 153640: loss = 0.09394
Step 153645: loss = 0.26836
Step 153650: loss = 0.13197
Step 153655: loss = 0.08912
Step 153660: loss = 0.06698
Step 153665: loss = 0.12685
Step 153670: loss = 0.09839
Step 153675: loss = 0.16530
Step 153680: loss = 0.04807
Step 153685: loss = 0.18332
Step 153690: loss = 0.04489
Step 153695: loss = 0.03635
Step 153700: loss = 0.15856
Step 153705: loss = 0.10818
Step 153710: loss = 0.48235
Step 153715: loss = 0.19160
Step 153720: loss = 0.14453
Step 153725: loss = 0.12856
Step 153730: loss = 0.11805
Step 153735: loss = 0.04506
Step 153740: loss = 0.07916
Step 153745: loss = 0.13639
Step 153750: loss = 0.04524
Step 153755: loss = 0.17222
Step 153760: loss = 0.16206
Step 153765: loss = 0.05617
Step 153770: loss = 0.14186
Step 153775: loss = 0.13364
Step 153780: loss = 0.13844
Step 153785: loss = 0.04934
Step 153790: loss = 0.12210
Step 153795: loss = 0.07541
Step 153800: loss = 0.09085
Step 153805: loss = 0.17596
Step 153810: loss = 0.19367
Step 153815: loss = 0.32166
Step 153820: loss = 0.14346
Step 153825: loss = 0.07675
Step 153830: loss = 0.33294
Step 153835: loss = 0.04278
Step 153840: loss = 0.20527
Step 153845: loss = 0.14049
Step 153850: loss = 0.14469
Step 153855: loss = 0.11209
Step 153860: loss = 0.08356
Step 153865: loss = 0.14186
Step 153870: loss = 0.19831
Step 153875: loss = 0.28547
Step 153880: loss = 0.03898
Step 153885: loss = 0.25208
Step 153890: loss = 0.15565
Step 153895: loss = 0.17035
Step 153900: loss = 0.11287
Step 153905: loss = 0.10139
Step 153910: loss = 0.09807
Step 153915: loss = 0.04298
Step 153920: loss = 0.07849
Step 153925: loss = 0.03654
Step 153930: loss = 0.02981
Step 153935: loss = 0.02011
Step 153940: loss = 0.08480
Step 153945: loss = 0.10811
Step 153950: loss = 0.06259
Step 153955: loss = 0.20720
Step 153960: loss = 0.18075
Step 153965: loss = 0.17214
Step 153970: loss = 0.16177
Step 153975: loss = 0.05404
Step 153980: loss = 0.23575
Step 153985: loss = 0.17063
Step 153990: loss = 0.18505
Step 153995: loss = 0.06847
Step 154000: loss = 0.08708
Training Data Eval:
  Num examples: 50000, Num correct: 47810, Precision @ 1: 0.9562
('Testing Data Eval: EPOCH->', 155)
  Num examples: 10000, Num correct: 6618, Precision @ 1: 0.6618
Step 154005: loss = 0.10110
Step 154010: loss = 0.11838
Step 154015: loss = 0.12693
Step 154020: loss = 0.11282
Step 154025: loss = 0.11394
Step 154030: loss = 0.11442
Step 154035: loss = 0.10830
Step 154040: loss = 0.03331
Step 154045: loss = 0.07494
Step 154050: loss = 0.13047
Step 154055: loss = 0.03118
Step 154060: loss = 0.08333
Step 154065: loss = 0.09506
Step 154070: loss = 0.05509
Step 154075: loss = 0.10439
Step 154080: loss = 0.11189
Step 154085: loss = 0.18596
Step 154090: loss = 0.16134
Step 154095: loss = 0.24634
Step 154100: loss = 0.09194
Step 154105: loss = 0.09350
Step 154110: loss = 0.13636
Step 154115: loss = 0.56407
Step 154120: loss = 0.17960
Step 154125: loss = 0.09993
Step 154130: loss = 0.31571
Step 154135: loss = 0.21042
Step 154140: loss = 0.20207
Step 154145: loss = 0.39042
Step 154150: loss = 0.04695
Step 154155: loss = 0.14757
Step 154160: loss = 0.28135
Step 154165: loss = 0.21842
Step 154170: loss = 0.04986
Step 154175: loss = 0.15741
Step 154180: loss = 0.29865
Step 154185: loss = 0.30104
Step 154190: loss = 0.17190
Step 154195: loss = 0.12490
Step 154200: loss = 0.10135
Step 154205: loss = 0.10162
Step 154210: loss = 0.25722
Step 154215: loss = 0.17605
Step 154220: loss = 0.14120
Step 154225: loss = 0.07762
Step 154230: loss = 0.10183
Step 154235: loss = 0.17487
Step 154240: loss = 0.04407
Step 154245: loss = 0.24115
Step 154250: loss = 0.10011
Step 154255: loss = 0.23015
Step 154260: loss = 0.09125
Step 154265: loss = 0.11136
Step 154270: loss = 0.06695
Step 154275: loss = 0.11690
Step 154280: loss = 0.16671
Step 154285: loss = 0.06034
Step 154290: loss = 0.09020
Step 154295: loss = 0.20614
Step 154300: loss = 0.16547
Step 154305: loss = 0.11103
Step 154310: loss = 0.08528
Step 154315: loss = 0.14296
Step 154320: loss = 0.07986
Step 154325: loss = 0.09221
Step 154330: loss = 0.10758
Step 154335: loss = 0.21517
Step 154340: loss = 0.18289
Step 154345: loss = 0.05198
Step 154350: loss = 0.25251
Step 154355: loss = 0.08199
Step 154360: loss = 0.03475
Step 154365: loss = 0.05794
Step 154370: loss = 0.16648
Step 154375: loss = 0.13145
Step 154380: loss = 0.14826
Step 154385: loss = 0.16275
Step 154390: loss = 0.10460
Step 154395: loss = 0.04257
Step 154400: loss = 0.06101
Step 154405: loss = 0.10073
Step 154410: loss = 0.02901
Step 154415: loss = 0.13214
Step 154420: loss = 0.19324
Step 154425: loss = 0.04410
Step 154430: loss = 0.10242
Step 154435: loss = 0.09774
Step 154440: loss = 0.02262
Step 154445: loss = 0.03034
Step 154450: loss = 0.23205
Step 154455: loss = 0.11019
Step 154460: loss = 0.08989
Step 154465: loss = 0.05586
Step 154470: loss = 0.15861
Step 154475: loss = 0.13507
Step 154480: loss = 0.23791
Step 154485: loss = 0.14085
Step 154490: loss = 0.11368
Step 154495: loss = 0.14186
Step 154500: loss = 0.04824
Step 154505: loss = 0.19258
Step 154510: loss = 0.13184
Step 154515: loss = 0.10591
Step 154520: loss = 0.09380
Step 154525: loss = 0.12489
Step 154530: loss = 0.13540
Step 154535: loss = 0.05259
Step 154540: loss = 0.24485
Step 154545: loss = 0.08378
Step 154550: loss = 0.04568
Step 154555: loss = 0.04113
Step 154560: loss = 0.16861
Step 154565: loss = 0.11659
Step 154570: loss = 0.08314
Step 154575: loss = 0.10055
Step 154580: loss = 0.12174
Step 154585: loss = 0.09752
Step 154590: loss = 0.07883
Step 154595: loss = 0.35757
Step 154600: loss = 0.30750
Step 154605: loss = 0.25531
Step 154610: loss = 0.29818
Step 154615: loss = 0.07457
Step 154620: loss = 0.13165
Step 154625: loss = 0.25450
Step 154630: loss = 0.02919
Step 154635: loss = 0.21077
Step 154640: loss = 0.04841
Step 154645: loss = 0.05347
Step 154650: loss = 0.07717
Step 154655: loss = 0.11012
Step 154660: loss = 0.21173
Step 154665: loss = 0.11775
Step 154670: loss = 0.19217
Step 154675: loss = 0.19995
Step 154680: loss = 0.16115
Step 154685: loss = 0.12017
Step 154690: loss = 0.06166
Step 154695: loss = 0.04666
Step 154700: loss = 0.08667
Step 154705: loss = 0.08538
Step 154710: loss = 0.06230
Step 154715: loss = 0.08444
Step 154720: loss = 0.18069
Step 154725: loss = 0.16320
Step 154730: loss = 0.08055
Step 154735: loss = 0.26208
Step 154740: loss = 0.14258
Step 154745: loss = 0.43991
Step 154750: loss = 0.16082
Step 154755: loss = 0.05760
Step 154760: loss = 0.05657
Step 154765: loss = 0.18561
Step 154770: loss = 0.27518
Step 154775: loss = 0.11061
Step 154780: loss = 0.15658
Step 154785: loss = 0.05052
Step 154790: loss = 0.03860
Step 154795: loss = 0.05465
Step 154800: loss = 0.19034
Step 154805: loss = 0.16788
Step 154810: loss = 0.17471
Step 154815: loss = 0.09425
Step 154820: loss = 0.06612
Step 154825: loss = 0.03923
Step 154830: loss = 0.14449
Step 154835: loss = 0.09789
Step 154840: loss = 0.08856
Step 154845: loss = 0.04533
Step 154850: loss = 0.20509
Step 154855: loss = 0.10634
Step 154860: loss = 0.12772
Step 154865: loss = 0.17811
Step 154870: loss = 0.11517
Step 154875: loss = 0.02645
Step 154880: loss = 0.04948
Step 154885: loss = 0.17463
Step 154890: loss = 0.22225
Step 154895: loss = 0.09738
Step 154900: loss = 0.13093
Step 154905: loss = 0.06740
Step 154910: loss = 0.07657
Step 154915: loss = 0.06581
Step 154920: loss = 0.08180
Step 154925: loss = 0.12794
Step 154930: loss = 0.13138
Step 154935: loss = 0.13800
Step 154940: loss = 0.16447
Step 154945: loss = 0.23784
Step 154950: loss = 0.03953
Step 154955: loss = 0.13152
Step 154960: loss = 0.05182
Step 154965: loss = 0.14917
Step 154970: loss = 0.16189
Step 154975: loss = 0.09112
Step 154980: loss = 0.08592
Step 154985: loss = 0.16162
Step 154990: loss = 0.07796
Step 154995: loss = 0.24491
Step 155000: loss = 0.02055
Training Data Eval:
  Num examples: 50000, Num correct: 48020, Precision @ 1: 0.9604
('Testing Data Eval: EPOCH->', 156)
  Num examples: 10000, Num correct: 6699, Precision @ 1: 0.6699
Step 155005: loss = 0.17874
Step 155010: loss = 0.23206
Step 155015: loss = 0.04893
Step 155020: loss = 0.11080
Step 155025: loss = 0.16415
Step 155030: loss = 0.06428
Step 155035: loss = 0.12114
Step 155040: loss = 0.10353
Step 155045: loss = 0.11843
Step 155050: loss = 0.06142
Step 155055: loss = 0.22388
Step 155060: loss = 0.11161
Step 155065: loss = 0.03501
Step 155070: loss = 0.41720
Step 155075: loss = 0.06387
Step 155080: loss = 0.08792
Step 155085: loss = 0.10781
Step 155090: loss = 0.05288
Step 155095: loss = 0.17814
Step 155100: loss = 0.05862
Step 155105: loss = 0.16580
Step 155110: loss = 0.07339
Step 155115: loss = 0.03868
Step 155120: loss = 0.06468
Step 155125: loss = 0.06760
Step 155130: loss = 0.10169
Step 155135: loss = 0.08419
Step 155140: loss = 0.33979
Step 155145: loss = 0.16969
Step 155150: loss = 0.07930
Step 155155: loss = 0.11577
Step 155160: loss = 0.16725
Step 155165: loss = 0.04034
Step 155170: loss = 0.15537
Step 155175: loss = 0.13583
Step 155180: loss = 0.18862
Step 155185: loss = 0.05559
Step 155190: loss = 0.06205
Step 155195: loss = 0.31211
Step 155200: loss = 0.05292
Step 155205: loss = 0.10033
Step 155210: loss = 0.15408
Step 155215: loss = 0.12566
Step 155220: loss = 0.45683
Step 155225: loss = 0.12453
Step 155230: loss = 0.05905
Step 155235: loss = 0.11278
Step 155240: loss = 0.10470
Step 155245: loss = 0.05241
Step 155250: loss = 0.20703
Step 155255: loss = 0.39498
Step 155260: loss = 0.11610
Step 155265: loss = 0.08038
Step 155270: loss = 0.02066
Step 155275: loss = 0.48838
Step 155280: loss = 0.10730
Step 155285: loss = 0.22010
Step 155290: loss = 0.11284
Step 155295: loss = 0.02754
Step 155300: loss = 0.11193
Step 155305: loss = 0.13113
Step 155310: loss = 0.03747
Step 155315: loss = 0.05177
Step 155320: loss = 0.30357
Step 155325: loss = 0.15093
Step 155330: loss = 0.05751
Step 155335: loss = 0.08326
Step 155340: loss = 0.14092
Step 155345: loss = 0.03504
Step 155350: loss = 0.21628
Step 155355: loss = 0.23438
Step 155360: loss = 0.06213
Step 155365: loss = 0.17930
Step 155370: loss = 0.34693
Step 155375: loss = 0.13830
Step 155380: loss = 0.08147
Step 155385: loss = 0.04521
Step 155390: loss = 0.06577
Step 155395: loss = 0.19384
Step 155400: loss = 0.10559
Step 155405: loss = 0.05332
Step 155410: loss = 0.33480
Step 155415: loss = 0.10076
Step 155420: loss = 0.11920
Step 155425: loss = 0.25890
Step 155430: loss = 0.10867
Step 155435: loss = 0.04913
Step 155440: loss = 0.17450
Step 155445: loss = 0.08551
Step 155450: loss = 0.14378
Step 155455: loss = 0.07543
Step 155460: loss = 0.20373
Step 155465: loss = 0.20251
Step 155470: loss = 0.09821
Step 155475: loss = 0.15309
Step 155480: loss = 0.10804
Step 155485: loss = 0.22893
Step 155490: loss = 0.19693
Step 155495: loss = 0.08756
Step 155500: loss = 0.21571
Step 155505: loss = 0.10135
Step 155510: loss = 0.20887
Step 155515: loss = 0.10306
Step 155520: loss = 0.06445
Step 155525: loss = 0.12267
Step 155530: loss = 0.09958
Step 155535: loss = 0.07103
Step 155540: loss = 0.10498
Step 155545: loss = 0.11847
Step 155550: loss = 0.05488
Step 155555: loss = 0.03924
Step 155560: loss = 0.32444
Step 155565: loss = 0.08118
Step 155570: loss = 0.12402
Step 155575: loss = 0.05803
Step 155580: loss = 0.01880
Step 155585: loss = 0.46984
Step 155590: loss = 0.17292
Step 155595: loss = 0.16982
Step 155600: loss = 0.09772
Step 155605: loss = 0.22814
Step 155610: loss = 0.23610
Step 155615: loss = 0.25309
Step 155620: loss = 0.03834
Step 155625: loss = 0.08622
Step 155630: loss = 0.04991
Step 155635: loss = 0.08867
Step 155640: loss = 0.07870
Step 155645: loss = 0.25315
Step 155650: loss = 0.04218
Step 155655: loss = 0.14448
Step 155660: loss = 0.05829
Step 155665: loss = 0.10121
Step 155670: loss = 0.17525
Step 155675: loss = 0.22773
Step 155680: loss = 0.03972
Step 155685: loss = 0.15911
Step 155690: loss = 0.04832
Step 155695: loss = 0.16119
Step 155700: loss = 0.23952
Step 155705: loss = 0.12691
Step 155710: loss = 0.07586
Step 155715: loss = 0.09145
Step 155720: loss = 0.09962
Step 155725: loss = 0.06419
Step 155730: loss = 0.07144
Step 155735: loss = 0.45879
Step 155740: loss = 0.10962
Step 155745: loss = 0.12528
Step 155750: loss = 0.22224
Step 155755: loss = 0.11490
Step 155760: loss = 0.06088
Step 155765: loss = 0.07784
Step 155770: loss = 0.17752
Step 155775: loss = 0.14409
Step 155780: loss = 0.06861
Step 155785: loss = 0.08723
Step 155790: loss = 0.13365
Step 155795: loss = 0.13065
Step 155800: loss = 0.12964
Step 155805: loss = 0.12237
Step 155810: loss = 0.12001
Step 155815: loss = 0.05620
Step 155820: loss = 0.04552
Step 155825: loss = 0.03885
Step 155830: loss = 0.09721
Step 155835: loss = 0.36697
Step 155840: loss = 0.10939
Step 155845: loss = 0.06642
Step 155850: loss = 0.06308
Step 155855: loss = 0.09478
Step 155860: loss = 0.29422
Step 155865: loss = 0.11118
Step 155870: loss = 0.18026
Step 155875: loss = 0.13040
Step 155880: loss = 0.34703
Step 155885: loss = 0.17526
Step 155890: loss = 0.13410
Step 155895: loss = 0.18296
Step 155900: loss = 0.09651
Step 155905: loss = 0.21828
Step 155910: loss = 0.18389
Step 155915: loss = 0.12843
Step 155920: loss = 0.15690
Step 155925: loss = 0.09418
Step 155930: loss = 0.16058
Step 155935: loss = 0.08204
Step 155940: loss = 0.04663
Step 155945: loss = 0.06496
Step 155950: loss = 0.12499
Step 155955: loss = 0.23139
Step 155960: loss = 0.13730
Step 155965: loss = 0.04177
Step 155970: loss = 0.11343
Step 155975: loss = 0.19663
Step 155980: loss = 0.17524
Step 155985: loss = 0.01646
Step 155990: loss = 0.24854
Step 155995: loss = 0.20511
Step 156000: loss = 0.13910
Training Data Eval:
  Num examples: 50000, Num correct: 47872, Precision @ 1: 0.9574
('Testing Data Eval: EPOCH->', 157)
  Num examples: 10000, Num correct: 6597, Precision @ 1: 0.6597
Step 156005: loss = 0.13610
Step 156010: loss = 0.08720
Step 156015: loss = 0.50404
Step 156020: loss = 0.27822
Step 156025: loss = 0.09221
Step 156030: loss = 0.19582
Step 156035: loss = 0.23067
Step 156040: loss = 0.03098
Step 156045: loss = 0.05893
Step 156050: loss = 0.20157
Step 156055: loss = 0.16440
Step 156060: loss = 0.17648
Step 156065: loss = 0.02998
Step 156070: loss = 0.31836
Step 156075: loss = 0.03307
Step 156080: loss = 0.03560
Step 156085: loss = 0.03746
Step 156090: loss = 0.06061
Step 156095: loss = 0.14170
Step 156100: loss = 0.07696
Step 156105: loss = 0.10381
Step 156110: loss = 0.24414
Step 156115: loss = 0.15153
Step 156120: loss = 0.13604
Step 156125: loss = 0.19728
Step 156130: loss = 0.15636
Step 156135: loss = 0.38064
Step 156140: loss = 0.04989
Step 156145: loss = 0.08099
Step 156150: loss = 0.35680
Step 156155: loss = 0.11265
Step 156160: loss = 0.07206
Step 156165: loss = 0.08479
Step 156170: loss = 0.08205
Step 156175: loss = 0.21320
Step 156180: loss = 0.13536
Step 156185: loss = 0.06561
Step 156190: loss = 0.18351
Step 156195: loss = 0.13088
Step 156200: loss = 0.04653
Step 156205: loss = 0.11041
Step 156210: loss = 0.14920
Step 156215: loss = 0.17525
Step 156220: loss = 0.11108
Step 156225: loss = 0.18291
Step 156230: loss = 0.04480
Step 156235: loss = 0.12958
Step 156240: loss = 0.21222
Step 156245: loss = 0.36702
Step 156250: loss = 0.20718
Step 156255: loss = 0.08825
Step 156260: loss = 0.04863
Step 156265: loss = 0.06948
Step 156270: loss = 0.16482
Step 156275: loss = 0.10010
Step 156280: loss = 0.10302
Step 156285: loss = 0.29896
Step 156290: loss = 0.03839
Step 156295: loss = 0.35105
Step 156300: loss = 0.05363
Step 156305: loss = 0.07847
Step 156310: loss = 0.10292
Step 156315: loss = 0.11299
Step 156320: loss = 0.14589
Step 156325: loss = 0.05235
Step 156330: loss = 0.06044
Step 156335: loss = 0.25719
Step 156340: loss = 0.11907
Step 156345: loss = 0.10527
Step 156350: loss = 0.15384
Step 156355: loss = 0.05510
Step 156360: loss = 0.25898
Step 156365: loss = 0.10623
Step 156370: loss = 0.19025
Step 156375: loss = 0.32386
Step 156380: loss = 0.10359
Step 156385: loss = 0.18804
Step 156390: loss = 0.03342
Step 156395: loss = 0.23145
Step 156400: loss = 0.05838
Step 156405: loss = 0.21831
Step 156410: loss = 0.31539
Step 156415: loss = 0.06061
Step 156420: loss = 0.19989
Step 156425: loss = 0.08042
Step 156430: loss = 0.25575
Step 156435: loss = 0.08653
Step 156440: loss = 0.10375
Step 156445: loss = 0.07176
Step 156450: loss = 0.14842
Step 156455: loss = 0.12838
Step 156460: loss = 0.18904
Step 156465: loss = 0.06404
Step 156470: loss = 0.07853
Step 156475: loss = 0.10319
Step 156480: loss = 0.04487
Step 156485: loss = 0.13216
Step 156490: loss = 0.11633
Step 156495: loss = 0.13117
Step 156500: loss = 0.06339
Step 156505: loss = 0.10860
Step 156510: loss = 0.09300
Step 156515: loss = 0.08447
Step 156520: loss = 0.06423
Step 156525: loss = 0.16456
Step 156530: loss = 0.18838
Step 156535: loss = 0.17008
Step 156540: loss = 0.06483
Step 156545: loss = 0.08749
Step 156550: loss = 0.15298
Step 156555: loss = 0.12810
Step 156560: loss = 0.18573
Step 156565: loss = 0.07293
Step 156570: loss = 0.15457
Step 156575: loss = 0.08072
Step 156580: loss = 0.15339
Step 156585: loss = 0.06675
Step 156590: loss = 0.16396
Step 156595: loss = 0.06052
Step 156600: loss = 0.03582
Step 156605: loss = 0.26449
Step 156610: loss = 0.23406
Step 156615: loss = 0.20160
Step 156620: loss = 0.15438
Step 156625: loss = 0.04950
Step 156630: loss = 0.12085
Step 156635: loss = 0.06715
Step 156640: loss = 0.03950
Step 156645: loss = 0.10469
Step 156650: loss = 0.11031
Step 156655: loss = 0.10355
Step 156660: loss = 0.06783
Step 156665: loss = 0.16390
Step 156670: loss = 0.16399
Step 156675: loss = 0.17305
Step 156680: loss = 0.15315
Step 156685: loss = 0.07951
Step 156690: loss = 0.19831
Step 156695: loss = 0.15215
Step 156700: loss = 0.04197
Step 156705: loss = 0.05949
Step 156710: loss = 0.12850
Step 156715: loss = 0.06908
Step 156720: loss = 0.09662
Step 156725: loss = 0.02278
Step 156730: loss = 0.05130
Step 156735: loss = 0.22101
Step 156740: loss = 0.04414
Step 156745: loss = 0.18294
Step 156750: loss = 0.04506
Step 156755: loss = 0.03912
Step 156760: loss = 0.03729
Step 156765: loss = 0.15155
Step 156770: loss = 0.05855
Step 156775: loss = 0.08588
Step 156780: loss = 0.24619
Step 156785: loss = 0.10134
Step 156790: loss = 0.15476
Step 156795: loss = 0.12755
Step 156800: loss = 0.08601
Step 156805: loss = 0.10499
Step 156810: loss = 0.17133
Step 156815: loss = 0.08156
Step 156820: loss = 0.64450
Step 156825: loss = 0.13330
Step 156830: loss = 0.12465
Step 156835: loss = 0.18255
Step 156840: loss = 0.05860
Step 156845: loss = 0.24197
Step 156850: loss = 0.08831
Step 156855: loss = 0.03182
Step 156860: loss = 0.05003
Step 156865: loss = 0.19622
Step 156870: loss = 0.09096
Step 156875: loss = 0.02490
Step 156880: loss = 0.15687
Step 156885: loss = 0.08731
Step 156890: loss = 0.06888
Step 156895: loss = 0.05088
Step 156900: loss = 0.05064
Step 156905: loss = 0.22373
Step 156910: loss = 0.08969
Step 156915: loss = 0.05135
Step 156920: loss = 0.05748
Step 156925: loss = 0.11985
Step 156930: loss = 0.07904
Step 156935: loss = 0.08043
Step 156940: loss = 0.11019
Step 156945: loss = 0.05228
Step 156950: loss = 0.23619
Step 156955: loss = 0.01032
Step 156960: loss = 0.20410
Step 156965: loss = 0.02485
Step 156970: loss = 0.07493
Step 156975: loss = 0.10385
Step 156980: loss = 0.19097
Step 156985: loss = 0.09569
Step 156990: loss = 0.22368
Step 156995: loss = 0.06571
Step 157000: loss = 0.01919
Training Data Eval:
  Num examples: 50000, Num correct: 47970, Precision @ 1: 0.9594
('Testing Data Eval: EPOCH->', 158)
  Num examples: 10000, Num correct: 6616, Precision @ 1: 0.6616
Step 157005: loss = 0.06239
Step 157010: loss = 0.38663
Step 157015: loss = 0.11923
Step 157020: loss = 0.17057
Step 157025: loss = 0.09086
Step 157030: loss = 0.08024
Step 157035: loss = 0.06243
Step 157040: loss = 0.11809
Step 157045: loss = 0.15566
Step 157050: loss = 0.09950
Step 157055: loss = 0.08743
Step 157060: loss = 0.19250
Step 157065: loss = 0.21596
Step 157070: loss = 0.03010
Step 157075: loss = 0.03849
Step 157080: loss = 0.11492
Step 157085: loss = 0.26198
Step 157090: loss = 0.06078
Step 157095: loss = 0.17946
Step 157100: loss = 0.14364
Step 157105: loss = 0.59423
Step 157110: loss = 0.35038
Step 157115: loss = 0.03958
Step 157120: loss = 0.16441
Step 157125: loss = 0.09841
Step 157130: loss = 0.06473
Step 157135: loss = 0.06859
Step 157140: loss = 0.14192
Step 157145: loss = 0.19784
Step 157150: loss = 0.18282
Step 157155: loss = 0.17281
Step 157160: loss = 0.10550
Step 157165: loss = 0.26193
Step 157170: loss = 0.09980
Step 157175: loss = 0.13555
Step 157180: loss = 0.18912
Step 157185: loss = 0.15619
Step 157190: loss = 0.07585
Step 157195: loss = 0.06138
Step 157200: loss = 0.14435
Step 157205: loss = 0.24274
Step 157210: loss = 0.05410
Step 157215: loss = 0.20624
Step 157220: loss = 0.05879
Step 157225: loss = 0.18645
Step 157230: loss = 0.34033
Step 157235: loss = 0.11592
Step 157240: loss = 0.15200
Step 157245: loss = 0.09127
Step 157250: loss = 0.21091
Step 157255: loss = 0.06867
Step 157260: loss = 0.23701
Step 157265: loss = 0.07897
Step 157270: loss = 0.06297
Step 157275: loss = 0.05724
Step 157280: loss = 0.07619
Step 157285: loss = 0.03702
Step 157290: loss = 0.09117
Step 157295: loss = 0.10086
Step 157300: loss = 0.07886
Step 157305: loss = 0.14878
Step 157310: loss = 0.19665
Step 157315: loss = 0.12790
Step 157320: loss = 0.02865
Step 157325: loss = 0.15808
Step 157330: loss = 0.09820
Step 157335: loss = 0.18331
Step 157340: loss = 0.03813
Step 157345: loss = 0.16580
Step 157350: loss = 0.15228
Step 157355: loss = 0.19641
Step 157360: loss = 0.12708
Step 157365: loss = 0.06520
Step 157370: loss = 0.07007
Step 157375: loss = 0.23268
Step 157380: loss = 0.13152
Step 157385: loss = 0.02147
Step 157390: loss = 0.03705
Step 157395: loss = 0.21694
Step 157400: loss = 0.18656
Step 157405: loss = 0.05400
Step 157410: loss = 0.15841
Step 157415: loss = 0.06662
Step 157420: loss = 0.32690
Step 157425: loss = 0.19691
Step 157430: loss = 0.26470
Step 157435: loss = 0.06903
Step 157440: loss = 0.09913
Step 157445: loss = 0.07265
Step 157450: loss = 0.05181
Step 157455: loss = 0.07205
Step 157460: loss = 0.13166
Step 157465: loss = 0.07886
Step 157470: loss = 0.11209
Step 157475: loss = 0.07182
Step 157480: loss = 0.11731
Step 157485: loss = 0.03141
Step 157490: loss = 0.28898
Step 157495: loss = 0.09656
Step 157500: loss = 0.08616
Step 157505: loss = 0.17280
Step 157510: loss = 0.06472
Step 157515: loss = 0.15566
Step 157520: loss = 0.02306
Step 157525: loss = 0.06336
Step 157530: loss = 0.19580
Step 157535: loss = 0.21865
Step 157540: loss = 0.03316
Step 157545: loss = 0.15030
Step 157550: loss = 0.03824
Step 157555: loss = 0.05758
Step 157560: loss = 0.12115
Step 157565: loss = 0.05771
Step 157570: loss = 0.07929
Step 157575: loss = 0.18340
Step 157580: loss = 0.21039
Step 157585: loss = 0.11230
Step 157590: loss = 0.16541
Step 157595: loss = 0.20666
Step 157600: loss = 0.16414
Step 157605: loss = 0.07011
Step 157610: loss = 0.11160
Step 157615: loss = 0.08964
Step 157620: loss = 0.07469
Step 157625: loss = 0.16932
Step 157630: loss = 0.10063
Step 157635: loss = 0.17400
Step 157640: loss = 0.06230
Step 157645: loss = 0.08686
Step 157650: loss = 0.03360
Step 157655: loss = 0.14115
Step 157660: loss = 0.22581
Step 157665: loss = 0.03314
Step 157670: loss = 0.04549
Step 157675: loss = 0.04837
Step 157680: loss = 0.06338
Step 157685: loss = 0.19477
Step 157690: loss = 0.03447
Step 157695: loss = 0.04214
Step 157700: loss = 0.03915
Step 157705: loss = 0.05404
Step 157710: loss = 0.09421
Step 157715: loss = 0.05974
Step 157720: loss = 0.04655
Step 157725: loss = 0.06556
Step 157730: loss = 0.10741
Step 157735: loss = 0.06172
Step 157740: loss = 0.16007
Step 157745: loss = 0.30973
Step 157750: loss = 0.06726
Step 157755: loss = 0.21787
Step 157760: loss = 0.25089
Step 157765: loss = 0.16087
Step 157770: loss = 0.23588
Step 157775: loss = 0.12544
Step 157780: loss = 0.08150
Step 157785: loss = 0.19184
Step 157790: loss = 0.05487
Step 157795: loss = 0.07077
Step 157800: loss = 0.05748
Step 157805: loss = 0.18223
Step 157810: loss = 0.09569
Step 157815: loss = 0.13116
Step 157820: loss = 0.32366
Step 157825: loss = 0.15739
Step 157830: loss = 0.08589
Step 157835: loss = 0.13483
Step 157840: loss = 0.04372
Step 157845: loss = 0.08106
Step 157850: loss = 0.05247
Step 157855: loss = 0.04726
Step 157860: loss = 0.12131
Step 157865: loss = 0.02712
Step 157870: loss = 0.07281
Step 157875: loss = 0.08500
Step 157880: loss = 0.15258
Step 157885: loss = 0.29666
Step 157890: loss = 0.08593
Step 157895: loss = 0.05450
Step 157900: loss = 0.08562
Step 157905: loss = 0.10690
Step 157910: loss = 0.07296
Step 157915: loss = 0.28041
Step 157920: loss = 0.06176
Step 157925: loss = 0.22406
Step 157930: loss = 0.08684
Step 157935: loss = 0.07395
Step 157940: loss = 0.11452
Step 157945: loss = 0.23909
Step 157950: loss = 0.11650
Step 157955: loss = 0.05887
Step 157960: loss = 0.13611
Step 157965: loss = 0.10701
Step 157970: loss = 0.09457
Step 157975: loss = 0.13836
Step 157980: loss = 0.07689
Step 157985: loss = 0.22799
Step 157990: loss = 0.25979
Step 157995: loss = 0.21259
Step 158000: loss = 0.30386
Training Data Eval:
  Num examples: 50000, Num correct: 46727, Precision @ 1: 0.9345
('Testing Data Eval: EPOCH->', 159)
  Num examples: 10000, Num correct: 6416, Precision @ 1: 0.6416
Step 158005: loss = 0.08365
Step 158010: loss = 0.15199
Step 158015: loss = 0.09605
Step 158020: loss = 0.14321
Step 158025: loss = 0.11041
Step 158030: loss = 0.14735
Step 158035: loss = 0.12022
Step 158040: loss = 0.21263
Step 158045: loss = 0.05885
Step 158050: loss = 0.24991
Step 158055: loss = 0.13927
Step 158060: loss = 0.46810
Step 158065: loss = 0.05650
Step 158070: loss = 0.12466
Step 158075: loss = 0.09849
Step 158080: loss = 0.04999
Step 158085: loss = 0.12780
Step 158090: loss = 0.05420
Step 158095: loss = 0.26209
Step 158100: loss = 0.07296
Step 158105: loss = 0.10276
Step 158110: loss = 0.27386
Step 158115: loss = 0.04348
Step 158120: loss = 0.26017
Step 158125: loss = 0.09578
Step 158130: loss = 0.05886
Step 158135: loss = 0.06198
Step 158140: loss = 0.02915
Step 158145: loss = 0.05316
Step 158150: loss = 0.11189
Step 158155: loss = 0.10313
Step 158160: loss = 0.08858
Step 158165: loss = 0.12622
Step 158170: loss = 0.10179
Step 158175: loss = 0.07128
Step 158180: loss = 0.07971
Step 158185: loss = 0.12702
Step 158190: loss = 0.16986
Step 158195: loss = 0.18795
Step 158200: loss = 0.13593
Step 158205: loss = 0.06450
Step 158210: loss = 0.24700
Step 158215: loss = 0.10019
Step 158220: loss = 0.07241
Step 158225: loss = 0.22647
Step 158230: loss = 0.31230
Step 158235: loss = 0.16577
Step 158240: loss = 0.11211
Step 158245: loss = 0.08637
Step 158250: loss = 0.15802
Step 158255: loss = 0.12119
Step 158260: loss = 0.13407
Step 158265: loss = 0.09224
Step 158270: loss = 0.06802
Step 158275: loss = 0.05080
Step 158280: loss = 0.20042
Step 158285: loss = 0.09420
Step 158290: loss = 0.16849
Step 158295: loss = 0.04856
Step 158300: loss = 0.07097
Step 158305: loss = 0.07395
Step 158310: loss = 0.08352
Step 158315: loss = 0.46077
Step 158320: loss = 0.22337
Step 158325: loss = 0.07695
Step 158330: loss = 0.20486
Step 158335: loss = 0.08448
Step 158340: loss = 0.07823
Step 158345: loss = 0.04663
Step 158350: loss = 0.22755
Step 158355: loss = 0.08503
Step 158360: loss = 0.16770
Step 158365: loss = 0.04950
Step 158370: loss = 0.03875
Step 158375: loss = 0.09878
Step 158380: loss = 0.25407
Step 158385: loss = 0.17474
Step 158390: loss = 0.12343
Step 158395: loss = 0.04453
Step 158400: loss = 0.12502
Step 158405: loss = 0.26445
Step 158410: loss = 0.31918
Step 158415: loss = 0.04550
Step 158420: loss = 0.18165
Step 158425: loss = 0.10032
Step 158430: loss = 0.21269
Step 158435: loss = 0.05004
Step 158440: loss = 0.04131
Step 158445: loss = 0.07563
Step 158450: loss = 0.15188
Step 158455: loss = 0.13976
Step 158460: loss = 0.05195
Step 158465: loss = 0.13399
Step 158470: loss = 0.16576
Step 158475: loss = 0.24755
Step 158480: loss = 0.03465
Step 158485: loss = 0.11361
Step 158490: loss = 0.13092
Step 158495: loss = 0.19238
Step 158500: loss = 0.14056
Step 158505: loss = 0.06535
Step 158510: loss = 0.08668
Step 158515: loss = 0.15389
Step 158520: loss = 0.19689
Step 158525: loss = 0.04953
Step 158530: loss = 0.15652
Step 158535: loss = 0.08726
Step 158540: loss = 0.32534
Step 158545: loss = 0.01908
Step 158550: loss = 0.10226
Step 158555: loss = 0.16431
Step 158560: loss = 0.05135
Step 158565: loss = 0.02904
Step 158570: loss = 0.18912
Step 158575: loss = 0.05499
Step 158580: loss = 0.14884
Step 158585: loss = 0.15870
Step 158590: loss = 0.09632
Step 158595: loss = 0.11377
Step 158600: loss = 0.20841
Step 158605: loss = 0.25220
Step 158610: loss = 0.15937
Step 158615: loss = 0.06406
Step 158620: loss = 0.13796
Step 158625: loss = 0.12187
Step 158630: loss = 0.07210
Step 158635: loss = 0.31526
Step 158640: loss = 0.13392
Step 158645: loss = 0.06280
Step 158650: loss = 0.21489
Step 158655: loss = 0.11675
Step 158660: loss = 0.22995
Step 158665: loss = 0.05245
Step 158670: loss = 0.08340
Step 158675: loss = 0.07490
Step 158680: loss = 0.12274
Step 158685: loss = 0.04768
Step 158690: loss = 0.10852
Step 158695: loss = 0.07839
Step 158700: loss = 0.09758
Step 158705: loss = 0.09810
Step 158710: loss = 0.20928
Step 158715: loss = 0.10793
Step 158720: loss = 0.24433
Step 158725: loss = 0.06588
Step 158730: loss = 0.20875
Step 158735: loss = 0.10724
Step 158740: loss = 0.04840
Step 158745: loss = 0.12386
Step 158750: loss = 0.06536
Step 158755: loss = 0.06317
Step 158760: loss = 0.03470
Step 158765: loss = 0.08946
Step 158770: loss = 0.04252
Step 158775: loss = 0.09777
Step 158780: loss = 0.07277
Step 158785: loss = 0.16746
Step 158790: loss = 0.15480
Step 158795: loss = 0.07308
Step 158800: loss = 0.05891
Step 158805: loss = 0.08421
Step 158810: loss = 0.21940
Step 158815: loss = 0.03605
Step 158820: loss = 0.02235
Step 158825: loss = 0.03671
Step 158830: loss = 0.28345
Step 158835: loss = 0.06113
Step 158840: loss = 0.14969
Step 158845: loss = 0.04424
Step 158850: loss = 0.03296
Step 158855: loss = 0.04998
Step 158860: loss = 0.11917
Step 158865: loss = 0.18286
Step 158870: loss = 0.08608
Step 158875: loss = 0.05076
Step 158880: loss = 0.17916
Step 158885: loss = 0.07272
Step 158890: loss = 0.05018
Step 158895: loss = 0.16951
Step 158900: loss = 0.24136
Step 158905: loss = 0.10949
Step 158910: loss = 0.10558
Step 158915: loss = 0.08247
Step 158920: loss = 0.13837
Step 158925: loss = 0.13675
Step 158930: loss = 0.14051
Step 158935: loss = 0.05633
Step 158940: loss = 0.03588
Step 158945: loss = 0.18306
Step 158950: loss = 0.16057
Step 158955: loss = 0.09000
Step 158960: loss = 0.13375
Step 158965: loss = 0.05477
Step 158970: loss = 0.01494
Step 158975: loss = 0.05776
Step 158980: loss = 0.07007
Step 158985: loss = 0.10996
Step 158990: loss = 0.15856
Step 158995: loss = 0.05422
Step 159000: loss = 0.14472
Training Data Eval:
  Num examples: 50000, Num correct: 48067, Precision @ 1: 0.9613
('Testing Data Eval: EPOCH->', 160)
  Num examples: 10000, Num correct: 6677, Precision @ 1: 0.6677
Step 159005: loss = 0.36016
Step 159010: loss = 0.11293
Step 159015: loss = 0.07978
Step 159020: loss = 0.02436
Step 159025: loss = 0.13956
Step 159030: loss = 0.05367
Step 159035: loss = 0.11038
Step 159040: loss = 0.05831
Step 159045: loss = 0.11098
Step 159050: loss = 0.05039
Step 159055: loss = 0.44035
Step 159060: loss = 0.15167
Step 159065: loss = 0.05492
Step 159070: loss = 0.08516
Step 159075: loss = 0.08207
Step 159080: loss = 0.12910
Step 159085: loss = 0.11397
Step 159090: loss = 0.18375
Step 159095: loss = 0.06882
Step 159100: loss = 0.02653
Step 159105: loss = 0.06665
Step 159110: loss = 0.20518
Step 159115: loss = 0.06460
Step 159120: loss = 0.10112
Step 159125: loss = 0.15028
Step 159130: loss = 0.04396
Step 159135: loss = 0.11234
Step 159140: loss = 0.07739
Step 159145: loss = 0.06389
Step 159150: loss = 0.11918
Step 159155: loss = 0.13095
Step 159160: loss = 0.03892
Step 159165: loss = 0.08299
Step 159170: loss = 0.01141
Step 159175: loss = 0.05494
Step 159180: loss = 0.13350
Step 159185: loss = 0.18381
Step 159190: loss = 0.07137
Step 159195: loss = 0.09402
Step 159200: loss = 0.37612
Step 159205: loss = 0.18139
Step 159210: loss = 0.06482
Step 159215: loss = 0.21386
Step 159220: loss = 0.13346
Step 159225: loss = 0.05927
Step 159230: loss = 0.08203
Step 159235: loss = 0.08602
Step 159240: loss = 0.22892
Step 159245: loss = 0.08131
Step 159250: loss = 0.15760
Step 159255: loss = 0.12557
Step 159260: loss = 0.09113
Step 159265: loss = 0.07603
Step 159270: loss = 0.32672
Step 159275: loss = 0.08191
Step 159280: loss = 0.22868
Step 159285: loss = 0.11456
Step 159290: loss = 0.04987
Step 159295: loss = 0.15120
Step 159300: loss = 0.02977
Step 159305: loss = 0.05042
Step 159310: loss = 0.22271
Step 159315: loss = 0.15082
Step 159320: loss = 0.13729
Step 159325: loss = 0.28677
Step 159330: loss = 0.01730
Step 159335: loss = 0.08465
Step 159340: loss = 0.11167
Step 159345: loss = 0.06683
Step 159350: loss = 0.37570
Step 159355: loss = 0.05854
Step 159360: loss = 0.03990
Step 159365: loss = 0.18174
Step 159370: loss = 0.09663
Step 159375: loss = 0.11013
Step 159380: loss = 0.10031
Step 159385: loss = 0.04264
Step 159390: loss = 0.03852
Step 159395: loss = 0.10013
Step 159400: loss = 0.07122
Step 159405: loss = 0.10803
Step 159410: loss = 0.03196
Step 159415: loss = 0.08871
Step 159420: loss = 0.21855
Step 159425: loss = 0.06453
Step 159430: loss = 0.03780
Step 159435: loss = 0.12286
Step 159440: loss = 0.06868
Step 159445: loss = 0.22690
Step 159450: loss = 0.07564
Step 159455: loss = 0.10206
Step 159460: loss = 0.15089
Step 159465: loss = 0.26683
Step 159470: loss = 0.13642
Step 159475: loss = 0.04359
Step 159480: loss = 0.04656
Step 159485: loss = 0.28548
Step 159490: loss = 0.08969
Step 159495: loss = 0.41744
Step 159500: loss = 0.11329
Step 159505: loss = 0.11167
Step 159510: loss = 0.34390
Step 159515: loss = 0.03073
Step 159520: loss = 0.10903
Step 159525: loss = 0.27983
Step 159530: loss = 0.16136
Step 159535: loss = 0.05555
Step 159540: loss = 0.06206
Step 159545: loss = 0.18629
Step 159550: loss = 0.09631
Step 159555: loss = 0.15345
Step 159560: loss = 0.14533
Step 159565: loss = 0.06216
Step 159570: loss = 0.04473
Step 159575: loss = 0.06738
Step 159580: loss = 0.12260
Step 159585: loss = 0.08082
Step 159590: loss = 0.02941
Step 159595: loss = 0.08631
Step 159600: loss = 0.06487
Step 159605: loss = 0.09785
Step 159610: loss = 0.09395
Step 159615: loss = 0.23920
Step 159620: loss = 0.04495
Step 159625: loss = 0.05320
Step 159630: loss = 0.29671
Step 159635: loss = 0.06245
Step 159640: loss = 0.02850
Step 159645: loss = 0.10755
Step 159650: loss = 0.17719
Step 159655: loss = 0.04195
Step 159660: loss = 0.18879
Step 159665: loss = 0.20705
Step 159670: loss = 0.10796
Step 159675: loss = 0.11666
Step 159680: loss = 0.08787
Step 159685: loss = 0.06790
Step 159690: loss = 0.06945
Step 159695: loss = 0.12166
Step 159700: loss = 0.07203
Step 159705: loss = 0.14464
Step 159710: loss = 0.12372
Step 159715: loss = 0.02698
Step 159720: loss = 0.11042
Step 159725: loss = 0.07909
Step 159730: loss = 0.06016
Step 159735: loss = 0.08260
Step 159740: loss = 0.22324
Step 159745: loss = 0.16609
Step 159750: loss = 0.05707
Step 159755: loss = 0.18815
Step 159760: loss = 0.17589
Step 159765: loss = 0.09884
Step 159770: loss = 0.03942
Step 159775: loss = 0.10745
Step 159780: loss = 0.03889
Step 159785: loss = 0.03852
Step 159790: loss = 0.13520
Step 159795: loss = 0.06362
Step 159800: loss = 0.10462
Step 159805: loss = 0.06474
Step 159810: loss = 0.22704
Step 159815: loss = 0.05576
Step 159820: loss = 0.17308
Step 159825: loss = 0.18416
Step 159830: loss = 0.20656
Step 159835: loss = 0.08857
Step 159840: loss = 0.08025
Step 159845: loss = 0.09230
Step 159850: loss = 0.09137
Step 159855: loss = 0.08800
Step 159860: loss = 0.04539
Step 159865: loss = 0.05517
Step 159870: loss = 0.03956
Step 159875: loss = 0.02692
Step 159880: loss = 0.02875
Step 159885: loss = 0.04250
Step 159890: loss = 0.07853
Step 159895: loss = 0.06987
Step 159900: loss = 0.15707
Step 159905: loss = 0.07433
Step 159910: loss = 0.08608
Step 159915: loss = 0.14213
Step 159920: loss = 0.08262
Step 159925: loss = 0.11365
Step 159930: loss = 0.27858
Step 159935: loss = 0.04155
Step 159940: loss = 0.13141
Step 159945: loss = 0.08588
Step 159950: loss = 0.17730
Step 159955: loss = 0.13154
Step 159960: loss = 0.15453
Step 159965: loss = 0.20320
Step 159970: loss = 0.06199
Step 159975: loss = 0.25697
Step 159980: loss = 0.09208
Step 159985: loss = 0.04481
Step 159990: loss = 0.18625
Step 159995: loss = 0.05653
Step 160000: loss = 0.05053
Training Data Eval:
  Num examples: 50000, Num correct: 47932, Precision @ 1: 0.9586
('Testing Data Eval: EPOCH->', 161)
  Num examples: 10000, Num correct: 6644, Precision @ 1: 0.6644
Step 160005: loss = 0.08087
Step 160010: loss = 0.20268
Step 160015: loss = 0.15059
Step 160020: loss = 0.06547
Step 160025: loss = 0.14186
Step 160030: loss = 0.08545
Step 160035: loss = 0.20098
Step 160040: loss = 0.05010
Step 160045: loss = 0.04489
Step 160050: loss = 0.06608
Step 160055: loss = 0.07748
Step 160060: loss = 0.26203
Step 160065: loss = 0.06807
Step 160070: loss = 0.07387
Step 160075: loss = 0.12337
Step 160080: loss = 0.21996
Step 160085: loss = 0.17375
Step 160090: loss = 0.16977
Step 160095: loss = 0.10821
Step 160100: loss = 0.06998
Step 160105: loss = 0.03909
Step 160110: loss = 0.07402
Step 160115: loss = 0.03559
Step 160120: loss = 0.14292
Step 160125: loss = 0.17918
Step 160130: loss = 0.04470
Step 160135: loss = 0.20536
Step 160140: loss = 0.05578
Step 160145: loss = 0.04820
Step 160150: loss = 0.17459
Step 160155: loss = 0.12032
Step 160160: loss = 0.15257
Step 160165: loss = 0.17753
Step 160170: loss = 0.11409
Step 160175: loss = 0.13055
Step 160180: loss = 0.24445
Step 160185: loss = 0.13343
Step 160190: loss = 0.17568
Step 160195: loss = 0.12689
Step 160200: loss = 0.15897
Step 160205: loss = 0.13851
Step 160210: loss = 0.09866
Step 160215: loss = 0.11578
Step 160220: loss = 0.05356
Step 160225: loss = 0.07165
Step 160230: loss = 0.29177
Step 160235: loss = 0.06354
Step 160240: loss = 0.06992
Step 160245: loss = 0.01892
Step 160250: loss = 0.28344
Step 160255: loss = 0.11078
Step 160260: loss = 0.18764
Step 160265: loss = 0.07596
Step 160270: loss = 0.09043
Step 160275: loss = 0.03361
Step 160280: loss = 0.16754
Step 160285: loss = 0.24822
Step 160290: loss = 0.20618
Step 160295: loss = 0.29763
Step 160300: loss = 0.28937
Step 160305: loss = 0.37468
Step 160310: loss = 0.11454
Step 160315: loss = 0.16270
Step 160320: loss = 0.09610
Step 160325: loss = 0.05407
Step 160330: loss = 0.13966
Step 160335: loss = 0.13823
Step 160340: loss = 0.02935
Step 160345: loss = 0.07551
Step 160350: loss = 0.15838
Step 160355: loss = 0.03888
Step 160360: loss = 0.10421
Step 160365: loss = 0.04630
Step 160370: loss = 0.12051
Step 160375: loss = 0.10400
Step 160380: loss = 0.02874
Step 160385: loss = 0.05242
Step 160390: loss = 0.44860
Step 160395: loss = 0.05407
Step 160400: loss = 0.10646
Step 160405: loss = 0.12113
Step 160410: loss = 0.03577
Step 160415: loss = 0.18594
Step 160420: loss = 0.16844
Step 160425: loss = 0.05125
Step 160430: loss = 0.20875
Step 160435: loss = 0.09612
Step 160440: loss = 0.09214
Step 160445: loss = 0.05754
Step 160450: loss = 0.13290
Step 160455: loss = 0.16041
Step 160460: loss = 0.08059
Step 160465: loss = 0.17626
Step 160470: loss = 0.05410
Step 160475: loss = 0.15724
Step 160480: loss = 0.10654
Step 160485: loss = 0.08609
Step 160490: loss = 0.19698
Step 160495: loss = 0.05936
Step 160500: loss = 0.28650
Step 160505: loss = 0.05855
Step 160510: loss = 0.16862
Step 160515: loss = 0.17739
Step 160520: loss = 0.05760
Step 160525: loss = 0.11539
Step 160530: loss = 0.30578
Step 160535: loss = 0.08482
Step 160540: loss = 0.12361
Step 160545: loss = 0.04650
Step 160550: loss = 0.16015
Step 160555: loss = 0.06543
Step 160560: loss = 0.15182
Step 160565: loss = 0.07783
Step 160570: loss = 0.21105
Step 160575: loss = 0.08681
Step 160580: loss = 0.07765
Step 160585: loss = 0.03508
Step 160590: loss = 0.07088
Step 160595: loss = 0.05947
Step 160600: loss = 0.04399
Step 160605: loss = 0.22785
Step 160610: loss = 0.09163
Step 160615: loss = 0.08492
Step 160620: loss = 0.13018
Step 160625: loss = 0.02637
Step 160630: loss = 0.17069
Step 160635: loss = 0.08564
Step 160640: loss = 0.05860
Step 160645: loss = 0.19555
Step 160650: loss = 0.15799
Step 160655: loss = 0.06471
Step 160660: loss = 0.06558
Step 160665: loss = 0.32449
Step 160670: loss = 0.08541
Step 160675: loss = 0.15934
Step 160680: loss = 0.09940
Step 160685: loss = 0.13609
Step 160690: loss = 0.22399
Step 160695: loss = 0.03440
Step 160700: loss = 0.08329
Step 160705: loss = 0.09278
Step 160710: loss = 0.31312
Step 160715: loss = 0.12176
Step 160720: loss = 0.11521
Step 160725: loss = 0.08990
Step 160730: loss = 0.04131
Step 160735: loss = 0.48679
Step 160740: loss = 0.14446
Step 160745: loss = 0.14223
Step 160750: loss = 0.32334
Step 160755: loss = 0.02902
Step 160760: loss = 0.21317
Step 160765: loss = 0.05376
Step 160770: loss = 0.05938
Step 160775: loss = 0.10151
Step 160780: loss = 0.15552
Step 160785: loss = 0.14918
Step 160790: loss = 0.04198
Step 160795: loss = 0.12754
Step 160800: loss = 0.15643
Step 160805: loss = 0.10950
Step 160810: loss = 0.07736
Step 160815: loss = 0.07618
Step 160820: loss = 0.12663
Step 160825: loss = 0.08680
Step 160830: loss = 0.12912
Step 160835: loss = 0.45281
Step 160840: loss = 0.12619
Step 160845: loss = 0.03316
Step 160850: loss = 0.12100
Step 160855: loss = 0.08988
Step 160860: loss = 0.07780
Step 160865: loss = 0.02277
Step 160870: loss = 0.04128
Step 160875: loss = 0.15862
Step 160880: loss = 0.02815
Step 160885: loss = 0.10259
Step 160890: loss = 0.06612
Step 160895: loss = 0.12814
Step 160900: loss = 0.07402
Step 160905: loss = 0.10410
Step 160910: loss = 0.09434
Step 160915: loss = 0.13845
Step 160920: loss = 0.05756
Step 160925: loss = 0.11645
Step 160930: loss = 0.03228
Step 160935: loss = 0.08570
Step 160940: loss = 0.06151
Step 160945: loss = 0.13947
Step 160950: loss = 0.07068
Step 160955: loss = 0.13155
Step 160960: loss = 0.19371
Step 160965: loss = 0.18363
Step 160970: loss = 0.12926
Step 160975: loss = 0.09128
Step 160980: loss = 0.15747
Step 160985: loss = 0.18930
Step 160990: loss = 0.05110
Step 160995: loss = 0.20195
Step 161000: loss = 0.05688
Training Data Eval:
  Num examples: 50000, Num correct: 47836, Precision @ 1: 0.9567
('Testing Data Eval: EPOCH->', 162)
  Num examples: 10000, Num correct: 6639, Precision @ 1: 0.6639
Step 161005: loss = 0.07308
Step 161010: loss = 0.08119
Step 161015: loss = 0.05759
Step 161020: loss = 0.04922
Step 161025: loss = 0.02844
Step 161030: loss = 0.09013
Step 161035: loss = 0.04336
Step 161040: loss = 0.14190
Step 161045: loss = 0.06567
Step 161050: loss = 0.05880
Step 161055: loss = 0.03569
Step 161060: loss = 0.04001
Step 161065: loss = 0.04345
Step 161070: loss = 0.11634
Step 161075: loss = 0.23494
Step 161080: loss = 0.16356
Step 161085: loss = 0.03019
Step 161090: loss = 0.10098
Step 161095: loss = 0.05127
Step 161100: loss = 0.04833
Step 161105: loss = 0.07127
Step 161110: loss = 0.12632
Step 161115: loss = 0.07357
Step 161120: loss = 0.05661
Step 161125: loss = 0.10992
Step 161130: loss = 0.16844
Step 161135: loss = 0.04133
Step 161140: loss = 0.23418
Step 161145: loss = 0.05460
Step 161150: loss = 0.17952
Step 161155: loss = 0.09494
Step 161160: loss = 0.09785
Step 161165: loss = 0.01608
Step 161170: loss = 0.11354
Step 161175: loss = 0.17513
Step 161180: loss = 0.19174
Step 161185: loss = 0.04328
Step 161190: loss = 0.06085
Step 161195: loss = 0.09656
Step 161200: loss = 0.12675
Step 161205: loss = 0.04664
Step 161210: loss = 0.11376
Step 161215: loss = 0.14744
Step 161220: loss = 0.03686
Step 161225: loss = 0.12090
Step 161230: loss = 0.05865
Step 161235: loss = 0.13518
Step 161240: loss = 0.11409
Step 161245: loss = 0.16453
Step 161250: loss = 0.26912
Step 161255: loss = 0.31801
Step 161260: loss = 0.04233
Step 161265: loss = 0.04795
Step 161270: loss = 0.04088
Step 161275: loss = 0.09632
Step 161280: loss = 0.06498
Step 161285: loss = 0.09043
Step 161290: loss = 0.09071
Step 161295: loss = 0.19462
Step 161300: loss = 0.26052
Step 161305: loss = 0.01624
Step 161310: loss = 0.10884
Step 161315: loss = 0.08710
Step 161320: loss = 0.19150
Step 161325: loss = 0.10631
Step 161330: loss = 0.08181
Step 161335: loss = 0.13949
Step 161340: loss = 0.29523
Step 161345: loss = 0.14802
Step 161350: loss = 0.24999
Step 161355: loss = 0.10595
Step 161360: loss = 0.15479
Step 161365: loss = 0.03607
Step 161370: loss = 0.10708
Step 161375: loss = 0.19947
Step 161380: loss = 0.02188
Step 161385: loss = 0.16741
Step 161390: loss = 0.07679
Step 161395: loss = 0.32640
Step 161400: loss = 0.13440
Step 161405: loss = 0.05246
Step 161410: loss = 0.08182
Step 161415: loss = 0.05479
Step 161420: loss = 0.09783
Step 161425: loss = 0.13183
Step 161430: loss = 0.14465
Step 161435: loss = 0.12211
Step 161440: loss = 0.11701
Step 161445: loss = 0.07900
Step 161450: loss = 0.06464
Step 161455: loss = 0.07562
Step 161460: loss = 0.05585
Step 161465: loss = 0.14102
Step 161470: loss = 0.05473
Step 161475: loss = 0.04793
Step 161480: loss = 0.13095
Step 161485: loss = 0.13608
Step 161490: loss = 0.11342
Step 161495: loss = 0.03195
Step 161500: loss = 0.06556
Step 161505: loss = 0.07602
Step 161510: loss = 0.06579
Step 161515: loss = 0.11220
Step 161520: loss = 0.10056
Step 161525: loss = 0.02471
Step 161530: loss = 0.02891
Step 161535: loss = 0.18043
Step 161540: loss = 0.07591
Step 161545: loss = 0.05037
Step 161550: loss = 0.07335
Step 161555: loss = 0.16824
Step 161560: loss = 0.08805
Step 161565: loss = 0.09629
Step 161570: loss = 0.12661
Step 161575: loss = 0.02887
Step 161580: loss = 0.08305
Step 161585: loss = 0.13654
Step 161590: loss = 0.14888
Step 161595: loss = 0.11678
Step 161600: loss = 0.06507
Step 161605: loss = 0.18093
Step 161610: loss = 0.21781
Step 161615: loss = 0.13323
Step 161620: loss = 0.18883
Step 161625: loss = 0.16574
Step 161630: loss = 0.12177
Step 161635: loss = 0.12388
Step 161640: loss = 0.29063
Step 161645: loss = 0.14269
Step 161650: loss = 0.13587
Step 161655: loss = 0.05257
Step 161660: loss = 0.15451
Step 161665: loss = 0.02836
Step 161670: loss = 0.03578
Step 161675: loss = 0.02103
Step 161680: loss = 0.10827
Step 161685: loss = 0.30866
Step 161690: loss = 0.13969
Step 161695: loss = 0.15309
Step 161700: loss = 0.08966
Step 161705: loss = 0.04685
Step 161710: loss = 0.17103
Step 161715: loss = 0.23166
Step 161720: loss = 0.12579
Step 161725: loss = 0.04311
Step 161730: loss = 0.15973
Step 161735: loss = 0.17709
Step 161740: loss = 0.26974
Step 161745: loss = 0.13226
Step 161750: loss = 0.04962
Step 161755: loss = 0.13351
Step 161760: loss = 0.16846
Step 161765: loss = 0.12863
Step 161770: loss = 0.03803
Step 161775: loss = 0.03847
Step 161780: loss = 0.07460
Step 161785: loss = 0.29380
Step 161790: loss = 0.06268
Step 161795: loss = 0.04114
Step 161800: loss = 0.19349
Step 161805: loss = 0.26940
Step 161810: loss = 0.28319
Step 161815: loss = 0.14782
Step 161820: loss = 0.30574
Step 161825: loss = 0.35109
Step 161830: loss = 0.10770
Step 161835: loss = 0.09352
Step 161840: loss = 0.05202
Step 161845: loss = 0.09730
Step 161850: loss = 0.13100
Step 161855: loss = 0.09555
Step 161860: loss = 0.23413
Step 161865: loss = 0.01649
Step 161870: loss = 0.02664
Step 161875: loss = 0.13000
Step 161880: loss = 0.16401
Step 161885: loss = 0.15167
Step 161890: loss = 0.18830
Step 161895: loss = 0.07784
Step 161900: loss = 0.06884
Step 161905: loss = 0.29286
Step 161910: loss = 0.03093
Step 161915: loss = 0.10015
Step 161920: loss = 0.09670
Step 161925: loss = 0.17553
Step 161930: loss = 0.31683
Step 161935: loss = 0.10973
Step 161940: loss = 0.11201
Step 161945: loss = 0.11951
Step 161950: loss = 0.07775
Step 161955: loss = 0.09863
Step 161960: loss = 0.06532
Step 161965: loss = 0.05372
Step 161970: loss = 0.11478
Step 161975: loss = 0.12790
Step 161980: loss = 0.13185
Step 161985: loss = 0.13019
Step 161990: loss = 0.42897
Step 161995: loss = 0.06383
Step 162000: loss = 0.15383
Training Data Eval:
  Num examples: 50000, Num correct: 47227, Precision @ 1: 0.9445
('Testing Data Eval: EPOCH->', 163)
  Num examples: 10000, Num correct: 6562, Precision @ 1: 0.6562
Step 162005: loss = 0.14440
Step 162010: loss = 0.45500
Step 162015: loss = 0.15344
Step 162020: loss = 0.22662
Step 162025: loss = 0.15715
Step 162030: loss = 0.14315
Step 162035: loss = 0.18810
Step 162040: loss = 0.10418
Step 162045: loss = 0.13652
Step 162050: loss = 0.17055
Step 162055: loss = 0.17517
Step 162060: loss = 0.34984
Step 162065: loss = 0.18029
Step 162070: loss = 0.13130
Step 162075: loss = 0.03439
Step 162080: loss = 0.10070
Step 162085: loss = 0.17346
Step 162090: loss = 0.06974
Step 162095: loss = 0.10375
Step 162100: loss = 0.14677
Step 162105: loss = 0.10920
Step 162110: loss = 0.05305
Step 162115: loss = 0.03624
Step 162120: loss = 0.05891
Step 162125: loss = 0.13324
Step 162130: loss = 0.18494
Step 162135: loss = 0.07370
Step 162140: loss = 0.07741
Step 162145: loss = 0.07691
Step 162150: loss = 0.07572
Step 162155: loss = 0.10863
Step 162160: loss = 0.10708
Step 162165: loss = 0.06597
Step 162170: loss = 0.08776
Step 162175: loss = 0.10853
Step 162180: loss = 0.11230
Step 162185: loss = 0.03116
Step 162190: loss = 0.25720
Step 162195: loss = 0.20839
Step 162200: loss = 0.28362
Step 162205: loss = 0.14280
Step 162210: loss = 0.06060
Step 162215: loss = 0.06175
Step 162220: loss = 0.16252
Step 162225: loss = 0.21576
Step 162230: loss = 0.04380
Step 162235: loss = 0.08071
Step 162240: loss = 0.14706
Step 162245: loss = 0.29004
Step 162250: loss = 0.07079
Step 162255: loss = 0.04685
Step 162260: loss = 0.10513
Step 162265: loss = 0.07445
Step 162270: loss = 0.13746
Step 162275: loss = 0.06889
Step 162280: loss = 0.15809
Step 162285: loss = 0.08621
Step 162290: loss = 0.09329
Step 162295: loss = 0.24502
Step 162300: loss = 0.17450
Step 162305: loss = 0.22198
Step 162310: loss = 0.08875
Step 162315: loss = 0.07845
Step 162320: loss = 0.11323
Step 162325: loss = 0.15445
Step 162330: loss = 0.15275
Step 162335: loss = 0.06736
Step 162340: loss = 0.10198
Step 162345: loss = 0.12127
Step 162350: loss = 0.34903
Step 162355: loss = 0.08771
Step 162360: loss = 0.04440
Step 162365: loss = 0.18909
Step 162370: loss = 0.09716
Step 162375: loss = 0.10558
Step 162380: loss = 0.01047
Step 162385: loss = 0.14951
Step 162390: loss = 0.16157
Step 162395: loss = 0.05255
Step 162400: loss = 0.13825
Step 162405: loss = 0.05900
Step 162410: loss = 0.17630
Step 162415: loss = 0.22713
Step 162420: loss = 0.04681
Step 162425: loss = 0.25016
Step 162430: loss = 0.07245
Step 162435: loss = 0.05781
Step 162440: loss = 0.16696
Step 162445: loss = 0.10012
Step 162450: loss = 0.17232
Step 162455: loss = 0.13803
Step 162460: loss = 0.20526
Step 162465: loss = 0.10397
Step 162470: loss = 0.10510
Step 162475: loss = 0.10382
Step 162480: loss = 0.10217
Step 162485: loss = 0.25484
Step 162490: loss = 0.01163
Step 162495: loss = 0.08494
Step 162500: loss = 0.01585
Step 162505: loss = 0.38810
Step 162510: loss = 0.20477
Step 162515: loss = 0.08261
Step 162520: loss = 0.14133
Step 162525: loss = 0.10626
Step 162530: loss = 0.19648
Step 162535: loss = 0.15868
Step 162540: loss = 0.05518
Step 162545: loss = 0.34410
Step 162550: loss = 0.13889
Step 162555: loss = 0.05350
Step 162560: loss = 0.09738
Step 162565: loss = 0.24985
Step 162570: loss = 0.03049
Step 162575: loss = 0.11095
Step 162580: loss = 0.09408
Step 162585: loss = 0.36115
Step 162590: loss = 0.05359
Step 162595: loss = 0.08891
Step 162600: loss = 0.08664
Step 162605: loss = 0.09116
Step 162610: loss = 0.11066
Step 162615: loss = 0.05712
Step 162620: loss = 0.11919
Step 162625: loss = 0.42591
Step 162630: loss = 0.16847
Step 162635: loss = 0.14323
Step 162640: loss = 0.15962
Step 162645: loss = 0.06196
Step 162650: loss = 0.04724
Step 162655: loss = 0.05438
Step 162660: loss = 0.08530
Step 162665: loss = 0.11252
Step 162670: loss = 0.10243
Step 162675: loss = 0.04662
Step 162680: loss = 0.12896
Step 162685: loss = 0.19542
Step 162690: loss = 0.08373
Step 162695: loss = 0.05796
Step 162700: loss = 0.10258
Step 162705: loss = 0.08820
Step 162710: loss = 0.11128
Step 162715: loss = 0.20278
Step 162720: loss = 0.06637
Step 162725: loss = 0.10166
Step 162730: loss = 0.06999
Step 162735: loss = 0.18347
Step 162740: loss = 0.14000
Step 162745: loss = 0.07322
Step 162750: loss = 0.13666
Step 162755: loss = 0.24130
Step 162760: loss = 0.17489
Step 162765: loss = 0.13399
Step 162770: loss = 0.05872
Step 162775: loss = 0.19135
Step 162780: loss = 0.17012
Step 162785: loss = 0.06309
Step 162790: loss = 0.11978
Step 162795: loss = 0.09727
Step 162800: loss = 0.27331
Step 162805: loss = 0.04820
Step 162810: loss = 0.04065
Step 162815: loss = 0.06067
Step 162820: loss = 0.12273
Step 162825: loss = 0.03834
Step 162830: loss = 0.14386
Step 162835: loss = 0.13037
Step 162840: loss = 0.13289
Step 162845: loss = 0.32995
Step 162850: loss = 0.09935
Step 162855: loss = 0.05691
Step 162860: loss = 0.14625
Step 162865: loss = 0.03049
Step 162870: loss = 0.23137
Step 162875: loss = 0.07268
Step 162880: loss = 0.09512
Step 162885: loss = 0.09304
Step 162890: loss = 0.10293
Step 162895: loss = 0.02746
Step 162900: loss = 0.04876
Step 162905: loss = 0.09667
Step 162910: loss = 0.12213
Step 162915: loss = 0.12244
Step 162920: loss = 0.06419
Step 162925: loss = 0.04329
Step 162930: loss = 0.13421
Step 162935: loss = 0.10198
Step 162940: loss = 0.17096
Step 162945: loss = 0.09797
Step 162950: loss = 0.15895
Step 162955: loss = 0.11729
Step 162960: loss = 0.10113
Step 162965: loss = 0.08148
Step 162970: loss = 0.02422
Step 162975: loss = 0.22615
Step 162980: loss = 0.08593
Step 162985: loss = 0.14904
Step 162990: loss = 0.07932
Step 162995: loss = 0.08719
Step 163000: loss = 0.21628
Training Data Eval:
  Num examples: 50000, Num correct: 47852, Precision @ 1: 0.9570
('Testing Data Eval: EPOCH->', 164)
  Num examples: 10000, Num correct: 6636, Precision @ 1: 0.6636
Step 163005: loss = 0.04774
Step 163010: loss = 0.11232
Step 163015: loss = 0.03956
Step 163020: loss = 0.05274
Step 163025: loss = 0.05635
Step 163030: loss = 0.18192
Step 163035: loss = 0.04651
Step 163040: loss = 0.06590
Step 163045: loss = 0.13928
Step 163050: loss = 0.03544
Step 163055: loss = 0.15023
Step 163060: loss = 0.20903
Step 163065: loss = 0.06678
Step 163070: loss = 0.02119
Step 163075: loss = 0.14019
Step 163080: loss = 0.10627
Step 163085: loss = 0.08966
Step 163090: loss = 0.23474
Step 163095: loss = 0.17541
Step 163100: loss = 0.29100
Step 163105: loss = 0.39778
Step 163110: loss = 0.26076
Step 163115: loss = 0.15773
Step 163120: loss = 0.22814
Step 163125: loss = 0.21623
Step 163130: loss = 0.41095
Step 163135: loss = 0.29409
Step 163140: loss = 0.09052
Step 163145: loss = 0.17824
Step 163150: loss = 0.07817
Step 163155: loss = 0.11515
Step 163160: loss = 0.11834
Step 163165: loss = 0.03242
Step 163170: loss = 0.11559
Step 163175: loss = 0.12659
Step 163180: loss = 0.02635
Step 163185: loss = 0.03328
Step 163190: loss = 0.11754
Step 163195: loss = 0.10205
Step 163200: loss = 0.05833
Step 163205: loss = 0.04834
Step 163210: loss = 0.05277
Step 163215: loss = 0.15154
Step 163220: loss = 0.06836
Step 163225: loss = 0.07468
Step 163230: loss = 0.18445
Step 163235: loss = 0.09760
Step 163240: loss = 0.09256
Step 163245: loss = 0.17240
Step 163250: loss = 0.07861
Step 163255: loss = 0.07118
Step 163260: loss = 0.05646
Step 163265: loss = 0.11548
Step 163270: loss = 0.28320
Step 163275: loss = 0.32570
Step 163280: loss = 0.11585
Step 163285: loss = 0.19012
Step 163290: loss = 0.12108
Step 163295: loss = 0.06219
Step 163300: loss = 0.08521
Step 163305: loss = 0.09067
Step 163310: loss = 0.13405
Step 163315: loss = 0.29569
Step 163320: loss = 0.02717
Step 163325: loss = 0.13845
Step 163330: loss = 0.05579
Step 163335: loss = 0.09763
Step 163340: loss = 0.05226
Step 163345: loss = 0.18636
Step 163350: loss = 0.11436
Step 163355: loss = 0.03623
Step 163360: loss = 0.06668
Step 163365: loss = 0.03742
Step 163370: loss = 0.28232
Step 163375: loss = 0.05636
Step 163380: loss = 0.23258
Step 163385: loss = 0.12161
Step 163390: loss = 0.06829
Step 163395: loss = 0.11502
Step 163400: loss = 0.05046
Step 163405: loss = 0.10885
Step 163410: loss = 0.06936
Step 163415: loss = 0.03169
Step 163420: loss = 0.11226
Step 163425: loss = 0.07225
Step 163430: loss = 0.05540
Step 163435: loss = 0.11090
Step 163440: loss = 0.10056
Step 163445: loss = 0.05728
Step 163450: loss = 0.12616
Step 163455: loss = 0.03688
Step 163460: loss = 0.17635
Step 163465: loss = 0.07099
Step 163470: loss = 0.19204
Step 163475: loss = 0.06116
Step 163480: loss = 0.22059
Step 163485: loss = 0.13055
Step 163490: loss = 0.08275
Step 163495: loss = 0.11996
Step 163500: loss = 0.12632
Step 163505: loss = 0.12709
Step 163510: loss = 0.05585
Step 163515: loss = 0.11763
Step 163520: loss = 0.01584
Step 163525: loss = 0.19475
Step 163530: loss = 0.12162
Step 163535: loss = 0.11256
Step 163540: loss = 0.17272
Step 163545: loss = 0.16036
Step 163550: loss = 0.11304
Step 163555: loss = 0.13276
Step 163560: loss = 0.30713
Step 163565: loss = 0.13793
Step 163570: loss = 0.14329
Step 163575: loss = 0.22575
Step 163580: loss = 0.16956
Step 163585: loss = 0.02889
Step 163590: loss = 0.06728
Step 163595: loss = 0.18798
Step 163600: loss = 0.11349
Step 163605: loss = 0.12559
Step 163610: loss = 0.15099
Step 163615: loss = 0.26708
Step 163620: loss = 0.05755
Step 163625: loss = 0.16667
Step 163630: loss = 0.05958
Step 163635: loss = 0.12581
Step 163640: loss = 0.04581
Step 163645: loss = 0.11068
Step 163650: loss = 0.28625
Step 163655: loss = 0.03684
Step 163660: loss = 0.23798
Step 163665: loss = 0.04030
Step 163670: loss = 0.04849
Step 163675: loss = 0.13977
Step 163680: loss = 0.08535
Step 163685: loss = 0.04652
Step 163690: loss = 0.09692
Step 163695: loss = 0.16113
Step 163700: loss = 0.16210
Step 163705: loss = 0.11030
Step 163710: loss = 0.09932
Step 163715: loss = 0.46659
Step 163720: loss = 0.13340
Step 163725: loss = 0.05332
Step 163730: loss = 0.12806
Step 163735: loss = 0.09004
Step 163740: loss = 0.38496
Step 163745: loss = 0.10399
Step 163750: loss = 0.35525
Step 163755: loss = 0.07273
Step 163760: loss = 0.22193
Step 163765: loss = 0.08320
Step 163770: loss = 0.04364
Step 163775: loss = 0.06676
Step 163780: loss = 0.13314
Step 163785: loss = 0.13333
Step 163790: loss = 0.10171
Step 163795: loss = 0.05454
Step 163800: loss = 0.10267
Step 163805: loss = 0.18640
Step 163810: loss = 0.17575
Step 163815: loss = 0.08613
Step 163820: loss = 0.22919
Step 163825: loss = 0.14042
Step 163830: loss = 0.18742
Step 163835: loss = 0.09063
Step 163840: loss = 0.05572
Step 163845: loss = 0.03106
Step 163850: loss = 0.31215
Step 163855: loss = 0.13365
Step 163860: loss = 0.19110
Step 163865: loss = 0.09986
Step 163870: loss = 0.11620
Step 163875: loss = 0.06544
Step 163880: loss = 0.39259
Step 163885: loss = 0.04678
Step 163890: loss = 0.15657
Step 163895: loss = 0.06777
Step 163900: loss = 0.18289
Step 163905: loss = 0.14668
Step 163910: loss = 0.03636
Step 163915: loss = 0.26540
Step 163920: loss = 0.09508
Step 163925: loss = 0.35005
Step 163930: loss = 0.04573
Step 163935: loss = 0.12887
Step 163940: loss = 0.22048
Step 163945: loss = 0.06724
Step 163950: loss = 0.09480
Step 163955: loss = 0.02910
Step 163960: loss = 0.19274
Step 163965: loss = 0.16860
Step 163970: loss = 0.06709
Step 163975: loss = 0.05675
Step 163980: loss = 0.17290
Step 163985: loss = 0.04599
Step 163990: loss = 0.14542
Step 163995: loss = 0.06211
Step 164000: loss = 0.09281
Training Data Eval:
  Num examples: 50000, Num correct: 48049, Precision @ 1: 0.9610
('Testing Data Eval: EPOCH->', 165)
  Num examples: 10000, Num correct: 6697, Precision @ 1: 0.6697
Step 164005: loss = 0.08794
Step 164010: loss = 0.10997
Step 164015: loss = 0.05382
Step 164020: loss = 0.15919
Step 164025: loss = 0.15585
Step 164030: loss = 0.07832
Step 164035: loss = 0.07860
Step 164040: loss = 0.10985
Step 164045: loss = 0.05044
Step 164050: loss = 0.14034
Step 164055: loss = 0.03960
Step 164060: loss = 0.07102
Step 164065: loss = 0.13835
Step 164070: loss = 0.20027
Step 164075: loss = 0.06670
Step 164080: loss = 0.08369
Step 164085: loss = 0.08879
Step 164090: loss = 0.09232
Step 164095: loss = 0.02605
Step 164100: loss = 0.07804
Step 164105: loss = 0.05138
Step 164110: loss = 0.12919
Step 164115: loss = 0.07172
Step 164120: loss = 0.18437
Step 164125: loss = 0.24710
Step 164130: loss = 0.09062
Step 164135: loss = 0.26623
Step 164140: loss = 0.23795
Step 164145: loss = 0.13563
Step 164150: loss = 0.04597
Step 164155: loss = 0.06642
Step 164160: loss = 0.15715
Step 164165: loss = 0.09567
Step 164170: loss = 0.12298
Step 164175: loss = 0.22375
Step 164180: loss = 0.18611
Step 164185: loss = 0.28035
Step 164190: loss = 0.20573
Step 164195: loss = 0.15203
Step 164200: loss = 0.06244
Step 164205: loss = 0.05996
Step 164210: loss = 0.04234
Step 164215: loss = 0.38745
Step 164220: loss = 0.16688
Step 164225: loss = 0.30543
Step 164230: loss = 0.18862
Step 164235: loss = 0.11108
Step 164240: loss = 0.07191
Step 164245: loss = 0.14720
Step 164250: loss = 0.15772
Step 164255: loss = 0.25351
Step 164260: loss = 0.14052
Step 164265: loss = 0.31016
Step 164270: loss = 0.07626
Step 164275: loss = 0.24028
Step 164280: loss = 0.14813
Step 164285: loss = 0.06379
Step 164290: loss = 0.08918
Step 164295: loss = 0.16674
Step 164300: loss = 0.03548
Step 164305: loss = 0.19186
Step 164310: loss = 0.12653
Step 164315: loss = 0.28949
Step 164320: loss = 0.04583
Step 164325: loss = 0.06005
Step 164330: loss = 0.16101
Step 164335: loss = 0.10403
Step 164340: loss = 0.08462
Step 164345: loss = 0.10192
Step 164350: loss = 0.40316
Step 164355: loss = 0.11715
Step 164360: loss = 0.11479
Step 164365: loss = 0.07111
Step 164370: loss = 0.06218
Step 164375: loss = 0.08124
Step 164380: loss = 0.14109
Step 164385: loss = 0.04722
Step 164390: loss = 0.16121
Step 164395: loss = 0.11234
Step 164400: loss = 0.06232
Step 164405: loss = 0.14379
Step 164410: loss = 0.37257
Step 164415: loss = 0.07857
Step 164420: loss = 0.05175
Step 164425: loss = 0.23306
Step 164430: loss = 0.16388
Step 164435: loss = 0.09210
Step 164440: loss = 0.05454
Step 164445: loss = 0.06656
Step 164450: loss = 0.06880
Step 164455: loss = 0.14474
Step 164460: loss = 0.07259
Step 164465: loss = 0.26556
Step 164470: loss = 0.10000
Step 164475: loss = 0.18914
Step 164480: loss = 0.13241
Step 164485: loss = 0.08977
Step 164490: loss = 0.24878
Step 164495: loss = 0.08220
Step 164500: loss = 0.22597
Step 164505: loss = 0.05306
Step 164510: loss = 0.09211
Step 164515: loss = 0.10370
Step 164520: loss = 0.07065
Step 164525: loss = 0.09969
Step 164530: loss = 0.22047
Step 164535: loss = 0.10398
Step 164540: loss = 0.18468
Step 164545: loss = 0.32526
Step 164550: loss = 0.07214
Step 164555: loss = 0.07829
Step 164560: loss = 0.13882
Step 164565: loss = 0.06680
Step 164570: loss = 0.30081
Step 164575: loss = 0.25582
Step 164580: loss = 0.21371
Step 164585: loss = 0.13212
Step 164590: loss = 0.03328
Step 164595: loss = 0.04089
Step 164600: loss = 0.07576
Step 164605: loss = 0.08229
Step 164610: loss = 0.05775
Step 164615: loss = 0.15566
Step 164620: loss = 0.04925
Step 164625: loss = 0.06455
Step 164630: loss = 0.36904
Step 164635: loss = 0.14143
Step 164640: loss = 0.05789
Step 164645: loss = 0.23704
Step 164650: loss = 0.06781
Step 164655: loss = 0.13265
Step 164660: loss = 0.15227
Step 164665: loss = 0.24692
Step 164670: loss = 0.05461
Step 164675: loss = 0.03226
Step 164680: loss = 0.33445
Step 164685: loss = 0.22076
Step 164690: loss = 0.04782
Step 164695: loss = 0.15713
Step 164700: loss = 0.17399
Step 164705: loss = 0.15291
Step 164710: loss = 0.07260
Step 164715: loss = 0.08908
Step 164720: loss = 0.24449
Step 164725: loss = 0.08836
Step 164730: loss = 0.08052
Step 164735: loss = 0.11973
Step 164740: loss = 0.17710
Step 164745: loss = 0.07621
Step 164750: loss = 0.36654
Step 164755: loss = 0.25554
Step 164760: loss = 0.14864
Step 164765: loss = 0.04658
Step 164770: loss = 0.14004
Step 164775: loss = 0.04536
Step 164780: loss = 0.07014
Step 164785: loss = 0.10704
Step 164790: loss = 0.17678
Step 164795: loss = 0.32013
Step 164800: loss = 0.18485
Step 164805: loss = 0.11586
Step 164810: loss = 0.33541
Step 164815: loss = 0.16214
Step 164820: loss = 0.07224
Step 164825: loss = 0.08660
Step 164830: loss = 0.32150
Step 164835: loss = 0.19734
Step 164840: loss = 0.13661
Step 164845: loss = 0.07377
Step 164850: loss = 0.16962
Step 164855: loss = 0.13706
Step 164860: loss = 0.03671
Step 164865: loss = 0.34423
Step 164870: loss = 0.08743
Step 164875: loss = 0.26611
Step 164880: loss = 0.06876
Step 164885: loss = 0.20489
Step 164890: loss = 0.13766
Step 164895: loss = 0.30937
Step 164900: loss = 0.15119
Step 164905: loss = 0.10576
Step 164910: loss = 0.08271
Step 164915: loss = 0.24914
Step 164920: loss = 0.07600
Step 164925: loss = 0.05430
Step 164930: loss = 0.10559
Step 164935: loss = 0.22541
Step 164940: loss = 0.09052
Step 164945: loss = 0.07930
Step 164950: loss = 0.14103
Step 164955: loss = 0.27810
Step 164960: loss = 0.24361
Step 164965: loss = 0.20990
Step 164970: loss = 0.06011
Step 164975: loss = 0.22492
Step 164980: loss = 0.20931
Step 164985: loss = 0.20605
Step 164990: loss = 0.09415
Step 164995: loss = 0.09285
Step 165000: loss = 0.05388
Training Data Eval:
  Num examples: 50000, Num correct: 47949, Precision @ 1: 0.9590
('Testing Data Eval: EPOCH->', 166)
  Num examples: 10000, Num correct: 6665, Precision @ 1: 0.6665
Step 165005: loss = 0.03189
Step 165010: loss = 0.03400
Step 165015: loss = 0.06562
Step 165020: loss = 0.06377
Step 165025: loss = 0.13200
Step 165030: loss = 0.06437
Step 165035: loss = 0.06683
Step 165040: loss = 0.08660
Step 165045: loss = 0.12842
Step 165050: loss = 0.11417
Step 165055: loss = 0.32954
Step 165060: loss = 0.05201
Step 165065: loss = 0.11232
Step 165070: loss = 0.22487
Step 165075: loss = 0.07957
Step 165080: loss = 0.13507
Step 165085: loss = 0.03690
Step 165090: loss = 0.05387
Step 165095: loss = 0.02973
Step 165100: loss = 0.08361
Step 165105: loss = 0.04972
Step 165110: loss = 0.05964
Step 165115: loss = 0.08117
Step 165120: loss = 0.16051
Step 165125: loss = 0.12545
Step 165130: loss = 0.12065
Step 165135: loss = 0.02881
Step 165140: loss = 0.13840
Step 165145: loss = 0.07426
Step 165150: loss = 0.16560
Step 165155: loss = 0.07978
Step 165160: loss = 0.15764
Step 165165: loss = 0.13851
Step 165170: loss = 0.12700
Step 165175: loss = 0.17635
Step 165180: loss = 0.08668
Step 165185: loss = 0.14198
Step 165190: loss = 0.18998
Step 165195: loss = 0.12056
Step 165200: loss = 0.09158
Step 165205: loss = 0.16186
Step 165210: loss = 0.18762
Step 165215: loss = 0.14901
Step 165220: loss = 0.04891
Step 165225: loss = 0.22290
Step 165230: loss = 0.09607
Step 165235: loss = 0.09031
Step 165240: loss = 0.13393
Step 165245: loss = 0.12036
Step 165250: loss = 0.18805
Step 165255: loss = 0.12650
Step 165260: loss = 0.10065
Step 165265: loss = 0.14907
Step 165270: loss = 0.04196
Step 165275: loss = 0.07576
Step 165280: loss = 0.23018
Step 165285: loss = 0.04504
Step 165290: loss = 0.31169
Step 165295: loss = 0.10763
Step 165300: loss = 0.12108
Step 165305: loss = 0.07365
Step 165310: loss = 0.04541
Step 165315: loss = 0.05179
Step 165320: loss = 0.18826
Step 165325: loss = 0.03414
Step 165330: loss = 0.32632
Step 165335: loss = 0.20961
Step 165340: loss = 0.10145
Step 165345: loss = 0.01451
Step 165350: loss = 0.09295
Step 165355: loss = 0.05515
Step 165360: loss = 0.11787
Step 165365: loss = 0.11067
Step 165370: loss = 0.10628
Step 165375: loss = 0.14288
Step 165380: loss = 0.14453
Step 165385: loss = 0.06630
Step 165390: loss = 0.18581
Step 165395: loss = 0.11320
Step 165400: loss = 0.07779
Step 165405: loss = 0.07350
Step 165410: loss = 0.02060
Step 165415: loss = 0.11070
Step 165420: loss = 0.03458
Step 165425: loss = 0.13893
Step 165430: loss = 0.19044
Step 165435: loss = 0.06428
Step 165440: loss = 0.02304
Step 165445: loss = 0.08811
Step 165450: loss = 0.11715
Step 165455: loss = 0.10687
Step 165460: loss = 0.22849
Step 165465: loss = 0.10203
Step 165470: loss = 0.10513
Step 165475: loss = 0.13292
Step 165480: loss = 0.19627
Step 165485: loss = 0.11994
Step 165490: loss = 0.18801
Step 165495: loss = 0.24837
Step 165500: loss = 0.16918
Step 165505: loss = 0.40943
Step 165510: loss = 0.21925
Step 165515: loss = 0.07370
Step 165520: loss = 0.02494
Step 165525: loss = 0.09892
Step 165530: loss = 0.12732
Step 165535: loss = 0.04880
Step 165540: loss = 0.12779
Step 165545: loss = 0.18552
Step 165550: loss = 0.02289
Step 165555: loss = 0.10690
Step 165560: loss = 0.05964
Step 165565: loss = 0.12995
Step 165570: loss = 0.11852
Step 165575: loss = 0.02439
Step 165580: loss = 0.09833
Step 165585: loss = 0.20357
Step 165590: loss = 0.14431
Step 165595: loss = 0.38689
Step 165600: loss = 0.29552
Step 165605: loss = 0.08972
Step 165610: loss = 0.07632
Step 165615: loss = 0.04558
Step 165620: loss = 0.34849
Step 165625: loss = 0.12565
Step 165630: loss = 0.14911
Step 165635: loss = 0.06585
Step 165640: loss = 0.08992
Step 165645: loss = 0.27824
Step 165650: loss = 0.05767
Step 165655: loss = 0.24002
Step 165660: loss = 0.05561
Step 165665: loss = 0.11874
Step 165670: loss = 0.30228
Step 165675: loss = 0.04246
Step 165680: loss = 0.04669
Step 165685: loss = 0.18914
Step 165690: loss = 0.12608
Step 165695: loss = 0.15668
Step 165700: loss = 0.12095
Step 165705: loss = 0.17357
Step 165710: loss = 0.02700
Step 165715: loss = 0.53340
Step 165720: loss = 0.13306
Step 165725: loss = 0.19519
Step 165730: loss = 0.11192
Step 165735: loss = 0.21180
Step 165740: loss = 0.13156
Step 165745: loss = 0.06521
Step 165750: loss = 0.11517
Step 165755: loss = 0.16835
Step 165760: loss = 0.23035
Step 165765: loss = 0.46137
Step 165770: loss = 0.04488
Step 165775: loss = 0.14846
Step 165780: loss = 0.25712
Step 165785: loss = 0.14134
Step 165790: loss = 0.04396
Step 165795: loss = 0.14180
Step 165800: loss = 0.18525
Step 165805: loss = 0.20062
Step 165810: loss = 0.04757
Step 165815: loss = 0.15866
Step 165820: loss = 0.10845
Step 165825: loss = 0.11399
Step 165830: loss = 0.06974
Step 165835: loss = 0.20465
Step 165840: loss = 0.09109
Step 165845: loss = 0.05452
Step 165850: loss = 0.08127
Step 165855: loss = 0.10123
Step 165860: loss = 0.04526
Step 165865: loss = 0.12297
Step 165870: loss = 0.18858
Step 165875: loss = 0.05510
Step 165880: loss = 0.05112
Step 165885: loss = 0.15656
Step 165890: loss = 0.14579
Step 165895: loss = 0.07110
Step 165900: loss = 0.04582
Step 165905: loss = 0.05204
Step 165910: loss = 0.11887
Step 165915: loss = 0.03569
Step 165920: loss = 0.16064
Step 165925: loss = 0.13985
Step 165930: loss = 0.05920
Step 165935: loss = 0.33447
Step 165940: loss = 0.23949
Step 165945: loss = 0.21009
Step 165950: loss = 0.19135
Step 165955: loss = 0.21026
Step 165960: loss = 0.05155
Step 165965: loss = 0.06158
Step 165970: loss = 0.16985
Step 165975: loss = 0.22057
Step 165980: loss = 0.18995
Step 165985: loss = 0.13942
Step 165990: loss = 0.13331
Step 165995: loss = 0.08334
Step 166000: loss = 0.08095
Training Data Eval:
  Num examples: 50000, Num correct: 47965, Precision @ 1: 0.9593
('Testing Data Eval: EPOCH->', 167)
  Num examples: 10000, Num correct: 6684, Precision @ 1: 0.6684
Step 166005: loss = 0.06616
Step 166010: loss = 0.02927
Step 166015: loss = 0.07061
Step 166020: loss = 0.35964
Step 166025: loss = 0.10668
Step 166030: loss = 0.03907
Step 166035: loss = 0.17729
Step 166040: loss = 0.28558
Step 166045: loss = 0.02324
Step 166050: loss = 0.11270
Step 166055: loss = 0.04065
Step 166060: loss = 0.06226
Step 166065: loss = 0.17431
Step 166070: loss = 0.06700
Step 166075: loss = 0.10734
Step 166080: loss = 0.11661
Step 166085: loss = 0.04183
Step 166090: loss = 0.15278
Step 166095: loss = 0.03050
Step 166100: loss = 0.11478
Step 166105: loss = 0.03856
Step 166110: loss = 0.17735
Step 166115: loss = 0.19681
Step 166120: loss = 0.14544
Step 166125: loss = 0.08059
Step 166130: loss = 0.12221
Step 166135: loss = 0.40395
Step 166140: loss = 0.10091
Step 166145: loss = 0.12896
Step 166150: loss = 0.08769
Step 166155: loss = 0.08233
Step 166160: loss = 0.12957
Step 166165: loss = 0.11187
Step 166170: loss = 0.04231
Step 166175: loss = 0.20929
Step 166180: loss = 0.21832
Step 166185: loss = 0.08365
Step 166190: loss = 0.23873
Step 166195: loss = 0.11642
Step 166200: loss = 0.06224
Step 166205: loss = 0.17046
Step 166210: loss = 0.09629
Step 166215: loss = 0.13498
Step 166220: loss = 0.10036
Step 166225: loss = 0.07839
Step 166230: loss = 0.05484
Step 166235: loss = 0.15234
Step 166240: loss = 0.07134
Step 166245: loss = 0.07116
Step 166250: loss = 0.08913
Step 166255: loss = 0.01029
Step 166260: loss = 0.04407
Step 166265: loss = 0.32468
Step 166270: loss = 0.08645
Step 166275: loss = 0.06837
Step 166280: loss = 0.09752
Step 166285: loss = 0.10828
Step 166290: loss = 0.16624
Step 166295: loss = 0.03998
Step 166300: loss = 0.11393
Step 166305: loss = 0.09271
Step 166310: loss = 0.14778
Step 166315: loss = 0.09936
Step 166320: loss = 0.17438
Step 166325: loss = 0.25170
Step 166330: loss = 0.12159
Step 166335: loss = 0.14540
Step 166340: loss = 0.15270
Step 166345: loss = 0.16390
Step 166350: loss = 0.11422
Step 166355: loss = 0.23478
Step 166360: loss = 0.05491
Step 166365: loss = 0.09277
Step 166370: loss = 0.17137
Step 166375: loss = 0.14340
Step 166380: loss = 0.25454
Step 166385: loss = 0.03260
Step 166390: loss = 0.15671
Step 166395: loss = 0.03947
Step 166400: loss = 0.08320
Step 166405: loss = 0.12722
Step 166410: loss = 0.19593
Step 166415: loss = 0.23656
Step 166420: loss = 0.11000
Step 166425: loss = 0.13818
Step 166430: loss = 0.08175
Step 166435: loss = 0.13743
Step 166440: loss = 0.12069
Step 166445: loss = 0.07079
Step 166450: loss = 0.09921
Step 166455: loss = 0.04995
Step 166460: loss = 0.06468
Step 166465: loss = 0.49858
Step 166470: loss = 0.13380
Step 166475: loss = 0.16097
Step 166480: loss = 0.02739
Step 166485: loss = 0.11555
Step 166490: loss = 0.17963
Step 166495: loss = 0.04191
Step 166500: loss = 0.10754
Step 166505: loss = 0.08084
Step 166510: loss = 0.11298
Step 166515: loss = 0.10215
Step 166520: loss = 0.07343
Step 166525: loss = 0.16069
Step 166530: loss = 0.15703
Step 166535: loss = 0.05903
Step 166540: loss = 0.03397
Step 166545: loss = 0.12485
Step 166550: loss = 0.10785
Step 166555: loss = 0.07712
Step 166560: loss = 0.23254
Step 166565: loss = 0.08408
Step 166570: loss = 0.03855
Step 166575: loss = 0.18153
Step 166580: loss = 0.08654
Step 166585: loss = 0.09863
Step 166590: loss = 0.02695
Step 166595: loss = 0.03456
Step 166600: loss = 0.15311
Step 166605: loss = 0.04462
Step 166610: loss = 0.09938
Step 166615: loss = 0.22646
Step 166620: loss = 0.21698
Step 166625: loss = 0.18057
Step 166630: loss = 0.16540
Step 166635: loss = 0.10332
Step 166640: loss = 0.02338
Step 166645: loss = 0.36350
Step 166650: loss = 0.20860
Step 166655: loss = 0.01628
Step 166660: loss = 0.04694
Step 166665: loss = 0.12508
Step 166670: loss = 0.20357
Step 166675: loss = 0.03062
Step 166680: loss = 0.19905
Step 166685: loss = 0.25360
Step 166690: loss = 0.25013
Step 166695: loss = 0.15756
Step 166700: loss = 0.04345
Step 166705: loss = 0.07122
Step 166710: loss = 0.11870
Step 166715: loss = 0.12326
Step 166720: loss = 0.35421
Step 166725: loss = 0.21912
Step 166730: loss = 0.07156
Step 166735: loss = 0.11809
Step 166740: loss = 0.14928
Step 166745: loss = 0.02367
Step 166750: loss = 0.14878
Step 166755: loss = 0.18976
Step 166760: loss = 0.16602
Step 166765: loss = 0.04968
Step 166770: loss = 0.41324
Step 166775: loss = 0.08207
Step 166780: loss = 0.29262
Step 166785: loss = 0.28131
Step 166790: loss = 0.28397
Step 166795: loss = 0.08150
Step 166800: loss = 0.04299
Step 166805: loss = 0.17895
Step 166810: loss = 0.01893
Step 166815: loss = 0.08358
Step 166820: loss = 0.09594
Step 166825: loss = 0.16149
Step 166830: loss = 0.10831
Step 166835: loss = 0.05549
Step 166840: loss = 0.30627
Step 166845: loss = 0.04761
Step 166850: loss = 0.24654
Step 166855: loss = 0.08085
Step 166860: loss = 0.12408
Step 166865: loss = 0.07930
Step 166870: loss = 0.15628
Step 166875: loss = 0.24317
Step 166880: loss = 0.07344
Step 166885: loss = 0.13427
Step 166890: loss = 0.10085
Step 166895: loss = 0.04419
Step 166900: loss = 0.21199
Step 166905: loss = 0.03590
Step 166910: loss = 0.14285
Step 166915: loss = 0.11598
Step 166920: loss = 0.11719
Step 166925: loss = 0.24158
Step 166930: loss = 0.36334
Step 166935: loss = 0.18663
Step 166940: loss = 0.20938
Step 166945: loss = 0.05893
Step 166950: loss = 0.09657
Step 166955: loss = 0.20412
Step 166960: loss = 0.20815
Step 166965: loss = 0.16850
Step 166970: loss = 0.18085
Step 166975: loss = 0.18032
Step 166980: loss = 0.25014
Step 166985: loss = 0.04878
Step 166990: loss = 0.05527
Step 166995: loss = 0.10151
Step 167000: loss = 0.11343
Training Data Eval:
  Num examples: 50000, Num correct: 47931, Precision @ 1: 0.9586
('Testing Data Eval: EPOCH->', 168)
  Num examples: 10000, Num correct: 6660, Precision @ 1: 0.6660
Step 167005: loss = 0.29634
Step 167010: loss = 0.09187
Step 167015: loss = 0.03997
Step 167020: loss = 0.10998
Step 167025: loss = 0.11218
Step 167030: loss = 0.10100
Step 167035: loss = 0.11243
Step 167040: loss = 0.19429
Step 167045: loss = 0.16115
Step 167050: loss = 0.03092
Step 167055: loss = 0.10824
Step 167060: loss = 0.13217
Step 167065: loss = 0.14672
Step 167070: loss = 0.08277
Step 167075: loss = 0.13335
Step 167080: loss = 0.06878
Step 167085: loss = 0.14047
Step 167090: loss = 0.10989
Step 167095: loss = 0.07120
Step 167100: loss = 0.18467
Step 167105: loss = 0.06861
Step 167110: loss = 0.11930
Step 167115: loss = 0.08921
Step 167120: loss = 0.14552
Step 167125: loss = 0.15804
Step 167130: loss = 0.19871
Step 167135: loss = 0.16195
Step 167140: loss = 0.03778
Step 167145: loss = 0.06743
Step 167150: loss = 0.11008
Step 167155: loss = 0.16062
Step 167160: loss = 0.13539
Step 167165: loss = 0.13120
Step 167170: loss = 0.09419
Step 167175: loss = 0.20939
Step 167180: loss = 0.14162
Step 167185: loss = 0.19023
Step 167190: loss = 0.13253
Step 167195: loss = 0.09989
Step 167200: loss = 0.06386
Step 167205: loss = 0.37777
Step 167210: loss = 0.29409
Step 167215: loss = 0.07205
Step 167220: loss = 0.06791
Step 167225: loss = 0.25237
Step 167230: loss = 0.07225
Step 167235: loss = 0.08503
Step 167240: loss = 0.09687
Step 167245: loss = 0.06335
Step 167250: loss = 0.18412
Step 167255: loss = 0.09180
Step 167260: loss = 0.02650
Step 167265: loss = 0.21762
Step 167270: loss = 0.05371
Step 167275: loss = 0.18720
Step 167280: loss = 0.06973
Step 167285: loss = 0.22882
Step 167290: loss = 0.37446
Step 167295: loss = 0.16768
Step 167300: loss = 0.06158
Step 167305: loss = 0.10686
Step 167310: loss = 0.14134
Step 167315: loss = 0.05928
Step 167320: loss = 0.08301
Step 167325: loss = 0.05734
Step 167330: loss = 0.21061
Step 167335: loss = 0.09966
Step 167340: loss = 0.03937
Step 167345: loss = 0.02290
Step 167350: loss = 0.05830
Step 167355: loss = 0.04846
Step 167360: loss = 0.06355
Step 167365: loss = 0.01760
Step 167370: loss = 0.13918
Step 167375: loss = 0.05407
Step 167380: loss = 0.10807
Step 167385: loss = 0.10042
Step 167390: loss = 0.25526
Step 167395: loss = 0.11042
Step 167400: loss = 0.03549
Step 167405: loss = 0.07581
Step 167410: loss = 0.07328
Step 167415: loss = 0.19337
Step 167420: loss = 0.18483
Step 167425: loss = 0.17698
Step 167430: loss = 0.18537
Step 167435: loss = 0.03633
Step 167440: loss = 0.06011
Step 167445: loss = 0.03299
Step 167450: loss = 0.07622
Step 167455: loss = 0.05106
Step 167460: loss = 0.12387
Step 167465: loss = 0.08933
Step 167470: loss = 0.08182
Step 167475: loss = 0.11762
Step 167480: loss = 0.11587
Step 167485: loss = 0.16288
Step 167490: loss = 0.12426
Step 167495: loss = 0.26415
Step 167500: loss = 0.12112
Step 167505: loss = 0.19820
Step 167510: loss = 0.03727
Step 167515: loss = 0.18286
Step 167520: loss = 0.11828
Step 167525: loss = 0.03615
Step 167530: loss = 0.09035
Step 167535: loss = 0.13871
Step 167540: loss = 0.18138
Step 167545: loss = 0.04214
Step 167550: loss = 0.06335
Step 167555: loss = 0.18374
Step 167560: loss = 0.10847
Step 167565: loss = 0.05265
Step 167570: loss = 0.06656
Step 167575: loss = 0.08029
Step 167580: loss = 0.26833
Step 167585: loss = 0.04334
Step 167590: loss = 0.22251
Step 167595: loss = 0.12031
Step 167600: loss = 0.11113
Step 167605: loss = 0.17234
Step 167610: loss = 0.20651
Step 167615: loss = 0.07788
Step 167620: loss = 0.06254
Step 167625: loss = 0.09072
Step 167630: loss = 0.20042
Step 167635: loss = 0.21916
Step 167640: loss = 0.13643
Step 167645: loss = 0.03532
Step 167650: loss = 0.03524
Step 167655: loss = 0.31750
Step 167660: loss = 0.03007
Step 167665: loss = 0.10448
Step 167670: loss = 0.09129
Step 167675: loss = 0.04566
Step 167680: loss = 0.12271
Step 167685: loss = 0.06215
Step 167690: loss = 0.10486
Step 167695: loss = 0.08157
Step 167700: loss = 0.09471
Step 167705: loss = 0.19428
Step 167710: loss = 0.04703
Step 167715: loss = 0.08328
Step 167720: loss = 0.12545
Step 167725: loss = 0.14844
Step 167730: loss = 0.02414
Step 167735: loss = 0.06215
Step 167740: loss = 0.12679
Step 167745: loss = 0.01341
Step 167750: loss = 0.26339
Step 167755: loss = 0.12129
Step 167760: loss = 0.07533
Step 167765: loss = 0.18442
Step 167770: loss = 0.15151
Step 167775: loss = 0.12218
Step 167780: loss = 0.07050
Step 167785: loss = 0.08068
Step 167790: loss = 0.11628
Step 167795: loss = 0.17012
Step 167800: loss = 0.19451
Step 167805: loss = 0.03580
Step 167810: loss = 0.10307
Step 167815: loss = 0.04667
Step 167820: loss = 0.15970
Step 167825: loss = 0.15623
Step 167830: loss = 0.04103
Step 167835: loss = 0.04924
Step 167840: loss = 0.17516
Step 167845: loss = 0.37041
Step 167850: loss = 0.17490
Step 167855: loss = 0.15777
Step 167860: loss = 0.43140
Step 167865: loss = 0.13160
Step 167870: loss = 0.08313
Step 167875: loss = 0.24242
Step 167880: loss = 0.24147
Step 167885: loss = 0.15063
Step 167890: loss = 0.08158
Step 167895: loss = 0.08644
Step 167900: loss = 0.06241
Step 167905: loss = 0.05313
Step 167910: loss = 0.10132
Step 167915: loss = 0.14649
Step 167920: loss = 0.09968
Step 167925: loss = 0.06669
Step 167930: loss = 0.10952
Step 167935: loss = 0.14437
Step 167940: loss = 0.03554
Step 167945: loss = 0.04495
Step 167950: loss = 0.08871
Step 167955: loss = 0.08170
Step 167960: loss = 0.07205
Step 167965: loss = 0.04254
Step 167970: loss = 0.07441
Step 167975: loss = 0.07955
Step 167980: loss = 0.08203
Step 167985: loss = 0.17378
Step 167990: loss = 0.09771
Step 167995: loss = 0.09540
Step 168000: loss = 0.24816
Training Data Eval:
  Num examples: 50000, Num correct: 48003, Precision @ 1: 0.9601
('Testing Data Eval: EPOCH->', 169)
  Num examples: 10000, Num correct: 6661, Precision @ 1: 0.6661
Step 168005: loss = 0.04341
Step 168010: loss = 0.10180
Step 168015: loss = 0.03086
Step 168020: loss = 0.06919
Step 168025: loss = 0.16392
Step 168030: loss = 0.03313
Step 168035: loss = 0.08503
Step 168040: loss = 0.05042
Step 168045: loss = 0.04309
Step 168050: loss = 0.15007
Step 168055: loss = 0.06363
Step 168060: loss = 0.05144
Step 168065: loss = 0.12463
Step 168070: loss = 0.07778
Step 168075: loss = 0.12767
Step 168080: loss = 0.06972
Step 168085: loss = 0.04245
Step 168090: loss = 0.03108
Step 168095: loss = 0.08267
Step 168100: loss = 0.05508
Step 168105: loss = 0.05321
Step 168110: loss = 0.19517
Step 168115: loss = 0.02572
Step 168120: loss = 0.03571
Step 168125: loss = 0.03990
Step 168130: loss = 0.16511
Step 168135: loss = 0.03077
Step 168140: loss = 0.06335
Step 168145: loss = 0.09714
Step 168150: loss = 0.18717
Step 168155: loss = 0.09331
Step 168160: loss = 0.06239
Step 168165: loss = 0.08669
Step 168170: loss = 0.07557
Step 168175: loss = 0.08449
Step 168180: loss = 0.03785
Step 168185: loss = 0.11607
Step 168190: loss = 0.22530
Step 168195: loss = 0.10224
Step 168200: loss = 0.03242
Step 168205: loss = 0.12209
Step 168210: loss = 0.08878
Step 168215: loss = 0.02796
Step 168220: loss = 0.03035
Step 168225: loss = 0.27938
Step 168230: loss = 0.03288
Step 168235: loss = 0.08095
Step 168240: loss = 0.07369
Step 168245: loss = 0.03726
Step 168250: loss = 0.05285
Step 168255: loss = 0.07069
Step 168260: loss = 0.08358
Step 168265: loss = 0.03234
Step 168270: loss = 0.17742
Step 168275: loss = 0.32021
Step 168280: loss = 0.09778
Step 168285: loss = 0.20178
Step 168290: loss = 0.05457
Step 168295: loss = 0.07129
Step 168300: loss = 0.06574
Step 168305: loss = 0.06292
Step 168310: loss = 0.12791
Step 168315: loss = 0.10342
Step 168320: loss = 0.09805
Step 168325: loss = 0.07793
Step 168330: loss = 0.09718
Step 168335: loss = 0.04889
Step 168340: loss = 0.06301
Step 168345: loss = 0.10070
Step 168350: loss = 0.04727
Step 168355: loss = 0.02352
Step 168360: loss = 0.03685
Step 168365: loss = 0.36743
Step 168370: loss = 0.20171
Step 168375: loss = 0.10008
Step 168380: loss = 0.25687
Step 168385: loss = 0.12956
Step 168390: loss = 0.15503
Step 168395: loss = 0.07705
Step 168400: loss = 0.20458
Step 168405: loss = 0.09117
Step 168410: loss = 0.07654
Step 168415: loss = 0.43857
Step 168420: loss = 0.08243
Step 168425: loss = 0.07407
Step 168430: loss = 0.10745
Step 168435: loss = 0.10819
Step 168440: loss = 0.04901
Step 168445: loss = 0.17224
Step 168450: loss = 0.08054
Step 168455: loss = 0.06852
Step 168460: loss = 0.11399
Step 168465: loss = 0.17005
Step 168470: loss = 0.04549
Step 168475: loss = 0.07258
Step 168480: loss = 0.11330
Step 168485: loss = 0.03084
Step 168490: loss = 0.03231
Step 168495: loss = 0.10210
Step 168500: loss = 0.01744
Step 168505: loss = 0.11336
Step 168510: loss = 0.05896
Step 168515: loss = 0.05220
Step 168520: loss = 0.15599
Step 168525: loss = 0.20863
Step 168530: loss = 0.15686
Step 168535: loss = 0.17599
Step 168540: loss = 0.09166
Step 168545: loss = 0.12793
Step 168550: loss = 0.19046
Step 168555: loss = 0.10360
Step 168560: loss = 0.05870
Step 168565: loss = 0.03898
Step 168570: loss = 0.12251
Step 168575: loss = 0.11214
Step 168580: loss = 0.16884
Step 168585: loss = 0.09175
Step 168590: loss = 0.06165
Step 168595: loss = 0.20631
Step 168600: loss = 0.03821
Step 168605: loss = 0.06574
Step 168610: loss = 0.04389
Step 168615: loss = 0.17471
Step 168620: loss = 0.14868
Step 168625: loss = 0.19988
Step 168630: loss = 0.11227
Step 168635: loss = 0.03754
Step 168640: loss = 0.06105
Step 168645: loss = 0.01911
Step 168650: loss = 0.06606
Step 168655: loss = 0.22003
Step 168660: loss = 0.04328
Step 168665: loss = 0.19525
Step 168670: loss = 0.10691
Step 168675: loss = 0.49798
Step 168680: loss = 0.36161
Step 168685: loss = 0.27535
Step 168690: loss = 0.14101
Step 168695: loss = 0.11806
Step 168700: loss = 0.24845
Step 168705: loss = 0.08313
Step 168710: loss = 0.16649
Step 168715: loss = 0.15532
Step 168720: loss = 0.04764
Step 168725: loss = 0.21486
Step 168730: loss = 0.08429
Step 168735: loss = 0.15978
Step 168740: loss = 0.25242
Step 168745: loss = 0.12928
Step 168750: loss = 0.22908
Step 168755: loss = 0.18800
Step 168760: loss = 0.36896
Step 168765: loss = 0.10829
Step 168770: loss = 0.08781
Step 168775: loss = 0.24308
Step 168780: loss = 0.14408
Step 168785: loss = 0.24116
Step 168790: loss = 0.10663
Step 168795: loss = 0.10517
Step 168800: loss = 0.16648
Step 168805: loss = 0.07056
Step 168810: loss = 0.20743
Step 168815: loss = 0.24268
Step 168820: loss = 0.16725
Step 168825: loss = 0.03945
Step 168830: loss = 0.25308
Step 168835: loss = 0.10288
Step 168840: loss = 0.15824
Step 168845: loss = 0.07039
Step 168850: loss = 0.10638
Step 168855: loss = 0.18664
Step 168860: loss = 0.03513
Step 168865: loss = 0.08710
Step 168870: loss = 0.07468
Step 168875: loss = 0.06292
Step 168880: loss = 0.29679
Step 168885: loss = 0.20411
Step 168890: loss = 0.25234
Step 168895: loss = 0.15185
Step 168900: loss = 0.29244
Step 168905: loss = 0.09087
Step 168910: loss = 0.07449
Step 168915: loss = 0.17032
Step 168920: loss = 0.07361
Step 168925: loss = 0.07177
Step 168930: loss = 0.16236
Step 168935: loss = 0.07634
Step 168940: loss = 0.14435
Step 168945: loss = 0.08202
Step 168950: loss = 0.13295
Step 168955: loss = 0.09885
Step 168960: loss = 0.12291
Step 168965: loss = 0.18258
Step 168970: loss = 0.09197
Step 168975: loss = 0.05479
Step 168980: loss = 0.04479
Step 168985: loss = 0.10942
Step 168990: loss = 0.03636
Step 168995: loss = 0.08145
Step 169000: loss = 0.02989
Training Data Eval:
  Num examples: 50000, Num correct: 48027, Precision @ 1: 0.9605
('Testing Data Eval: EPOCH->', 170)
  Num examples: 10000, Num correct: 6632, Precision @ 1: 0.6632
Step 169005: loss = 0.09861
Step 169010: loss = 0.07372
Step 169015: loss = 0.09123
Step 169020: loss = 0.11715
Step 169025: loss = 0.14417
Step 169030: loss = 0.11172
Step 169035: loss = 0.04342
Step 169040: loss = 0.29419
Step 169045: loss = 0.05350
Step 169050: loss = 0.14389
Step 169055: loss = 0.03166
Step 169060: loss = 0.12630
Step 169065: loss = 0.33536
Step 169070: loss = 0.03885
Step 169075: loss = 0.11379
Step 169080: loss = 0.06376
Step 169085: loss = 0.28969
Step 169090: loss = 0.18466
Step 169095: loss = 0.13823
Step 169100: loss = 0.16383
Step 169105: loss = 0.19734
Step 169110: loss = 0.24802
Step 169115: loss = 0.19967
Step 169120: loss = 0.09532
Step 169125: loss = 0.04716
Step 169130: loss = 0.27502
Step 169135: loss = 0.22085
Step 169140: loss = 0.08011
Step 169145: loss = 0.06065
Step 169150: loss = 0.14644
Step 169155: loss = 0.16170
Step 169160: loss = 0.03265
Step 169165: loss = 0.07857
Step 169170: loss = 0.15388
Step 169175: loss = 0.09118
Step 169180: loss = 0.13406
Step 169185: loss = 0.21718
Step 169190: loss = 0.06228
Step 169195: loss = 0.11104
Step 169200: loss = 0.07685
Step 169205: loss = 0.09770
Step 169210: loss = 0.08683
Step 169215: loss = 0.13582
Step 169220: loss = 0.03527
Step 169225: loss = 0.10702
Step 169230: loss = 0.15962
Step 169235: loss = 0.05439
Step 169240: loss = 0.07387
Step 169245: loss = 0.18842
Step 169250: loss = 0.11394
Step 169255: loss = 0.13688
Step 169260: loss = 0.06417
Step 169265: loss = 0.12307
Step 169270: loss = 0.08437
Step 169275: loss = 0.09396
Step 169280: loss = 0.12000
Step 169285: loss = 0.10638
Step 169290: loss = 0.14596
Step 169295: loss = 0.04122
Step 169300: loss = 0.05936
Step 169305: loss = 0.14183
Step 169310: loss = 0.22906
Step 169315: loss = 0.22146
Step 169320: loss = 0.18281
Step 169325: loss = 0.11204
Step 169330: loss = 0.10313
Step 169335: loss = 0.08884
Step 169340: loss = 0.19278
Step 169345: loss = 0.03827
Step 169350: loss = 0.16395
Step 169355: loss = 0.15894
Step 169360: loss = 0.13915
Step 169365: loss = 0.18642
Step 169370: loss = 0.06281
Step 169375: loss = 0.20182
Step 169380: loss = 0.12251
Step 169385: loss = 0.09481
Step 169390: loss = 0.07037
Step 169395: loss = 0.07215
Step 169400: loss = 0.21645
Step 169405: loss = 0.12440
Step 169410: loss = 0.15875
Step 169415: loss = 0.11382
Step 169420: loss = 0.07211
Step 169425: loss = 0.17800
Step 169430: loss = 0.05091
Step 169435: loss = 0.09926
Step 169440: loss = 0.05643
Step 169445: loss = 0.14425
Step 169450: loss = 0.19108
Step 169455: loss = 0.19936
Step 169460: loss = 0.09296
Step 169465: loss = 0.07016
Step 169470: loss = 0.16364
Step 169475: loss = 0.11015
Step 169480: loss = 0.23385
Step 169485: loss = 0.19050
Step 169490: loss = 0.14187
Step 169495: loss = 0.16596
Step 169500: loss = 0.49338
Step 169505: loss = 0.04850
Step 169510: loss = 0.29245
Step 169515: loss = 0.10011
Step 169520: loss = 0.11184
Step 169525: loss = 0.12747
Step 169530: loss = 0.15122
Step 169535: loss = 0.03446
Step 169540: loss = 0.06411
Step 169545: loss = 0.13660
Step 169550: loss = 0.22430
Step 169555: loss = 0.08079
Step 169560: loss = 0.08973
Step 169565: loss = 0.09725
Step 169570: loss = 0.08046
Step 169575: loss = 0.10690
Step 169580: loss = 0.12551
Step 169585: loss = 0.12609
Step 169590: loss = 0.02552
Step 169595: loss = 0.15280
Step 169600: loss = 0.05954
Step 169605: loss = 0.15118
Step 169610: loss = 0.18028
Step 169615: loss = 0.03421
Step 169620: loss = 0.20636
Step 169625: loss = 0.02311
Step 169630: loss = 0.15884
Step 169635: loss = 0.16038
Step 169640: loss = 0.05803
Step 169645: loss = 0.08696
Step 169650: loss = 0.03616
Step 169655: loss = 0.03302
Step 169660: loss = 0.14733
Step 169665: loss = 0.09512
Step 169670: loss = 0.25413
Step 169675: loss = 0.06173
Step 169680: loss = 0.07267
Step 169685: loss = 0.03812
Step 169690: loss = 0.12544
Step 169695: loss = 0.22758
Step 169700: loss = 0.05268
Step 169705: loss = 0.09748
Step 169710: loss = 0.07909
Step 169715: loss = 0.09740
Step 169720: loss = 0.09764
Step 169725: loss = 0.01645
Step 169730: loss = 0.19468
Step 169735: loss = 0.18486
Step 169740: loss = 0.08719
Step 169745: loss = 0.01705
Step 169750: loss = 0.08231
Step 169755: loss = 0.08710
Step 169760: loss = 0.12360
Step 169765: loss = 0.11043
Step 169770: loss = 0.20116
Step 169775: loss = 0.06451
Step 169780: loss = 0.08229
Step 169785: loss = 0.07473
Step 169790: loss = 0.07848
Step 169795: loss = 0.21799
Step 169800: loss = 0.13136
Step 169805: loss = 0.07765
Step 169810: loss = 0.18900
Step 169815: loss = 0.06181
Step 169820: loss = 0.04798
Step 169825: loss = 0.06633
Step 169830: loss = 0.12448
Step 169835: loss = 0.23973
Step 169840: loss = 0.18097
Step 169845: loss = 0.14702
Step 169850: loss = 0.03512
Step 169855: loss = 0.13342
Step 169860: loss = 0.08490
Step 169865: loss = 0.12160
Step 169870: loss = 0.17353
Step 169875: loss = 0.08778
Step 169880: loss = 0.06931
Step 169885: loss = 0.29256
Step 169890: loss = 0.35148
Step 169895: loss = 0.14445
Step 169900: loss = 0.15469
Step 169905: loss = 0.26017
Step 169910: loss = 0.05918
Step 169915: loss = 0.17475
Step 169920: loss = 0.27943
Step 169925: loss = 0.25410
Step 169930: loss = 0.26403
Step 169935: loss = 0.03901
Step 169940: loss = 0.11327
Step 169945: loss = 0.22191
Step 169950: loss = 0.24432
Step 169955: loss = 0.05147
Step 169960: loss = 0.29055
Step 169965: loss = 0.11146
Step 169970: loss = 0.08227
Step 169975: loss = 0.02037
Step 169980: loss = 0.14841
Step 169985: loss = 0.16138
Step 169990: loss = 0.15742
Step 169995: loss = 0.04818
Step 170000: loss = 0.15225
Training Data Eval:
  Num examples: 50000, Num correct: 48072, Precision @ 1: 0.9614
('Testing Data Eval: EPOCH->', 171)
  Num examples: 10000, Num correct: 6606, Precision @ 1: 0.6606
Step 170005: loss = 0.03806
Step 170010: loss = 0.02733
Step 170015: loss = 0.05201
Step 170020: loss = 0.07045
Step 170025: loss = 0.14165
Step 170030: loss = 0.13260
Step 170035: loss = 0.11678
Step 170040: loss = 0.04218
Step 170045: loss = 0.15972
Step 170050: loss = 0.07350
Step 170055: loss = 0.16487
Step 170060: loss = 0.07837
Step 170065: loss = 0.02435
Step 170070: loss = 0.15124
Step 170075: loss = 0.10521
Step 170080: loss = 0.06023
Step 170085: loss = 0.09520
Step 170090: loss = 0.03477
Step 170095: loss = 0.16719
Step 170100: loss = 0.07575
Step 170105: loss = 0.01768
Step 170110: loss = 0.06861
Step 170115: loss = 0.18363
Step 170120: loss = 0.15843
Step 170125: loss = 0.13424
Step 170130: loss = 0.07335
Step 170135: loss = 0.10953
Step 170140: loss = 0.04686
Step 170145: loss = 0.07080
Step 170150: loss = 0.33541
Step 170155: loss = 0.29316
Step 170160: loss = 0.24827
Step 170165: loss = 0.03782
Step 170170: loss = 0.18622
Step 170175: loss = 0.10432
Step 170180: loss = 0.14736
Step 170185: loss = 0.10114
Step 170190: loss = 0.15937
Step 170195: loss = 0.18061
Step 170200: loss = 0.06710
Step 170205: loss = 0.06031
Step 170210: loss = 0.18617
Step 170215: loss = 0.05340
Step 170220: loss = 0.09639
Step 170225: loss = 0.12591
Step 170230: loss = 0.35845
Step 170235: loss = 0.13244
Step 170240: loss = 0.07031
Step 170245: loss = 0.14026
Step 170250: loss = 0.04330
Step 170255: loss = 0.06016
Step 170260: loss = 0.20542
Step 170265: loss = 0.15439
Step 170270: loss = 0.12607
Step 170275: loss = 0.25356
Step 170280: loss = 0.24417
Step 170285: loss = 0.08532
Step 170290: loss = 0.14688
Step 170295: loss = 0.11183
Step 170300: loss = 0.08302
Step 170305: loss = 0.21137
Step 170310: loss = 0.07139
Step 170315: loss = 0.12682
Step 170320: loss = 0.07296
Step 170325: loss = 0.03536
Step 170330: loss = 0.25626
Step 170335: loss = 0.12997
Step 170340: loss = 0.08666
Step 170345: loss = 0.05502
Step 170350: loss = 0.14250
Step 170355: loss = 0.05251
Step 170360: loss = 0.06262
Step 170365: loss = 0.17538
Step 170370: loss = 0.05036
Step 170375: loss = 0.02872
Step 170380: loss = 0.04643
Step 170385: loss = 0.07633
Step 170390: loss = 0.11913
Step 170395: loss = 0.12249
Step 170400: loss = 0.05245
Step 170405: loss = 0.06029
Step 170410: loss = 0.06610
Step 170415: loss = 0.07488
Step 170420: loss = 0.07718
Step 170425: loss = 0.04570
Step 170430: loss = 0.22425
Step 170435: loss = 0.17753
Step 170440: loss = 0.01521
Step 170445: loss = 0.16184
Step 170450: loss = 0.07245
Step 170455: loss = 0.01680
Step 170460: loss = 0.06002
Step 170465: loss = 0.08216
Step 170470: loss = 0.11921
Step 170475: loss = 0.10241
Step 170480: loss = 0.04706
Step 170485: loss = 0.08843
Step 170490: loss = 0.09402
Step 170495: loss = 0.08390
Step 170500: loss = 0.03016
Step 170505: loss = 0.03929
Step 170510: loss = 0.05905
Step 170515: loss = 0.06903
Step 170520: loss = 0.07716
Step 170525: loss = 0.17815
Step 170530: loss = 0.17947
Step 170535: loss = 0.05867
Step 170540: loss = 0.26612
Step 170545: loss = 0.03184
Step 170550: loss = 0.23497
Step 170555: loss = 0.04348
Step 170560: loss = 0.14494
Step 170565: loss = 0.18477
Step 170570: loss = 0.09177
Step 170575: loss = 0.05709
Step 170580: loss = 0.27096
Step 170585: loss = 0.14729
Step 170590: loss = 0.19366
Step 170595: loss = 0.08577
Step 170600: loss = 0.35148
Step 170605: loss = 0.06762
Step 170610: loss = 0.04486
Step 170615: loss = 0.14504
Step 170620: loss = 0.13696
Step 170625: loss = 0.10154
Step 170630: loss = 0.24722
Step 170635: loss = 0.22559
Step 170640: loss = 0.06193
Step 170645: loss = 0.23342
Step 170650: loss = 0.17369
Step 170655: loss = 0.07966
Step 170660: loss = 0.14057
Step 170665: loss = 0.15640
Step 170670: loss = 0.09027
Step 170675: loss = 0.21771
Step 170680: loss = 0.05208
Step 170685: loss = 0.18689
Step 170690: loss = 0.09752
Step 170695: loss = 0.38003
Step 170700: loss = 0.02134
Step 170705: loss = 0.06273
Step 170710: loss = 0.03998
Step 170715: loss = 0.21705
Step 170720: loss = 0.10304
Step 170725: loss = 0.08105
Step 170730: loss = 0.05882
Step 170735: loss = 0.19087
Step 170740: loss = 0.25065
Step 170745: loss = 0.22262
Step 170750: loss = 0.09685
Step 170755: loss = 0.06704
Step 170760: loss = 0.14044
Step 170765: loss = 0.07287
Step 170770: loss = 0.12742
Step 170775: loss = 0.03600
Step 170780: loss = 0.14331
Step 170785: loss = 0.16455
Step 170790: loss = 0.24747
Step 170795: loss = 0.07602
Step 170800: loss = 0.04146
Step 170805: loss = 0.07870
Step 170810: loss = 0.03161
Step 170815: loss = 0.16357
Step 170820: loss = 0.13835
Step 170825: loss = 0.04377
Step 170830: loss = 0.12124
Step 170835: loss = 0.18613
Step 170840: loss = 0.06942
Step 170845: loss = 0.15494
Step 170850: loss = 0.20981
Step 170855: loss = 0.12878
Step 170860: loss = 0.13349
Step 170865: loss = 0.09102
Step 170870: loss = 0.07260
Step 170875: loss = 0.02995
Step 170880: loss = 0.06082
Step 170885: loss = 0.17161
Step 170890: loss = 0.09243
Step 170895: loss = 0.18632
Step 170900: loss = 0.06804
Step 170905: loss = 0.03793
Step 170910: loss = 0.12003
Step 170915: loss = 0.20925
Step 170920: loss = 0.10873
Step 170925: loss = 0.21992
Step 170930: loss = 0.21599
Step 170935: loss = 0.20228
Step 170940: loss = 0.10294
Step 170945: loss = 0.05440
Step 170950: loss = 0.08564
Step 170955: loss = 0.03238
Step 170960: loss = 0.07226
Step 170965: loss = 0.16138
Step 170970: loss = 0.10409
Step 170975: loss = 0.22671
Step 170980: loss = 0.24610
Step 170985: loss = 0.12214
Step 170990: loss = 0.02089
Step 170995: loss = 0.11455
Step 171000: loss = 0.19226
Training Data Eval:
  Num examples: 50000, Num correct: 48204, Precision @ 1: 0.9641
('Testing Data Eval: EPOCH->', 172)
  Num examples: 10000, Num correct: 6574, Precision @ 1: 0.6574
Step 171005: loss = 0.08680
Step 171010: loss = 0.02193
Step 171015: loss = 0.10101
Step 171020: loss = 0.10670
Step 171025: loss = 0.05814
Step 171030: loss = 0.01763
Step 171035: loss = 0.06492
Step 171040: loss = 0.06483
Step 171045: loss = 0.15876
Step 171050: loss = 0.02084
Step 171055: loss = 0.13115
Step 171060: loss = 0.19285
Step 171065: loss = 0.08104
Step 171070: loss = 0.04940
Step 171075: loss = 0.05153
Step 171080: loss = 0.15068
Step 171085: loss = 0.13314
Step 171090: loss = 0.05863
Step 171095: loss = 0.09335
Step 171100: loss = 0.07813
Step 171105: loss = 0.16206
Step 171110: loss = 0.25361
Step 171115: loss = 0.03257
Step 171120: loss = 0.13650
Step 171125: loss = 0.06733
Step 171130: loss = 0.07111
Step 171135: loss = 0.11510
Step 171140: loss = 0.05823
Step 171145: loss = 0.13098
Step 171150: loss = 0.06355
Step 171155: loss = 0.12838
Step 171160: loss = 0.07814
Step 171165: loss = 0.08956
Step 171170: loss = 0.12543
Step 171175: loss = 0.04040
Step 171180: loss = 0.07525
Step 171185: loss = 0.25731
Step 171190: loss = 0.05926
Step 171195: loss = 0.23226
Step 171200: loss = 0.10946
Step 171205: loss = 0.07335
Step 171210: loss = 0.12409
Step 171215: loss = 0.09094
Step 171220: loss = 0.01712
Step 171225: loss = 0.12994
Step 171230: loss = 0.12811
Step 171235: loss = 0.16678
Step 171240: loss = 0.14718
Step 171245: loss = 0.08454
Step 171250: loss = 0.07346
Step 171255: loss = 0.11407
Step 171260: loss = 0.09000
Step 171265: loss = 0.29988
Step 171270: loss = 0.08518
Step 171275: loss = 0.07154
Step 171280: loss = 0.10993
Step 171285: loss = 0.15578
Step 171290: loss = 0.03387
Step 171295: loss = 0.24499
Step 171300: loss = 0.06465
Step 171305: loss = 0.17131
Step 171310: loss = 0.04091
Step 171315: loss = 0.10039
Step 171320: loss = 0.07662
Step 171325: loss = 0.10680
Step 171330: loss = 0.03363
Step 171335: loss = 0.11556
Step 171340: loss = 0.08541
Step 171345: loss = 0.03796
Step 171350: loss = 0.23782
Step 171355: loss = 0.21039
Step 171360: loss = 0.15987
Step 171365: loss = 0.14434
Step 171370: loss = 0.03291
Step 171375: loss = 0.14948
Step 171380: loss = 0.34694
Step 171385: loss = 0.14970
Step 171390: loss = 0.34719
Step 171395: loss = 0.09789
Step 171400: loss = 0.06298
Step 171405: loss = 0.12852
Step 171410: loss = 0.06000
Step 171415: loss = 0.06570
Step 171420: loss = 0.23588
Step 171425: loss = 0.07218
Step 171430: loss = 0.03983
Step 171435: loss = 0.39603
Step 171440: loss = 0.10238
Step 171445: loss = 0.02851
Step 171450: loss = 0.09504
Step 171455: loss = 0.11244
Step 171460: loss = 0.13474
Step 171465: loss = 0.10522
Step 171470: loss = 0.04956
Step 171475: loss = 0.05908
Step 171480: loss = 0.21641
Step 171485: loss = 0.18255
Step 171490: loss = 0.26672
Step 171495: loss = 0.13150
Step 171500: loss = 0.10666
Step 171505: loss = 0.08304
Step 171510: loss = 0.04285
Step 171515: loss = 0.18217
Step 171520: loss = 0.10527
Step 171525: loss = 0.07228
Step 171530: loss = 0.11794
Step 171535: loss = 0.06906
Step 171540: loss = 0.04942
Step 171545: loss = 0.09100
Step 171550: loss = 0.13506
Step 171555: loss = 0.02939
Step 171560: loss = 0.37372
Step 171565: loss = 0.07264
Step 171570: loss = 0.17427
Step 171575: loss = 0.09990
Step 171580: loss = 0.05196
Step 171585: loss = 0.05652
Step 171590: loss = 0.09157
Step 171595: loss = 0.09589
Step 171600: loss = 0.08081
Step 171605: loss = 0.04556
Step 171610: loss = 0.16557
Step 171615: loss = 0.04086
Step 171620: loss = 0.18155
Step 171625: loss = 0.04288
Step 171630: loss = 0.05366
Step 171635: loss = 0.02950
Step 171640: loss = 0.19902
Step 171645: loss = 0.12621
Step 171650: loss = 0.09664
Step 171655: loss = 0.06635
Step 171660: loss = 0.20985
Step 171665: loss = 0.02083
Step 171670: loss = 0.03605
Step 171675: loss = 0.09763
Step 171680: loss = 0.10560
Step 171685: loss = 0.03650
Step 171690: loss = 0.05612
Step 171695: loss = 0.16086
Step 171700: loss = 0.01719
Step 171705: loss = 0.13619
Step 171710: loss = 0.12327
Step 171715: loss = 0.06521
Step 171720: loss = 0.21944
Step 171725: loss = 0.11878
Step 171730: loss = 0.02837
Step 171735: loss = 0.21940
Step 171740: loss = 0.10518
Step 171745: loss = 0.10890
Step 171750: loss = 0.06523
Step 171755: loss = 0.14948
Step 171760: loss = 0.11720
Step 171765: loss = 0.15250
Step 171770: loss = 0.11236
Step 171775: loss = 0.19792
Step 171780: loss = 0.11460
Step 171785: loss = 0.09138
Step 171790: loss = 0.03183
Step 171795: loss = 0.06297
Step 171800: loss = 0.05538
Step 171805: loss = 0.13155
Step 171810: loss = 0.06999
Step 171815: loss = 0.38074
Step 171820: loss = 0.17983
Step 171825: loss = 0.07505
Step 171830: loss = 0.11179
Step 171835: loss = 0.27164
Step 171840: loss = 0.08592
Step 171845: loss = 0.04282
Step 171850: loss = 0.07180
Step 171855: loss = 0.06282
Step 171860: loss = 0.10691
Step 171865: loss = 0.12571
Step 171870: loss = 0.15585
Step 171875: loss = 0.22980
Step 171880: loss = 0.08056
Step 171885: loss = 0.04603
Step 171890: loss = 0.27551
Step 171895: loss = 0.03174
Step 171900: loss = 0.07535
Step 171905: loss = 0.08459
Step 171910: loss = 0.14543
Step 171915: loss = 0.08970
Step 171920: loss = 0.12382
Step 171925: loss = 0.18673
Step 171930: loss = 0.13564
Step 171935: loss = 0.08689
Step 171940: loss = 0.09483
Step 171945: loss = 0.28915
Step 171950: loss = 0.02770
Step 171955: loss = 0.13492
Step 171960: loss = 0.11865
Step 171965: loss = 0.18388
Step 171970: loss = 0.16316
Step 171975: loss = 0.15987
Step 171980: loss = 0.15006
Step 171985: loss = 0.09965
Step 171990: loss = 0.08442
Step 171995: loss = 0.08494
Step 172000: loss = 0.17750
Training Data Eval:
  Num examples: 50000, Num correct: 47851, Precision @ 1: 0.9570
('Testing Data Eval: EPOCH->', 173)
  Num examples: 10000, Num correct: 6639, Precision @ 1: 0.6639
Step 172005: loss = 0.16915
Step 172010: loss = 0.07057
Step 172015: loss = 0.08102
Step 172020: loss = 0.02538
Step 172025: loss = 0.31484
Step 172030: loss = 0.15365
Step 172035: loss = 0.04339
Step 172040: loss = 0.14802
Step 172045: loss = 0.16382
Step 172050: loss = 0.08055
Step 172055: loss = 0.10308
Step 172060: loss = 0.05609
Step 172065: loss = 0.06443
Step 172070: loss = 0.05365
Step 172075: loss = 0.23575
Step 172080: loss = 0.05042
Step 172085: loss = 0.06594
Step 172090: loss = 0.12659
Step 172095: loss = 0.09978
Step 172100: loss = 0.12993
Step 172105: loss = 0.17532
Step 172110: loss = 0.20030
Step 172115: loss = 0.04438
Step 172120: loss = 0.12244
Step 172125: loss = 0.07704
Step 172130: loss = 0.12799
Step 172135: loss = 0.07591
Step 172140: loss = 0.36158
Step 172145: loss = 0.08176
Step 172150: loss = 0.08871
Step 172155: loss = 0.04198
Step 172160: loss = 0.10411
Step 172165: loss = 0.11169
Step 172170: loss = 0.14181
Step 172175: loss = 0.19377
Step 172180: loss = 0.09233
Step 172185: loss = 0.02696
Step 172190: loss = 0.05964
Step 172195: loss = 0.18307
Step 172200: loss = 0.03109
Step 172205: loss = 0.09633
Step 172210: loss = 0.21540
Step 172215: loss = 0.06666
Step 172220: loss = 0.03604
Step 172225: loss = 0.16309
Step 172230: loss = 0.26350
Step 172235: loss = 0.16270
Step 172240: loss = 0.34064
Step 172245: loss = 0.22336
Step 172250: loss = 0.03036
Step 172255: loss = 0.09547
Step 172260: loss = 0.09245
Step 172265: loss = 0.15825
Step 172270: loss = 0.13488
Step 172275: loss = 0.33209
Step 172280: loss = 0.04948
Step 172285: loss = 0.06541
Step 172290: loss = 0.01306
Step 172295: loss = 0.08568
Step 172300: loss = 0.11959
Step 172305: loss = 0.04501
Step 172310: loss = 0.04657
Step 172315: loss = 0.06761
Step 172320: loss = 0.05335
Step 172325: loss = 0.05789
Step 172330: loss = 0.13112
Step 172335: loss = 0.06854
Step 172340: loss = 0.21395
Step 172345: loss = 0.08886
Step 172350: loss = 0.15122
Step 172355: loss = 0.16815
Step 172360: loss = 0.18538
Step 172365: loss = 0.09076
Step 172370: loss = 0.06550
Step 172375: loss = 0.11768
Step 172380: loss = 0.23474
Step 172385: loss = 0.10531
Step 172390: loss = 0.07549
Step 172395: loss = 0.16053
Step 172400: loss = 0.11957
Step 172405: loss = 0.20695
Step 172410: loss = 0.10234
Step 172415: loss = 0.06643
Step 172420: loss = 0.08661
Step 172425: loss = 0.07061
Step 172430: loss = 0.12135
Step 172435: loss = 0.11185
Step 172440: loss = 0.09299
Step 172445: loss = 0.18653
Step 172450: loss = 0.28767
Step 172455: loss = 0.16498
Step 172460: loss = 0.11292
Step 172465: loss = 0.13328
Step 172470: loss = 0.05176
Step 172475: loss = 0.02513
Step 172480: loss = 0.19308
Step 172485: loss = 0.21467
Step 172490: loss = 0.12529
Step 172495: loss = 0.27977
Step 172500: loss = 0.09451
Step 172505: loss = 0.05819
Step 172510: loss = 0.07573
Step 172515: loss = 0.08991
Step 172520: loss = 0.12033
Step 172525: loss = 0.00832
Step 172530: loss = 0.03050
Step 172535: loss = 0.10107
Step 172540: loss = 0.05475
Step 172545: loss = 0.16895
Step 172550: loss = 0.10147
Step 172555: loss = 0.05243
Step 172560: loss = 0.07246
Step 172565: loss = 0.11914
Step 172570: loss = 0.13568
Step 172575: loss = 0.35183
Step 172580: loss = 0.25521
Step 172585: loss = 0.03099
Step 172590: loss = 0.06855
Step 172595: loss = 0.11070
Step 172600: loss = 0.08759
Step 172605: loss = 0.19819
Step 172610: loss = 0.08950
Step 172615: loss = 0.02981
Step 172620: loss = 0.06531
Step 172625: loss = 0.08593
Step 172630: loss = 0.04320
Step 172635: loss = 0.18043
Step 172640: loss = 0.29411
Step 172645: loss = 0.18896
Step 172650: loss = 0.06956
Step 172655: loss = 0.05513
Step 172660: loss = 0.06026
Step 172665: loss = 0.04627
Step 172670: loss = 0.31591
Step 172675: loss = 0.14544
Step 172680: loss = 0.05271
Step 172685: loss = 0.06116
Step 172690: loss = 0.03696
Step 172695: loss = 0.07797
Step 172700: loss = 0.16647
Step 172705: loss = 0.13254
Step 172710: loss = 0.18513
Step 172715: loss = 0.14811
Step 172720: loss = 0.17916
Step 172725: loss = 0.05872
Step 172730: loss = 0.11142
Step 172735: loss = 0.05985
Step 172740: loss = 0.20070
Step 172745: loss = 0.03390
Step 172750: loss = 0.23929
Step 172755: loss = 0.12589
Step 172760: loss = 0.07625
Step 172765: loss = 0.02517
Step 172770: loss = 0.10082
Step 172775: loss = 0.25047
Step 172780: loss = 0.13451
Step 172785: loss = 0.13418
Step 172790: loss = 0.26367
Step 172795: loss = 0.03139
Step 172800: loss = 0.09890
Step 172805: loss = 0.15913
Step 172810: loss = 0.24051
Step 172815: loss = 0.15047
Step 172820: loss = 0.11702
Step 172825: loss = 0.03184
Step 172830: loss = 0.07230
Step 172835: loss = 0.08652
Step 172840: loss = 0.07798
Step 172845: loss = 0.07455
Step 172850: loss = 0.10188
Step 172855: loss = 0.13532
Step 172860: loss = 0.09400
Step 172865: loss = 0.10799
Step 172870: loss = 0.11436
Step 172875: loss = 0.25685
Step 172880: loss = 0.09250
Step 172885: loss = 0.21506
Step 172890: loss = 0.08176
Step 172895: loss = 0.19882
Step 172900: loss = 0.18233
Step 172905: loss = 0.39192
Step 172910: loss = 0.06260
Step 172915: loss = 0.05047
Step 172920: loss = 0.09722
Step 172925: loss = 0.05464
Step 172930: loss = 0.15433
Step 172935: loss = 0.11747
Step 172940: loss = 0.35859
Step 172945: loss = 0.03946
Step 172950: loss = 0.05198
Step 172955: loss = 0.01893
Step 172960: loss = 0.18310
Step 172965: loss = 0.03905
Step 172970: loss = 0.25596
Step 172975: loss = 0.18203
Step 172980: loss = 0.08759
Step 172985: loss = 0.08323
Step 172990: loss = 0.10104
Step 172995: loss = 0.08837
Step 173000: loss = 0.04832
Training Data Eval:
  Num examples: 50000, Num correct: 48045, Precision @ 1: 0.9609
('Testing Data Eval: EPOCH->', 174)
  Num examples: 10000, Num correct: 6723, Precision @ 1: 0.6723
Step 173005: loss = 0.02565
Step 173010: loss = 0.12921
Step 173015: loss = 0.16630
Step 173020: loss = 0.03395
Step 173025: loss = 0.13259
Step 173030: loss = 0.04734
Step 173035: loss = 0.06741
Step 173040: loss = 0.01974
Step 173045: loss = 0.04913
Step 173050: loss = 0.28239
Step 173055: loss = 0.10252
Step 173060: loss = 0.18030
Step 173065: loss = 0.13017
Step 173070: loss = 0.10779
Step 173075: loss = 0.14093
Step 173080: loss = 0.04184
Step 173085: loss = 0.22786
Step 173090: loss = 0.07950
Step 173095: loss = 0.15115
Step 173100: loss = 0.03856
Step 173105: loss = 0.15643
Step 173110: loss = 0.09818
Step 173115: loss = 0.21736
Step 173120: loss = 0.19022
Step 173125: loss = 0.14759
Step 173130: loss = 0.12277
Step 173135: loss = 0.17181
Step 173140: loss = 0.21215
Step 173145: loss = 0.12176
Step 173150: loss = 0.08519
Step 173155: loss = 0.17845
Step 173160: loss = 0.06930
Step 173165: loss = 0.09003
Step 173170: loss = 0.06051
Step 173175: loss = 0.03840
Step 173180: loss = 0.21706
Step 173185: loss = 0.08801
Step 173190: loss = 0.23923
Step 173195: loss = 0.14101
Step 173200: loss = 0.04996
Step 173205: loss = 0.23166
Step 173210: loss = 0.10089
Step 173215: loss = 0.30552
Step 173220: loss = 0.08529
Step 173225: loss = 0.02948
Step 173230: loss = 0.13756
Step 173235: loss = 0.11648
Step 173240: loss = 0.08568
Step 173245: loss = 0.03577
Step 173250: loss = 0.02895
Step 173255: loss = 0.14359
Step 173260: loss = 0.22711
Step 173265: loss = 0.03092
Step 173270: loss = 0.12017
Step 173275: loss = 0.22284
Step 173280: loss = 0.13330
Step 173285: loss = 0.03628
Step 173290: loss = 0.07194
Step 173295: loss = 0.04813
Step 173300: loss = 0.17486
Step 173305: loss = 0.09027
Step 173310: loss = 0.20446
Step 173315: loss = 0.11852
Step 173320: loss = 0.03956
Step 173325: loss = 0.32807
Step 173330: loss = 0.02645
Step 173335: loss = 0.09799
Step 173340: loss = 0.13106
Step 173345: loss = 0.29135
Step 173350: loss = 0.20051
Step 173355: loss = 0.08944
Step 173360: loss = 0.26203
Step 173365: loss = 0.12511
Step 173370: loss = 0.05906
Step 173375: loss = 0.22825
Step 173380: loss = 0.07470
Step 173385: loss = 0.11055
Step 173390: loss = 0.09899
Step 173395: loss = 0.18328
Step 173400: loss = 0.05611
Step 173405: loss = 0.04843
Step 173410: loss = 0.08519
Step 173415: loss = 0.07386
Step 173420: loss = 0.38440
Step 173425: loss = 0.09982
Step 173430: loss = 0.03994
Step 173435: loss = 0.10623
Step 173440: loss = 0.17179
Step 173445: loss = 0.14865
Step 173450: loss = 0.08321
Step 173455: loss = 0.10703
Step 173460: loss = 0.03083
Step 173465: loss = 0.31063
Step 173470: loss = 0.04138
Step 173475: loss = 0.11123
Step 173480: loss = 0.03684
Step 173485: loss = 0.11159
Step 173490: loss = 0.15782
Step 173495: loss = 0.07853
Step 173500: loss = 0.12572
Step 173505: loss = 0.02219
Step 173510: loss = 0.07010
Step 173515: loss = 0.08053
Step 173520: loss = 0.04013
Step 173525: loss = 0.02981
Step 173530: loss = 0.13877
Step 173535: loss = 0.09828
Step 173540: loss = 0.04067
Step 173545: loss = 0.21088
Step 173550: loss = 0.04836
Step 173555: loss = 0.25986
Step 173560: loss = 0.04392
Step 173565: loss = 0.06391
Step 173570: loss = 0.04205
Step 173575: loss = 0.04562
Step 173580: loss = 0.10022
Step 173585: loss = 0.12514
Step 173590: loss = 0.04325
Step 173595: loss = 0.07206
Step 173600: loss = 0.07457
Step 173605: loss = 0.41698
Step 173610: loss = 0.08418
Step 173615: loss = 0.05287
Step 173620: loss = 0.34407
Step 173625: loss = 0.15171
Step 173630: loss = 0.05622
Step 173635: loss = 0.05410
Step 173640: loss = 0.09804
Step 173645: loss = 0.15238
Step 173650: loss = 0.02765
Step 173655: loss = 0.33202
Step 173660: loss = 0.15748
Step 173665: loss = 0.16121
Step 173670: loss = 0.12562
Step 173675: loss = 0.11921
Step 173680: loss = 0.22605
Step 173685: loss = 0.05095
Step 173690: loss = 0.08573
Step 173695: loss = 0.03961
Step 173700: loss = 0.29233
Step 173705: loss = 0.13785
Step 173710: loss = 0.12114
Step 173715: loss = 0.04507
Step 173720: loss = 0.08026
Step 173725: loss = 0.08636
Step 173730: loss = 0.06189
Step 173735: loss = 0.11869
Step 173740: loss = 0.05407
Step 173745: loss = 0.01841
Step 173750: loss = 0.12464
Step 173755: loss = 0.03338
Step 173760: loss = 0.09577
Step 173765: loss = 0.04966
Step 173770: loss = 0.05999
Step 173775: loss = 0.11392
Step 173780: loss = 0.56987
Step 173785: loss = 0.03515
Step 173790: loss = 0.21203
Step 173795: loss = 0.11417
Step 173800: loss = 0.11262
Step 173805: loss = 0.07564
Step 173810: loss = 0.08505
Step 173815: loss = 0.11129
Step 173820: loss = 0.12912
Step 173825: loss = 0.06581
Step 173830: loss = 0.17574
Step 173835: loss = 0.03634
Step 173840: loss = 0.17785
Step 173845: loss = 0.03065
Step 173850: loss = 0.04077
Step 173855: loss = 0.05424
Step 173860: loss = 0.23640
Step 173865: loss = 0.02351
Step 173870: loss = 0.17441
Step 173875: loss = 0.14922
Step 173880: loss = 0.08218
Step 173885: loss = 0.08546
Step 173890: loss = 0.17526
Step 173895: loss = 0.04604
Step 173900: loss = 0.13064
Step 173905: loss = 0.13059
Step 173910: loss = 0.10445
Step 173915: loss = 0.05073
Step 173920: loss = 0.14068
Step 173925: loss = 0.16094
Step 173930: loss = 0.07469
Step 173935: loss = 0.07385
Step 173940: loss = 0.06896
Step 173945: loss = 0.08819
Step 173950: loss = 0.08385
Step 173955: loss = 0.09761
Step 173960: loss = 0.18317
Step 173965: loss = 0.24093
Step 173970: loss = 0.05508
Step 173975: loss = 0.22764
Step 173980: loss = 0.13220
Step 173985: loss = 0.08596
Step 173990: loss = 0.22059
Step 173995: loss = 0.04576
Step 174000: loss = 0.07651
Training Data Eval:
  Num examples: 50000, Num correct: 48056, Precision @ 1: 0.9611
('Testing Data Eval: EPOCH->', 175)
  Num examples: 10000, Num correct: 6712, Precision @ 1: 0.6712
Step 174005: loss = 0.14289
Step 174010: loss = 0.16265
Step 174015: loss = 0.06621
Step 174020: loss = 0.06878
Step 174025: loss = 0.07809
Step 174030: loss = 0.07552
Step 174035: loss = 0.12557
Step 174040: loss = 0.06904
Step 174045: loss = 0.05370
Step 174050: loss = 0.38936
Step 174055: loss = 0.05143
Step 174060: loss = 0.11627
Step 174065: loss = 0.02985
Step 174070: loss = 0.12047
Step 174075: loss = 0.04407
Step 174080: loss = 0.05878
Step 174085: loss = 0.08932
Step 174090: loss = 0.17364
Step 174095: loss = 0.05194
Step 174100: loss = 0.24914
Step 174105: loss = 0.05353
Step 174110: loss = 0.02904
Step 174115: loss = 0.24767
Step 174120: loss = 0.05835
Step 174125: loss = 0.20638
Step 174130: loss = 0.05467
Step 174135: loss = 0.07719
Step 174140: loss = 0.03874
Step 174145: loss = 0.06488
Step 174150: loss = 0.03429
Step 174155: loss = 0.05747
Step 174160: loss = 0.15439
Step 174165: loss = 0.04282
Step 174170: loss = 0.07411
Step 174175: loss = 0.25179
Step 174180: loss = 0.24798
Step 174185: loss = 0.08981
Step 174190: loss = 0.28065
Step 174195: loss = 0.22276
Step 174200: loss = 0.28582
Step 174205: loss = 0.24007
Step 174210: loss = 0.05458
Step 174215: loss = 0.19034
Step 174220: loss = 0.11883
Step 174225: loss = 0.18781
Step 174230: loss = 0.10984
Step 174235: loss = 0.03555
Step 174240: loss = 0.11933
Step 174245: loss = 0.11514
Step 174250: loss = 0.29617
Step 174255: loss = 0.12723
Step 174260: loss = 0.04716
Step 174265: loss = 0.06064
Step 174270: loss = 0.11862
Step 174275: loss = 0.12075
Step 174280: loss = 0.11040
Step 174285: loss = 0.07490
Step 174290: loss = 0.03403
Step 174295: loss = 0.06039
Step 174300: loss = 0.28086
Step 174305: loss = 0.08072
Step 174310: loss = 0.10139
Step 174315: loss = 0.08200
Step 174320: loss = 0.26659
Step 174325: loss = 0.06096
Step 174330: loss = 0.03445
Step 174335: loss = 0.14671
Step 174340: loss = 0.23478
Step 174345: loss = 0.02889
Step 174350: loss = 0.01548
Step 174355: loss = 0.07061
Step 174360: loss = 0.14451
Step 174365: loss = 0.12640
Step 174370: loss = 0.22564
Step 174375: loss = 0.18615
Step 174380: loss = 0.16013
Step 174385: loss = 0.39128
Step 174390: loss = 0.05473
Step 174395: loss = 0.19489
Step 174400: loss = 0.03855
Step 174405: loss = 0.07126
Step 174410: loss = 0.09987
Step 174415: loss = 0.04424
Step 174420: loss = 0.06745
Step 174425: loss = 0.10414
Step 174430: loss = 0.03240
Step 174435: loss = 0.12757
Step 174440: loss = 0.05028
Step 174445: loss = 0.04281
Step 174450: loss = 0.04931
Step 174455: loss = 0.18056
Step 174460: loss = 0.08703
Step 174465: loss = 0.02730
Step 174470: loss = 0.08175
Step 174475: loss = 0.01358
Step 174480: loss = 0.16191
Step 174485: loss = 0.12650
Step 174490: loss = 0.04158
Step 174495: loss = 0.17255
Step 174500: loss = 0.09471
Step 174505: loss = 0.11920
Step 174510: loss = 0.21888
Step 174515: loss = 0.02734
Step 174520: loss = 0.10982
Step 174525: loss = 0.12080
Step 174530: loss = 0.08789
Step 174535: loss = 0.03469
Step 174540: loss = 0.11326
Step 174545: loss = 0.04500
Step 174550: loss = 0.17118
Step 174555: loss = 0.04988
Step 174560: loss = 0.18028
Step 174565: loss = 0.27732
Step 174570: loss = 0.21069
Step 174575: loss = 0.02099
Step 174580: loss = 0.04364
Step 174585: loss = 0.35321
Step 174590: loss = 0.03909
Step 174595: loss = 0.09409
Step 174600: loss = 0.07384
Step 174605: loss = 0.04582
Step 174610: loss = 0.05597
Step 174615: loss = 0.12045
Step 174620: loss = 0.11384
Step 174625: loss = 0.22397
Step 174630: loss = 0.26453
Step 174635: loss = 0.15468
Step 174640: loss = 0.06341
Step 174645: loss = 0.03822
Step 174650: loss = 0.06855
Step 174655: loss = 0.32918
Step 174660: loss = 0.10960
Step 174665: loss = 0.06198
Step 174670: loss = 0.15400
Step 174675: loss = 0.03208
Step 174680: loss = 0.06940
Step 174685: loss = 0.13244
Step 174690: loss = 0.16487
Step 174695: loss = 0.10337
Step 174700: loss = 0.08729
Step 174705: loss = 0.04702
Step 174710: loss = 0.09555
Step 174715: loss = 0.02112
Step 174720: loss = 0.24780
Step 174725: loss = 0.13150
Step 174730: loss = 0.04701
Step 174735: loss = 0.06531
Step 174740: loss = 0.04164
Step 174745: loss = 0.30636
Step 174750: loss = 0.20561
Step 174755: loss = 0.15052
Step 174760: loss = 0.04029
Step 174765: loss = 0.12906
Step 174770: loss = 0.02154
Step 174775: loss = 0.17008
Step 174780: loss = 0.03919
Step 174785: loss = 0.08296
Step 174790: loss = 0.20682
Step 174795: loss = 0.14725
Step 174800: loss = 0.10347
Step 174805: loss = 0.30115
Step 174810: loss = 0.04595
Step 174815: loss = 0.07998
Step 174820: loss = 0.04602
Step 174825: loss = 0.06789
Step 174830: loss = 0.06648
Step 174835: loss = 0.02888
Step 174840: loss = 0.21798
Step 174845: loss = 0.03851
Step 174850: loss = 0.18327
Step 174855: loss = 0.04302
Step 174860: loss = 0.14506
Step 174865: loss = 0.05764
Step 174870: loss = 0.10911
Step 174875: loss = 0.01459
Step 174880: loss = 0.06808
Step 174885: loss = 0.13499
Step 174890: loss = 0.13357
Step 174895: loss = 0.08714
Step 174900: loss = 0.09701
Step 174905: loss = 0.16205
Step 174910: loss = 0.06797
Step 174915: loss = 0.14430
Step 174920: loss = 0.06569
Step 174925: loss = 0.10648
Step 174930: loss = 0.20610
Step 174935: loss = 0.11172
Step 174940: loss = 0.11832
Step 174945: loss = 0.02627
Step 174950: loss = 0.05993
Step 174955: loss = 0.06151
Step 174960: loss = 0.14095
Step 174965: loss = 0.10971
Step 174970: loss = 0.07821
Step 174975: loss = 0.05961
Step 174980: loss = 0.22648
Step 174985: loss = 0.05642
Step 174990: loss = 0.18533
Step 174995: loss = 0.07383
Step 175000: loss = 0.42075
Training Data Eval:
  Num examples: 50000, Num correct: 48183, Precision @ 1: 0.9637
('Testing Data Eval: EPOCH->', 176)
  Num examples: 10000, Num correct: 6734, Precision @ 1: 0.6734
Step 175005: loss = 0.07559
Step 175010: loss = 0.08626
Step 175015: loss = 0.08891
Step 175020: loss = 0.17848
Step 175025: loss = 0.09707
Step 175030: loss = 0.07179
Step 175035: loss = 0.11229
Step 175040: loss = 0.08749
Step 175045: loss = 0.06597
Step 175050: loss = 0.12945
Step 175055: loss = 0.10525
Step 175060: loss = 0.15635
Step 175065: loss = 0.03813
Step 175070: loss = 0.03514
Step 175075: loss = 0.06375
Step 175080: loss = 0.05870
Step 175085: loss = 0.01408
Step 175090: loss = 0.09426
Step 175095: loss = 0.04728
Step 175100: loss = 0.12652
Step 175105: loss = 0.09770
Step 175110: loss = 0.06354
Step 175115: loss = 0.05931
Step 175120: loss = 0.57779
Step 175125: loss = 0.10640
Step 175130: loss = 0.04367
Step 175135: loss = 0.06917
Step 175140: loss = 0.05299
Step 175145: loss = 0.11568
Step 175150: loss = 0.31206
Step 175155: loss = 0.13680
Step 175160: loss = 0.07649
Step 175165: loss = 0.08613
Step 175170: loss = 0.08714
Step 175175: loss = 0.07205
Step 175180: loss = 0.18900
Step 175185: loss = 0.09287
Step 175190: loss = 0.18173
Step 175195: loss = 0.10365
Step 175200: loss = 0.20713
Step 175205: loss = 0.15225
Step 175210: loss = 0.08230
Step 175215: loss = 0.03788
Step 175220: loss = 0.10188
Step 175225: loss = 0.02932
Step 175230: loss = 0.07358
Step 175235: loss = 0.06818
Step 175240: loss = 0.19469
Step 175245: loss = 0.06037
Step 175250: loss = 0.03542
Step 175255: loss = 0.14480
Step 175260: loss = 0.08611
Step 175265: loss = 0.05106
Step 175270: loss = 0.19655
Step 175275: loss = 0.15380
Step 175280: loss = 0.15029
Step 175285: loss = 0.09735
Step 175290: loss = 0.09490
Step 175295: loss = 0.15030
Step 175300: loss = 0.04171
Step 175305: loss = 0.16430
Step 175310: loss = 0.15265
Step 175315: loss = 0.07793
Step 175320: loss = 0.15412
Step 175325: loss = 0.07350
Step 175330: loss = 0.29821
Step 175335: loss = 0.11065
Step 175340: loss = 0.05677
Step 175345: loss = 0.03665
Step 175350: loss = 0.06685
Step 175355: loss = 0.11268
Step 175360: loss = 0.07047
Step 175365: loss = 0.06829
Step 175370: loss = 0.15036
Step 175375: loss = 0.01338
Step 175380: loss = 0.53887
Step 175385: loss = 0.10884
Step 175390: loss = 0.22935
Step 175395: loss = 0.38764
Step 175400: loss = 0.10718
Step 175405: loss = 0.07547
Step 175410: loss = 0.02897
Step 175415: loss = 0.01865
Step 175420: loss = 0.08649
Step 175425: loss = 0.02264
Step 175430: loss = 0.09284
Step 175435: loss = 0.18042
Step 175440: loss = 0.14794
Step 175445: loss = 0.07999
Step 175450: loss = 0.16262
Step 175455: loss = 0.17055
Step 175460: loss = 0.11055
Step 175465: loss = 0.15255
Step 175470: loss = 0.19331
Step 175475: loss = 0.21108
Step 175480: loss = 0.07261
Step 175485: loss = 0.14334
Step 175490: loss = 0.09672
Step 175495: loss = 0.15602
Step 175500: loss = 0.12288
Step 175505: loss = 0.10063
Step 175510: loss = 0.09519
Step 175515: loss = 0.04145
Step 175520: loss = 0.04554
Step 175525: loss = 0.02674
Step 175530: loss = 0.19934
Step 175535: loss = 0.07056
Step 175540: loss = 0.05016
Step 175545: loss = 0.08374
Step 175550: loss = 0.19038
Step 175555: loss = 0.10980
Step 175560: loss = 0.15248
Step 175565: loss = 0.18111
Step 175570: loss = 0.10709
Step 175575: loss = 0.08948
Step 175580: loss = 0.12692
Step 175585: loss = 0.11872
Step 175590: loss = 0.11563
Step 175595: loss = 0.10283
Step 175600: loss = 0.15488
Step 175605: loss = 0.03567
Step 175610: loss = 0.03177
Step 175615: loss = 0.20315
Step 175620: loss = 0.09852
Step 175625: loss = 0.16617
Step 175630: loss = 0.28156
Step 175635: loss = 0.54548
Step 175640: loss = 0.22667
Step 175645: loss = 0.16399
Step 175650: loss = 0.04767
Step 175655: loss = 0.04940
Step 175660: loss = 0.04959
Step 175665: loss = 0.10698
Step 175670: loss = 0.06408
Step 175675: loss = 0.18981
Step 175680: loss = 0.11937
Step 175685: loss = 0.02413
Step 175690: loss = 0.05258
Step 175695: loss = 0.02792
Step 175700: loss = 0.09074
Step 175705: loss = 0.21089
Step 175710: loss = 0.05420
Step 175715: loss = 0.06338
Step 175720: loss = 0.11858
Step 175725: loss = 0.16498
Step 175730: loss = 0.11710
Step 175735: loss = 0.03248
Step 175740: loss = 0.09518
Step 175745: loss = 0.35550
Step 175750: loss = 0.05062
Step 175755: loss = 0.05541
Step 175760: loss = 0.04109
Step 175765: loss = 0.04951
Step 175770: loss = 0.10216
Step 175775: loss = 0.15384
Step 175780: loss = 0.09842
Step 175785: loss = 0.30308
Step 175790: loss = 0.04407
Step 175795: loss = 0.19689
Step 175800: loss = 0.23866
Step 175805: loss = 0.07299
Step 175810: loss = 0.14487
Step 175815: loss = 0.06556
Step 175820: loss = 0.12227
Step 175825: loss = 0.06295
Step 175830: loss = 0.08864
Step 175835: loss = 0.19179
Step 175840: loss = 0.08736
Step 175845: loss = 0.16242
Step 175850: loss = 0.06324
Step 175855: loss = 0.09813
Step 175860: loss = 0.05127
Step 175865: loss = 0.04050
Step 175870: loss = 0.05815
Step 175875: loss = 0.20074
Step 175880: loss = 0.11403
Step 175885: loss = 0.12947
Step 175890: loss = 0.19992
Step 175895: loss = 0.02607
Step 175900: loss = 0.09848
Step 175905: loss = 0.12204
Step 175910: loss = 0.20170
Step 175915: loss = 0.13786
Step 175920: loss = 0.01712
Step 175925: loss = 0.10646
Step 175930: loss = 0.05128
Step 175935: loss = 0.21467
Step 175940: loss = 0.12458
Step 175945: loss = 0.07098
Step 175950: loss = 0.09102
Step 175955: loss = 0.09997
Step 175960: loss = 0.10829
Step 175965: loss = 0.03796
Step 175970: loss = 0.07336
Step 175975: loss = 0.11095
Step 175980: loss = 0.28739
Step 175985: loss = 0.19394
Step 175990: loss = 0.03454
Step 175995: loss = 0.13786
Step 176000: loss = 0.07027
Training Data Eval:
  Num examples: 50000, Num correct: 48146, Precision @ 1: 0.9629
('Testing Data Eval: EPOCH->', 177)
  Num examples: 10000, Num correct: 6716, Precision @ 1: 0.6716
Step 176005: loss = 0.04967
Step 176010: loss = 0.05685
Step 176015: loss = 0.17599
Step 176020: loss = 0.04298
Step 176025: loss = 0.11471
Step 176030: loss = 0.12314
Step 176035: loss = 0.05429
Step 176040: loss = 0.20542
Step 176045: loss = 0.10687
Step 176050: loss = 0.06025
Step 176055: loss = 0.05105
Step 176060: loss = 0.06891
Step 176065: loss = 0.09818
Step 176070: loss = 0.06047
Step 176075: loss = 0.06082
Step 176080: loss = 0.01407
Step 176085: loss = 0.10313
Step 176090: loss = 0.05714
Step 176095: loss = 0.18974
Step 176100: loss = 0.25367
Step 176105: loss = 0.09779
Step 176110: loss = 0.10408
Step 176115: loss = 0.29872
Step 176120: loss = 0.30842
Step 176125: loss = 0.12129
Step 176130: loss = 0.03800
Step 176135: loss = 0.09053
Step 176140: loss = 0.14193
Step 176145: loss = 0.03104
Step 176150: loss = 0.07190
Step 176155: loss = 0.09780
Step 176160: loss = 0.06739
Step 176165: loss = 0.06062
Step 176170: loss = 0.03216
Step 176175: loss = 0.13655
Step 176180: loss = 0.07307
Step 176185: loss = 0.20532
Step 176190: loss = 0.07289
Step 176195: loss = 0.11414
Step 176200: loss = 0.03461
Step 176205: loss = 0.08817
Step 176210: loss = 0.11752
Step 176215: loss = 0.20096
Step 176220: loss = 0.10506
Step 176225: loss = 0.13194
Step 176230: loss = 0.06220
Step 176235: loss = 0.06082
Step 176240: loss = 0.03155
Step 176245: loss = 0.12619
Step 176250: loss = 0.02200
Step 176255: loss = 0.09098
Step 176260: loss = 0.13250
Step 176265: loss = 0.06801
Step 176270: loss = 0.01388
Step 176275: loss = 0.03886
Step 176280: loss = 0.15102
Step 176285: loss = 0.05104
Step 176290: loss = 0.14430
Step 176295: loss = 0.02948
Step 176300: loss = 0.02532
Step 176305: loss = 0.13302
Step 176310: loss = 0.26902
Step 176315: loss = 0.14608
Step 176320: loss = 0.13110
Step 176325: loss = 0.06038
Step 176330: loss = 0.11222
Step 176335: loss = 0.11390
Step 176340: loss = 0.09334
Step 176345: loss = 0.02679
Step 176350: loss = 0.14894
Step 176355: loss = 0.06076
Step 176360: loss = 0.05808
Step 176365: loss = 0.19529
Step 176370: loss = 0.06405
Step 176375: loss = 0.02936
Step 176380: loss = 0.13521
Step 176385: loss = 0.10589
Step 176390: loss = 0.17452
Step 176395: loss = 0.03755
Step 176400: loss = 0.02926
Step 176405: loss = 0.11751
Step 176410: loss = 0.18841
Step 176415: loss = 0.05057
Step 176420: loss = 0.09123
Step 176425: loss = 0.04035
Step 176430: loss = 0.16082
Step 176435: loss = 0.33405
Step 176440: loss = 0.07855
Step 176445: loss = 0.18754
Step 176450: loss = 0.20692
Step 176455: loss = 0.15378
Step 176460: loss = 0.06060
Step 176465: loss = 0.02282
Step 176470: loss = 0.09004
Step 176475: loss = 0.21121
Step 176480: loss = 0.14218
Step 176485: loss = 0.18953
Step 176490: loss = 0.06764
Step 176495: loss = 0.03188
Step 176500: loss = 0.11560
Step 176505: loss = 0.07045
Step 176510: loss = 0.06965
Step 176515: loss = 0.06640
Step 176520: loss = 0.16591
Step 176525: loss = 0.03718
Step 176530: loss = 0.37688
Step 176535: loss = 0.12711
Step 176540: loss = 0.05068
Step 176545: loss = 0.22528
Step 176550: loss = 0.05384
Step 176555: loss = 0.10578
Step 176560: loss = 0.20504
Step 176565: loss = 0.04752
Step 176570: loss = 0.11969
Step 176575: loss = 0.13988
Step 176580: loss = 0.08166
Step 176585: loss = 0.06939
Step 176590: loss = 0.29679
Step 176595: loss = 0.12289
Step 176600: loss = 0.20941
Step 176605: loss = 0.39720
Step 176610: loss = 0.05918
Step 176615: loss = 0.08000
Step 176620: loss = 0.06545
Step 176625: loss = 0.18249
Step 176630: loss = 0.21183
Step 176635: loss = 0.05008
Step 176640: loss = 0.05079
Step 176645: loss = 0.13744
Step 176650: loss = 0.07555
Step 176655: loss = 0.21071
Step 176660: loss = 0.32749
Step 176665: loss = 0.09253
Step 176670: loss = 0.09773
Step 176675: loss = 0.03432
Step 176680: loss = 0.13944
Step 176685: loss = 0.35204
Step 176690: loss = 0.12734
Step 176695: loss = 0.06756
Step 176700: loss = 0.05683
Step 176705: loss = 0.07415
Step 176710: loss = 0.04414
Step 176715: loss = 0.11737
Step 176720: loss = 0.03370
Step 176725: loss = 0.06760
Step 176730: loss = 0.16634
Step 176735: loss = 0.09553
Step 176740: loss = 0.19868
Step 176745: loss = 0.12118
Step 176750: loss = 0.05018
Step 176755: loss = 0.13202
Step 176760: loss = 0.18358
Step 176765: loss = 0.28776
Step 176770: loss = 0.14602
Step 176775: loss = 0.04114
Step 176780: loss = 0.28422
Step 176785: loss = 0.26814
Step 176790: loss = 0.10934
Step 176795: loss = 0.10620
Step 176800: loss = 0.10635
Step 176805: loss = 0.06417
Step 176810: loss = 0.25942
Step 176815: loss = 0.26948
Step 176820: loss = 0.09558
Step 176825: loss = 0.08839
Step 176830: loss = 0.09482
Step 176835: loss = 0.11287
Step 176840: loss = 0.07558
Step 176845: loss = 0.06411
Step 176850: loss = 0.21434
Step 176855: loss = 0.25518
Step 176860: loss = 0.41129
Step 176865: loss = 0.30485
Step 176870: loss = 0.31664
Step 176875: loss = 0.10287
Step 176880: loss = 0.14147
Step 176885: loss = 0.11774
Step 176890: loss = 0.07474
Step 176895: loss = 0.05253
Step 176900: loss = 0.06766
Step 176905: loss = 0.02871
Step 176910: loss = 0.20875
Step 176915: loss = 0.03669
Step 176920: loss = 0.09938
Step 176925: loss = 0.14539
Step 176930: loss = 0.05489
Step 176935: loss = 0.11843
Step 176940: loss = 0.05482
Step 176945: loss = 0.02729
Step 176950: loss = 0.26645
Step 176955: loss = 0.03316
Step 176960: loss = 0.17536
Step 176965: loss = 0.10941
Step 176970: loss = 0.23704
Step 176975: loss = 0.19515
Step 176980: loss = 0.13888
Step 176985: loss = 0.23066
Step 176990: loss = 0.13904
Step 176995: loss = 0.32686
Step 177000: loss = 0.19305
Training Data Eval:
  Num examples: 50000, Num correct: 47923, Precision @ 1: 0.9585
('Testing Data Eval: EPOCH->', 178)
  Num examples: 10000, Num correct: 6652, Precision @ 1: 0.6652
Step 177005: loss = 0.05133
Step 177010: loss = 0.12611
Step 177015: loss = 0.03799
Step 177020: loss = 0.02924
Step 177025: loss = 0.15042
Step 177030: loss = 0.04147
Step 177035: loss = 0.28178
Step 177040: loss = 0.04466
Step 177045: loss = 0.13487
Step 177050: loss = 0.14215
Step 177055: loss = 0.10775
Step 177060: loss = 0.25450
Step 177065: loss = 0.23623
Step 177070: loss = 0.06998
Step 177075: loss = 0.12596
Step 177080: loss = 0.02530
Step 177085: loss = 0.22988
Step 177090: loss = 0.09278
Step 177095: loss = 0.16571
Step 177100: loss = 0.08118
Step 177105: loss = 0.05959
Step 177110: loss = 0.05889
Step 177115: loss = 0.13115
Step 177120: loss = 0.18033
Step 177125: loss = 0.10634
Step 177130: loss = 0.17682
Step 177135: loss = 0.03778
Step 177140: loss = 0.04843
Step 177145: loss = 0.06009
Step 177150: loss = 0.10274
Step 177155: loss = 0.05528
Step 177160: loss = 0.08134
Step 177165: loss = 0.26349
Step 177170: loss = 0.09853
Step 177175: loss = 0.03580
Step 177180: loss = 0.31228
Step 177185: loss = 0.03736
Step 177190: loss = 0.22371
Step 177195: loss = 0.09685
Step 177200: loss = 0.07047
Step 177205: loss = 0.10747
Step 177210: loss = 0.03288
Step 177215: loss = 0.11713
Step 177220: loss = 0.20602
Step 177225: loss = 0.11933
Step 177230: loss = 0.12287
Step 177235: loss = 0.18151
Step 177240: loss = 0.02168
Step 177245: loss = 0.03960
Step 177250: loss = 0.08198
Step 177255: loss = 0.02080
Step 177260: loss = 0.14333
Step 177265: loss = 0.06839
Step 177270: loss = 0.10764
Step 177275: loss = 0.02053
Step 177280: loss = 0.06141
Step 177285: loss = 0.04168
Step 177290: loss = 0.06081
Step 177295: loss = 0.13238
Step 177300: loss = 0.06212
Step 177305: loss = 0.11200
Step 177310: loss = 0.27024
Step 177315: loss = 0.05514
Step 177320: loss = 0.14222
Step 177325: loss = 0.06803
Step 177330: loss = 0.13795
Step 177335: loss = 0.16084
Step 177340: loss = 0.18960
Step 177345: loss = 0.92540
Step 177350: loss = 0.07522
Step 177355: loss = 0.10566
Step 177360: loss = 0.29359
Step 177365: loss = 0.32314
Step 177370: loss = 0.05932
Step 177375: loss = 0.09630
Step 177380: loss = 0.11079
Step 177385: loss = 0.05674
Step 177390: loss = 0.19733
Step 177395: loss = 0.30576
Step 177400: loss = 0.20627
Step 177405: loss = 0.37705
Step 177410: loss = 0.09048
Step 177415: loss = 0.18261
Step 177420: loss = 0.19725
Step 177425: loss = 0.09355
Step 177430: loss = 0.21666
Step 177435: loss = 0.20044
Step 177440: loss = 0.07010
Step 177445: loss = 0.18685
Step 177450: loss = 0.06426
Step 177455: loss = 0.11598
Step 177460: loss = 0.08902
Step 177465: loss = 0.04023
Step 177470: loss = 0.19899
Step 177475: loss = 0.16263
Step 177480: loss = 0.03287
Step 177485: loss = 0.17193
Step 177490: loss = 0.09723
Step 177495: loss = 0.04109
Step 177500: loss = 0.03985
Step 177505: loss = 0.13338
Step 177510: loss = 0.16894
Step 177515: loss = 0.22573
Step 177520: loss = 0.05987
Step 177525: loss = 0.04439
Step 177530: loss = 0.11049
Step 177535: loss = 0.12690
Step 177540: loss = 0.17959
Step 177545: loss = 0.25578
Step 177550: loss = 0.19050
Step 177555: loss = 0.19049
Step 177560: loss = 0.04532
Step 177565: loss = 0.01813
Step 177570: loss = 0.05807
Step 177575: loss = 0.08239
Step 177580: loss = 0.04858
Step 177585: loss = 0.11712
Step 177590: loss = 0.12284
Step 177595: loss = 0.12358
Step 177600: loss = 0.11355
Step 177605: loss = 0.05631
Step 177610: loss = 0.15770
Step 177615: loss = 0.04171
Step 177620: loss = 0.07027
Step 177625: loss = 0.12257
Step 177630: loss = 0.06477
Step 177635: loss = 0.12203
Step 177640: loss = 0.09722
Step 177645: loss = 0.04469
Step 177650: loss = 0.21020
Step 177655: loss = 0.11874
Step 177660: loss = 0.24236
Step 177665: loss = 0.08427
Step 177670: loss = 0.06059
Step 177675: loss = 0.01593
Step 177680: loss = 0.05991
Step 177685: loss = 0.15551
Step 177690: loss = 0.05727
Step 177695: loss = 0.06026
Step 177700: loss = 0.05337
Step 177705: loss = 0.05698
Step 177710: loss = 0.10435
Step 177715: loss = 0.14400
Step 177720: loss = 0.12149
Step 177725: loss = 0.13960
Step 177730: loss = 0.04700
Step 177735: loss = 0.16337
Step 177740: loss = 0.12729
Step 177745: loss = 0.05022
Step 177750: loss = 0.09711
Step 177755: loss = 0.05806
Step 177760: loss = 0.09839
Step 177765: loss = 0.04381
Step 177770: loss = 0.17487
Step 177775: loss = 0.01494
Step 177780: loss = 0.08333
Step 177785: loss = 0.30449
Step 177790: loss = 0.03211
Step 177795: loss = 0.05915
Step 177800: loss = 0.21357
Step 177805: loss = 0.07654
Step 177810: loss = 0.09636
Step 177815: loss = 0.01917
Step 177820: loss = 0.03126
Step 177825: loss = 0.10031
Step 177830: loss = 0.03755
Step 177835: loss = 0.01786
Step 177840: loss = 0.02824
Step 177845: loss = 0.08774
Step 177850: loss = 0.15897
Step 177855: loss = 0.07389
Step 177860: loss = 0.07095
Step 177865: loss = 0.16574
Step 177870: loss = 0.12300
Step 177875: loss = 0.14260
Step 177880: loss = 0.24191
Step 177885: loss = 0.04856
Step 177890: loss = 0.23211
Step 177895: loss = 0.12341
Step 177900: loss = 0.04144
Step 177905: loss = 0.05991
Step 177910: loss = 0.17124
Step 177915: loss = 0.10886
Step 177920: loss = 0.08543
Step 177925: loss = 0.31470
Step 177930: loss = 0.20821
Step 177935: loss = 0.06173
Step 177940: loss = 0.40042
Step 177945: loss = 0.08829
Step 177950: loss = 0.04461
Step 177955: loss = 0.12288
Step 177960: loss = 0.08474
Step 177965: loss = 0.11788
Step 177970: loss = 0.09349
Step 177975: loss = 0.15914
Step 177980: loss = 0.09268
Step 177985: loss = 0.10888
Step 177990: loss = 0.15477
Step 177995: loss = 0.05314
Step 178000: loss = 0.03270
Training Data Eval:
  Num examples: 50000, Num correct: 48155, Precision @ 1: 0.9631
('Testing Data Eval: EPOCH->', 179)
  Num examples: 10000, Num correct: 6780, Precision @ 1: 0.6780
Step 178005: loss = 0.06205
Step 178010: loss = 0.10561
Step 178015: loss = 0.12626
Step 178020: loss = 0.18929
Step 178025: loss = 0.13391
Step 178030: loss = 0.03351
Step 178035: loss = 0.12890
Step 178040: loss = 0.18731
Step 178045: loss = 0.12136
Step 178050: loss = 0.04606
Step 178055: loss = 0.20764
Step 178060: loss = 0.23992
Step 178065: loss = 0.03586
Step 178070: loss = 0.09551
Step 178075: loss = 0.05309
Step 178080: loss = 0.14300
Step 178085: loss = 0.04485
Step 178090: loss = 0.13547
Step 178095: loss = 0.10622
Step 178100: loss = 0.05264
Step 178105: loss = 0.59865
Step 178110: loss = 0.15049
Step 178115: loss = 0.05136
Step 178120: loss = 0.04248
Step 178125: loss = 0.06404
Step 178130: loss = 0.06444
Step 178135: loss = 0.03274
Step 178140: loss = 0.08129
Step 178145: loss = 0.22818
Step 178150: loss = 0.13177
Step 178155: loss = 0.06222
Step 178160: loss = 0.15858
Step 178165: loss = 0.16656
Step 178170: loss = 0.08683
Step 178175: loss = 0.23011
Step 178180: loss = 0.06163
Step 178185: loss = 0.12372
Step 178190: loss = 0.03397
Step 178195: loss = 0.05084
Step 178200: loss = 0.20002
Step 178205: loss = 0.20408
Step 178210: loss = 0.02986
Step 178215: loss = 0.09914
Step 178220: loss = 0.12431
Step 178225: loss = 0.17353
Step 178230: loss = 0.05647
Step 178235: loss = 0.09360
Step 178240: loss = 0.03716
Step 178245: loss = 0.15944
Step 178250: loss = 0.22862
Step 178255: loss = 0.08815
Step 178260: loss = 0.06513
Step 178265: loss = 0.12630
Step 178270: loss = 0.04880
Step 178275: loss = 0.09235
Step 178280: loss = 0.06515
Step 178285: loss = 0.02566
Step 178290: loss = 0.08639
Step 178295: loss = 0.05738
Step 178300: loss = 0.36846
Step 178305: loss = 0.07124
Step 178310: loss = 0.02458
Step 178315: loss = 0.27196
Step 178320: loss = 0.03492
Step 178325: loss = 0.15466
Step 178330: loss = 0.30611
Step 178335: loss = 0.08431
Step 178340: loss = 0.10971
Step 178345: loss = 0.09281
Step 178350: loss = 0.07744
Step 178355: loss = 0.08647
Step 178360: loss = 0.17824
Step 178365: loss = 0.04231
Step 178370: loss = 0.06321
Step 178375: loss = 0.06208
Step 178380: loss = 0.05055
Step 178385: loss = 0.10455
Step 178390: loss = 0.04694
Step 178395: loss = 0.25933
Step 178400: loss = 0.33319
Step 178405: loss = 0.09767
Step 178410: loss = 0.13734
Step 178415: loss = 0.08437
Step 178420: loss = 0.14125
Step 178425: loss = 0.06670
Step 178430: loss = 0.14261
Step 178435: loss = 0.20126
Step 178440: loss = 0.10388
Step 178445: loss = 0.04316
Step 178450: loss = 0.18135
Step 178455: loss = 0.03773
Step 178460: loss = 0.11473
Step 178465: loss = 0.06941
Step 178470: loss = 0.17051
Step 178475: loss = 0.13554
Step 178480: loss = 0.11279
Step 178485: loss = 0.07534
Step 178490: loss = 0.10624
Step 178495: loss = 0.12090
Step 178500: loss = 0.04056
Step 178505: loss = 0.03332
Step 178510: loss = 0.20416
Step 178515: loss = 0.19275
Step 178520: loss = 0.13137
Step 178525: loss = 0.12588
Step 178530: loss = 0.22899
Step 178535: loss = 0.10732
Step 178540: loss = 0.12665
Step 178545: loss = 0.07903
Step 178550: loss = 0.07533
Step 178555: loss = 0.15421
Step 178560: loss = 0.21996
Step 178565: loss = 0.09055
Step 178570: loss = 0.05814
Step 178575: loss = 0.04061
Step 178580: loss = 0.10875
Step 178585: loss = 0.05540
Step 178590: loss = 0.09171
Step 178595: loss = 0.08652
Step 178600: loss = 0.08354
Step 178605: loss = 0.09762
Step 178610: loss = 0.18299
Step 178615: loss = 0.02921
Step 178620: loss = 0.31663
Step 178625: loss = 0.04596
Step 178630: loss = 0.16897
Step 178635: loss = 0.24763
Step 178640: loss = 0.04911
Step 178645: loss = 0.12084
Step 178650: loss = 0.18379
Step 178655: loss = 0.07993
Step 178660: loss = 0.20147
Step 178665: loss = 0.13733
Step 178670: loss = 0.14592
Step 178675: loss = 0.22139
Step 178680: loss = 0.10304
Step 178685: loss = 0.08109
Step 178690: loss = 0.29554
Step 178695: loss = 0.14380
Step 178700: loss = 0.06562
Step 178705: loss = 0.12833
Step 178710: loss = 0.07418
Step 178715: loss = 0.08538
Step 178720: loss = 0.15141
Step 178725: loss = 0.34047
Step 178730: loss = 0.07453
Step 178735: loss = 0.18263
Step 178740: loss = 0.04410
Step 178745: loss = 0.15917
Step 178750: loss = 0.04922
Step 178755: loss = 0.09586
Step 178760: loss = 0.18743
Step 178765: loss = 0.18054
Step 178770: loss = 0.10022
Step 178775: loss = 0.08732
Step 178780: loss = 0.08931
Step 178785: loss = 0.09795
Step 178790: loss = 0.07815
Step 178795: loss = 0.07959
Step 178800: loss = 0.03550
Step 178805: loss = 0.19527
Step 178810: loss = 0.20637
Step 178815: loss = 0.08600
Step 178820: loss = 0.26271
Step 178825: loss = 0.11285
Step 178830: loss = 0.16012
Step 178835: loss = 0.10149
Step 178840: loss = 0.10279
Step 178845: loss = 0.23095
Step 178850: loss = 0.08762
Step 178855: loss = 0.21682
Step 178860: loss = 0.08233
Step 178865: loss = 0.04172
Step 178870: loss = 0.23885
Step 178875: loss = 0.10640
Step 178880: loss = 0.10730
Step 178885: loss = 0.07814
Step 178890: loss = 0.25376
Step 178895: loss = 0.19475
Step 178900: loss = 0.09132
Step 178905: loss = 0.07742
Step 178910: loss = 0.04964
Step 178915: loss = 0.22781
Step 178920: loss = 0.16802
Step 178925: loss = 0.17354
Step 178930: loss = 0.05117
Step 178935: loss = 0.08109
Step 178940: loss = 0.06257
Step 178945: loss = 0.18420
Step 178950: loss = 0.18425
Step 178955: loss = 0.04088
Step 178960: loss = 0.13513
Step 178965: loss = 0.10981
Step 178970: loss = 0.07951
Step 178975: loss = 0.08909
Step 178980: loss = 0.07180
Step 178985: loss = 0.19085
Step 178990: loss = 0.22948
Step 178995: loss = 0.23200
Step 179000: loss = 0.09390
Training Data Eval:
  Num examples: 50000, Num correct: 47986, Precision @ 1: 0.9597
('Testing Data Eval: EPOCH->', 180)
  Num examples: 10000, Num correct: 6610, Precision @ 1: 0.6610
Step 179005: loss = 0.09705
Step 179010: loss = 0.07555
Step 179015: loss = 0.13024
Step 179020: loss = 0.09174
Step 179025: loss = 0.21204
Step 179030: loss = 0.10966
Step 179035: loss = 0.14131
Step 179040: loss = 0.05480
Step 179045: loss = 0.12832
Step 179050: loss = 0.08378
Step 179055: loss = 0.12389
Step 179060: loss = 0.21305
Step 179065: loss = 0.18604
Step 179070: loss = 0.04316
Step 179075: loss = 0.14890
Step 179080: loss = 0.27179
Step 179085: loss = 0.09563
Step 179090: loss = 0.05225
Step 179095: loss = 0.22193
Step 179100: loss = 0.23398
Step 179105: loss = 0.05828
Step 179110: loss = 0.12203
Step 179115: loss = 0.02524
Step 179120: loss = 0.04228
Step 179125: loss = 0.02218
Step 179130: loss = 0.05698
Step 179135: loss = 0.09665
Step 179140: loss = 0.08702
Step 179145: loss = 0.03967
Step 179150: loss = 0.20718
Step 179155: loss = 0.05371
Step 179160: loss = 0.05040
Step 179165: loss = 0.03905
Step 179170: loss = 0.12243
Step 179175: loss = 0.08380
Step 179180: loss = 0.10222
Step 179185: loss = 0.11046
Step 179190: loss = 0.14404
Step 179195: loss = 0.39714
Step 179200: loss = 0.11255
Step 179205: loss = 0.11189
Step 179210: loss = 0.04217
Step 179215: loss = 0.12019
Step 179220: loss = 0.20891
Step 179225: loss = 0.10018
Step 179230: loss = 0.05055
Step 179235: loss = 0.20895
Step 179240: loss = 0.18585
Step 179245: loss = 0.08952
Step 179250: loss = 0.05176
Step 179255: loss = 0.11972
Step 179260: loss = 0.09214
Step 179265: loss = 0.03169
Step 179270: loss = 0.21639
Step 179275: loss = 0.39345
Step 179280: loss = 0.05099
Step 179285: loss = 0.12775
Step 179290: loss = 0.17801
Step 179295: loss = 0.02098
Step 179300: loss = 0.36659
Step 179305: loss = 0.24969
Step 179310: loss = 0.11615
Step 179315: loss = 0.04546
Step 179320: loss = 0.05588
Step 179325: loss = 0.06075
Step 179330: loss = 0.07673
Step 179335: loss = 0.08204
Step 179340: loss = 0.12650
Step 179345: loss = 0.25003
Step 179350: loss = 0.09870
Step 179355: loss = 0.02349
Step 179360: loss = 0.11861
Step 179365: loss = 0.07608
Step 179370: loss = 0.11293
Step 179375: loss = 0.06290
Step 179380: loss = 0.12711
Step 179385: loss = 0.01693
Step 179390: loss = 0.03104
Step 179395: loss = 0.26924
Step 179400: loss = 0.17535
Step 179405: loss = 0.08237
Step 179410: loss = 0.11520
Step 179415: loss = 0.09973
Step 179420: loss = 0.06457
Step 179425: loss = 0.04848
Step 179430: loss = 0.06707
Step 179435: loss = 0.05734
Step 179440: loss = 0.07754
Step 179445: loss = 0.03975
Step 179450: loss = 0.07577
Step 179455: loss = 0.03099
Step 179460: loss = 0.07024
Step 179465: loss = 0.08557
Step 179470: loss = 0.06574
Step 179475: loss = 0.03208
Step 179480: loss = 0.12127
Step 179485: loss = 0.07430
Step 179490: loss = 0.16725
Step 179495: loss = 0.23912
Step 179500: loss = 0.16240
Step 179505: loss = 0.19165
Step 179510: loss = 0.06116
Step 179515: loss = 0.16888
Step 179520: loss = 0.08103
Step 179525: loss = 0.10008
Step 179530: loss = 0.08671
Step 179535: loss = 0.09245
Step 179540: loss = 0.03737
Step 179545: loss = 0.03328
Step 179550: loss = 0.08025
Step 179555: loss = 0.02393
Step 179560: loss = 0.04757
Step 179565: loss = 0.11542
Step 179570: loss = 0.22846
Step 179575: loss = 0.05930
Step 179580: loss = 0.16467
Step 179585: loss = 0.17378
Step 179590: loss = 0.10040
Step 179595: loss = 0.05343
Step 179600: loss = 0.06339
Step 179605: loss = 0.07367
Step 179610: loss = 0.10516
Step 179615: loss = 0.08725
Step 179620: loss = 0.12745
Step 179625: loss = 0.22543
Step 179630: loss = 0.07065
Step 179635: loss = 0.02571
Step 179640: loss = 0.13370
Step 179645: loss = 0.10743
Step 179650: loss = 0.09907
Step 179655: loss = 0.02341
Step 179660: loss = 0.04557
Step 179665: loss = 0.10464
Step 179670: loss = 0.10325
Step 179675: loss = 0.11058
Step 179680: loss = 0.19089
Step 179685: loss = 0.05505
Step 179690: loss = 0.07805
Step 179695: loss = 0.34038
Step 179700: loss = 0.10638
Step 179705: loss = 0.10246
Step 179710: loss = 0.18470
Step 179715: loss = 0.04930
Step 179720: loss = 0.06707
Step 179725: loss = 0.23910
Step 179730: loss = 0.07320
Step 179735: loss = 0.39928
Step 179740: loss = 0.11346
Step 179745: loss = 0.19823
Step 179750: loss = 0.12321
Step 179755: loss = 0.22520
Step 179760: loss = 0.13756
Step 179765: loss = 0.12330
Step 179770: loss = 0.13612
Step 179775: loss = 0.32226
Step 179780: loss = 0.24993
Step 179785: loss = 0.10792
Step 179790: loss = 0.06594
Step 179795: loss = 0.04057
Step 179800: loss = 0.08122
Step 179805: loss = 0.14810
Step 179810: loss = 0.05204
Step 179815: loss = 0.18607
Step 179820: loss = 0.03653
Step 179825: loss = 0.17594
Step 179830: loss = 0.06703
Step 179835: loss = 0.10102
Step 179840: loss = 0.11329
Step 179845: loss = 0.06510
Step 179850: loss = 0.11500
Step 179855: loss = 0.07495
Step 179860: loss = 0.07470
Step 179865: loss = 0.05407
Step 179870: loss = 0.13837
Step 179875: loss = 0.09101
Step 179880: loss = 0.14779
Step 179885: loss = 0.22324
Step 179890: loss = 0.03085
Step 179895: loss = 0.01365
Step 179900: loss = 0.11884
Step 179905: loss = 0.26098
Step 179910: loss = 0.02797
Step 179915: loss = 0.10053
Step 179920: loss = 0.07157
Step 179925: loss = 0.20098
Step 179930: loss = 0.11360
Step 179935: loss = 0.29312
Step 179940: loss = 0.02595
Step 179945: loss = 0.09658
Step 179950: loss = 0.08017
Step 179955: loss = 0.10709
Step 179960: loss = 0.15063
Step 179965: loss = 0.06225
Step 179970: loss = 0.06027
Step 179975: loss = 0.03303
Step 179980: loss = 0.05568
Step 179985: loss = 0.07252
Step 179990: loss = 0.05516
Step 179995: loss = 0.12415
Step 180000: loss = 0.03733
Training Data Eval:
  Num examples: 50000, Num correct: 48145, Precision @ 1: 0.9629
('Testing Data Eval: EPOCH->', 181)
  Num examples: 10000, Num correct: 6669, Precision @ 1: 0.6669
Step 180005: loss = 0.03965
Step 180010: loss = 0.09547
Step 180015: loss = 0.10599
Step 180020: loss = 0.06310
Step 180025: loss = 0.01852
Step 180030: loss = 0.08124
Step 180035: loss = 0.07341
Step 180040: loss = 0.02608
Step 180045: loss = 0.14426
Step 180050: loss = 0.08430
Step 180055: loss = 0.05304
Step 180060: loss = 0.10139
Step 180065: loss = 0.17872
Step 180070: loss = 0.05675
Step 180075: loss = 0.09161
Step 180080: loss = 0.21855
Step 180085: loss = 0.20160
Step 180090: loss = 0.13758
Step 180095: loss = 0.27193
Step 180100: loss = 0.11462
Step 180105: loss = 0.11698
Step 180110: loss = 0.15029
Step 180115: loss = 0.17701
Step 180120: loss = 0.05487
Step 180125: loss = 0.03509
Step 180130: loss = 0.04808
Step 180135: loss = 0.42817
Step 180140: loss = 0.04731
Step 180145: loss = 0.07647
Step 180150: loss = 0.04899
Step 180155: loss = 0.03463
Step 180160: loss = 0.16549
Step 180165: loss = 0.08826
Step 180170: loss = 0.10435
Step 180175: loss = 0.02080
Step 180180: loss = 0.02449
Step 180185: loss = 0.05732
Step 180190: loss = 0.13884
Step 180195: loss = 0.13749
Step 180200: loss = 0.05245
Step 180205: loss = 0.20323
Step 180210: loss = 0.08752
Step 180215: loss = 0.09414
Step 180220: loss = 0.06630
Step 180225: loss = 0.10973
Step 180230: loss = 0.11216
Step 180235: loss = 0.03858
Step 180240: loss = 0.21758
Step 180245: loss = 0.19812
Step 180250: loss = 0.26369
Step 180255: loss = 0.20809
Step 180260: loss = 0.03869
Step 180265: loss = 0.12639
Step 180270: loss = 0.12990
Step 180275: loss = 0.15346
Step 180280: loss = 0.02928
Step 180285: loss = 0.15552
Step 180290: loss = 0.07066
Step 180295: loss = 0.07890
Step 180300: loss = 0.06432
Step 180305: loss = 0.31909
Step 180310: loss = 0.03572
Step 180315: loss = 0.09102
Step 180320: loss = 0.04295
Step 180325: loss = 0.09514
Step 180330: loss = 0.18219
Step 180335: loss = 0.11846
Step 180340: loss = 0.12622
Step 180345: loss = 0.14637
Step 180350: loss = 0.23607
Step 180355: loss = 0.08895
Step 180360: loss = 0.19048
Step 180365: loss = 0.03386
Step 180370: loss = 0.06195
Step 180375: loss = 0.09631
Step 180380: loss = 0.03687
Step 180385: loss = 0.08003
Step 180390: loss = 0.08353
Step 180395: loss = 0.08360
Step 180400: loss = 0.04601
Step 180405: loss = 0.07949
Step 180410: loss = 0.08264
Step 180415: loss = 0.17065
Step 180420: loss = 0.05336
Step 180425: loss = 0.02610
Step 180430: loss = 0.16004
Step 180435: loss = 0.10761
Step 180440: loss = 0.15031
Step 180445: loss = 0.08494
Step 180450: loss = 0.13032
Step 180455: loss = 0.06385
Step 180460: loss = 0.06983
Step 180465: loss = 0.06430
Step 180470: loss = 0.06986
Step 180475: loss = 0.10428
Step 180480: loss = 0.18547
Step 180485: loss = 0.10865
Step 180490: loss = 0.13826
Step 180495: loss = 0.06208
Step 180500: loss = 0.02138
Step 180505: loss = 0.20254
Step 180510: loss = 0.02817
Step 180515: loss = 0.08902
Step 180520: loss = 0.17599
Step 180525: loss = 0.07674
Step 180530: loss = 0.05624
Step 180535: loss = 0.20518
Step 180540: loss = 0.13984
Step 180545: loss = 0.02561
Step 180550: loss = 0.14788
Step 180555: loss = 0.31553
Step 180560: loss = 0.03199
Step 180565: loss = 0.15879
Step 180570: loss = 0.12564
Step 180575: loss = 0.03183
Step 180580: loss = 0.12393
Step 180585: loss = 0.07947
Step 180590: loss = 0.20869
Step 180595: loss = 0.16233
Step 180600: loss = 0.25711
Step 180605: loss = 0.07037
Step 180610: loss = 0.18474
Step 180615: loss = 0.19074
Step 180620: loss = 0.09929
Step 180625: loss = 0.09175
Step 180630: loss = 0.20935
Step 180635: loss = 0.09647
Step 180640: loss = 0.10533
Step 180645: loss = 0.25473
Step 180650: loss = 0.21848
Step 180655: loss = 0.06824
Step 180660: loss = 0.32692
Step 180665: loss = 0.01637
Step 180670: loss = 0.32137
Step 180675: loss = 0.17409
Step 180680: loss = 0.04968
Step 180685: loss = 0.17798
Step 180690: loss = 0.11348
Step 180695: loss = 0.13185
Step 180700: loss = 0.14720
Step 180705: loss = 0.03891
Step 180710: loss = 0.05352
Step 180715: loss = 0.05548
Step 180720: loss = 0.02163
Step 180725: loss = 0.12463
Step 180730: loss = 0.02356
Step 180735: loss = 0.05280
Step 180740: loss = 0.05220
Step 180745: loss = 0.07708
Step 180750: loss = 0.07033
Step 180755: loss = 0.21127
Step 180760: loss = 0.17447
Step 180765: loss = 0.03336
Step 180770: loss = 0.09955
Step 180775: loss = 0.19680
Step 180780: loss = 0.06394
Step 180785: loss = 0.09453
Step 180790: loss = 0.07028
Step 180795: loss = 0.11429
Step 180800: loss = 0.12276
Step 180805: loss = 0.06100
Step 180810: loss = 0.05349
Step 180815: loss = 0.05300
Step 180820: loss = 0.04754
Step 180825: loss = 0.05274
Step 180830: loss = 0.06601
Step 180835: loss = 0.12060
Step 180840: loss = 0.27649
Step 180845: loss = 0.02494
Step 180850: loss = 0.02306
Step 180855: loss = 0.06184
Step 180860: loss = 0.10692
Step 180865: loss = 0.18224
Step 180870: loss = 0.15864
Step 180875: loss = 0.17773
Step 180880: loss = 0.15555
Step 180885: loss = 0.10939
Step 180890: loss = 0.58685
Step 180895: loss = 0.10887
Step 180900: loss = 0.12778
Step 180905: loss = 0.05952
Step 180910: loss = 0.03823
Step 180915: loss = 0.18379
Step 180920: loss = 0.28407
Step 180925: loss = 0.06497
Step 180930: loss = 0.03064
Step 180935: loss = 0.11374
Step 180940: loss = 0.19331
Step 180945: loss = 0.07280
Step 180950: loss = 0.06552
Step 180955: loss = 0.27714
Step 180960: loss = 0.04792
Step 180965: loss = 0.10988
Step 180970: loss = 0.07511
Step 180975: loss = 0.25935
Step 180980: loss = 0.04817
Step 180985: loss = 0.02690
Step 180990: loss = 0.23021
Step 180995: loss = 0.08767
Step 181000: loss = 0.02540
Training Data Eval:
  Num examples: 50000, Num correct: 48091, Precision @ 1: 0.9618
('Testing Data Eval: EPOCH->', 182)
  Num examples: 10000, Num correct: 6710, Precision @ 1: 0.6710
Step 181005: loss = 0.10402
Step 181010: loss = 0.09553
Step 181015: loss = 0.04245
Step 181020: loss = 0.04364
Step 181025: loss = 0.02925
Step 181030: loss = 0.15566
Step 181035: loss = 0.09568
Step 181040: loss = 0.24686
Step 181045: loss = 0.15981
Step 181050: loss = 0.08573
Step 181055: loss = 0.09529
Step 181060: loss = 0.05816
Step 181065: loss = 0.07400
Step 181070: loss = 0.26461
Step 181075: loss = 0.18870
Step 181080: loss = 0.10694
Step 181085: loss = 0.11410
Step 181090: loss = 0.04368
Step 181095: loss = 0.15451
Step 181100: loss = 0.16651
Step 181105: loss = 0.26084
Step 181110: loss = 0.25156
Step 181115: loss = 0.06838
Step 181120: loss = 0.02588
Step 181125: loss = 0.02467
Step 181130: loss = 0.07128
Step 181135: loss = 0.03464
Step 181140: loss = 0.08803
Step 181145: loss = 0.10580
Step 181150: loss = 0.11015
Step 181155: loss = 0.07123
Step 181160: loss = 0.04873
Step 181165: loss = 0.19924
Step 181170: loss = 0.08140
Step 181175: loss = 0.03684
Step 181180: loss = 0.09949
Step 181185: loss = 0.08245
Step 181190: loss = 0.10560
Step 181195: loss = 0.12708
Step 181200: loss = 0.03713
Step 181205: loss = 0.14940
Step 181210: loss = 0.11299
Step 181215: loss = 0.16688
Step 181220: loss = 0.06605
Step 181225: loss = 0.11288
Step 181230: loss = 0.12683
Step 181235: loss = 0.17154
Step 181240: loss = 0.10537
Step 181245: loss = 0.07486
Step 181250: loss = 0.08606
Step 181255: loss = 0.18792
Step 181260: loss = 0.16370
Step 181265: loss = 0.25249
Step 181270: loss = 0.08026
Step 181275: loss = 0.09979
Step 181280: loss = 0.09554
Step 181285: loss = 0.10023
Step 181290: loss = 0.13282
Step 181295: loss = 0.06485
Step 181300: loss = 0.24107
Step 181305: loss = 0.34796
Step 181310: loss = 0.12447
Step 181315: loss = 0.10114
Step 181320: loss = 0.06373
Step 181325: loss = 0.04034
Step 181330: loss = 0.07028
Step 181335: loss = 0.06159
Step 181340: loss = 0.12391
Step 181345: loss = 0.17316
Step 181350: loss = 0.07416
Step 181355: loss = 0.08892
Step 181360: loss = 0.07629
Step 181365: loss = 0.13729
Step 181370: loss = 0.02239
Step 181375: loss = 0.04758
Step 181380: loss = 0.18251
Step 181385: loss = 0.13305
Step 181390: loss = 0.07134
Step 181395: loss = 0.18741
Step 181400: loss = 0.04358
Step 181405: loss = 0.05481
Step 181410: loss = 0.12508
Step 181415: loss = 0.12583
Step 181420: loss = 0.15039
Step 181425: loss = 0.06499
Step 181430: loss = 0.19452
Step 181435: loss = 0.13211
Step 181440: loss = 0.05454
Step 181445: loss = 0.04394
Step 181450: loss = 0.02056
Step 181455: loss = 0.04023
Step 181460: loss = 0.02847
Step 181465: loss = 0.10761
Step 181470: loss = 0.11893
Step 181475: loss = 0.12239
Step 181480: loss = 0.12412
Step 181485: loss = 0.03977
Step 181490: loss = 0.02830
Step 181495: loss = 0.25287
Step 181500: loss = 0.11616
Step 181505: loss = 0.20851
Step 181510: loss = 0.07046
Step 181515: loss = 0.09334
Step 181520: loss = 0.27224
Step 181525: loss = 0.07982
Step 181530: loss = 0.38840
Step 181535: loss = 0.16656
Step 181540: loss = 0.13737
Step 181545: loss = 0.10922
Step 181550: loss = 0.11042
Step 181555: loss = 0.11225
Step 181560: loss = 0.05369
Step 181565: loss = 0.19284
Step 181570: loss = 0.23913
Step 181575: loss = 0.14542
Step 181580: loss = 0.07144
Step 181585: loss = 0.09918
Step 181590: loss = 0.03018
Step 181595: loss = 0.05286
Step 181600: loss = 0.07395
Step 181605: loss = 0.15707
Step 181610: loss = 0.13105
Step 181615: loss = 0.16076
Step 181620: loss = 0.18534
Step 181625: loss = 0.14478
Step 181630: loss = 0.05327
Step 181635: loss = 0.21536
Step 181640: loss = 0.05092
Step 181645: loss = 0.08421
Step 181650: loss = 0.12720
Step 181655: loss = 0.07319
Step 181660: loss = 0.06302
Step 181665: loss = 0.08863
Step 181670: loss = 0.17069
Step 181675: loss = 0.34066
Step 181680: loss = 0.16793
Step 181685: loss = 0.20357
Step 181690: loss = 0.05466
Step 181695: loss = 0.05950
Step 181700: loss = 0.11391
Step 181705: loss = 0.19350
Step 181710: loss = 0.08615
Step 181715: loss = 0.08155
Step 181720: loss = 0.08436
Step 181725: loss = 0.08998
Step 181730: loss = 0.20188
Step 181735: loss = 0.02220
Step 181740: loss = 0.05513
Step 181745: loss = 0.29512
Step 181750: loss = 0.13225
Step 181755: loss = 0.04686
Step 181760: loss = 0.03125
Step 181765: loss = 0.02502
Step 181770: loss = 0.13444
Step 181775: loss = 0.07214
Step 181780: loss = 0.15028
Step 181785: loss = 0.07475
Step 181790: loss = 0.08875
Step 181795: loss = 0.01486
Step 181800: loss = 0.11218
Step 181805: loss = 0.05597
Step 181810: loss = 0.16522
Step 181815: loss = 0.07409
Step 181820: loss = 0.22458
Step 181825: loss = 0.03798
Step 181830: loss = 0.04897
Step 181835: loss = 0.12212
Step 181840: loss = 0.03020
Step 181845: loss = 0.11329
Step 181850: loss = 0.11989
Step 181855: loss = 0.10298
Step 181860: loss = 0.05071
Step 181865: loss = 0.01526
Step 181870: loss = 0.04567
Step 181875: loss = 0.15558
Step 181880: loss = 0.13333
Step 181885: loss = 0.09342
Step 181890: loss = 0.12869
Step 181895: loss = 0.05790
Step 181900: loss = 0.02813
Step 181905: loss = 0.05819
Step 181910: loss = 0.08329
Step 181915: loss = 0.09485
Step 181920: loss = 0.11133
Step 181925: loss = 0.03643
Step 181930: loss = 0.11736
Step 181935: loss = 0.12823
Step 181940: loss = 0.06670
Step 181945: loss = 0.10642
Step 181950: loss = 0.06366
Step 181955: loss = 0.11914
Step 181960: loss = 0.09317
Step 181965: loss = 0.12397
Step 181970: loss = 0.09153
Step 181975: loss = 0.24600
Step 181980: loss = 0.14801
Step 181985: loss = 0.22977
Step 181990: loss = 0.14353
Step 181995: loss = 0.16783
Step 182000: loss = 0.07078
Training Data Eval:
  Num examples: 50000, Num correct: 48028, Precision @ 1: 0.9606
('Testing Data Eval: EPOCH->', 183)
  Num examples: 10000, Num correct: 6712, Precision @ 1: 0.6712
Step 182005: loss = 0.08371
Step 182010: loss = 0.05880
Step 182015: loss = 0.16717
Step 182020: loss = 0.21817
Step 182025: loss = 0.25040
Step 182030: loss = 0.25898
Step 182035: loss = 0.27969
Step 182040: loss = 0.02573
Step 182045: loss = 0.07441
Step 182050: loss = 0.21292
Step 182055: loss = 0.08783
Step 182060: loss = 0.03008
Step 182065: loss = 0.15143
Step 182070: loss = 0.06609
Step 182075: loss = 0.10858
Step 182080: loss = 0.14585
Step 182085: loss = 0.10645
Step 182090: loss = 0.35874
Step 182095: loss = 0.06974
Step 182100: loss = 0.22107
Step 182105: loss = 0.11997
Step 182110: loss = 0.14170
Step 182115: loss = 0.04084
Step 182120: loss = 0.08422
Step 182125: loss = 0.03310
Step 182130: loss = 0.12490
Step 182135: loss = 0.00957
Step 182140: loss = 0.31210
Step 182145: loss = 0.06658
Step 182150: loss = 0.09653
Step 182155: loss = 0.06316
Step 182160: loss = 0.08715
Step 182165: loss = 0.07976
Step 182170: loss = 0.13630
Step 182175: loss = 0.06402
Step 182180: loss = 0.17224
Step 182185: loss = 0.04453
Step 182190: loss = 0.04692
Step 182195: loss = 0.11186
Step 182200: loss = 0.19893
Step 182205: loss = 0.07490
Step 182210: loss = 0.05975
Step 182215: loss = 0.04872
Step 182220: loss = 0.10272
Step 182225: loss = 0.29713
Step 182230: loss = 0.11892
Step 182235: loss = 0.07918
Step 182240: loss = 0.14763
Step 182245: loss = 0.14939
Step 182250: loss = 0.07775
Step 182255: loss = 0.13273
Step 182260: loss = 0.26098
Step 182265: loss = 0.12427
Step 182270: loss = 0.03009
Step 182275: loss = 0.11652
Step 182280: loss = 0.02266
Step 182285: loss = 0.17239
Step 182290: loss = 0.08429
Step 182295: loss = 0.05395
Step 182300: loss = 0.18095
Step 182305: loss = 0.32406
Step 182310: loss = 0.12140
Step 182315: loss = 0.04303
Step 182320: loss = 0.08843
Step 182325: loss = 0.05235
Step 182330: loss = 0.05935
Step 182335: loss = 0.05361
Step 182340: loss = 0.26707
Step 182345: loss = 0.16818
Step 182350: loss = 0.04378
Step 182355: loss = 0.05148
Step 182360: loss = 0.20825
Step 182365: loss = 0.06038
Step 182370: loss = 0.16824
Step 182375: loss = 0.13845
Step 182380: loss = 0.13012
Step 182385: loss = 0.08261
Step 182390: loss = 0.07423
Step 182395: loss = 0.09093
Step 182400: loss = 0.14309
Step 182405: loss = 0.14454
Step 182410: loss = 0.05049
Step 182415: loss = 0.03070
Step 182420: loss = 0.09809
Step 182425: loss = 0.18629
Step 182430: loss = 0.06439
Step 182435: loss = 0.06648
Step 182440: loss = 0.15961
Step 182445: loss = 0.18696
Step 182450: loss = 0.04263
Step 182455: loss = 0.06511
Step 182460: loss = 0.06101
Step 182465: loss = 0.03922
Step 182470: loss = 0.03902
Step 182475: loss = 0.03201
Step 182480: loss = 0.22336
Step 182485: loss = 0.01844
Step 182490: loss = 0.07549
Step 182495: loss = 0.28090
Step 182500: loss = 0.06781
Step 182505: loss = 0.16514
Step 182510: loss = 0.13486
Step 182515: loss = 0.20347
Step 182520: loss = 0.09414
Step 182525: loss = 0.06287
Step 182530: loss = 0.02182
Step 182535: loss = 0.06096
Step 182540: loss = 0.01150
Step 182545: loss = 0.06403
Step 182550: loss = 0.06289
Step 182555: loss = 0.17473
Step 182560: loss = 0.13815
Step 182565: loss = 0.04610
Step 182570: loss = 0.05062
Step 182575: loss = 0.02925
Step 182580: loss = 0.10621
Step 182585: loss = 0.06049
Step 182590: loss = 0.08546
Step 182595: loss = 0.12909
Step 182600: loss = 0.10971
Step 182605: loss = 0.09888
Step 182610: loss = 0.19899
Step 182615: loss = 0.06427
Step 182620: loss = 0.09085
Step 182625: loss = 0.04887
Step 182630: loss = 0.06140
Step 182635: loss = 0.17900
Step 182640: loss = 0.24643
Step 182645: loss = 0.11855
Step 182650: loss = 0.11312
Step 182655: loss = 0.13078
Step 182660: loss = 0.09797
Step 182665: loss = 0.01784
Step 182670: loss = 0.05303
Step 182675: loss = 0.09426
Step 182680: loss = 0.11237
Step 182685: loss = 0.16111
Step 182690: loss = 0.08576
Step 182695: loss = 0.11260
Step 182700: loss = 0.02939
Step 182705: loss = 0.14013
Step 182710: loss = 0.17998
Step 182715: loss = 0.05304
Step 182720: loss = 0.45195
Step 182725: loss = 0.07606
Step 182730: loss = 0.04080
Step 182735: loss = 0.04391
Step 182740: loss = 0.13472
Step 182745: loss = 0.46496
Step 182750: loss = 0.14757
Step 182755: loss = 0.12042
Step 182760: loss = 0.12311
Step 182765: loss = 0.12428
Step 182770: loss = 0.17905
Step 182775: loss = 0.11544
Step 182780: loss = 0.06563
Step 182785: loss = 0.04851
Step 182790: loss = 0.04993
Step 182795: loss = 0.06405
Step 182800: loss = 0.18093
Step 182805: loss = 0.11640
Step 182810: loss = 0.09157
Step 182815: loss = 0.04672
Step 182820: loss = 0.05011
Step 182825: loss = 0.11439
Step 182830: loss = 0.17784
Step 182835: loss = 0.27859
Step 182840: loss = 0.17263
Step 182845: loss = 0.04746
Step 182850: loss = 0.07817
Step 182855: loss = 0.27513
Step 182860: loss = 0.08799
Step 182865: loss = 0.07934
Step 182870: loss = 0.14622
Step 182875: loss = 0.17781
Step 182880: loss = 0.10633
Step 182885: loss = 0.14961
Step 182890: loss = 0.15719
Step 182895: loss = 0.07020
Step 182900: loss = 0.11766
Step 182905: loss = 0.06888
Step 182910: loss = 0.09340
Step 182915: loss = 0.06996
Step 182920: loss = 0.06640
Step 182925: loss = 0.08052
Step 182930: loss = 0.15066
Step 182935: loss = 0.13692
Step 182940: loss = 0.18902
Step 182945: loss = 0.04709
Step 182950: loss = 0.12055
Step 182955: loss = 0.17613
Step 182960: loss = 0.06530
Step 182965: loss = 0.32216
Step 182970: loss = 0.06325
Step 182975: loss = 0.03936
Step 182980: loss = 0.05677
Step 182985: loss = 0.09936
Step 182990: loss = 0.10268
Step 182995: loss = 0.04028
Step 183000: loss = 0.10220
Training Data Eval:
  Num examples: 50000, Num correct: 48037, Precision @ 1: 0.9607
('Testing Data Eval: EPOCH->', 184)
  Num examples: 10000, Num correct: 6696, Precision @ 1: 0.6696
Step 183005: loss = 0.04055
Step 183010: loss = 0.10599
Step 183015: loss = 0.10642
Step 183020: loss = 0.08013
Step 183025: loss = 0.08403
Step 183030: loss = 0.34273
Step 183035: loss = 0.07703
Step 183040: loss = 0.15522
Step 183045: loss = 0.12992
Step 183050: loss = 0.12737
Step 183055: loss = 0.21868
Step 183060: loss = 0.01513
Step 183065: loss = 0.13482
Step 183070: loss = 0.26248
Step 183075: loss = 0.10698
Step 183080: loss = 0.14762
Step 183085: loss = 0.06644
Step 183090: loss = 0.10110
Step 183095: loss = 0.13024
Step 183100: loss = 0.17142
Step 183105: loss = 0.04883
Step 183110: loss = 0.16761
Step 183115: loss = 0.03139
Step 183120: loss = 0.11995
Step 183125: loss = 0.05589
Step 183130: loss = 0.15088
Step 183135: loss = 0.32593
Step 183140: loss = 0.09517
Step 183145: loss = 0.10651
Step 183150: loss = 0.19012
Step 183155: loss = 0.04276
Step 183160: loss = 0.20969
Step 183165: loss = 0.03480
Step 183170: loss = 0.06080
Step 183175: loss = 0.29106
Step 183180: loss = 0.14093
Step 183185: loss = 0.06440
Step 183190: loss = 0.06240
Step 183195: loss = 0.04287
Step 183200: loss = 0.08548
Step 183205: loss = 0.09162
Step 183210: loss = 0.29144
Step 183215: loss = 0.22878
Step 183220: loss = 0.08598
Step 183225: loss = 0.07026
Step 183230: loss = 0.03650
Step 183235: loss = 0.22854
Step 183240: loss = 0.03859
Step 183245: loss = 0.06660
Step 183250: loss = 0.14125
Step 183255: loss = 0.04951
Step 183260: loss = 0.03684
Step 183265: loss = 0.02516
Step 183270: loss = 0.02840
Step 183275: loss = 0.11325
Step 183280: loss = 0.01873
Step 183285: loss = 0.10732
Step 183290: loss = 0.13169
Step 183295: loss = 0.03538
Step 183300: loss = 0.07603
Step 183305: loss = 0.06186
Step 183310: loss = 0.15305
Step 183315: loss = 0.11645
Step 183320: loss = 0.11440
Step 183325: loss = 0.08449
Step 183330: loss = 0.10027
Step 183335: loss = 0.03416
Step 183340: loss = 0.18512
Step 183345: loss = 0.01957
Step 183350: loss = 0.09596
Step 183355: loss = 0.06866
Step 183360: loss = 0.08479
Step 183365: loss = 0.06973
Step 183370: loss = 0.08986
Step 183375: loss = 0.09105
Step 183380: loss = 0.32548
Step 183385: loss = 0.20976
Step 183390: loss = 0.12430
Step 183395: loss = 0.12078
Step 183400: loss = 0.04051
Step 183405: loss = 0.07676
Step 183410: loss = 0.04521
Step 183415: loss = 0.04757
Step 183420: loss = 0.05876
Step 183425: loss = 0.05524
Step 183430: loss = 0.11382
Step 183435: loss = 0.13180
Step 183440: loss = 0.10920
Step 183445: loss = 0.33557
Step 183450: loss = 0.12082
Step 183455: loss = 0.08212
Step 183460: loss = 0.16663
Step 183465: loss = 0.22495
Step 183470: loss = 0.05415
Step 183475: loss = 0.06903
Step 183480: loss = 0.02365
Step 183485: loss = 0.47625
Step 183490: loss = 0.07343
Step 183495: loss = 0.11326
Step 183500: loss = 0.09695
Step 183505: loss = 0.16840
Step 183510: loss = 0.04179
Step 183515: loss = 0.07973
Step 183520: loss = 0.05077
Step 183525: loss = 0.06353
Step 183530: loss = 0.06482
Step 183535: loss = 0.06971
Step 183540: loss = 0.02133
Step 183545: loss = 0.04376
Step 183550: loss = 0.12667
Step 183555: loss = 0.10886
Step 183560: loss = 0.26499
Step 183565: loss = 0.15996
Step 183570: loss = 0.10702
Step 183575: loss = 0.04966
Step 183580: loss = 0.01120
Step 183585: loss = 0.13235
Step 183590: loss = 0.05626
Step 183595: loss = 0.04612
Step 183600: loss = 0.08634
Step 183605: loss = 0.04251
Step 183610: loss = 0.04674
Step 183615: loss = 0.30187
Step 183620: loss = 0.12598
Step 183625: loss = 0.19695
Step 183630: loss = 0.16380
Step 183635: loss = 0.11743
Step 183640: loss = 0.08435
Step 183645: loss = 0.06637
Step 183650: loss = 0.07717
Step 183655: loss = 0.24710
Step 183660: loss = 0.01802
Step 183665: loss = 0.07171
Step 183670: loss = 0.02519
Step 183675: loss = 0.07037
Step 183680: loss = 0.05541
Step 183685: loss = 0.30738
Step 183690: loss = 0.25108
Step 183695: loss = 0.06762
Step 183700: loss = 0.03594
Step 183705: loss = 0.09103
Step 183710: loss = 0.14541
Step 183715: loss = 0.11037
Step 183720: loss = 0.42259
Step 183725: loss = 0.33264
Step 183730: loss = 0.08870
Step 183735: loss = 0.14925
Step 183740: loss = 0.02306
Step 183745: loss = 0.03919
Step 183750: loss = 0.04861
Step 183755: loss = 0.02355
Step 183760: loss = 0.12677
Step 183765: loss = 0.03092
Step 183770: loss = 0.16935
Step 183775: loss = 0.12961
Step 183780: loss = 0.10411
Step 183785: loss = 0.07630
Step 183790: loss = 0.05863
Step 183795: loss = 0.02123
Step 183800: loss = 0.04508
Step 183805: loss = 0.05980
Step 183810: loss = 0.18347
Step 183815: loss = 0.05749
Step 183820: loss = 0.06346
Step 183825: loss = 0.05204
Step 183830: loss = 0.06708
Step 183835: loss = 0.21427
Step 183840: loss = 0.06362
Step 183845: loss = 0.14083
Step 183850: loss = 0.08090
Step 183855: loss = 0.10643
Step 183860: loss = 0.31729
Step 183865: loss = 0.28915
Step 183870: loss = 0.12078
Step 183875: loss = 0.16283
Step 183880: loss = 0.18967
Step 183885: loss = 0.21844
Step 183890: loss = 0.04889
Step 183895: loss = 0.17936
Step 183900: loss = 0.03606
Step 183905: loss = 0.07363
Step 183910: loss = 0.07023
Step 183915: loss = 0.07290
Step 183920: loss = 0.12739
Step 183925: loss = 0.17013
Step 183930: loss = 0.09558
Step 183935: loss = 0.11537
Step 183940: loss = 0.08294
Step 183945: loss = 0.11666
Step 183950: loss = 0.05917
Step 183955: loss = 0.24621
Step 183960: loss = 0.05043
Step 183965: loss = 0.08943
Step 183970: loss = 0.02716
Step 183975: loss = 0.09608
Step 183980: loss = 0.02885
Step 183985: loss = 0.02296
Step 183990: loss = 0.08411
Step 183995: loss = 0.12386
Step 184000: loss = 0.14252
Training Data Eval:
  Num examples: 50000, Num correct: 48282, Precision @ 1: 0.9656
('Testing Data Eval: EPOCH->', 185)
  Num examples: 10000, Num correct: 6766, Precision @ 1: 0.6766
Step 184005: loss = 0.09455
Step 184010: loss = 0.07609
Step 184015: loss = 0.06870
Step 184020: loss = 0.10388
Step 184025: loss = 0.16756
Step 184030: loss = 0.27609
Step 184035: loss = 0.09978
Step 184040: loss = 0.21341
Step 184045: loss = 0.10210
Step 184050: loss = 0.09111
Step 184055: loss = 0.05845
Step 184060: loss = 0.24431
Step 184065: loss = 0.05833
Step 184070: loss = 0.10021
Step 184075: loss = 0.03663
Step 184080: loss = 0.05538
Step 184085: loss = 0.04087
Step 184090: loss = 0.07906
Step 184095: loss = 0.15020
Step 184100: loss = 0.04292
Step 184105: loss = 0.14207
Step 184110: loss = 0.04880
Step 184115: loss = 0.09610
Step 184120: loss = 0.04022
Step 184125: loss = 0.18084
Step 184130: loss = 0.19459
Step 184135: loss = 0.04649
Step 184140: loss = 0.11972
Step 184145: loss = 0.11915
Step 184150: loss = 0.09453
Step 184155: loss = 0.07030
Step 184160: loss = 0.09034
Step 184165: loss = 0.05267
Step 184170: loss = 0.13681
Step 184175: loss = 0.07630
Step 184180: loss = 0.25545
Step 184185: loss = 0.05759
Step 184190: loss = 0.06135
Step 184195: loss = 0.03362
Step 184200: loss = 0.10732
Step 184205: loss = 0.27164
Step 184210: loss = 0.06135
Step 184215: loss = 0.15361
Step 184220: loss = 0.12489
Step 184225: loss = 0.01686
Step 184230: loss = 0.04858
Step 184235: loss = 0.16407
Step 184240: loss = 0.24531
Step 184245: loss = 0.06782
Step 184250: loss = 0.21191
Step 184255: loss = 0.13073
Step 184260: loss = 0.10073
Step 184265: loss = 0.02774
Step 184270: loss = 0.10323
Step 184275: loss = 0.04138
Step 184280: loss = 0.15307
Step 184285: loss = 0.06606
Step 184290: loss = 0.09616
Step 184295: loss = 0.12538
Step 184300: loss = 0.30011
Step 184305: loss = 0.11504
Step 184310: loss = 0.07524
Step 184315: loss = 0.24447
Step 184320: loss = 0.15688
Step 184325: loss = 0.04284
Step 184330: loss = 0.07620
Step 184335: loss = 0.03765
Step 184340: loss = 0.07238
Step 184345: loss = 0.16879
Step 184350: loss = 0.05403
Step 184355: loss = 0.14056
Step 184360: loss = 0.07973
Step 184365: loss = 0.04036
Step 184370: loss = 0.13432
Step 184375: loss = 0.07941
Step 184380: loss = 0.04728
Step 184385: loss = 0.04412
Step 184390: loss = 0.08938
Step 184395: loss = 0.17803
Step 184400: loss = 0.24942
Step 184405: loss = 0.12223
Step 184410: loss = 0.08596
Step 184415: loss = 0.01723
Step 184420: loss = 0.10968
Step 184425: loss = 0.03150
Step 184430: loss = 0.05501
Step 184435: loss = 0.06234
Step 184440: loss = 0.07947
Step 184445: loss = 0.10770
Step 184450: loss = 0.04974
Step 184455: loss = 0.05611
Step 184460: loss = 0.05949
Step 184465: loss = 0.02761
Step 184470: loss = 0.05472
Step 184475: loss = 0.06643
Step 184480: loss = 0.29114
Step 184485: loss = 0.37464
Step 184490: loss = 0.06122
Step 184495: loss = 0.01597
Step 184500: loss = 0.13713
Step 184505: loss = 0.16512
Step 184510: loss = 0.17405
Step 184515: loss = 0.04547
Step 184520: loss = 0.47569
Step 184525: loss = 0.09569
Step 184530: loss = 0.05934
Step 184535: loss = 0.07057
Step 184540: loss = 0.05889
Step 184545: loss = 0.17041
Step 184550: loss = 0.08709
Step 184555: loss = 0.06989
Step 184560: loss = 0.03281
Step 184565: loss = 0.04304
Step 184570: loss = 0.09321
Step 184575: loss = 0.03722
Step 184580: loss = 0.05716
Step 184585: loss = 0.24892
Step 184590: loss = 0.09962
Step 184595: loss = 0.08643
Step 184600: loss = 0.05333
Step 184605: loss = 0.18454
Step 184610: loss = 0.02545
Step 184615: loss = 0.08634
Step 184620: loss = 0.08761
Step 184625: loss = 0.04913
Step 184630: loss = 0.08934
Step 184635: loss = 0.09958
Step 184640: loss = 0.11478
Step 184645: loss = 0.05392
Step 184650: loss = 0.00882
Step 184655: loss = 0.10551
Step 184660: loss = 0.06240
Step 184665: loss = 0.19299
Step 184670: loss = 0.08170
Step 184675: loss = 0.12887
Step 184680: loss = 0.08570
Step 184685: loss = 0.06558
Step 184690: loss = 0.09509
Step 184695: loss = 0.08856
Step 184700: loss = 0.01682
Step 184705: loss = 0.09025
Step 184710: loss = 0.05664
Step 184715: loss = 0.06758
Step 184720: loss = 0.11219
Step 184725: loss = 0.23729
Step 184730: loss = 0.13303
Step 184735: loss = 0.09987
Step 184740: loss = 0.13889
Step 184745: loss = 0.09506
Step 184750: loss = 0.20448
Step 184755: loss = 0.09279
Step 184760: loss = 0.10324
Step 184765: loss = 0.09140
Step 184770: loss = 0.03266
Step 184775: loss = 0.20918
Step 184780: loss = 0.05009
Step 184785: loss = 0.08389
Step 184790: loss = 0.08576
Step 184795: loss = 0.14574
Step 184800: loss = 0.08703
Step 184805: loss = 0.19258
Step 184810: loss = 0.14732
Step 184815: loss = 0.03754
Step 184820: loss = 0.04082
Step 184825: loss = 0.08305
Step 184830: loss = 0.10116
Step 184835: loss = 0.15420
Step 184840: loss = 0.16626
Step 184845: loss = 0.25134
Step 184850: loss = 0.08245
Step 184855: loss = 0.07043
Step 184860: loss = 0.20000
Step 184865: loss = 0.07190
Step 184870: loss = 0.16827
Step 184875: loss = 0.02976
Step 184880: loss = 0.09090
Step 184885: loss = 0.02315
Step 184890: loss = 0.05921
Step 184895: loss = 0.21000
Step 184900: loss = 0.04672
Step 184905: loss = 0.03600
Step 184910: loss = 0.04301
Step 184915: loss = 0.08574
Step 184920: loss = 0.04550
Step 184925: loss = 0.09088
Step 184930: loss = 0.12644
Step 184935: loss = 0.40365
Step 184940: loss = 0.06168
Step 184945: loss = 0.04224
Step 184950: loss = 0.02680
Step 184955: loss = 0.07972
Step 184960: loss = 0.05502
Step 184965: loss = 0.02863
Step 184970: loss = 0.20820
Step 184975: loss = 0.32946
Step 184980: loss = 0.12002
Step 184985: loss = 0.03663
Step 184990: loss = 0.04105
Step 184995: loss = 0.02909
Step 185000: loss = 0.24384
Training Data Eval:
  Num examples: 50000, Num correct: 48112, Precision @ 1: 0.9622
('Testing Data Eval: EPOCH->', 186)
  Num examples: 10000, Num correct: 6690, Precision @ 1: 0.6690
Step 185005: loss = 0.17091
Step 185010: loss = 0.05839
Step 185015: loss = 0.03966
Step 185020: loss = 0.17720
Step 185025: loss = 0.08680
Step 185030: loss = 0.11730
Step 185035: loss = 0.20937
Step 185040: loss = 0.03017
Step 185045: loss = 0.09294
Step 185050: loss = 0.05969
Step 185055: loss = 0.19147
Step 185060: loss = 0.05082
Step 185065: loss = 0.11871
Step 185070: loss = 0.03821
Step 185075: loss = 0.12143
Step 185080: loss = 0.14228
Step 185085: loss = 0.01953
Step 185090: loss = 0.12280
Step 185095: loss = 0.16680
Step 185100: loss = 0.12342
Step 185105: loss = 0.17345
Step 185110: loss = 0.05425
Step 185115: loss = 0.11003
Step 185120: loss = 0.09949
Step 185125: loss = 0.06419
Step 185130: loss = 0.18226
Step 185135: loss = 0.07337
Step 185140: loss = 0.06389
Step 185145: loss = 0.08633
Step 185150: loss = 0.02183
Step 185155: loss = 0.10174
Step 185160: loss = 0.08952
Step 185165: loss = 0.14804
Step 185170: loss = 0.14687
Step 185175: loss = 0.13994
Step 185180: loss = 0.14320
Step 185185: loss = 0.16155
Step 185190: loss = 0.31866
Step 185195: loss = 0.02982
Step 185200: loss = 0.11185
Step 185205: loss = 0.26420
Step 185210: loss = 0.20970
Step 185215: loss = 0.17661
Step 185220: loss = 0.06289
Step 185225: loss = 0.05329
Step 185230: loss = 0.26063
Step 185235: loss = 0.09597
Step 185240: loss = 0.16855
Step 185245: loss = 0.08690
Step 185250: loss = 0.06320
Step 185255: loss = 0.05180
Step 185260: loss = 0.05501
Step 185265: loss = 0.12302
Step 185270: loss = 0.06288
Step 185275: loss = 0.17573
Step 185280: loss = 0.04725
Step 185285: loss = 0.12208
Step 185290: loss = 0.07319
Step 185295: loss = 0.18483
Step 185300: loss = 0.03335
Step 185305: loss = 0.03073
Step 185310: loss = 0.14859
Step 185315: loss = 0.17295
Step 185320: loss = 0.12611
Step 185325: loss = 0.05013
Step 185330: loss = 0.02415
Step 185335: loss = 0.09804
Step 185340: loss = 0.18161
Step 185345: loss = 0.20438
Step 185350: loss = 0.04944
Step 185355: loss = 0.22270
Step 185360: loss = 0.06133
Step 185365: loss = 0.24627
Step 185370: loss = 0.03016
Step 185375: loss = 0.03405
Step 185380: loss = 0.06162
Step 185385: loss = 0.06580
Step 185390: loss = 0.16881
Step 185395: loss = 0.06842
Step 185400: loss = 0.06258
Step 185405: loss = 0.06942
Step 185410: loss = 0.03362
Step 185415: loss = 0.09964
Step 185420: loss = 0.03782
Step 185425: loss = 0.09533
Step 185430: loss = 0.08130
Step 185435: loss = 0.15074
Step 185440: loss = 0.06950
Step 185445: loss = 0.12474
Step 185450: loss = 0.06765
Step 185455: loss = 0.14282
Step 185460: loss = 0.09209
Step 185465: loss = 0.03703
Step 185470: loss = 0.05795
Step 185475: loss = 0.06304
Step 185480: loss = 0.05219
Step 185485: loss = 0.07671
Step 185490: loss = 0.12665
Step 185495: loss = 0.16028
Step 185500: loss = 0.05570
Step 185505: loss = 0.04383
Step 185510: loss = 0.10372
Step 185515: loss = 0.06374
Step 185520: loss = 0.09478
Step 185525: loss = 0.06734
Step 185530: loss = 0.14709
Step 185535: loss = 0.11179
Step 185540: loss = 0.02697
Step 185545: loss = 0.12380
Step 185550: loss = 0.20685
Step 185555: loss = 0.47734
Step 185560: loss = 0.17745
Step 185565: loss = 0.06560
Step 185570: loss = 0.08577
Step 185575: loss = 0.16848
Step 185580: loss = 0.01450
Step 185585: loss = 0.12736
Step 185590: loss = 0.07536
Step 185595: loss = 0.10345
Step 185600: loss = 0.10594
Step 185605: loss = 0.03902
Step 185610: loss = 0.10779
Step 185615: loss = 0.06295
Step 185620: loss = 0.03873
Step 185625: loss = 0.06933
Step 185630: loss = 0.13862
Step 185635: loss = 0.17024
Step 185640: loss = 0.09123
Step 185645: loss = 0.10841
Step 185650: loss = 0.29805
Step 185655: loss = 0.01801
Step 185660: loss = 0.05606
Step 185665: loss = 0.04922
Step 185670: loss = 0.15910
Step 185675: loss = 0.11752
Step 185680: loss = 0.05670
Step 185685: loss = 0.11790
Step 185690: loss = 0.04608
Step 185695: loss = 0.05811
Step 185700: loss = 0.09401
Step 185705: loss = 0.14429
Step 185710: loss = 0.22737
Step 185715: loss = 0.03079
Step 185720: loss = 0.14720
Step 185725: loss = 0.08244
Step 185730: loss = 0.32083
Step 185735: loss = 0.03918
Step 185740: loss = 0.26687
Step 185745: loss = 0.04874
Step 185750: loss = 0.06545
Step 185755: loss = 0.04179
Step 185760: loss = 0.13104
Step 185765: loss = 0.03127
Step 185770: loss = 0.11312
Step 185775: loss = 0.06844
Step 185780: loss = 0.22077
Step 185785: loss = 0.05124
Step 185790: loss = 0.15065
Step 185795: loss = 0.04844
Step 185800: loss = 0.12056
Step 185805: loss = 0.39334
Step 185810: loss = 0.10713
Step 185815: loss = 0.12127
Step 185820: loss = 0.05910
Step 185825: loss = 0.13241
Step 185830: loss = 0.04071
Step 185835: loss = 0.13612
Step 185840: loss = 0.03564
Step 185845: loss = 0.08966
Step 185850: loss = 0.06051
Step 185855: loss = 0.14478
Step 185860: loss = 0.05178
Step 185865: loss = 0.07737
Step 185870: loss = 0.10143
Step 185875: loss = 0.06836
Step 185880: loss = 0.11749
Step 185885: loss = 0.03842
Step 185890: loss = 0.04005
Step 185895: loss = 0.05869
Step 185900: loss = 0.20069
Step 185905: loss = 0.08246
Step 185910: loss = 0.12641
Step 185915: loss = 0.12229
Step 185920: loss = 0.13503
Step 185925: loss = 0.04453
Step 185930: loss = 0.03128
Step 185935: loss = 0.10946
Step 185940: loss = 0.06316
Step 185945: loss = 0.16197
Step 185950: loss = 0.03191
Step 185955: loss = 0.05317
Step 185960: loss = 0.11445
Step 185965: loss = 0.15536
Step 185970: loss = 0.05936
Step 185975: loss = 0.07659
Step 185980: loss = 0.01758
Step 185985: loss = 0.03769
Step 185990: loss = 0.30223
Step 185995: loss = 0.15988
Step 186000: loss = 0.16457
Training Data Eval:
  Num examples: 50000, Num correct: 48277, Precision @ 1: 0.9655
('Testing Data Eval: EPOCH->', 187)
  Num examples: 10000, Num correct: 6792, Precision @ 1: 0.6792
Step 186005: loss = 0.06638
Step 186010: loss = 0.06389
Step 186015: loss = 0.09383
Step 186020: loss = 0.03686
Step 186025: loss = 0.03623
Step 186030: loss = 0.18878
Step 186035: loss = 0.29838
Step 186040: loss = 0.04256
Step 186045: loss = 0.14111
Step 186050: loss = 0.01495
Step 186055: loss = 0.08304
Step 186060: loss = 0.09364
Step 186065: loss = 0.06447
Step 186070: loss = 0.06117
Step 186075: loss = 0.15418
Step 186080: loss = 0.04910
Step 186085: loss = 0.01926
Step 186090: loss = 0.04350
Step 186095: loss = 0.10169
Step 186100: loss = 0.05625
Step 186105: loss = 0.01663
Step 186110: loss = 0.02912
Step 186115: loss = 0.33727
Step 186120: loss = 0.11737
Step 186125: loss = 0.37818
Step 186130: loss = 0.10113
Step 186135: loss = 0.18834
Step 186140: loss = 0.22325
Step 186145: loss = 0.22575
Step 186150: loss = 0.05885
Step 186155: loss = 0.21690
Step 186160: loss = 0.09061
Step 186165: loss = 0.03868
Step 186170: loss = 0.05708
Step 186175: loss = 0.10134
Step 186180: loss = 0.02637
Step 186185: loss = 0.10944
Step 186190: loss = 0.04680
Step 186195: loss = 0.07290
Step 186200: loss = 0.13896
Step 186205: loss = 0.19203
Step 186210: loss = 0.05661
Step 186215: loss = 0.05450
Step 186220: loss = 0.01035
Step 186225: loss = 0.32519
Step 186230: loss = 0.02250
Step 186235: loss = 0.03590
Step 186240: loss = 0.07039
Step 186245: loss = 0.01972
Step 186250: loss = 0.11047
Step 186255: loss = 0.09004
Step 186260: loss = 0.05619
Step 186265: loss = 0.17340
Step 186270: loss = 0.08280
Step 186275: loss = 0.09811
Step 186280: loss = 0.18087
Step 186285: loss = 0.01976
Step 186290: loss = 0.06384
Step 186295: loss = 0.03039
Step 186300: loss = 0.09077
Step 186305: loss = 0.04516
Step 186310: loss = 0.05859
Step 186315: loss = 0.21518
Step 186320: loss = 0.04024
Step 186325: loss = 0.10493
Step 186330: loss = 0.07727
Step 186335: loss = 0.02461
Step 186340: loss = 0.05754
Step 186345: loss = 0.11816
Step 186350: loss = 0.06619
Step 186355: loss = 0.10323
Step 186360: loss = 0.15884
Step 186365: loss = 0.12324
Step 186370: loss = 0.04075
Step 186375: loss = 0.11514
Step 186380: loss = 0.09192
Step 186385: loss = 0.07289
Step 186390: loss = 0.15855
Step 186395: loss = 0.19899
Step 186400: loss = 0.06278
Step 186405: loss = 0.12853
Step 186410: loss = 0.25074
Step 186415: loss = 0.08288
Step 186420: loss = 0.09365
Step 186425: loss = 0.07982
Step 186430: loss = 0.22515
Step 186435: loss = 0.06039
Step 186440: loss = 0.09304
Step 186445: loss = 0.06275
Step 186450: loss = 0.12175
Step 186455: loss = 0.25613
Step 186460: loss = 0.24422
Step 186465: loss = 0.13680
Step 186470: loss = 0.14253
Step 186475: loss = 0.07606
Step 186480: loss = 0.10455
Step 186485: loss = 0.03840
Step 186490: loss = 0.09528
Step 186495: loss = 0.19010
Step 186500: loss = 0.07185
Step 186505: loss = 0.14215
Step 186510: loss = 0.03437
Step 186515: loss = 0.04407
Step 186520: loss = 0.04764
Step 186525: loss = 0.10836
Step 186530: loss = 0.16609
Step 186535: loss = 0.07954
Step 186540: loss = 0.09134
Step 186545: loss = 0.02933
Step 186550: loss = 0.04303
Step 186555: loss = 0.01662
Step 186560: loss = 0.19897
Step 186565: loss = 0.07633
Step 186570: loss = 0.10929
Step 186575: loss = 0.25034
Step 186580: loss = 0.24751
Step 186585: loss = 0.15266
Step 186590: loss = 0.49718
Step 186595: loss = 0.17789
Step 186600: loss = 0.13222
Step 186605: loss = 0.12396
Step 186610: loss = 0.04880
Step 186615: loss = 0.06983
Step 186620: loss = 0.05599
Step 186625: loss = 0.16469
Step 186630: loss = 0.25889
Step 186635: loss = 0.09272
Step 186640: loss = 0.12405
Step 186645: loss = 0.02837
Step 186650: loss = 0.04886
Step 186655: loss = 0.03399
Step 186660: loss = 0.20166
Step 186665: loss = 0.03158
Step 186670: loss = 0.11106
Step 186675: loss = 0.07552
Step 186680: loss = 0.10894
Step 186685: loss = 0.05991
Step 186690: loss = 0.09468
Step 186695: loss = 0.08869
Step 186700: loss = 0.07607
Step 186705: loss = 0.15302
Step 186710: loss = 0.10759
Step 186715: loss = 0.03855
Step 186720: loss = 0.10512
Step 186725: loss = 0.08998
Step 186730: loss = 0.05830
Step 186735: loss = 0.05602
Step 186740: loss = 0.08336
Step 186745: loss = 0.03345
Step 186750: loss = 0.06059
Step 186755: loss = 0.15234
Step 186760: loss = 0.12020
Step 186765: loss = 0.03099
Step 186770: loss = 0.04449
Step 186775: loss = 0.15790
Step 186780: loss = 0.13209
Step 186785: loss = 0.09691
Step 186790: loss = 0.08071
Step 186795: loss = 0.09572
Step 186800: loss = 0.10180
Step 186805: loss = 0.17902
Step 186810: loss = 0.25234
Step 186815: loss = 0.07183
Step 186820: loss = 0.13418
Step 186825: loss = 0.07551
Step 186830: loss = 0.11817
Step 186835: loss = 0.24468
Step 186840: loss = 0.17465
Step 186845: loss = 0.15185
Step 186850: loss = 0.13361
Step 186855: loss = 0.03438
Step 186860: loss = 0.09630
Step 186865: loss = 0.05902
Step 186870: loss = 0.06482
Step 186875: loss = 0.07569
Step 186880: loss = 0.02369
Step 186885: loss = 0.16429
Step 186890: loss = 0.20310
Step 186895: loss = 0.31635
Step 186900: loss = 0.07829
Step 186905: loss = 0.04735
Step 186910: loss = 0.04002
Step 186915: loss = 0.07877
Step 186920: loss = 0.07315
Step 186925: loss = 0.03122
Step 186930: loss = 0.16648
Step 186935: loss = 0.12312
Step 186940: loss = 0.13778
Step 186945: loss = 0.06715
Step 186950: loss = 0.09898
Step 186955: loss = 0.15448
Step 186960: loss = 0.05437
Step 186965: loss = 0.12636
Step 186970: loss = 0.08047
Step 186975: loss = 0.20808
Step 186980: loss = 0.13687
Step 186985: loss = 0.16107
Step 186990: loss = 0.03484
Step 186995: loss = 0.09035
Step 187000: loss = 0.10972
Training Data Eval:
  Num examples: 50000, Num correct: 48223, Precision @ 1: 0.9645
('Testing Data Eval: EPOCH->', 188)
  Num examples: 10000, Num correct: 6692, Precision @ 1: 0.6692
Step 187005: loss = 0.10951
Step 187010: loss = 0.09328
Step 187015: loss = 0.05972
Step 187020: loss = 0.25567
Step 187025: loss = 0.09298
Step 187030: loss = 0.03699
Step 187035: loss = 0.08236
Step 187040: loss = 0.06928
Step 187045: loss = 0.14647
Step 187050: loss = 0.04030
Step 187055: loss = 0.03292
Step 187060: loss = 0.30707
Step 187065: loss = 0.03864
Step 187070: loss = 0.10253
Step 187075: loss = 0.10100
Step 187080: loss = 0.15269
Step 187085: loss = 0.07781
Step 187090: loss = 0.10185
Step 187095: loss = 0.04844
Step 187100: loss = 0.08162
Step 187105: loss = 0.13244
Step 187110: loss = 0.05265
Step 187115: loss = 0.03192
Step 187120: loss = 0.13116
Step 187125: loss = 0.05800
Step 187130: loss = 0.12523
Step 187135: loss = 0.09492
Step 187140: loss = 0.04460
Step 187145: loss = 0.30845
Step 187150: loss = 0.11448
Step 187155: loss = 0.06320
Step 187160: loss = 0.10401
Step 187165: loss = 0.09134
Step 187170: loss = 0.25036
Step 187175: loss = 0.12488
Step 187180: loss = 0.13874
Step 187185: loss = 0.06586
Step 187190: loss = 0.04468
Step 187195: loss = 0.20296
Step 187200: loss = 0.10551
Step 187205: loss = 0.06012
Step 187210: loss = 0.10838
Step 187215: loss = 0.20314
Step 187220: loss = 0.11802
Step 187225: loss = 0.15174
Step 187230: loss = 0.14232
Step 187235: loss = 0.13184
Step 187240: loss = 0.10711
Step 187245: loss = 0.29396
Step 187250: loss = 0.04111
Step 187255: loss = 0.07768
Step 187260: loss = 0.06029
Step 187265: loss = 0.14075
Step 187270: loss = 0.18749
Step 187275: loss = 0.12064
Step 187280: loss = 0.05215
Step 187285: loss = 0.03104
Step 187290: loss = 0.19138
Step 187295: loss = 0.07889
Step 187300: loss = 0.08223
Step 187305: loss = 0.25874
Step 187310: loss = 0.23875
Step 187315: loss = 0.08522
Step 187320: loss = 0.09653
Step 187325: loss = 0.38696
Step 187330: loss = 0.08075
Step 187335: loss = 0.22403
Step 187340: loss = 0.16239
Step 187345: loss = 0.07020
Step 187350: loss = 0.05929
Step 187355: loss = 0.17436
Step 187360: loss = 0.08378
Step 187365: loss = 0.08370
Step 187370: loss = 0.05620
Step 187375: loss = 0.03678
Step 187380: loss = 0.10895
Step 187385: loss = 0.11268
Step 187390: loss = 0.02913
Step 187395: loss = 0.05149
Step 187400: loss = 0.24683
Step 187405: loss = 0.14841
Step 187410: loss = 0.11554
Step 187415: loss = 0.47610
Step 187420: loss = 0.06974
Step 187425: loss = 0.09116
Step 187430: loss = 0.04322
Step 187435: loss = 0.07468
Step 187440: loss = 0.21667
Step 187445: loss = 0.04156
Step 187450: loss = 0.18249
Step 187455: loss = 0.03617
Step 187460: loss = 0.11488
Step 187465: loss = 0.04932
Step 187470: loss = 0.07214
Step 187475: loss = 0.23376
Step 187480: loss = 0.05363
Step 187485: loss = 0.05799
Step 187490: loss = 0.07349
Step 187495: loss = 0.05390
Step 187500: loss = 0.08201
Step 187505: loss = 0.21216
Step 187510: loss = 0.12551
Step 187515: loss = 0.21819
Step 187520: loss = 0.06362
Step 187525: loss = 0.10124
Step 187530: loss = 0.06676
Step 187535: loss = 0.10171
Step 187540: loss = 0.14682
Step 187545: loss = 0.14066
Step 187550: loss = 0.06261
Step 187555: loss = 0.42107
Step 187560: loss = 0.20311
Step 187565: loss = 0.05827
Step 187570: loss = 0.12739
Step 187575: loss = 0.10617
Step 187580: loss = 0.04526
Step 187585: loss = 0.05108
Step 187590: loss = 0.08864
Step 187595: loss = 0.14587
Step 187600: loss = 0.10414
Step 187605: loss = 0.15655
Step 187610: loss = 0.19178
Step 187615: loss = 0.08111
Step 187620: loss = 0.09544
Step 187625: loss = 0.55859
Step 187630: loss = 0.10035
Step 187635: loss = 0.21287
Step 187640: loss = 0.07732
Step 187645: loss = 0.28808
Step 187650: loss = 0.23395
Step 187655: loss = 0.10581
Step 187660: loss = 0.12852
Step 187665: loss = 0.11949
Step 187670: loss = 0.21596
Step 187675: loss = 0.37074
Step 187680: loss = 0.06561
Step 187685: loss = 0.12468
Step 187690: loss = 0.07147
Step 187695: loss = 0.05937
Step 187700: loss = 0.26965
Step 187705: loss = 0.06909
Step 187710: loss = 0.14447
Step 187715: loss = 0.13604
Step 187720: loss = 0.10059
Step 187725: loss = 0.10527
Step 187730: loss = 0.04084
Step 187735: loss = 0.27878
Step 187740: loss = 0.11132
Step 187745: loss = 0.07426
Step 187750: loss = 0.20915
Step 187755: loss = 0.02986
Step 187760: loss = 0.03026
Step 187765: loss = 0.02333
Step 187770: loss = 0.28587
Step 187775: loss = 0.04825
Step 187780: loss = 0.03428
Step 187785: loss = 0.08534
Step 187790: loss = 0.19780
Step 187795: loss = 0.07275
Step 187800: loss = 0.04661
Step 187805: loss = 0.16804
Step 187810: loss = 0.04600
Step 187815: loss = 0.09933
Step 187820: loss = 0.09754
Step 187825: loss = 0.09012
Step 187830: loss = 0.06908
Step 187835: loss = 0.05342
Step 187840: loss = 0.22833
Step 187845: loss = 0.14110
Step 187850: loss = 0.11513
Step 187855: loss = 0.04903
Step 187860: loss = 0.16665
Step 187865: loss = 0.04856
Step 187870: loss = 0.15034
Step 187875: loss = 0.22968
Step 187880: loss = 0.06465
Step 187885: loss = 0.17786
Step 187890: loss = 0.05639
Step 187895: loss = 0.07285
Step 187900: loss = 0.15243
Step 187905: loss = 0.13783
Step 187910: loss = 0.17018
Step 187915: loss = 0.15576
Step 187920: loss = 0.04423
Step 187925: loss = 0.08454
Step 187930: loss = 0.03718
Step 187935: loss = 0.12270
Step 187940: loss = 0.16145
Step 187945: loss = 0.03071
Step 187950: loss = 0.16602
Step 187955: loss = 0.02972
Step 187960: loss = 0.06328
Step 187965: loss = 0.02653
Step 187970: loss = 0.04644
Step 187975: loss = 0.04074
Step 187980: loss = 0.05616
Step 187985: loss = 0.33871
Step 187990: loss = 0.05204
Step 187995: loss = 0.13002
Step 188000: loss = 0.13222
Training Data Eval:
  Num examples: 50000, Num correct: 48084, Precision @ 1: 0.9617
('Testing Data Eval: EPOCH->', 189)
  Num examples: 10000, Num correct: 6599, Precision @ 1: 0.6599
Step 188005: loss = 0.17399
Step 188010: loss = 0.02221
Step 188015: loss = 0.24234
Step 188020: loss = 0.13470
Step 188025: loss = 0.16316
Step 188030: loss = 0.06881
Step 188035: loss = 0.07529
Step 188040: loss = 0.07932
Step 188045: loss = 0.03561
Step 188050: loss = 0.23807
Step 188055: loss = 0.06889
Step 188060: loss = 0.07041
Step 188065: loss = 0.11090
Step 188070: loss = 0.17990
Step 188075: loss = 0.02661
Step 188080: loss = 0.09483
Step 188085: loss = 0.27168
Step 188090: loss = 0.13035
Step 188095: loss = 0.05147
Step 188100: loss = 0.13357
Step 188105: loss = 0.03270
Step 188110: loss = 0.18851
Step 188115: loss = 0.03579
Step 188120: loss = 0.07830
Step 188125: loss = 0.10911
Step 188130: loss = 0.10916
Step 188135: loss = 0.04841
Step 188140: loss = 0.11921
Step 188145: loss = 0.13314
Step 188150: loss = 0.14544
Step 188155: loss = 0.10927
Step 188160: loss = 0.22415
Step 188165: loss = 0.14292
Step 188170: loss = 0.11180
Step 188175: loss = 0.21779
Step 188180: loss = 0.04298
Step 188185: loss = 0.14743
Step 188190: loss = 0.11021
Step 188195: loss = 0.19035
Step 188200: loss = 0.05311
Step 188205: loss = 0.11018
Step 188210: loss = 0.05744
Step 188215: loss = 0.07752
Step 188220: loss = 0.05613
Step 188225: loss = 0.11520
Step 188230: loss = 0.08792
Step 188235: loss = 0.17271
Step 188240: loss = 0.21014
Step 188245: loss = 0.12485
Step 188250: loss = 0.25781
Step 188255: loss = 0.14157
Step 188260: loss = 0.22081
Step 188265: loss = 0.19783
Step 188270: loss = 0.12935
Step 188275: loss = 0.06060
Step 188280: loss = 0.04213
Step 188285: loss = 0.31235
Step 188290: loss = 0.03786
Step 188295: loss = 0.04052
Step 188300: loss = 0.03088
Step 188305: loss = 0.06822
Step 188310: loss = 0.06968
Step 188315: loss = 0.09226
Step 188320: loss = 0.07849
Step 188325: loss = 0.11993
Step 188330: loss = 0.09572
Step 188335: loss = 0.14220
Step 188340: loss = 0.18000
Step 188345: loss = 0.10769
Step 188350: loss = 0.08714
Step 188355: loss = 0.04248
Step 188360: loss = 0.03446
Step 188365: loss = 0.36936
Step 188370: loss = 0.06941
Step 188375: loss = 0.21282
Step 188380: loss = 0.20064
Step 188385: loss = 0.03952
Step 188390: loss = 0.03409
Step 188395: loss = 0.12585
Step 188400: loss = 0.08179
Step 188405: loss = 0.07290
Step 188410: loss = 0.06730
Step 188415: loss = 0.13228
Step 188420: loss = 0.06103
Step 188425: loss = 0.23697
Step 188430: loss = 0.31371
Step 188435: loss = 0.07323
Step 188440: loss = 0.03248
Step 188445: loss = 0.06775
Step 188450: loss = 0.06170
Step 188455: loss = 0.12684
Step 188460: loss = 0.08650
Step 188465: loss = 0.06357
Step 188470: loss = 0.12006
Step 188475: loss = 0.08253
Step 188480: loss = 0.03375
Step 188485: loss = 0.24427
Step 188490: loss = 0.03080
Step 188495: loss = 0.18240
Step 188500: loss = 0.08309
Step 188505: loss = 0.09213
Step 188510: loss = 0.08787
Step 188515: loss = 0.07625
Step 188520: loss = 0.04597
Step 188525: loss = 0.07014
Step 188530: loss = 0.02567
Step 188535: loss = 0.09772
Step 188540: loss = 0.09099
Step 188545: loss = 0.04520
Step 188550: loss = 0.31767
Step 188555: loss = 0.26403
Step 188560: loss = 0.19118
Step 188565: loss = 0.11940
Step 188570: loss = 0.07893
Step 188575: loss = 0.03027
Step 188580: loss = 0.09878
Step 188585: loss = 0.10839
Step 188590: loss = 0.12674
Step 188595: loss = 0.10156
Step 188600: loss = 0.35569
Step 188605: loss = 0.06731
Step 188610: loss = 0.03531
Step 188615: loss = 0.06975
Step 188620: loss = 0.07365
Step 188625: loss = 0.05333
Step 188630: loss = 0.09855
Step 188635: loss = 0.20106
Step 188640: loss = 0.07158
Step 188645: loss = 0.07943
Step 188650: loss = 0.07873
Step 188655: loss = 0.03322
Step 188660: loss = 0.04669
Step 188665: loss = 0.19555
Step 188670: loss = 0.10585
Step 188675: loss = 0.16209
Step 188680: loss = 0.04298
Step 188685: loss = 0.07763
Step 188690: loss = 0.07240
Step 188695: loss = 0.17623
Step 188700: loss = 0.05303
Step 188705: loss = 0.02342
Step 188710: loss = 0.18474
Step 188715: loss = 0.03717
Step 188720: loss = 0.09177
Step 188725: loss = 0.31776
Step 188730: loss = 0.12853
Step 188735: loss = 0.09159
Step 188740: loss = 0.10589
Step 188745: loss = 0.04171
Step 188750: loss = 0.10856
Step 188755: loss = 0.05181
Step 188760: loss = 0.12657
Step 188765: loss = 0.04413
Step 188770: loss = 0.02722
Step 188775: loss = 0.17310
Step 188780: loss = 0.08457
Step 188785: loss = 0.06458
Step 188790: loss = 0.17173
Step 188795: loss = 0.07476
Step 188800: loss = 0.05647
Step 188805: loss = 0.06284
Step 188810: loss = 0.09918
Step 188815: loss = 0.07697
Step 188820: loss = 0.07058
Step 188825: loss = 0.14699
Step 188830: loss = 0.11667
Step 188835: loss = 0.08651
Step 188840: loss = 0.07281
Step 188845: loss = 0.14484
Step 188850: loss = 0.04598
Step 188855: loss = 0.04355
Step 188860: loss = 0.06966
Step 188865: loss = 0.08954
Step 188870: loss = 0.03131
Step 188875: loss = 0.02540
Step 188880: loss = 0.06298
Step 188885: loss = 0.03866
Step 188890: loss = 0.06581
Step 188895: loss = 0.31514
Step 188900: loss = 0.08934
Step 188905: loss = 0.07536
Step 188910: loss = 0.27452
Step 188915: loss = 0.13425
Step 188920: loss = 0.20612
Step 188925: loss = 0.02571
Step 188930: loss = 0.18341
Step 188935: loss = 0.01776
Step 188940: loss = 0.07480
Step 188945: loss = 0.13408
Step 188950: loss = 0.19387
Step 188955: loss = 0.04451
Step 188960: loss = 0.09052
Step 188965: loss = 0.03358
Step 188970: loss = 0.03527
Step 188975: loss = 0.07191
Step 188980: loss = 0.06072
Step 188985: loss = 0.04420
Step 188990: loss = 0.17406
Step 188995: loss = 0.05252
Step 189000: loss = 0.16940
Training Data Eval:
  Num examples: 50000, Num correct: 48334, Precision @ 1: 0.9667
('Testing Data Eval: EPOCH->', 190)
  Num examples: 10000, Num correct: 6680, Precision @ 1: 0.6680
Step 189005: loss = 0.05575
Step 189010: loss = 0.07934
Step 189015: loss = 0.07005
Step 189020: loss = 0.16122
Step 189025: loss = 0.12873
Step 189030: loss = 0.12681
Step 189035: loss = 0.04175
Step 189040: loss = 0.08418
Step 189045: loss = 0.03048
Step 189050: loss = 0.07872
Step 189055: loss = 0.02500
Step 189060: loss = 0.16203
Step 189065: loss = 0.09682
Step 189070: loss = 0.21165
Step 189075: loss = 0.03049
Step 189080: loss = 0.02887
Step 189085: loss = 0.13772
Step 189090: loss = 0.11238
Step 189095: loss = 0.04632
Step 189100: loss = 0.07475
Step 189105: loss = 0.06194
Step 189110: loss = 0.21840
Step 189115: loss = 0.17060
Step 189120: loss = 0.16816
Step 189125: loss = 0.30117
Step 189130: loss = 0.04301
Step 189135: loss = 0.07463
Step 189140: loss = 0.16884
Step 189145: loss = 0.24530
Step 189150: loss = 0.13876
Step 189155: loss = 0.13918
Step 189160: loss = 0.25419
Step 189165: loss = 0.07346
Step 189170: loss = 0.25801
Step 189175: loss = 0.05557
Step 189180: loss = 0.23656
Step 189185: loss = 0.14849
Step 189190: loss = 0.02912
Step 189195: loss = 0.16782
Step 189200: loss = 0.08014
Step 189205: loss = 0.05707
Step 189210: loss = 0.05505
Step 189215: loss = 0.14063
Step 189220: loss = 0.28853
Step 189225: loss = 0.11616
Step 189230: loss = 0.21968
Step 189235: loss = 0.11085
Step 189240: loss = 0.06260
Step 189245: loss = 0.06795
Step 189250: loss = 0.24177
Step 189255: loss = 0.12039
Step 189260: loss = 0.24651
Step 189265: loss = 0.07987
Step 189270: loss = 0.23352
Step 189275: loss = 0.09147
Step 189280: loss = 0.06289
Step 189285: loss = 0.12379
Step 189290: loss = 0.21333
Step 189295: loss = 0.06974
Step 189300: loss = 0.04886
Step 189305: loss = 0.21710
Step 189310: loss = 0.10912
Step 189315: loss = 0.14170
Step 189320: loss = 0.16849
Step 189325: loss = 0.18201
Step 189330: loss = 0.09697
Step 189335: loss = 0.25560
Step 189340: loss = 0.27807
Step 189345: loss = 0.05461
Step 189350: loss = 0.17934
Step 189355: loss = 0.09728
Step 189360: loss = 0.06380
Step 189365: loss = 0.10966
Step 189370: loss = 0.07121
Step 189375: loss = 0.03413
Step 189380: loss = 0.07077
Step 189385: loss = 0.06227
Step 189390: loss = 0.41699
Step 189395: loss = 0.17460
Step 189400: loss = 0.11343
Step 189405: loss = 0.04273
Step 189410: loss = 0.05108
Step 189415: loss = 0.21913
Step 189420: loss = 0.04901
Step 189425: loss = 0.15029
Step 189430: loss = 0.19620
Step 189435: loss = 0.15164
Step 189440: loss = 0.20654
Step 189445: loss = 0.04735
Step 189450: loss = 0.18790
Step 189455: loss = 0.09398
Step 189460: loss = 0.12096
Step 189465: loss = 0.06578
Step 189470: loss = 0.08901
Step 189475: loss = 0.20489
Step 189480: loss = 0.05076
Step 189485: loss = 0.04061
Step 189490: loss = 0.10102
Step 189495: loss = 0.09786
Step 189500: loss = 0.19926
Step 189505: loss = 0.14538
Step 189510: loss = 0.32694
Step 189515: loss = 0.12449
Step 189520: loss = 0.09079
Step 189525: loss = 0.19376
Step 189530: loss = 0.30495
Step 189535: loss = 0.07469
Step 189540: loss = 0.01646
Step 189545: loss = 0.06857
Step 189550: loss = 0.01816
Step 189555: loss = 0.04560
Step 189560: loss = 0.06773
Step 189565: loss = 0.06588
Step 189570: loss = 0.09935
Step 189575: loss = 0.05469
Step 189580: loss = 0.17401
Step 189585: loss = 0.06588
Step 189590: loss = 0.06827
Step 189595: loss = 0.16492
Step 189600: loss = 0.28180
Step 189605: loss = 0.08772
Step 189610: loss = 0.08677
Step 189615: loss = 0.10593
Step 189620: loss = 0.08893
Step 189625: loss = 0.07712
Step 189630: loss = 0.16369
Step 189635: loss = 0.12337
Step 189640: loss = 0.08596
Step 189645: loss = 0.06572
Step 189650: loss = 0.09230
Step 189655: loss = 0.07901
Step 189660: loss = 0.12442
Step 189665: loss = 0.17044
Step 189670: loss = 0.10167
Step 189675: loss = 0.02706
Step 189680: loss = 0.11705
Step 189685: loss = 0.04552
Step 189690: loss = 0.06136
Step 189695: loss = 0.14096
Step 189700: loss = 0.09037
Step 189705: loss = 0.36697
Step 189710: loss = 0.21245
Step 189715: loss = 0.04444
Step 189720: loss = 0.03649
Step 189725: loss = 0.05324
Step 189730: loss = 0.08931
Step 189735: loss = 0.14809
Step 189740: loss = 0.05153
Step 189745: loss = 0.12281
Step 189750: loss = 0.12963
Step 189755: loss = 0.07426
Step 189760: loss = 0.08562
Step 189765: loss = 0.26621
Step 189770: loss = 0.09566
Step 189775: loss = 0.04847
Step 189780: loss = 0.04412
Step 189785: loss = 0.03216
Step 189790: loss = 0.19347
Step 189795: loss = 0.34166
Step 189800: loss = 0.13986
Step 189805: loss = 0.04088
Step 189810: loss = 0.20360
Step 189815: loss = 0.21003
Step 189820: loss = 0.03253
Step 189825: loss = 0.12924
Step 189830: loss = 0.20180
Step 189835: loss = 0.09256
Step 189840: loss = 0.27947
Step 189845: loss = 0.09300
Step 189850: loss = 0.09579
Step 189855: loss = 0.17639
Step 189860: loss = 0.05294
Step 189865: loss = 0.25027
Step 189870: loss = 0.14386
Step 189875: loss = 0.10980
Step 189880: loss = 0.09664
Step 189885: loss = 0.14055
Step 189890: loss = 0.09290
Step 189895: loss = 0.12793
Step 189900: loss = 0.05975
Step 189905: loss = 0.09625
Step 189910: loss = 0.05264
Step 189915: loss = 0.03526
Step 189920: loss = 0.12051
Step 189925: loss = 0.07655
Step 189930: loss = 0.11409
Step 189935: loss = 0.05712
Step 189940: loss = 0.24127
Step 189945: loss = 0.08088
Step 189950: loss = 0.03799
Step 189955: loss = 0.13476
Step 189960: loss = 0.12144
Step 189965: loss = 0.08506
Step 189970: loss = 0.02470
Step 189975: loss = 0.06694
Step 189980: loss = 0.12443
Step 189985: loss = 0.11632
Step 189990: loss = 0.15507
Step 189995: loss = 0.09565
Step 190000: loss = 0.19608
Training Data Eval:
  Num examples: 50000, Num correct: 48162, Precision @ 1: 0.9632
('Testing Data Eval: EPOCH->', 191)
  Num examples: 10000, Num correct: 6740, Precision @ 1: 0.6740
Step 190005: loss = 0.05331
Step 190010: loss = 0.38195
Step 190015: loss = 0.02549
Step 190020: loss = 0.06446
Step 190025: loss = 0.16121
Step 190030: loss = 0.04332
Step 190035: loss = 0.18206
Step 190040: loss = 0.09994
Step 190045: loss = 0.01849
Step 190050: loss = 0.05911
Step 190055: loss = 0.02249
Step 190060: loss = 0.14455
Step 190065: loss = 0.05381
Step 190070: loss = 0.07172
Step 190075: loss = 0.22711
Step 190080: loss = 0.02747
Step 190085: loss = 0.05341
Step 190090: loss = 0.42322
Step 190095: loss = 0.22649
Step 190100: loss = 0.06711
Step 190105: loss = 0.07132
Step 190110: loss = 0.02667
Step 190115: loss = 0.03493
Step 190120: loss = 0.06977
Step 190125: loss = 0.32557
Step 190130: loss = 0.07739
Step 190135: loss = 0.13044
Step 190140: loss = 0.07542
Step 190145: loss = 0.14302
Step 190150: loss = 0.13903
Step 190155: loss = 0.02641
Step 190160: loss = 0.15811
Step 190165: loss = 0.06878
Step 190170: loss = 0.01409
Step 190175: loss = 0.04277
Step 190180: loss = 0.10561
Step 190185: loss = 0.08393
Step 190190: loss = 0.09373
Step 190195: loss = 0.07914
Step 190200: loss = 0.23324
Step 190205: loss = 0.06502
Step 190210: loss = 0.08671
Step 190215: loss = 0.11850
Step 190220: loss = 0.06597
Step 190225: loss = 0.01947
Step 190230: loss = 0.04112
Step 190235: loss = 0.11363
Step 190240: loss = 0.11182
Step 190245: loss = 0.07913
Step 190250: loss = 0.08527
Step 190255: loss = 0.11223
Step 190260: loss = 0.07206
Step 190265: loss = 0.10763
Step 190270: loss = 0.08067
Step 190275: loss = 0.15949
Step 190280: loss = 0.17719
Step 190285: loss = 0.26971
Step 190290: loss = 0.06638
Step 190295: loss = 0.11406
Step 190300: loss = 0.03723
Step 190305: loss = 0.21298
Step 190310: loss = 0.22238
Step 190315: loss = 0.09095
Step 190320: loss = 0.04624
Step 190325: loss = 0.13670
Step 190330: loss = 0.12939
Step 190335: loss = 0.06363
Step 190340: loss = 0.16202
Step 190345: loss = 0.08073
Step 190350: loss = 0.22242
Step 190355: loss = 0.13336
Step 190360: loss = 0.26249
Step 190365: loss = 0.18142
Step 190370: loss = 0.06693
Step 190375: loss = 0.11900
Step 190380: loss = 0.12463
Step 190385: loss = 0.02277
Step 190390: loss = 0.10996
Step 190395: loss = 0.08990
Step 190400: loss = 0.06762
Step 190405: loss = 0.13088
Step 190410: loss = 0.14077
Step 190415: loss = 0.09528
Step 190420: loss = 0.16388
Step 190425: loss = 0.11585
Step 190430: loss = 0.06496
Step 190435: loss = 0.13734
Step 190440: loss = 0.08446
Step 190445: loss = 0.04669
Step 190450: loss = 0.02909
Step 190455: loss = 0.09678
Step 190460: loss = 0.04110
Step 190465: loss = 0.04590
Step 190470: loss = 0.07144
Step 190475: loss = 0.06578
Step 190480: loss = 0.10782
Step 190485: loss = 0.06517
Step 190490: loss = 0.06625
Step 190495: loss = 0.13235
Step 190500: loss = 0.04933
Step 190505: loss = 0.00866
Step 190510: loss = 0.03697
Step 190515: loss = 0.09759
Step 190520: loss = 0.19801
Step 190525: loss = 0.03938
Step 190530: loss = 0.02770
Step 190535: loss = 0.07352
Step 190540: loss = 0.17633
Step 190545: loss = 0.18397
Step 190550: loss = 0.10635
Step 190555: loss = 0.24492
Step 190560: loss = 0.14159
Step 190565: loss = 0.07509
Step 190570: loss = 0.04319
Step 190575: loss = 0.05508
Step 190580: loss = 0.04046
Step 190585: loss = 0.09441
Step 190590: loss = 0.13522
Step 190595: loss = 0.27972
Step 190600: loss = 0.20038
Step 190605: loss = 0.07448
Step 190610: loss = 0.07272
Step 190615: loss = 0.03538
Step 190620: loss = 0.10547
Step 190625: loss = 0.03073
Step 190630: loss = 0.02461
Step 190635: loss = 0.03939
Step 190640: loss = 0.06843
Step 190645: loss = 0.09814
Step 190650: loss = 0.05297
Step 190655: loss = 0.09538
Step 190660: loss = 0.04686
Step 190665: loss = 0.17667
Step 190670: loss = 0.09541
Step 190675: loss = 0.02669
Step 190680: loss = 0.11276
Step 190685: loss = 0.07671
Step 190690: loss = 0.09940
Step 190695: loss = 0.16278
Step 190700: loss = 0.15814
Step 190705: loss = 0.11920
Step 190710: loss = 0.13455
Step 190715: loss = 0.41906
Step 190720: loss = 0.09265
Step 190725: loss = 0.17537
Step 190730: loss = 0.04030
Step 190735: loss = 0.12943
Step 190740: loss = 0.05586
Step 190745: loss = 0.27408
Step 190750: loss = 0.07938
Step 190755: loss = 0.07883
Step 190760: loss = 0.10634
Step 190765: loss = 0.17385
Step 190770: loss = 0.05268
Step 190775: loss = 0.13326
Step 190780: loss = 0.36415
Step 190785: loss = 0.08872
Step 190790: loss = 0.03656
Step 190795: loss = 0.28531
Step 190800: loss = 0.21365
Step 190805: loss = 0.05570
Step 190810: loss = 0.05419
Step 190815: loss = 0.05796
Step 190820: loss = 0.07967
Step 190825: loss = 0.14362
Step 190830: loss = 0.08496
Step 190835: loss = 0.09038
Step 190840: loss = 0.12961
Step 190845: loss = 0.08108
Step 190850: loss = 0.11520
Step 190855: loss = 0.04849
Step 190860: loss = 0.08513
Step 190865: loss = 0.21896
Step 190870: loss = 0.17182
Step 190875: loss = 0.20999
Step 190880: loss = 0.03055
Step 190885: loss = 0.03957
Step 190890: loss = 0.32691
Step 190895: loss = 0.06394
Step 190900: loss = 0.08563
Step 190905: loss = 0.07996
Step 190910: loss = 0.10845
Step 190915: loss = 0.07532
Step 190920: loss = 0.18032
Step 190925: loss = 0.12505
Step 190930: loss = 0.11082
Step 190935: loss = 0.13547
Step 190940: loss = 0.10379
Step 190945: loss = 0.08289
Step 190950: loss = 0.04757
Step 190955: loss = 0.04615
Step 190960: loss = 0.15649
Step 190965: loss = 0.04305
Step 190970: loss = 0.32417
Step 190975: loss = 0.05604
Step 190980: loss = 0.09831
Step 190985: loss = 0.03282
Step 190990: loss = 0.09764
Step 190995: loss = 0.15940
Step 191000: loss = 0.12824
Training Data Eval:
  Num examples: 50000, Num correct: 48236, Precision @ 1: 0.9647
('Testing Data Eval: EPOCH->', 192)
  Num examples: 10000, Num correct: 6738, Precision @ 1: 0.6738
Step 191005: loss = 0.06694
Step 191010: loss = 0.03392
Step 191015: loss = 0.20437
Step 191020: loss = 0.17076
Step 191025: loss = 0.05549
Step 191030: loss = 0.25200
Step 191035: loss = 0.03370
Step 191040: loss = 0.08704
Step 191045: loss = 0.08262
Step 191050: loss = 0.11508
Step 191055: loss = 0.02477
Step 191060: loss = 0.02268
Step 191065: loss = 0.03813
Step 191070: loss = 0.24076
Step 191075: loss = 0.06324
Step 191080: loss = 0.05561
Step 191085: loss = 0.05055
Step 191090: loss = 0.23239
Step 191095: loss = 0.05426
Step 191100: loss = 0.03638
Step 191105: loss = 0.03787
Step 191110: loss = 0.10732
Step 191115: loss = 0.05035
Step 191120: loss = 0.10282
Step 191125: loss = 0.05768
Step 191130: loss = 0.10566
Step 191135: loss = 0.07960
Step 191140: loss = 0.06373
Step 191145: loss = 0.19235
Step 191150: loss = 0.15683
Step 191155: loss = 0.17950
Step 191160: loss = 0.07370
Step 191165: loss = 0.11676
Step 191170: loss = 0.04440
Step 191175: loss = 0.07598
Step 191180: loss = 0.03558
Step 191185: loss = 0.07373
Step 191190: loss = 0.18266
Step 191195: loss = 0.07166
Step 191200: loss = 0.13427
Step 191205: loss = 0.12711
Step 191210: loss = 0.09599
Step 191215: loss = 0.02010
Step 191220: loss = 0.24967
Step 191225: loss = 0.04126
Step 191230: loss = 0.18228
Step 191235: loss = 0.06513
Step 191240: loss = 0.08389
Step 191245: loss = 0.14502
Step 191250: loss = 0.11166
Step 191255: loss = 0.24003
Step 191260: loss = 0.18312
Step 191265: loss = 0.06454
Step 191270: loss = 0.05596
Step 191275: loss = 0.05427
Step 191280: loss = 0.11540
Step 191285: loss = 0.12847
Step 191290: loss = 0.09461
Step 191295: loss = 0.13780
Step 191300: loss = 0.10126
Step 191305: loss = 0.03384
Step 191310: loss = 0.22979
Step 191315: loss = 0.07274
Step 191320: loss = 0.03214
Step 191325: loss = 0.03857
Step 191330: loss = 0.08807
Step 191335: loss = 0.06969
Step 191340: loss = 0.10835
Step 191345: loss = 0.08822
Step 191350: loss = 0.15983
Step 191355: loss = 0.10466
Step 191360: loss = 0.04365
Step 191365: loss = 0.09752
Step 191370: loss = 0.14536
Step 191375: loss = 0.11340
Step 191380: loss = 0.08729
Step 191385: loss = 0.07051
Step 191390: loss = 0.05064
Step 191395: loss = 0.06850
Step 191400: loss = 0.10679
Step 191405: loss = 0.15039
Step 191410: loss = 0.10370
Step 191415: loss = 0.01512
Step 191420: loss = 0.10227
Step 191425: loss = 0.08714
Step 191430: loss = 0.03857
Step 191435: loss = 0.03614
Step 191440: loss = 0.27649
Step 191445: loss = 0.12180
Step 191450: loss = 0.04756
Step 191455: loss = 0.16671
Step 191460: loss = 0.06237
Step 191465: loss = 0.07699
Step 191470: loss = 0.10910
Step 191475: loss = 0.07424
Step 191480: loss = 0.08122
Step 191485: loss = 0.12528
Step 191490: loss = 0.11739
Step 191495: loss = 0.05168
Step 191500: loss = 0.04213
Step 191505: loss = 0.09908
Step 191510: loss = 0.19802
Step 191515: loss = 0.10795
Step 191520: loss = 0.14541
Step 191525: loss = 0.04063
Step 191530: loss = 0.07816
Step 191535: loss = 0.01805
Step 191540: loss = 0.03787
Step 191545: loss = 0.13569
Step 191550: loss = 0.10953
Step 191555: loss = 0.22313
Step 191560: loss = 0.18696
Step 191565: loss = 0.22696
Step 191570: loss = 0.03606
Step 191575: loss = 0.07875
Step 191580: loss = 0.09314
Step 191585: loss = 0.03197
Step 191590: loss = 0.10421
Step 191595: loss = 0.07144
Step 191600: loss = 0.13840
Step 191605: loss = 0.05165
Step 191610: loss = 0.05681
Step 191615: loss = 0.05314
Step 191620: loss = 0.14519
Step 191625: loss = 0.08924
Step 191630: loss = 0.07477
Step 191635: loss = 0.23404
Step 191640: loss = 0.08220
Step 191645: loss = 0.29356
Step 191650: loss = 0.17210
Step 191655: loss = 0.04350
Step 191660: loss = 0.10760
Step 191665: loss = 0.06397
Step 191670: loss = 0.10201
Step 191675: loss = 0.18907
Step 191680: loss = 0.06986
Step 191685: loss = 0.03660
Step 191690: loss = 0.06844
Step 191695: loss = 0.05316
Step 191700: loss = 0.21000
Step 191705: loss = 0.22624
Step 191710: loss = 0.18098
Step 191715: loss = 0.08788
Step 191720: loss = 0.14693
Step 191725: loss = 0.14263
Step 191730: loss = 0.29425
Step 191735: loss = 0.15905
Step 191740: loss = 0.05642
Step 191745: loss = 0.10787
Step 191750: loss = 0.05810
Step 191755: loss = 0.05361
Step 191760: loss = 0.09542
Step 191765: loss = 0.19420
Step 191770: loss = 0.05063
Step 191775: loss = 0.11320
Step 191780: loss = 0.26378
Step 191785: loss = 0.10331
Step 191790: loss = 0.06401
Step 191795: loss = 0.05628
Step 191800: loss = 0.10016
Step 191805: loss = 0.17735
Step 191810: loss = 0.07199
Step 191815: loss = 0.02876
Step 191820: loss = 0.06026
Step 191825: loss = 0.11635
Step 191830: loss = 0.10818
Step 191835: loss = 0.13107
Step 191840: loss = 0.08514
Step 191845: loss = 0.06473
Step 191850: loss = 0.12412
Step 191855: loss = 0.11012
Step 191860: loss = 0.00969
Step 191865: loss = 0.05124
Step 191870: loss = 0.03903
Step 191875: loss = 0.05161
Step 191880: loss = 0.10727
Step 191885: loss = 0.13237
Step 191890: loss = 0.18513
Step 191895: loss = 0.11940
Step 191900: loss = 0.09451
Step 191905: loss = 0.07877
Step 191910: loss = 0.07057
Step 191915: loss = 0.02389
Step 191920: loss = 0.13501
Step 191925: loss = 0.10740
Step 191930: loss = 0.17998
Step 191935: loss = 0.09074
Step 191940: loss = 0.05946
Step 191945: loss = 0.02056
Step 191950: loss = 0.04971
Step 191955: loss = 0.11768
Step 191960: loss = 0.03621
Step 191965: loss = 0.08789
Step 191970: loss = 0.09943
Step 191975: loss = 0.22944
Step 191980: loss = 0.17639
Step 191985: loss = 0.24758
Step 191990: loss = 0.06621
Step 191995: loss = 0.05102
Step 192000: loss = 0.22730
Training Data Eval:
  Num examples: 50000, Num correct: 48181, Precision @ 1: 0.9636
('Testing Data Eval: EPOCH->', 193)
  Num examples: 10000, Num correct: 6660, Precision @ 1: 0.6660
Step 192005: loss = 0.04975
Step 192010: loss = 0.12673
Step 192015: loss = 0.30872
Step 192020: loss = 0.09067
Step 192025: loss = 0.07203
Step 192030: loss = 0.07628
Step 192035: loss = 0.17220
Step 192040: loss = 0.05444
Step 192045: loss = 0.05458
Step 192050: loss = 0.04909
Step 192055: loss = 0.03310
Step 192060: loss = 0.08015
Step 192065: loss = 0.21048
Step 192070: loss = 0.23412
Step 192075: loss = 0.28705
Step 192080: loss = 0.11712
Step 192085: loss = 0.14029
Step 192090: loss = 0.03207
Step 192095: loss = 0.05578
Step 192100: loss = 0.01824
Step 192105: loss = 0.12108
Step 192110: loss = 0.05299
Step 192115: loss = 0.26290
Step 192120: loss = 0.37491
Step 192125: loss = 0.14521
Step 192130: loss = 0.34162
Step 192135: loss = 0.18008
Step 192140: loss = 0.35513
Step 192145: loss = 0.09412
Step 192150: loss = 0.11883
Step 192155: loss = 0.30747
Step 192160: loss = 0.05650
Step 192165: loss = 0.03372
Step 192170: loss = 0.05194
Step 192175: loss = 0.04678
Step 192180: loss = 0.06713
Step 192185: loss = 0.03916
Step 192190: loss = 0.07592
Step 192195: loss = 0.05501
Step 192200: loss = 0.06103
Step 192205: loss = 0.36401
Step 192210: loss = 0.43432
Step 192215: loss = 0.05091
Step 192220: loss = 0.17789
Step 192225: loss = 0.08389
Step 192230: loss = 0.17315
Step 192235: loss = 0.03673
Step 192240: loss = 0.06632
Step 192245: loss = 0.04283
Step 192250: loss = 0.06881
Step 192255: loss = 0.12687
Step 192260: loss = 0.11105
Step 192265: loss = 0.10950
Step 192270: loss = 0.14927
Step 192275: loss = 0.02956
Step 192280: loss = 0.05501
Step 192285: loss = 0.01699
Step 192290: loss = 0.56339
Step 192295: loss = 0.09748
Step 192300: loss = 0.27454
Step 192305: loss = 0.08619
Step 192310: loss = 0.02134
Step 192315: loss = 0.07938
Step 192320: loss = 0.12634
Step 192325: loss = 0.13376
Step 192330: loss = 0.11630
Step 192335: loss = 0.03283
Step 192340: loss = 0.03675
Step 192345: loss = 0.17346
Step 192350: loss = 0.04313
Step 192355: loss = 0.07266
Step 192360: loss = 0.04268
Step 192365: loss = 0.07043
Step 192370: loss = 0.14694
Step 192375: loss = 0.15005
Step 192380: loss = 0.05503
Step 192385: loss = 0.08355
Step 192390: loss = 0.17472
Step 192395: loss = 0.08057
Step 192400: loss = 0.21237
Step 192405: loss = 0.13697
Step 192410: loss = 0.01733
Step 192415: loss = 0.07673
Step 192420: loss = 0.05826
Step 192425: loss = 0.07975
Step 192430: loss = 0.07692
Step 192435: loss = 0.09887
Step 192440: loss = 0.05289
Step 192445: loss = 0.06708
Step 192450: loss = 0.04563
Step 192455: loss = 0.01763
Step 192460: loss = 0.11993
Step 192465: loss = 0.07929
Step 192470: loss = 0.14145
Step 192475: loss = 0.06415
Step 192480: loss = 0.07496
Step 192485: loss = 0.04157
Step 192490: loss = 0.27469
Step 192495: loss = 0.12366
Step 192500: loss = 0.16143
Step 192505: loss = 0.23287
Step 192510: loss = 0.09913
Step 192515: loss = 0.13061
Step 192520: loss = 0.09744
Step 192525: loss = 0.08640
Step 192530: loss = 0.07829
Step 192535: loss = 0.04096
Step 192540: loss = 0.24387
Step 192545: loss = 0.07118
Step 192550: loss = 0.11441
Step 192555: loss = 0.07312
Step 192560: loss = 0.08871
Step 192565: loss = 0.04006
Step 192570: loss = 0.03472
Step 192575: loss = 0.04651
Step 192580: loss = 0.09269
Step 192585: loss = 0.14421
Step 192590: loss = 0.03674
Step 192595: loss = 0.04658
Step 192600: loss = 0.02445
Step 192605: loss = 0.24795
Step 192610: loss = 0.08809
Step 192615: loss = 0.07544
Step 192620: loss = 0.16996
Step 192625: loss = 0.05105
Step 192630: loss = 0.17631
Step 192635: loss = 0.04354
Step 192640: loss = 0.13384
Step 192645: loss = 0.05244
Step 192650: loss = 0.08783
Step 192655: loss = 0.11650
Step 192660: loss = 0.13890
Step 192665: loss = 0.05153
Step 192670: loss = 0.01923
Step 192675: loss = 0.08340
Step 192680: loss = 0.12028
Step 192685: loss = 0.20805
Step 192690: loss = 0.08045
Step 192695: loss = 0.06250
Step 192700: loss = 0.12368
Step 192705: loss = 0.15245
Step 192710: loss = 0.24597
Step 192715: loss = 0.05952
Step 192720: loss = 0.13443
Step 192725: loss = 0.11771
Step 192730: loss = 0.03086
Step 192735: loss = 0.06329
Step 192740: loss = 0.07191
Step 192745: loss = 0.02697
Step 192750: loss = 0.06801
Step 192755: loss = 0.10281
Step 192760: loss = 0.05770
Step 192765: loss = 0.03533
Step 192770: loss = 0.42916
Step 192775: loss = 0.09211
Step 192780: loss = 0.24639
Step 192785: loss = 0.06564
Step 192790: loss = 0.11703
Step 192795: loss = 0.10502
Step 192800: loss = 0.10459
Step 192805: loss = 0.02396
Step 192810: loss = 0.06653
Step 192815: loss = 0.11375
Step 192820: loss = 0.04515
Step 192825: loss = 0.22082
Step 192830: loss = 0.28842
Step 192835: loss = 0.19003
Step 192840: loss = 0.11303
Step 192845: loss = 0.04800
Step 192850: loss = 0.15561
Step 192855: loss = 0.09816
Step 192860: loss = 0.16994
Step 192865: loss = 0.06567
Step 192870: loss = 0.08289
Step 192875: loss = 0.15188
Step 192880: loss = 0.06309
Step 192885: loss = 0.05471
Step 192890: loss = 0.07087
Step 192895: loss = 0.04087
Step 192900: loss = 0.28285
Step 192905: loss = 0.09255
Step 192910: loss = 0.05922
Step 192915: loss = 0.23545
Step 192920: loss = 0.10148
Step 192925: loss = 0.13484
Step 192930: loss = 0.13674
Step 192935: loss = 0.04138
Step 192940: loss = 0.06575
Step 192945: loss = 0.06420
Step 192950: loss = 0.02983
Step 192955: loss = 0.04144
Step 192960: loss = 0.12844
Step 192965: loss = 0.18300
Step 192970: loss = 0.10047
Step 192975: loss = 0.06312
Step 192980: loss = 0.06986
Step 192985: loss = 0.03732
Step 192990: loss = 0.06044
Step 192995: loss = 0.06795
Step 193000: loss = 0.06266
Training Data Eval:
  Num examples: 50000, Num correct: 48062, Precision @ 1: 0.9612
('Testing Data Eval: EPOCH->', 194)
  Num examples: 10000, Num correct: 6638, Precision @ 1: 0.6638
Step 193005: loss = 0.05677
Step 193010: loss = 0.12657
Step 193015: loss = 0.12594
Step 193020: loss = 0.06841
Step 193025: loss = 0.10235
Step 193030: loss = 0.17227
Step 193035: loss = 0.12242
Step 193040: loss = 0.30041
Step 193045: loss = 0.03554
Step 193050: loss = 0.02863
Step 193055: loss = 0.06557
Step 193060: loss = 0.12589
Step 193065: loss = 0.09386
Step 193070: loss = 0.10820
Step 193075: loss = 0.07323
Step 193080: loss = 0.09026
Step 193085: loss = 0.08120
Step 193090: loss = 0.05162
Step 193095: loss = 0.03742
Step 193100: loss = 0.06167
Step 193105: loss = 0.08661
Step 193110: loss = 0.08697
Step 193115: loss = 0.05477
Step 193120: loss = 0.14468
Step 193125: loss = 0.01014
Step 193130: loss = 0.04933
Step 193135: loss = 0.09331
Step 193140: loss = 0.04207
Step 193145: loss = 0.06747
Step 193150: loss = 0.15009
Step 193155: loss = 0.02290
Step 193160: loss = 0.04101
Step 193165: loss = 0.47885
Step 193170: loss = 0.07476
Step 193175: loss = 0.12231
Step 193180: loss = 0.04845
Step 193185: loss = 0.10773
Step 193190: loss = 0.11001
Step 193195: loss = 0.12964
Step 193200: loss = 0.01596
Step 193205: loss = 0.05052
Step 193210: loss = 0.13643
Step 193215: loss = 0.04971
Step 193220: loss = 0.08759
Step 193225: loss = 0.07570
Step 193230: loss = 0.25263
Step 193235: loss = 0.08085
Step 193240: loss = 0.17940
Step 193245: loss = 0.10485
Step 193250: loss = 0.21736
Step 193255: loss = 0.10215
Step 193260: loss = 0.41717
Step 193265: loss = 0.11316
Step 193270: loss = 0.11934
Step 193275: loss = 0.24417
Step 193280: loss = 0.03720
Step 193285: loss = 0.14113
Step 193290: loss = 0.08427
Step 193295: loss = 0.02485
Step 193300: loss = 0.06566
Step 193305: loss = 0.07869
Step 193310: loss = 0.04298
Step 193315: loss = 0.04037
Step 193320: loss = 0.08996
Step 193325: loss = 0.16594
Step 193330: loss = 0.09572
Step 193335: loss = 0.12211
Step 193340: loss = 0.04756
Step 193345: loss = 0.04583
Step 193350: loss = 0.04553
Step 193355: loss = 0.04482
Step 193360: loss = 0.02765
Step 193365: loss = 0.11314
Step 193370: loss = 0.05177
Step 193375: loss = 0.06328
Step 193380: loss = 0.13565
Step 193385: loss = 0.11851
Step 193390: loss = 0.17220
Step 193395: loss = 0.10192
Step 193400: loss = 0.04024
Step 193405: loss = 0.06687
Step 193410: loss = 0.12247
Step 193415: loss = 0.03259
Step 193420: loss = 0.17150
Step 193425: loss = 0.21767
Step 193430: loss = 0.10040
Step 193435: loss = 0.04070
Step 193440: loss = 0.16417
Step 193445: loss = 0.23582
Step 193450: loss = 0.05653
Step 193455: loss = 0.09960
Step 193460: loss = 0.06622
Step 193465: loss = 0.05078
Step 193470: loss = 0.02748
Step 193475: loss = 0.15257
Step 193480: loss = 0.26252
Step 193485: loss = 0.06626
Step 193490: loss = 0.11551
Step 193495: loss = 0.12321
Step 193500: loss = 0.30080
Step 193505: loss = 0.03042
Step 193510: loss = 0.06903
Step 193515: loss = 0.12551
Step 193520: loss = 0.15462
Step 193525: loss = 0.03187
Step 193530: loss = 0.12375
Step 193535: loss = 0.16251
Step 193540: loss = 0.07007
Step 193545: loss = 0.08313
Step 193550: loss = 0.05797
Step 193555: loss = 0.08832
Step 193560: loss = 0.13684
Step 193565: loss = 0.08512
Step 193570: loss = 0.22322
Step 193575: loss = 0.20349
Step 193580: loss = 0.09618
Step 193585: loss = 0.16546
Step 193590: loss = 0.11143
Step 193595: loss = 0.05211
Step 193600: loss = 0.07739
Step 193605: loss = 0.10199
Step 193610: loss = 0.20195
Step 193615: loss = 0.10996
Step 193620: loss = 0.22797
Step 193625: loss = 0.03169
Step 193630: loss = 0.03290
Step 193635: loss = 0.10424
Step 193640: loss = 0.06922
Step 193645: loss = 0.07527
Step 193650: loss = 0.21065
Step 193655: loss = 0.30706
Step 193660: loss = 0.16155
Step 193665: loss = 0.04407
Step 193670: loss = 0.04990
Step 193675: loss = 0.14903
Step 193680: loss = 0.06098
Step 193685: loss = 0.11761
Step 193690: loss = 0.09383
Step 193695: loss = 0.07499
Step 193700: loss = 0.24767
Step 193705: loss = 0.15361
Step 193710: loss = 0.05041
Step 193715: loss = 0.10133
Step 193720: loss = 0.23310
Step 193725: loss = 0.11303
Step 193730: loss = 0.09296
Step 193735: loss = 0.09432
Step 193740: loss = 0.14115
Step 193745: loss = 0.11396
Step 193750: loss = 0.17023
Step 193755: loss = 0.08782
Step 193760: loss = 0.03987
Step 193765: loss = 0.11869
Step 193770: loss = 0.15392
Step 193775: loss = 0.29224
Step 193780: loss = 0.10310
Step 193785: loss = 0.11325
Step 193790: loss = 0.22871
Step 193795: loss = 0.04792
Step 193800: loss = 0.04511
Step 193805: loss = 0.17091
Step 193810: loss = 0.12986
Step 193815: loss = 0.05007
Step 193820: loss = 0.10059
Step 193825: loss = 0.23847
Step 193830: loss = 0.08613
Step 193835: loss = 0.03704
Step 193840: loss = 0.08028
Step 193845: loss = 0.24612
Step 193850: loss = 0.15266
Step 193855: loss = 0.08870
Step 193860: loss = 0.03361
Step 193865: loss = 0.05671
Step 193870: loss = 0.07483
Step 193875: loss = 0.08111
Step 193880: loss = 0.19565
Step 193885: loss = 0.08199
Step 193890: loss = 0.10371
Step 193895: loss = 0.16351
Step 193900: loss = 0.05440
Step 193905: loss = 0.10124
Step 193910: loss = 0.09995
Step 193915: loss = 0.10551
Step 193920: loss = 0.10763
Step 193925: loss = 0.12320
Step 193930: loss = 0.21242
Step 193935: loss = 0.05200
Step 193940: loss = 0.15157
Step 193945: loss = 0.07450
Step 193950: loss = 0.06471
Step 193955: loss = 0.06674
Step 193960: loss = 0.10770
Step 193965: loss = 0.07982
Step 193970: loss = 0.07266
Step 193975: loss = 0.11431
Step 193980: loss = 0.09037
Step 193985: loss = 0.10723
Step 193990: loss = 0.04307
Step 193995: loss = 0.17894
Step 194000: loss = 0.04827
Training Data Eval:
  Num examples: 50000, Num correct: 48147, Precision @ 1: 0.9629
('Testing Data Eval: EPOCH->', 195)
  Num examples: 10000, Num correct: 6731, Precision @ 1: 0.6731
Step 194005: loss = 0.04144
Step 194010: loss = 0.06785
Step 194015: loss = 0.13213
Step 194020: loss = 0.33896
Step 194025: loss = 0.02571
Step 194030: loss = 0.08614
Step 194035: loss = 0.03033
Step 194040: loss = 0.10637
Step 194045: loss = 0.02794
Step 194050: loss = 0.36189
Step 194055: loss = 0.10434
Step 194060: loss = 0.05666
Step 194065: loss = 0.06887
Step 194070: loss = 0.13748
Step 194075: loss = 0.17379
Step 194080: loss = 0.08907
Step 194085: loss = 0.05190
Step 194090: loss = 0.10869
Step 194095: loss = 0.14425
Step 194100: loss = 0.17128
Step 194105: loss = 0.05407
Step 194110: loss = 0.04526
Step 194115: loss = 0.14640
Step 194120: loss = 0.13147
Step 194125: loss = 0.05705
Step 194130: loss = 0.14827
Step 194135: loss = 0.37787
Step 194140: loss = 0.04888
Step 194145: loss = 0.31645
Step 194150: loss = 0.10433
Step 194155: loss = 0.23514
Step 194160: loss = 0.05153
Step 194165: loss = 0.09793
Step 194170: loss = 0.06111
Step 194175: loss = 0.05496
Step 194180: loss = 0.10842
Step 194185: loss = 0.16057
Step 194190: loss = 0.17218
Step 194195: loss = 0.07431
Step 194200: loss = 0.08968
Step 194205: loss = 0.28113
Step 194210: loss = 0.15412
Step 194215: loss = 0.23944
Step 194220: loss = 0.10603
Step 194225: loss = 0.13021
Step 194230: loss = 0.06261
Step 194235: loss = 0.04441
Step 194240: loss = 0.05570
Step 194245: loss = 0.05854
Step 194250: loss = 0.16873
Step 194255: loss = 0.26171
Step 194260: loss = 0.26673
Step 194265: loss = 0.07582
Step 194270: loss = 0.04835
Step 194275: loss = 0.07248
Step 194280: loss = 0.03290
Step 194285: loss = 0.22091
Step 194290: loss = 0.04803
Step 194295: loss = 0.03054
Step 194300: loss = 0.24874
Step 194305: loss = 0.08990
Step 194310: loss = 0.05205
Step 194315: loss = 0.14155
Step 194320: loss = 0.11716
Step 194325: loss = 0.09942
Step 194330: loss = 0.05519
Step 194335: loss = 0.15176
Step 194340: loss = 0.08721
Step 194345: loss = 0.11863
Step 194350: loss = 0.04601
Step 194355: loss = 0.06806
Step 194360: loss = 0.05021
Step 194365: loss = 0.06047
Step 194370: loss = 0.09638
Step 194375: loss = 0.07599
Step 194380: loss = 0.04251
Step 194385: loss = 0.07246
Step 194390: loss = 0.10057
Step 194395: loss = 0.04776
Step 194400: loss = 0.05902
Step 194405: loss = 0.04139
Step 194410: loss = 0.15475
Step 194415: loss = 0.04857
Step 194420: loss = 0.02690
Step 194425: loss = 0.16602
Step 194430: loss = 0.07482
Step 194435: loss = 0.02382
Step 194440: loss = 0.10122
Step 194445: loss = 0.18458
Step 194450: loss = 0.08160
Step 194455: loss = 0.08963
Step 194460: loss = 0.05297
Step 194465: loss = 0.03613
Step 194470: loss = 0.18820
Step 194475: loss = 0.09723
Step 194480: loss = 0.01686
Step 194485: loss = 0.09536
Step 194490: loss = 0.08040
Step 194495: loss = 0.02552
Step 194500: loss = 0.17413
Step 194505: loss = 0.11401
Step 194510: loss = 0.23044
Step 194515: loss = 0.14392
Step 194520: loss = 0.11813
Step 194525: loss = 0.20120
Step 194530: loss = 0.29584
Step 194535: loss = 0.04711
Step 194540: loss = 0.04517
Step 194545: loss = 0.03803
Step 194550: loss = 0.03065
Step 194555: loss = 0.03060
Step 194560: loss = 0.06654
Step 194565: loss = 0.06046
Step 194570: loss = 0.03630
Step 194575: loss = 0.15370
Step 194580: loss = 0.21662
Step 194585: loss = 0.17701
Step 194590: loss = 0.14787
Step 194595: loss = 0.04643
Step 194600: loss = 0.09247
Step 194605: loss = 0.22459
Step 194610: loss = 0.11627
Step 194615: loss = 0.07350
Step 194620: loss = 0.46139
Step 194625: loss = 0.05331
Step 194630: loss = 0.06112
Step 194635: loss = 0.25628
Step 194640: loss = 0.08627
Step 194645: loss = 0.04550
Step 194650: loss = 0.12520
Step 194655: loss = 0.39801
Step 194660: loss = 0.12972
Step 194665: loss = 0.10651
Step 194670: loss = 0.14688
Step 194675: loss = 0.05031
Step 194680: loss = 0.06417
Step 194685: loss = 0.19066
Step 194690: loss = 0.09196
Step 194695: loss = 0.10715
Step 194700: loss = 0.04012
Step 194705: loss = 0.09004
Step 194710: loss = 0.08184
Step 194715: loss = 0.10774
Step 194720: loss = 0.06333
Step 194725: loss = 0.02114
Step 194730: loss = 0.02336
Step 194735: loss = 0.21503
Step 194740: loss = 0.04280
Step 194745: loss = 0.11474
Step 194750: loss = 0.15454
Step 194755: loss = 0.04641
Step 194760: loss = 0.12053
Step 194765: loss = 0.11293
Step 194770: loss = 0.09228
Step 194775: loss = 0.06243
Step 194780: loss = 0.13873
Step 194785: loss = 0.06461
Step 194790: loss = 0.15313
Step 194795: loss = 0.13319
Step 194800: loss = 0.02245
Step 194805: loss = 0.26888
Step 194810: loss = 0.03457
Step 194815: loss = 0.43424
Step 194820: loss = 0.02907
Step 194825: loss = 0.21568
Step 194830: loss = 0.32155
Step 194835: loss = 0.02818
Step 194840: loss = 0.08544
Step 194845: loss = 0.07500
Step 194850: loss = 0.09158
Step 194855: loss = 0.07542
Step 194860: loss = 0.08923
Step 194865: loss = 0.05621
Step 194870: loss = 0.10241
Step 194875: loss = 0.03660
Step 194880: loss = 0.11622
Step 194885: loss = 0.15501
Step 194890: loss = 0.07281
Step 194895: loss = 0.14429
Step 194900: loss = 0.07403
Step 194905: loss = 0.04375
Step 194910: loss = 0.05145
Step 194915: loss = 0.06655
Step 194920: loss = 0.03322
Step 194925: loss = 0.06940
Step 194930: loss = 0.07614
Step 194935: loss = 0.07031
Step 194940: loss = 0.06599
Step 194945: loss = 0.05245
Step 194950: loss = 0.08471
Step 194955: loss = 0.05096
Step 194960: loss = 0.08781
Step 194965: loss = 0.25243
Step 194970: loss = 0.10188
Step 194975: loss = 0.09005
Step 194980: loss = 0.02496
Step 194985: loss = 0.13782
Step 194990: loss = 0.16584
Step 194995: loss = 0.13357
Step 195000: loss = 0.01163
Training Data Eval:
  Num examples: 50000, Num correct: 48305, Precision @ 1: 0.9661
('Testing Data Eval: EPOCH->', 196)
  Num examples: 10000, Num correct: 6763, Precision @ 1: 0.6763
Step 195005: loss = 0.18386
Step 195010: loss = 0.03925
Step 195015: loss = 0.11502
Step 195020: loss = 0.01350
Step 195025: loss = 0.10452
Step 195030: loss = 0.08678
Step 195035: loss = 0.12540
Step 195040: loss = 0.20213
Step 195045: loss = 0.06016
Step 195050: loss = 0.06754
Step 195055: loss = 0.16370
Step 195060: loss = 0.07196
Step 195065: loss = 0.06518
Step 195070: loss = 0.13870
Step 195075: loss = 0.09574
Step 195080: loss = 0.09122
Step 195085: loss = 0.15980
Step 195090: loss = 0.09440
Step 195095: loss = 0.10819
Step 195100: loss = 0.12348
Step 195105: loss = 0.13525
Step 195110: loss = 0.03254
Step 195115: loss = 0.23077
Step 195120: loss = 0.11851
Step 195125: loss = 0.08361
Step 195130: loss = 0.04623
Step 195135: loss = 0.07935
Step 195140: loss = 0.22880
Step 195145: loss = 0.15594
Step 195150: loss = 0.05147
Step 195155: loss = 0.05490
Step 195160: loss = 0.32415
Step 195165: loss = 0.07335
Step 195170: loss = 0.16562
Step 195175: loss = 0.10257
Step 195180: loss = 0.08397
Step 195185: loss = 0.03249
Step 195190: loss = 0.03139
Step 195195: loss = 0.29625
Step 195200: loss = 0.23667
Step 195205: loss = 0.20496
Step 195210: loss = 0.12937
Step 195215: loss = 0.12503
Step 195220: loss = 0.04369
Step 195225: loss = 0.03879
Step 195230: loss = 0.16105
Step 195235: loss = 0.07593
Step 195240: loss = 0.04698
Step 195245: loss = 0.05078
Step 195250: loss = 0.11288
Step 195255: loss = 0.35056
Step 195260: loss = 0.05536
Step 195265: loss = 0.28174
Step 195270: loss = 0.04693
Step 195275: loss = 0.09630
Step 195280: loss = 0.05518
Step 195285: loss = 0.10598
Step 195290: loss = 0.05630
Step 195295: loss = 0.10059
Step 195300: loss = 0.05204
Step 195305: loss = 0.08979
Step 195310: loss = 0.13741
Step 195315: loss = 0.11645
Step 195320: loss = 0.02175
Step 195325: loss = 0.03061
Step 195330: loss = 0.12508
Step 195335: loss = 0.06429
Step 195340: loss = 0.10672
Step 195345: loss = 0.14079
Step 195350: loss = 0.07690
Step 195355: loss = 0.09848
Step 195360: loss = 0.10170
Step 195365: loss = 0.09345
Step 195370: loss = 0.19226
Step 195375: loss = 0.10855
Step 195380: loss = 0.06672
Step 195385: loss = 0.10519
Step 195390: loss = 0.04109
Step 195395: loss = 0.09676
Step 195400: loss = 0.01223
Step 195405: loss = 0.05083
Step 195410: loss = 0.03990
Step 195415: loss = 0.08578
Step 195420: loss = 0.37239
Step 195425: loss = 0.24052
Step 195430: loss = 0.17881
Step 195435: loss = 0.07987
Step 195440: loss = 0.18087
Step 195445: loss = 0.04042
Step 195450: loss = 0.06180
Step 195455: loss = 0.12438
Step 195460: loss = 0.16590
Step 195465: loss = 0.05026
Step 195470: loss = 0.33399
Step 195475: loss = 0.05251
Step 195480: loss = 0.21659
Step 195485: loss = 0.02591
Step 195490: loss = 0.11514
Step 195495: loss = 0.11883
Step 195500: loss = 0.05669
Step 195505: loss = 0.19561
Step 195510: loss = 0.13285
Step 195515: loss = 0.06884
Step 195520: loss = 0.11579
Step 195525: loss = 0.10635
Step 195530: loss = 0.32870
Step 195535: loss = 0.05018
Step 195540: loss = 0.23782
Step 195545: loss = 0.10357
Step 195550: loss = 0.07915
Step 195555: loss = 0.07310
Step 195560: loss = 0.06094
Step 195565: loss = 0.03389
Step 195570: loss = 0.04360
Step 195575: loss = 0.05366
Step 195580: loss = 0.02625
Step 195585: loss = 0.07872
Step 195590: loss = 0.04764
Step 195595: loss = 0.03302
Step 195600: loss = 0.32989
Step 195605: loss = 0.04797
Step 195610: loss = 0.03272
Step 195615: loss = 0.04253
Step 195620: loss = 0.12502
Step 195625: loss = 0.16582
Step 195630: loss = 0.26929
Step 195635: loss = 0.04787
Step 195640: loss = 0.02049
Step 195645: loss = 0.26716
Step 195650: loss = 0.24245
Step 195655: loss = 0.17656
Step 195660: loss = 0.02360
Step 195665: loss = 0.06826
Step 195670: loss = 0.12565
Step 195675: loss = 0.26795
Step 195680: loss = 0.02894
Step 195685: loss = 0.06024
Step 195690: loss = 0.06447
Step 195695: loss = 0.09825
Step 195700: loss = 0.15463
Step 195705: loss = 0.07012
Step 195710: loss = 0.06307
Step 195715: loss = 0.14213
Step 195720: loss = 0.02576
Step 195725: loss = 0.18772
Step 195730: loss = 0.06813
Step 195735: loss = 0.07542
Step 195740: loss = 0.07421
Step 195745: loss = 0.04765
Step 195750: loss = 0.02580
Step 195755: loss = 0.12495
Step 195760: loss = 0.23399
Step 195765: loss = 0.02552
Step 195770: loss = 0.05934
Step 195775: loss = 0.03155
Step 195780: loss = 0.13057
Step 195785: loss = 0.12214
Step 195790: loss = 0.05806
Step 195795: loss = 0.13906
Step 195800: loss = 0.20722
Step 195805: loss = 0.02410
Step 195810: loss = 0.15494
Step 195815: loss = 0.06463
Step 195820: loss = 0.30300
Step 195825: loss = 0.34596
Step 195830: loss = 0.13025
Step 195835: loss = 0.16014
Step 195840: loss = 0.05535
Step 195845: loss = 0.15994
Step 195850: loss = 0.04177
Step 195855: loss = 0.15547
Step 195860: loss = 0.11401
Step 195865: loss = 0.14153
Step 195870: loss = 0.29678
Step 195875: loss = 0.02686
Step 195880: loss = 0.18536
Step 195885: loss = 0.05427
Step 195890: loss = 0.05214
Step 195895: loss = 0.09950
Step 195900: loss = 0.03295
Step 195905: loss = 0.05060
Step 195910: loss = 0.06228
Step 195915: loss = 0.16227
Step 195920: loss = 0.13685
Step 195925: loss = 0.16112
Step 195930: loss = 0.12339
Step 195935: loss = 0.03682
Step 195940: loss = 0.03523
Step 195945: loss = 0.06549
Step 195950: loss = 0.06421
Step 195955: loss = 0.08485
Step 195960: loss = 0.11031
Step 195965: loss = 0.02015
Step 195970: loss = 0.06708
Step 195975: loss = 0.20335
Step 195980: loss = 0.19180
Step 195985: loss = 0.05460
Step 195990: loss = 0.05583
Step 195995: loss = 0.07757
Step 196000: loss = 0.10105
Training Data Eval:
  Num examples: 50000, Num correct: 48234, Precision @ 1: 0.9647
('Testing Data Eval: EPOCH->', 197)
  Num examples: 10000, Num correct: 6680, Precision @ 1: 0.6680
Step 196005: loss = 0.02834
Step 196010: loss = 0.06305
Step 196015: loss = 0.12852
Step 196020: loss = 0.19083
Step 196025: loss = 0.04771
Step 196030: loss = 0.04104
Step 196035: loss = 0.09725
Step 196040: loss = 0.10725
Step 196045: loss = 0.05187
Step 196050: loss = 0.13575
Step 196055: loss = 0.03053
Step 196060: loss = 0.09318
Step 196065: loss = 0.08031
Step 196070: loss = 0.24078
Step 196075: loss = 0.09622
Step 196080: loss = 0.17490
Step 196085: loss = 0.02520
Step 196090: loss = 0.16103
Step 196095: loss = 0.04358
Step 196100: loss = 0.04221
Step 196105: loss = 0.04494
Step 196110: loss = 0.03454
Step 196115: loss = 0.14817
Step 196120: loss = 0.04112
Step 196125: loss = 0.03283
Step 196130: loss = 0.03178
Step 196135: loss = 0.25713
Step 196140: loss = 0.14682
Step 196145: loss = 0.05784
Step 196150: loss = 0.24542
Step 196155: loss = 0.07928
Step 196160: loss = 0.11291
Step 196165: loss = 0.05521
Step 196170: loss = 0.08736
Step 196175: loss = 0.09563
Step 196180: loss = 0.07691
Step 196185: loss = 0.18241
Step 196190: loss = 0.06389
Step 196195: loss = 0.02965
Step 196200: loss = 0.07603
Step 196205: loss = 0.30838
Step 196210: loss = 0.04251
Step 196215: loss = 0.12484
Step 196220: loss = 0.20373
Step 196225: loss = 0.11108
Step 196230: loss = 0.06862
Step 196235: loss = 0.05122
Step 196240: loss = 0.03669
Step 196245: loss = 0.09213
Step 196250: loss = 0.09158
Step 196255: loss = 0.08287
Step 196260: loss = 0.11206
Step 196265: loss = 0.12347
Step 196270: loss = 0.12787
Step 196275: loss = 0.24754
Step 196280: loss = 0.10726
Step 196285: loss = 0.49717
Step 196290: loss = 0.23448
Step 196295: loss = 0.15547
Step 196300: loss = 0.40489
Step 196305: loss = 0.17584
Step 196310: loss = 0.04331
Step 196315: loss = 0.29616
Step 196320: loss = 0.09019
Step 196325: loss = 0.10246
Step 196330: loss = 0.33814
Step 196335: loss = 0.11385
Step 196340: loss = 0.09957
Step 196345: loss = 0.06060
Step 196350: loss = 0.05757
Step 196355: loss = 0.09995
Step 196360: loss = 0.25845
Step 196365: loss = 0.08561
Step 196370: loss = 0.10745
Step 196375: loss = 0.05762
Step 196380: loss = 0.18254
Step 196385: loss = 0.13204
Step 196390: loss = 0.10491
Step 196395: loss = 0.09187
Step 196400: loss = 0.21175
Step 196405: loss = 0.21075
Step 196410: loss = 0.05903
Step 196415: loss = 0.02628
Step 196420: loss = 0.01781
Step 196425: loss = 0.04657
Step 196430: loss = 0.14132
Step 196435: loss = 0.19010
Step 196440: loss = 0.10401
Step 196445: loss = 0.03259
Step 196450: loss = 0.07919
Step 196455: loss = 0.15602
Step 196460: loss = 0.11263
Step 196465: loss = 0.06048
Step 196470: loss = 0.11020
Step 196475: loss = 0.17557
Step 196480: loss = 0.10231
Step 196485: loss = 0.02510
Step 196490: loss = 0.13057
Step 196495: loss = 0.08816
Step 196500: loss = 0.03883
Step 196505: loss = 0.06729
Step 196510: loss = 0.08743
Step 196515: loss = 0.19390
Step 196520: loss = 0.10064
Step 196525: loss = 0.12056
Step 196530: loss = 0.30144
Step 196535: loss = 0.11530
Step 196540: loss = 0.14793
Step 196545: loss = 0.03017
Step 196550: loss = 0.09471
Step 196555: loss = 0.08823
Step 196560: loss = 0.10836
Step 196565: loss = 0.20771
Step 196570: loss = 0.20334
Step 196575: loss = 0.29088
Step 196580: loss = 0.03899
Step 196585: loss = 0.11755
Step 196590: loss = 0.07444
Step 196595: loss = 0.23703
Step 196600: loss = 0.05659
Step 196605: loss = 0.04340
Step 196610: loss = 0.03298
Step 196615: loss = 0.05355
Step 196620: loss = 0.09633
Step 196625: loss = 0.03798
Step 196630: loss = 0.10185
Step 196635: loss = 0.05473
Step 196640: loss = 0.05509
Step 196645: loss = 0.10804
Step 196650: loss = 0.07933
Step 196655: loss = 0.27660
Step 196660: loss = 0.05134
Step 196665: loss = 0.23445
Step 196670: loss = 0.02943
Step 196675: loss = 0.08218
Step 196680: loss = 0.05029
Step 196685: loss = 0.05132
Step 196690: loss = 0.05074
Step 196695: loss = 0.01992
Step 196700: loss = 0.24697
Step 196705: loss = 0.12026
Step 196710: loss = 0.13854
Step 196715: loss = 0.10165
Step 196720: loss = 0.04161
Step 196725: loss = 0.18063
Step 196730: loss = 0.10744
Step 196735: loss = 0.13953
Step 196740: loss = 0.22347
Step 196745: loss = 0.05050
Step 196750: loss = 0.03540
Step 196755: loss = 0.12990
Step 196760: loss = 0.12096
Step 196765: loss = 0.13949
Step 196770: loss = 0.11164
Step 196775: loss = 0.04319
Step 196780: loss = 0.12177
Step 196785: loss = 0.08866
Step 196790: loss = 0.03278
Step 196795: loss = 0.05277
Step 196800: loss = 0.13213
Step 196805: loss = 0.24199
Step 196810: loss = 0.14599
Step 196815: loss = 0.16804
Step 196820: loss = 0.09119
Step 196825: loss = 0.02056
Step 196830: loss = 0.15264
Step 196835: loss = 0.10077
Step 196840: loss = 0.11082
Step 196845: loss = 0.18848
Step 196850: loss = 0.22326
Step 196855: loss = 0.13692
Step 196860: loss = 0.10076
Step 196865: loss = 0.04187
Step 196870: loss = 0.06503
Step 196875: loss = 0.03257
Step 196880: loss = 0.18305
Step 196885: loss = 0.18480
Step 196890: loss = 0.05125
Step 196895: loss = 0.15583
Step 196900: loss = 0.10287
Step 196905: loss = 0.03411
Step 196910: loss = 0.02559
Step 196915: loss = 0.07443
Step 196920: loss = 0.11691
Step 196925: loss = 0.10967
Step 196930: loss = 0.05106
Step 196935: loss = 0.10650
Step 196940: loss = 0.05441
Step 196945: loss = 0.12121
Step 196950: loss = 0.17001
Step 196955: loss = 0.03452
Step 196960: loss = 0.09814
Step 196965: loss = 0.07624
Step 196970: loss = 0.12959
Step 196975: loss = 0.02662
Step 196980: loss = 0.01883
Step 196985: loss = 0.11173
Step 196990: loss = 0.22368
Step 196995: loss = 0.09341
Step 197000: loss = 0.03952
Training Data Eval:
  Num examples: 50000, Num correct: 48261, Precision @ 1: 0.9652
('Testing Data Eval: EPOCH->', 198)
  Num examples: 10000, Num correct: 6747, Precision @ 1: 0.6747
Step 197005: loss = 0.05289
Step 197010: loss = 0.08026
Step 197015: loss = 0.21057
Step 197020: loss = 0.07514
Step 197025: loss = 0.08716
Step 197030: loss = 0.08104
Step 197035: loss = 0.15714
Step 197040: loss = 0.02408
Step 197045: loss = 0.25830
Step 197050: loss = 0.14819
Step 197055: loss = 0.12743
Step 197060: loss = 0.14369
Step 197065: loss = 0.23585
Step 197070: loss = 0.05606
Step 197075: loss = 0.04684
Step 197080: loss = 0.11140
Step 197085: loss = 0.03505
Step 197090: loss = 0.03905
Step 197095: loss = 0.04472
Step 197100: loss = 0.18185
Step 197105: loss = 0.08508
Step 197110: loss = 0.14810
Step 197115: loss = 0.03134
Step 197120: loss = 0.13097
Step 197125: loss = 0.14913
Step 197130: loss = 0.18384
Step 197135: loss = 0.06356
Step 197140: loss = 0.05258
Step 197145: loss = 0.20116
Step 197150: loss = 0.25511
Step 197155: loss = 0.20160
Step 197160: loss = 0.16101
Step 197165: loss = 0.04404
Step 197170: loss = 0.05634
Step 197175: loss = 0.01527
Step 197180: loss = 0.10920
Step 197185: loss = 0.05103
Step 197190: loss = 0.14292
Step 197195: loss = 0.18832
Step 197200: loss = 0.12928
Step 197205: loss = 0.07115
Step 197210: loss = 0.04841
Step 197215: loss = 0.06344
Step 197220: loss = 0.02428
Step 197225: loss = 0.29307
Step 197230: loss = 0.08812
Step 197235: loss = 0.06132
Step 197240: loss = 0.08750
Step 197245: loss = 0.06323
Step 197250: loss = 0.24529
Step 197255: loss = 0.07642
Step 197260: loss = 0.11386
Step 197265: loss = 0.17976
Step 197270: loss = 0.14773
Step 197275: loss = 0.06401
Step 197280: loss = 0.10376
Step 197285: loss = 0.04655
Step 197290: loss = 0.05694
Step 197295: loss = 0.09104
Step 197300: loss = 0.19315
Step 197305: loss = 0.09498
Step 197310: loss = 0.04821
Step 197315: loss = 0.07988
Step 197320: loss = 0.03042
Step 197325: loss = 0.03644
Step 197330: loss = 0.00985
Step 197335: loss = 0.07521
Step 197340: loss = 0.02540
Step 197345: loss = 0.01812
Step 197350: loss = 0.02614
Step 197355: loss = 0.28077
Step 197360: loss = 0.16987
Step 197365: loss = 0.34953
Step 197370: loss = 0.05773
Step 197375: loss = 0.04717
Step 197380: loss = 0.13891
Step 197385: loss = 0.03714
Step 197390: loss = 0.13321
Step 197395: loss = 0.04366
Step 197400: loss = 0.06849
Step 197405: loss = 0.06131
Step 197410: loss = 0.02441
Step 197415: loss = 0.09942
Step 197420: loss = 0.06423
Step 197425: loss = 0.04963
Step 197430: loss = 0.21495
Step 197435: loss = 0.12573
Step 197440: loss = 0.05637
Step 197445: loss = 0.06286
Step 197450: loss = 0.26844
Step 197455: loss = 0.12221
Step 197460: loss = 0.06532
Step 197465: loss = 0.05968
Step 197470: loss = 0.23778
Step 197475: loss = 0.05950
Step 197480: loss = 0.09452
Step 197485: loss = 0.07756
Step 197490: loss = 0.23882
Step 197495: loss = 0.07373
Step 197500: loss = 0.02053
Step 197505: loss = 0.01068
Step 197510: loss = 0.04950
Step 197515: loss = 0.20792
Step 197520: loss = 0.20456
Step 197525: loss = 0.17176
Step 197530: loss = 0.06785
Step 197535: loss = 0.04223
Step 197540: loss = 0.09217
Step 197545: loss = 0.11299
Step 197550: loss = 0.08011
Step 197555: loss = 0.04212
Step 197560: loss = 0.07553
Step 197565: loss = 0.05932
Step 197570: loss = 0.09750
Step 197575: loss = 0.09765
Step 197580: loss = 0.13769
Step 197585: loss = 0.20494
Step 197590: loss = 0.10336
Step 197595: loss = 0.12496
Step 197600: loss = 0.03312
Step 197605: loss = 0.03896
Step 197610: loss = 0.06777
Step 197615: loss = 0.22479
Step 197620: loss = 0.20933
Step 197625: loss = 0.03729
Step 197630: loss = 0.06023
Step 197635: loss = 0.15555
Step 197640: loss = 0.05133
Step 197645: loss = 0.12883
Step 197650: loss = 0.13554
Step 197655: loss = 0.09033
Step 197660: loss = 0.10258
Step 197665: loss = 0.14790
Step 197670: loss = 0.04978
Step 197675: loss = 0.07282
Step 197680: loss = 0.10535
Step 197685: loss = 0.22158
Step 197690: loss = 0.05179
Step 197695: loss = 0.05362
Step 197700: loss = 0.05573
Step 197705: loss = 0.14894
Step 197710: loss = 0.18273
Step 197715: loss = 0.08900
Step 197720: loss = 0.21534
Step 197725: loss = 0.07617
Step 197730: loss = 0.05611
Step 197735: loss = 0.05310
Step 197740: loss = 0.07029
Step 197745: loss = 0.07172
Step 197750: loss = 0.08735
Step 197755: loss = 0.10070
Step 197760: loss = 0.06436
Step 197765: loss = 0.11161
Step 197770: loss = 0.03390
Step 197775: loss = 0.07749
Step 197780: loss = 0.07678
Step 197785: loss = 0.07926
Step 197790: loss = 0.06820
Step 197795: loss = 0.21024
Step 197800: loss = 0.08002
Step 197805: loss = 0.09219
Step 197810: loss = 0.21649
Step 197815: loss = 0.13175
Step 197820: loss = 0.02866
Step 197825: loss = 0.33099
Step 197830: loss = 0.05773
Step 197835: loss = 0.14621
Step 197840: loss = 0.01660
Step 197845: loss = 0.07790
Step 197850: loss = 0.07754
Step 197855: loss = 0.16274
Step 197860: loss = 0.12119
Step 197865: loss = 0.03858
Step 197870: loss = 0.12964
Step 197875: loss = 0.11885
Step 197880: loss = 0.09998
Step 197885: loss = 0.08733
Step 197890: loss = 0.06880
Step 197895: loss = 0.05965
Step 197900: loss = 0.02433
Step 197905: loss = 0.02267
Step 197910: loss = 0.01852
Step 197915: loss = 0.17886
Step 197920: loss = 0.21039
Step 197925: loss = 0.13043
Step 197930: loss = 0.07412
Step 197935: loss = 0.08467
Step 197940: loss = 0.15624
Step 197945: loss = 0.17950
Step 197950: loss = 0.15840
Step 197955: loss = 0.16143
Step 197960: loss = 0.22425
Step 197965: loss = 0.13439
Step 197970: loss = 0.06579
Step 197975: loss = 0.12320
Step 197980: loss = 0.08293
Step 197985: loss = 0.08629
Step 197990: loss = 0.25846
Step 197995: loss = 0.23389
Step 198000: loss = 0.21014
Training Data Eval:
  Num examples: 50000, Num correct: 47802, Precision @ 1: 0.9560
('Testing Data Eval: EPOCH->', 199)
  Num examples: 10000, Num correct: 6721, Precision @ 1: 0.6721
Step 198005: loss = 0.13263
Step 198010: loss = 0.18000
Step 198015: loss = 0.12514
Step 198020: loss = 0.11800
Step 198025: loss = 0.08806
Step 198030: loss = 0.35559
Step 198035: loss = 0.10045
Step 198040: loss = 0.06691
Step 198045: loss = 0.11622
Step 198050: loss = 0.16360
Step 198055: loss = 0.09693
Step 198060: loss = 0.03392
Step 198065: loss = 0.03376
Step 198070: loss = 0.08878
Step 198075: loss = 0.03909
Step 198080: loss = 0.08473
Step 198085: loss = 0.07202
Step 198090: loss = 0.21441
Step 198095: loss = 0.11627
Step 198100: loss = 0.26261
Step 198105: loss = 0.16790
Step 198110: loss = 0.10023
Step 198115: loss = 0.09048
Step 198120: loss = 0.12241
Step 198125: loss = 0.15072
Step 198130: loss = 0.05124
Step 198135: loss = 0.08067
Step 198140: loss = 0.07268
Step 198145: loss = 0.14966
Step 198150: loss = 0.04602
Step 198155: loss = 0.13344
Step 198160: loss = 0.02404
Step 198165: loss = 0.09247
Step 198170: loss = 0.11303
Step 198175: loss = 0.12041
Step 198180: loss = 0.07435
Step 198185: loss = 0.13210
Step 198190: loss = 0.12066
Step 198195: loss = 0.03378
Step 198200: loss = 0.03811
Step 198205: loss = 0.07937
Step 198210: loss = 0.04880
Step 198215: loss = 0.07749
Step 198220: loss = 0.43117
Step 198225: loss = 0.25595
Step 198230: loss = 0.09338
Step 198235: loss = 0.04766
Step 198240: loss = 0.07451
Step 198245: loss = 0.08787
Step 198250: loss = 0.09752
Step 198255: loss = 0.16406
Step 198260: loss = 0.06681
Step 198265: loss = 0.05872
Step 198270: loss = 0.09620
Step 198275: loss = 0.07278
Step 198280: loss = 0.08093
Step 198285: loss = 0.12524
Step 198290: loss = 0.12482
Step 198295: loss = 0.13581
Step 198300: loss = 0.21754
Step 198305: loss = 0.13400
Step 198310: loss = 0.16342
Step 198315: loss = 0.03769
Step 198320: loss = 0.02480
Step 198325: loss = 0.04841
Step 198330: loss = 0.10611
Step 198335: loss = 0.04301
Step 198340: loss = 0.10482
Step 198345: loss = 0.03403
Step 198350: loss = 0.14069
Step 198355: loss = 0.05946
Step 198360: loss = 0.08948
Step 198365: loss = 0.07241
Step 198370: loss = 0.13560
Step 198375: loss = 0.09260
Step 198380: loss = 0.06875
Step 198385: loss = 0.05420
Step 198390: loss = 0.14627
Step 198395: loss = 0.16929
Step 198400: loss = 0.09565
Step 198405: loss = 0.08921
Step 198410: loss = 0.14555
Step 198415: loss = 0.20709
Step 198420: loss = 0.03453
Step 198425: loss = 0.02783
Step 198430: loss = 0.13528
Step 198435: loss = 0.10358
Step 198440: loss = 0.05855
Step 198445: loss = 0.07077
Step 198450: loss = 0.07084
Step 198455: loss = 0.29542
Step 198460: loss = 0.42539
Step 198465: loss = 0.10624
Step 198470: loss = 0.05550
Step 198475: loss = 0.05241
Step 198480: loss = 0.16607
Step 198485: loss = 0.11374
Step 198490: loss = 0.09757
Step 198495: loss = 0.12961
Step 198500: loss = 0.09760
Step 198505: loss = 0.17996
Step 198510: loss = 0.05505
Step 198515: loss = 0.08140
Step 198520: loss = 0.04772
Step 198525: loss = 0.12524
Step 198530: loss = 0.09039
Step 198535: loss = 0.05256
Step 198540: loss = 0.02119
Step 198545: loss = 0.06952
Step 198550: loss = 0.27543
Step 198555: loss = 0.04526
Step 198560: loss = 0.06848
Step 198565: loss = 0.23292
Step 198570: loss = 0.25216
Step 198575: loss = 0.19052
Step 198580: loss = 0.12619
Step 198585: loss = 0.10374
Step 198590: loss = 0.10624
Step 198595: loss = 0.22462
Step 198600: loss = 0.05184
Step 198605: loss = 0.07510
Step 198610: loss = 0.20983
Step 198615: loss = 0.06927
Step 198620: loss = 0.25106
Step 198625: loss = 0.09568
Step 198630: loss = 0.13021
Step 198635: loss = 0.02494
Step 198640: loss = 0.06582
Step 198645: loss = 0.38030
Step 198650: loss = 0.23881
Step 198655: loss = 0.04193
Step 198660: loss = 0.17717
Step 198665: loss = 0.06246
Step 198670: loss = 0.12161
Step 198675: loss = 0.18504
Step 198680: loss = 0.03369
Step 198685: loss = 0.04320
Step 198690: loss = 0.05015
Step 198695: loss = 0.17655
Step 198700: loss = 0.12932
Step 198705: loss = 0.07883
Step 198710: loss = 0.03644
Step 198715: loss = 0.22663
Step 198720: loss = 0.19656
Step 198725: loss = 0.08365
Step 198730: loss = 0.17914
Step 198735: loss = 0.09249
Step 198740: loss = 0.02331
Step 198745: loss = 0.05049
Step 198750: loss = 0.04973
Step 198755: loss = 0.08888
Step 198760: loss = 0.11160
Step 198765: loss = 0.09639
Step 198770: loss = 0.02904
Step 198775: loss = 0.08492
Step 198780: loss = 0.08736
Step 198785: loss = 0.21703
Step 198790: loss = 0.05715
Step 198795: loss = 0.09026
Step 198800: loss = 0.02411
Step 198805: loss = 0.03061
Step 198810: loss = 0.11038
Step 198815: loss = 0.04714
Step 198820: loss = 0.02599
Step 198825: loss = 0.06602
Step 198830: loss = 0.04776
Step 198835: loss = 0.06574
Step 198840: loss = 0.08641
Step 198845: loss = 0.03305
Step 198850: loss = 0.06923
Step 198855: loss = 0.09479
Step 198860: loss = 0.05554
Step 198865: loss = 0.05624
Step 198870: loss = 0.06122
Step 198875: loss = 0.02692
Step 198880: loss = 0.07853
Step 198885: loss = 0.06344
Step 198890: loss = 0.54586
Step 198895: loss = 0.05337
Step 198900: loss = 0.09474
Step 198905: loss = 0.09583
Step 198910: loss = 0.04604
Step 198915: loss = 0.01856
Step 198920: loss = 0.13307
Step 198925: loss = 0.11708
Step 198930: loss = 0.09148
Step 198935: loss = 0.11162
Step 198940: loss = 0.10486
Step 198945: loss = 0.12709
Step 198950: loss = 0.06232
Step 198955: loss = 0.07675
Step 198960: loss = 0.09834
Step 198965: loss = 0.08349
Step 198970: loss = 0.05190
Step 198975: loss = 0.05565
Step 198980: loss = 0.02913
Step 198985: loss = 0.10293
Step 198990: loss = 0.20223
Step 198995: loss = 0.06451
Step 199000: loss = 0.01567
Training Data Eval:
  Num examples: 50000, Num correct: 48222, Precision @ 1: 0.9644
('Testing Data Eval: EPOCH->', 200)
  Num examples: 10000, Num correct: 6724, Precision @ 1: 0.6724
Step 199005: loss = 0.11022
Step 199010: loss = 0.20836
Step 199015: loss = 0.16710
Step 199020: loss = 0.16447
Step 199025: loss = 0.19121
Step 199030: loss = 0.07728
Step 199035: loss = 0.02998
Step 199040: loss = 0.11290
Step 199045: loss = 0.16412
Step 199050: loss = 0.19469
Step 199055: loss = 0.32240
Step 199060: loss = 0.07407
Step 199065: loss = 0.18896
Step 199070: loss = 0.03843
Step 199075: loss = 0.18167
Step 199080: loss = 0.09430
Step 199085: loss = 0.15017
Step 199090: loss = 0.18511
Step 199095: loss = 0.02376
Step 199100: loss = 0.01780
Step 199105: loss = 0.03033
Step 199110: loss = 0.06841
Step 199115: loss = 0.16941
Step 199120: loss = 0.11549
Step 199125: loss = 0.04115
Step 199130: loss = 0.21857
Step 199135: loss = 0.08068
Step 199140: loss = 0.06791
Step 199145: loss = 0.05017
Step 199150: loss = 0.06125
Step 199155: loss = 0.23458
Step 199160: loss = 0.12595
Step 199165: loss = 0.15877
Step 199170: loss = 0.05592
Step 199175: loss = 0.07913
Step 199180: loss = 0.06386
Step 199185: loss = 0.11987
Step 199190: loss = 0.15328
Step 199195: loss = 0.03579
Step 199200: loss = 0.06495
Step 199205: loss = 0.03997
Step 199210: loss = 0.03400
Step 199215: loss = 0.23792
Step 199220: loss = 0.10096
Step 199225: loss = 0.20193
Step 199230: loss = 0.13721
Step 199235: loss = 0.06444
Step 199240: loss = 0.21411
Step 199245: loss = 0.06632
Step 199250: loss = 0.13350
Step 199255: loss = 0.13695
Step 199260: loss = 0.20014
Step 199265: loss = 0.13848
Step 199270: loss = 0.09841
Step 199275: loss = 0.08423
Step 199280: loss = 0.10414
Step 199285: loss = 0.07418
Step 199290: loss = 0.18211
Step 199295: loss = 0.04688
Step 199300: loss = 0.08346
Step 199305: loss = 0.09962
Step 199310: loss = 0.18216
Step 199315: loss = 0.02259
Step 199320: loss = 0.13513
Step 199325: loss = 0.36476
Step 199330: loss = 0.04219
Step 199335: loss = 0.03847
Step 199340: loss = 0.06701
Step 199345: loss = 0.03754
Step 199350: loss = 0.11107
Step 199355: loss = 0.17938
Step 199360: loss = 0.02322
Step 199365: loss = 0.19818
Step 199370: loss = 0.22470
Step 199375: loss = 0.05490
Step 199380: loss = 0.06499
Step 199385: loss = 0.01435
Step 199390: loss = 0.16851
Step 199395: loss = 0.00770
Step 199400: loss = 0.10102
Step 199405: loss = 0.12069
Step 199410: loss = 0.06251
Step 199415: loss = 0.07571
Step 199420: loss = 0.17948
Step 199425: loss = 0.08636
Step 199430: loss = 0.07733
Step 199435: loss = 0.18599
Step 199440: loss = 0.04257
Step 199445: loss = 0.06926
Step 199450: loss = 0.00756
Step 199455: loss = 0.09252
Step 199460: loss = 0.06112
Step 199465: loss = 0.05480
Step 199470: loss = 0.15179
Step 199475: loss = 0.19929
Step 199480: loss = 0.07224
Step 199485: loss = 0.18569
Step 199490: loss = 0.09238
Step 199495: loss = 0.07123
Step 199500: loss = 0.05255
Step 199505: loss = 0.12223
Step 199510: loss = 0.16247
Step 199515: loss = 0.09325
Step 199520: loss = 0.12154
Step 199525: loss = 0.05396
Step 199530: loss = 0.03385
Step 199535: loss = 0.16837
Step 199540: loss = 0.23288
Step 199545: loss = 0.03451
Step 199550: loss = 0.15167
Step 199555: loss = 0.02661
Step 199560: loss = 0.12739
Step 199565: loss = 0.03427
Step 199570: loss = 0.11012
Step 199575: loss = 0.13718
Step 199580: loss = 0.04417
Step 199585: loss = 0.04287
Step 199590: loss = 0.03486
Step 199595: loss = 0.17845
Step 199600: loss = 0.09460
Step 199605: loss = 0.09872
Step 199610: loss = 0.17878
Step 199615: loss = 0.14620
Step 199620: loss = 0.05952
Step 199625: loss = 0.10266
Step 199630: loss = 0.10102
Step 199635: loss = 0.10705
Step 199640: loss = 0.03479
Step 199645: loss = 0.01907
Step 199650: loss = 0.11663
Step 199655: loss = 0.02506
Step 199660: loss = 0.17039
Step 199665: loss = 0.16954
Step 199670: loss = 0.06617
Step 199675: loss = 0.18423
Step 199680: loss = 0.14956
Step 199685: loss = 0.06377
Step 199690: loss = 0.14649
Step 199695: loss = 0.13348
Step 199700: loss = 0.04418
Step 199705: loss = 0.17092
Step 199710: loss = 0.02927
Step 199715: loss = 0.09325
Step 199720: loss = 0.05974
Step 199725: loss = 0.14086
Step 199730: loss = 0.10682
Step 199735: loss = 0.07464
Step 199740: loss = 0.19199
Step 199745: loss = 0.10690
Step 199750: loss = 0.06783
Step 199755: loss = 0.10062
Step 199760: loss = 0.03656
Step 199765: loss = 0.12592
Step 199770: loss = 0.11685
Step 199775: loss = 0.03703
Step 199780: loss = 0.11480
Step 199785: loss = 0.07585
Step 199790: loss = 0.08344
Step 199795: loss = 0.02999
Step 199800: loss = 0.21727
Step 199805: loss = 0.10745
Step 199810: loss = 0.08744
Step 199815: loss = 0.04906
Step 199820: loss = 0.08855
Step 199825: loss = 0.09172
Step 199830: loss = 0.08282
Step 199835: loss = 0.27813
Step 199840: loss = 0.08586
Step 199845: loss = 0.08326
Step 199850: loss = 0.07584
Step 199855: loss = 0.07299
Step 199860: loss = 0.02067
Step 199865: loss = 0.28216
Step 199870: loss = 0.11353
Step 199875: loss = 0.05408
Step 199880: loss = 0.20121
Step 199885: loss = 0.06182
Step 199890: loss = 0.05168
Step 199895: loss = 0.11374
Step 199900: loss = 0.05131
Step 199905: loss = 0.24141
Step 199910: loss = 0.11762
Step 199915: loss = 0.16207
Step 199920: loss = 0.11069
Step 199925: loss = 0.20621
Step 199930: loss = 0.11701
Step 199935: loss = 0.08754
Step 199940: loss = 0.20402
Step 199945: loss = 0.07733
Step 199950: loss = 0.29798
Step 199955: loss = 0.12856
Step 199960: loss = 0.06081
Step 199965: loss = 0.07337
Step 199970: loss = 0.04566
Step 199975: loss = 0.04786
Step 199980: loss = 0.07743
Step 199985: loss = 0.12609
Step 199990: loss = 0.06694
Step 199995: loss = 0.04619
Step 200000: loss = 0.08197
Training Data Eval:
  Num examples: 50000, Num correct: 48272, Precision @ 1: 0.9654
('Testing Data Eval: EPOCH->', 201)
  Num examples: 10000, Num correct: 6717, Precision @ 1: 0.6717
Step 200005: loss = 0.19532
Step 200010: loss = 0.02786
Step 200015: loss = 0.04725
Step 200020: loss = 0.10646
Step 200025: loss = 0.03761
Step 200030: loss = 0.04288
Step 200035: loss = 0.09327
Step 200040: loss = 0.06492
Step 200045: loss = 0.06371
Step 200050: loss = 0.08043
Step 200055: loss = 0.05324
Step 200060: loss = 0.03951
Step 200065: loss = 0.12119
Step 200070: loss = 0.06751
Step 200075: loss = 0.04959
Step 200080: loss = 0.10825
Step 200085: loss = 0.07521
Step 200090: loss = 0.10257
Step 200095: loss = 0.03042
Step 200100: loss = 0.04891
Step 200105: loss = 0.03973
Step 200110: loss = 0.13367
Step 200115: loss = 0.12610
Step 200120: loss = 0.07135
Step 200125: loss = 0.08071
Step 200130: loss = 0.22744
Step 200135: loss = 0.08054
Step 200140: loss = 0.07392
Step 200145: loss = 0.05151
Step 200150: loss = 0.05150
Step 200155: loss = 0.08976
Step 200160: loss = 0.10174
Step 200165: loss = 0.11589
Step 200170: loss = 0.10269
Step 200175: loss = 0.07281
Step 200180: loss = 0.05187
Step 200185: loss = 0.06338
Step 200190: loss = 0.04277
Step 200195: loss = 0.03200
Step 200200: loss = 0.07245
Step 200205: loss = 0.61279
Step 200210: loss = 0.08733
Step 200215: loss = 0.08973
Step 200220: loss = 0.05742
Step 200225: loss = 0.05225
Step 200230: loss = 0.03580
Step 200235: loss = 0.03039
Step 200240: loss = 0.03201
Step 200245: loss = 0.13690
Step 200250: loss = 0.14528
Step 200255: loss = 0.08949
Step 200260: loss = 0.07281
Step 200265: loss = 0.07878
Step 200270: loss = 0.08754
Step 200275: loss = 0.12223
Step 200280: loss = 0.20207
Step 200285: loss = 0.24578
Step 200290: loss = 0.18145
Step 200295: loss = 0.28862
Step 200300: loss = 0.07844
Step 200305: loss = 0.04954
Step 200310: loss = 0.16259
Step 200315: loss = 0.16402
Step 200320: loss = 0.16437
Step 200325: loss = 0.04099
Step 200330: loss = 0.07434
Step 200335: loss = 0.12256
Step 200340: loss = 0.06601
Step 200345: loss = 0.02828
Step 200350: loss = 0.04856
Step 200355: loss = 0.02323
Step 200360: loss = 0.15883
Step 200365: loss = 0.07561
Step 200370: loss = 0.15663
Step 200375: loss = 0.18197
Step 200380: loss = 0.32712
Step 200385: loss = 0.05728
Step 200390: loss = 0.03816
Step 200395: loss = 0.05839
Step 200400: loss = 0.14059
Step 200405: loss = 0.19162
Step 200410: loss = 0.25052
Step 200415: loss = 0.13200
Step 200420: loss = 0.03568
Step 200425: loss = 0.02461
Step 200430: loss = 0.18181
Step 200435: loss = 0.08678
Step 200440: loss = 0.01604
Step 200445: loss = 0.04183
Step 200450: loss = 0.02915
Step 200455: loss = 0.08787
Step 200460: loss = 0.03355
Step 200465: loss = 0.08316
Step 200470: loss = 0.05420
Step 200475: loss = 0.08638
Step 200480: loss = 0.04370
Step 200485: loss = 0.05138
Step 200490: loss = 0.09679
Step 200495: loss = 0.16896
Step 200500: loss = 0.19521
Step 200505: loss = 0.06542
Step 200510: loss = 0.18463
Step 200515: loss = 0.08797
Step 200520: loss = 0.08368
Step 200525: loss = 0.06349
Step 200530: loss = 0.17777
Step 200535: loss = 0.22478
Step 200540: loss = 0.15405
Step 200545: loss = 0.04673
Step 200550: loss = 0.10640
Step 200555: loss = 0.18643
Step 200560: loss = 0.04838
Step 200565: loss = 0.04154
Step 200570: loss = 0.05100
Step 200575: loss = 0.07724
Step 200580: loss = 0.03034
Step 200585: loss = 0.04744
Step 200590: loss = 0.11704
Step 200595: loss = 0.07334
Step 200600: loss = 0.13512
Step 200605: loss = 0.07579
Step 200610: loss = 0.07829
Step 200615: loss = 0.04618
Step 200620: loss = 0.16465
Step 200625: loss = 0.14039
Step 200630: loss = 0.13944
Step 200635: loss = 0.09534
Step 200640: loss = 0.14429
Step 200645: loss = 0.16257
Step 200650: loss = 0.13628
Step 200655: loss = 0.10382
Step 200660: loss = 0.34887
Step 200665: loss = 0.05844
Step 200670: loss = 0.02952
Step 200675: loss = 0.20788
Step 200680: loss = 0.21331
Step 200685: loss = 0.19310
Step 200690: loss = 0.03539
Step 200695: loss = 0.10555
Step 200700: loss = 0.12772
Step 200705: loss = 0.20385
Step 200710: loss = 0.05390
Step 200715: loss = 0.09126
Step 200720: loss = 0.05537
Step 200725: loss = 0.24180
Step 200730: loss = 0.11998
Step 200735: loss = 0.06620
Step 200740: loss = 0.05194
Step 200745: loss = 0.15375
Step 200750: loss = 0.05824
Step 200755: loss = 0.08708
Step 200760: loss = 0.11071
Step 200765: loss = 0.05470
Step 200770: loss = 0.03715
Step 200775: loss = 0.12691
Step 200780: loss = 0.05294
Step 200785: loss = 0.10132
Step 200790: loss = 0.04605
Step 200795: loss = 0.05669
Step 200800: loss = 0.12292
Step 200805: loss = 0.17209
Step 200810: loss = 0.21489
Step 200815: loss = 0.02628
Step 200820: loss = 0.06655
Step 200825: loss = 0.10050
Step 200830: loss = 0.19631
Step 200835: loss = 0.08265
Step 200840: loss = 0.08732
Step 200845: loss = 0.01788
Step 200850: loss = 0.16383
Step 200855: loss = 0.07761
Step 200860: loss = 0.18949
Step 200865: loss = 0.33312
Step 200870: loss = 0.13718
Step 200875: loss = 0.17267
Step 200880: loss = 0.18103
Step 200885: loss = 0.05272
Step 200890: loss = 0.22546
Step 200895: loss = 0.10852
Step 200900: loss = 0.15697
Step 200905: loss = 0.03723
Step 200910: loss = 0.31925
Step 200915: loss = 0.15030
Step 200920: loss = 0.07897
Step 200925: loss = 0.09922
Step 200930: loss = 0.08046
Step 200935: loss = 0.20056
Step 200940: loss = 0.03017
Step 200945: loss = 0.06651
Step 200950: loss = 0.44290
Step 200955: loss = 0.14888
Step 200960: loss = 0.13445
Step 200965: loss = 0.08800
Step 200970: loss = 0.06224
Step 200975: loss = 0.06881
Step 200980: loss = 0.23439
Step 200985: loss = 0.09474
Step 200990: loss = 0.08655
Step 200995: loss = 0.09294
Step 201000: loss = 0.12278
Training Data Eval:
  Num examples: 50000, Num correct: 48310, Precision @ 1: 0.9662
('Testing Data Eval: EPOCH->', 202)
  Num examples: 10000, Num correct: 6725, Precision @ 1: 0.6725
Step 201005: loss = 0.07984
Step 201010: loss = 0.42738
Step 201015: loss = 0.07622
Step 201020: loss = 0.11571
Step 201025: loss = 0.10544
Step 201030: loss = 0.09732
Step 201035: loss = 0.07886
Step 201040: loss = 0.05053
Step 201045: loss = 0.00877
Step 201050: loss = 0.04799
Step 201055: loss = 0.19984
Step 201060: loss = 0.06828
Step 201065: loss = 0.07135
Step 201070: loss = 0.09851
Step 201075: loss = 0.06946
Step 201080: loss = 0.09377
Step 201085: loss = 0.06890
Step 201090: loss = 0.03689
Step 201095: loss = 0.06119
Step 201100: loss = 0.16482
Step 201105: loss = 0.14973
Step 201110: loss = 0.03155
Step 201115: loss = 0.13630
Step 201120: loss = 0.15181
Step 201125: loss = 0.11837
Step 201130: loss = 0.10334
Step 201135: loss = 0.27645
Step 201140: loss = 0.06296
Step 201145: loss = 0.21326
Step 201150: loss = 0.05280
Step 201155: loss = 0.05730
Step 201160: loss = 0.18120
Step 201165: loss = 0.33128
Step 201170: loss = 0.06427
Step 201175: loss = 0.15816
Step 201180: loss = 0.10947
Step 201185: loss = 0.26787
Step 201190: loss = 0.10941
Step 201195: loss = 0.15634
Step 201200: loss = 0.08615
Step 201205: loss = 0.11448
Step 201210: loss = 0.12387
Step 201215: loss = 0.02707
Step 201220: loss = 0.07509
Step 201225: loss = 0.06449
Step 201230: loss = 0.09051
Step 201235: loss = 0.03694
Step 201240: loss = 0.11060
Step 201245: loss = 0.17659
Step 201250: loss = 0.03256
Step 201255: loss = 0.11695
Step 201260: loss = 0.15571
Step 201265: loss = 0.09962
Step 201270: loss = 0.03698
Step 201275: loss = 0.12436
Step 201280: loss = 0.02146
Step 201285: loss = 0.02813
Step 201290: loss = 0.14768
Step 201295: loss = 0.05268
Step 201300: loss = 0.06827
Step 201305: loss = 0.15355
Step 201310: loss = 0.12322
Step 201315: loss = 0.07215
Step 201320: loss = 0.10954
Step 201325: loss = 0.13153
Step 201330: loss = 0.12598
Step 201335: loss = 0.11161
Step 201340: loss = 0.03115
Step 201345: loss = 0.24366
Step 201350: loss = 0.06955
Step 201355: loss = 0.14479
Step 201360: loss = 0.17599
Step 201365: loss = 0.11368
Step 201370: loss = 0.11915
Step 201375: loss = 0.17581
Step 201380: loss = 0.13496
Step 201385: loss = 0.12908
Step 201390: loss = 0.08326
Step 201395: loss = 0.07623
Step 201400: loss = 0.25019
Step 201405: loss = 0.19442
Step 201410: loss = 0.12259
Step 201415: loss = 0.21084
Step 201420: loss = 0.09560
Step 201425: loss = 0.04393
Step 201430: loss = 0.03082
Step 201435: loss = 0.08327
Step 201440: loss = 0.25644
Step 201445: loss = 0.17035
Step 201450: loss = 0.09416
Step 201455: loss = 0.06526
Step 201460: loss = 0.11674
Step 201465: loss = 0.06008
Step 201470: loss = 0.13085
Step 201475: loss = 0.10226
Step 201480: loss = 0.14979
Step 201485: loss = 0.07023
Step 201490: loss = 0.03606
Step 201495: loss = 0.18152
Step 201500: loss = 0.07612
Step 201505: loss = 0.19061
Step 201510: loss = 0.15637
Step 201515: loss = 0.08222
Step 201520: loss = 0.04634
Step 201525: loss = 0.01454
Step 201530: loss = 0.09057
Step 201535: loss = 0.11064
Step 201540: loss = 0.15087
Step 201545: loss = 0.14145
Step 201550: loss = 0.06012
Step 201555: loss = 0.03244
Step 201560: loss = 0.14905
Step 201565: loss = 0.05790
Step 201570: loss = 0.08108
Step 201575: loss = 0.02042
Step 201580: loss = 0.15940
Step 201585: loss = 0.11050
Step 201590: loss = 0.07176
Step 201595: loss = 0.03358
Step 201600: loss = 0.06187
Step 201605: loss = 0.08796
Step 201610: loss = 0.04613
Step 201615: loss = 0.03061
Step 201620: loss = 0.02423
Step 201625: loss = 0.19537
Step 201630: loss = 0.06757
Step 201635: loss = 0.06663
Step 201640: loss = 0.08328
Step 201645: loss = 0.10003
Step 201650: loss = 0.14849
Step 201655: loss = 0.10961
Step 201660: loss = 0.14713
Step 201665: loss = 0.04726
Step 201670: loss = 0.14107
Step 201675: loss = 0.21341
Step 201680: loss = 0.12287
Step 201685: loss = 0.02005
Step 201690: loss = 0.19921
Step 201695: loss = 0.15985
Step 201700: loss = 0.09274
Step 201705: loss = 0.14858
Step 201710: loss = 0.08286
Step 201715: loss = 0.18824
Step 201720: loss = 0.24367
Step 201725: loss = 0.05012
Step 201730: loss = 0.17770
Step 201735: loss = 0.23018
Step 201740: loss = 0.09130
Step 201745: loss = 0.17165
Step 201750: loss = 0.16943
Step 201755: loss = 0.06874
Step 201760: loss = 0.07611
Step 201765: loss = 0.15675
Step 201770: loss = 0.08744
Step 201775: loss = 0.25995
Step 201780: loss = 0.11390
Step 201785: loss = 0.04337
Step 201790: loss = 0.15522
Step 201795: loss = 0.23817
Step 201800: loss = 0.22780
Step 201805: loss = 0.11644
Step 201810: loss = 0.06547
Step 201815: loss = 0.12673
Step 201820: loss = 0.11968
Step 201825: loss = 0.10841
Step 201830: loss = 0.09292
Step 201835: loss = 0.20862
Step 201840: loss = 0.11964
Step 201845: loss = 0.27754
Step 201850: loss = 0.11331
Step 201855: loss = 0.06401
Step 201860: loss = 0.18548
Step 201865: loss = 0.08009
Step 201870: loss = 0.10854
Step 201875: loss = 0.12444
Step 201880: loss = 0.06707
Step 201885: loss = 0.04752
Step 201890: loss = 0.03544
Step 201895: loss = 0.05812
Step 201900: loss = 0.81088
Step 201905: loss = 0.11109
Step 201910: loss = 0.06666
Step 201915: loss = 0.03500
Step 201920: loss = 0.07632
Step 201925: loss = 0.03622
Step 201930: loss = 0.11491
Step 201935: loss = 0.13037
Step 201940: loss = 0.11026
Step 201945: loss = 0.02336
Step 201950: loss = 0.14024
Step 201955: loss = 0.18162
Step 201960: loss = 0.16372
Step 201965: loss = 0.14473
Step 201970: loss = 0.07610
Step 201975: loss = 0.03626
Step 201980: loss = 0.07850
Step 201985: loss = 0.03301
Step 201990: loss = 0.13403
Step 201995: loss = 0.08499
Step 202000: loss = 0.12101
Training Data Eval:
  Num examples: 50000, Num correct: 48286, Precision @ 1: 0.9657
('Testing Data Eval: EPOCH->', 203)
  Num examples: 10000, Num correct: 6709, Precision @ 1: 0.6709
Step 202005: loss = 0.04691
Step 202010: loss = 0.12568
Step 202015: loss = 0.07543
Step 202020: loss = 0.13119
Step 202025: loss = 0.28329
Step 202030: loss = 0.12604
Step 202035: loss = 0.02229
Step 202040: loss = 0.08729
Step 202045: loss = 0.06514
Step 202050: loss = 0.03441
Step 202055: loss = 0.06819
Step 202060: loss = 0.10396
Step 202065: loss = 0.08794
Step 202070: loss = 0.10264
Step 202075: loss = 0.05289
Step 202080: loss = 0.08340
Step 202085: loss = 0.14201
Step 202090: loss = 0.05875
Step 202095: loss = 0.03484
Step 202100: loss = 0.11469
Step 202105: loss = 0.16660
Step 202110: loss = 0.17382
Step 202115: loss = 0.04514
Step 202120: loss = 0.09172
Step 202125: loss = 0.05960
Step 202130: loss = 0.13615
Step 202135: loss = 0.04841
Step 202140: loss = 0.07541
Step 202145: loss = 0.21477
Step 202150: loss = 0.15363
Step 202155: loss = 0.04687
Step 202160: loss = 0.06058
Step 202165: loss = 0.04571
Step 202170: loss = 0.10618
Step 202175: loss = 0.03456
Step 202180: loss = 0.02854
Step 202185: loss = 0.16159
Step 202190: loss = 0.23118
Step 202195: loss = 0.02266
Step 202200: loss = 0.07223
Step 202205: loss = 0.02833
Step 202210: loss = 0.05510
Step 202215: loss = 0.03238
Step 202220: loss = 0.05945
Step 202225: loss = 0.07266
Step 202230: loss = 0.05333
Step 202235: loss = 0.34314
Step 202240: loss = 0.03474
Step 202245: loss = 0.04878
Step 202250: loss = 0.03554
Step 202255: loss = 0.08674
Step 202260: loss = 0.05688
Step 202265: loss = 0.07150
Step 202270: loss = 0.11634
Step 202275: loss = 0.06847
Step 202280: loss = 0.10049
Step 202285: loss = 0.01483
Step 202290: loss = 0.10051
Step 202295: loss = 0.05793
Step 202300: loss = 0.16817
Step 202305: loss = 0.07715
Step 202310: loss = 0.09417
Step 202315: loss = 0.11333
Step 202320: loss = 0.22865
Step 202325: loss = 0.02985
Step 202330: loss = 0.09948
Step 202335: loss = 0.08029
Step 202340: loss = 0.09473
Step 202345: loss = 0.04892
Step 202350: loss = 0.12600
Step 202355: loss = 0.06287
Step 202360: loss = 0.04544
Step 202365: loss = 0.31008
Step 202370: loss = 0.05916
Step 202375: loss = 0.10555
Step 202380: loss = 0.13407
Step 202385: loss = 0.09047
Step 202390: loss = 0.08750
Step 202395: loss = 0.11712
Step 202400: loss = 0.05086
Step 202405: loss = 0.19494
Step 202410: loss = 0.04833
Step 202415: loss = 0.01854
Step 202420: loss = 0.14206
Step 202425: loss = 0.24262
Step 202430: loss = 0.10044
Step 202435: loss = 0.07930
Step 202440: loss = 0.02538
Step 202445: loss = 0.13157
Step 202450: loss = 0.04741
Step 202455: loss = 0.02816
Step 202460: loss = 0.07066
Step 202465: loss = 0.08342
Step 202470: loss = 0.03590
Step 202475: loss = 0.08846
Step 202480: loss = 0.16160
Step 202485: loss = 0.11268
Step 202490: loss = 0.08705
Step 202495: loss = 0.11621
Step 202500: loss = 0.04104
Step 202505: loss = 0.17116
Step 202510: loss = 0.06522
Step 202515: loss = 0.07832
Step 202520: loss = 0.04332
Step 202525: loss = 0.04729
Step 202530: loss = 0.22481
Step 202535: loss = 0.15747
Step 202540: loss = 0.11598
Step 202545: loss = 0.09259
Step 202550: loss = 0.20271
Step 202555: loss = 0.14178
Step 202560: loss = 0.14154
Step 202565: loss = 0.03782
Step 202570: loss = 0.09022
Step 202575: loss = 0.07373
Step 202580: loss = 0.24714
Step 202585: loss = 0.04432
Step 202590: loss = 0.12251
Step 202595: loss = 0.05350
Step 202600: loss = 0.05474
Step 202605: loss = 0.06352
Step 202610: loss = 0.15485
Step 202615: loss = 0.15772
Step 202620: loss = 0.03195
Step 202625: loss = 0.07093
Step 202630: loss = 0.10393
Step 202635: loss = 0.09373
Step 202640: loss = 0.24460
Step 202645: loss = 0.15660
Step 202650: loss = 0.03979
Step 202655: loss = 0.19982
Step 202660: loss = 0.07464
Step 202665: loss = 0.06691
Step 202670: loss = 0.05518
Step 202675: loss = 0.07557
Step 202680: loss = 0.07311
Step 202685: loss = 0.29242
Step 202690: loss = 0.17630
Step 202695: loss = 0.02744
Step 202700: loss = 0.09092
Step 202705: loss = 0.15073
Step 202710: loss = 0.08328
Step 202715: loss = 0.34152
Step 202720: loss = 0.08289
Step 202725: loss = 0.47707
Step 202730: loss = 0.10060
Step 202735: loss = 0.08605
Step 202740: loss = 0.09560
Step 202745: loss = 0.09321
Step 202750: loss = 0.02643
Step 202755: loss = 0.05646
Step 202760: loss = 0.08957
Step 202765: loss = 0.05733
Step 202770: loss = 0.06148
Step 202775: loss = 0.08051
Step 202780: loss = 0.10130
Step 202785: loss = 0.06018
Step 202790: loss = 0.12764
Step 202795: loss = 0.10960
Step 202800: loss = 0.02688
Step 202805: loss = 0.05277
Step 202810: loss = 0.06031
Step 202815: loss = 0.17949
Step 202820: loss = 0.07031
Step 202825: loss = 0.07456
Step 202830: loss = 0.17811
Step 202835: loss = 0.05020
Step 202840: loss = 0.06127
Step 202845: loss = 0.09278
Step 202850: loss = 0.13422
Step 202855: loss = 0.28010
Step 202860: loss = 0.32922
Step 202865: loss = 0.07816
Step 202870: loss = 0.15261
Step 202875: loss = 0.08754
Step 202880: loss = 0.10011
Step 202885: loss = 0.12856
Step 202890: loss = 0.03244
Step 202895: loss = 0.07169
Step 202900: loss = 0.06977
Step 202905: loss = 0.14057
Step 202910: loss = 0.07606
Step 202915: loss = 0.13271
Step 202920: loss = 0.03279
Step 202925: loss = 0.03887
Step 202930: loss = 0.09006
Step 202935: loss = 0.04214
Step 202940: loss = 0.03662
Step 202945: loss = 0.07919
Step 202950: loss = 0.03750
Step 202955: loss = 0.10285
Step 202960: loss = 0.09133
Step 202965: loss = 0.15508
Step 202970: loss = 0.02951
Step 202975: loss = 0.13373
Step 202980: loss = 0.06197
Step 202985: loss = 0.16703
Step 202990: loss = 0.09028
Step 202995: loss = 0.03802
Step 203000: loss = 0.12788
Training Data Eval:
  Num examples: 50000, Num correct: 48325, Precision @ 1: 0.9665
('Testing Data Eval: EPOCH->', 204)
  Num examples: 10000, Num correct: 6677, Precision @ 1: 0.6677
Step 203005: loss = 0.07967
Step 203010: loss = 0.10281
Step 203015: loss = 0.11473
Step 203020: loss = 0.05968
Step 203025: loss = 0.04265
Step 203030: loss = 0.25950
Step 203035: loss = 0.07803
Step 203040: loss = 0.03347
Step 203045: loss = 0.05613
Step 203050: loss = 0.05550
Step 203055: loss = 0.26259
Step 203060: loss = 0.08736
Step 203065: loss = 0.14782
Step 203070: loss = 0.14315
Step 203075: loss = 0.12819
Step 203080: loss = 0.11804
Step 203085: loss = 0.06748
Step 203090: loss = 0.08302
Step 203095: loss = 0.08469
Step 203100: loss = 0.10694
Step 203105: loss = 0.13392
Step 203110: loss = 0.19872
Step 203115: loss = 0.07528
Step 203120: loss = 0.15987
Step 203125: loss = 0.27845
Step 203130: loss = 0.03991
Step 203135: loss = 0.04888
Step 203140: loss = 0.12671
Step 203145: loss = 0.02069
Step 203150: loss = 0.31859
Step 203155: loss = 0.12752
Step 203160: loss = 0.09154
Step 203165: loss = 0.06852
Step 203170: loss = 0.04305
Step 203175: loss = 0.24514
Step 203180: loss = 0.11617
Step 203185: loss = 0.05013
Step 203190: loss = 0.13350
Step 203195: loss = 0.09674
Step 203200: loss = 0.10996
Step 203205: loss = 0.02986
Step 203210: loss = 0.08755
Step 203215: loss = 0.05446
Step 203220: loss = 0.14319
Step 203225: loss = 0.07353
Step 203230: loss = 0.04841
Step 203235: loss = 0.18652
Step 203240: loss = 0.08012
Step 203245: loss = 0.06553
Step 203250: loss = 0.09126
Step 203255: loss = 0.08957
Step 203260: loss = 0.14695
Step 203265: loss = 0.24530
Step 203270: loss = 0.15492
Step 203275: loss = 0.03853
Step 203280: loss = 0.15319
Step 203285: loss = 0.25323
Step 203290: loss = 0.21580
Step 203295: loss = 0.07709
Step 203300: loss = 0.04222
Step 203305: loss = 0.09687
Step 203310: loss = 0.04836
Step 203315: loss = 0.10349
Step 203320: loss = 0.07088
Step 203325: loss = 0.04970
Step 203330: loss = 0.04696
Step 203335: loss = 0.19199
Step 203340: loss = 0.05780
Step 203345: loss = 0.26325
Step 203350: loss = 0.12745
Step 203355: loss = 0.03170
Step 203360: loss = 0.08381
Step 203365: loss = 0.05074
Step 203370: loss = 0.07706
Step 203375: loss = 0.10359
Step 203380: loss = 0.12964
Step 203385: loss = 0.02888
Step 203390: loss = 0.05988
Step 203395: loss = 0.04732
Step 203400: loss = 0.18230
Step 203405: loss = 0.01952
Step 203410: loss = 0.05669
Step 203415: loss = 0.18461
Step 203420: loss = 0.17585
Step 203425: loss = 0.01468
Step 203430: loss = 0.01415
Step 203435: loss = 0.03448
Step 203440: loss = 0.16184
Step 203445: loss = 0.09015
Step 203450: loss = 0.16446
Step 203455: loss = 0.10761
Step 203460: loss = 0.09002
Step 203465: loss = 0.04134
Step 203470: loss = 0.01436
Step 203475: loss = 0.05760
Step 203480: loss = 0.07667
Step 203485: loss = 0.17228
Step 203490: loss = 0.07887
Step 203495: loss = 0.08206
Step 203500: loss = 0.02744
Step 203505: loss = 0.21943
Step 203510: loss = 0.06271
Step 203515: loss = 0.06477
Step 203520: loss = 0.07761
Step 203525: loss = 0.06592
Step 203530: loss = 0.28263
Step 203535: loss = 0.06497
Step 203540: loss = 0.02517
Step 203545: loss = 0.04449
Step 203550: loss = 0.05640
Step 203555: loss = 0.11597
Step 203560: loss = 0.02378
Step 203565: loss = 0.13285
Step 203570: loss = 0.05057
Step 203575: loss = 0.05800
Step 203580: loss = 0.04946
Step 203585: loss = 0.05672
Step 203590: loss = 0.02975
Step 203595: loss = 0.02678
Step 203600: loss = 0.10492
Step 203605: loss = 0.03842
Step 203610: loss = 0.01772
Step 203615: loss = 0.17663
Step 203620: loss = 0.10984
Step 203625: loss = 0.09222
Step 203630: loss = 0.08335
Step 203635: loss = 0.20522
Step 203640: loss = 0.12029
Step 203645: loss = 0.09356
Step 203650: loss = 0.01529
Step 203655: loss = 0.12093
Step 203660: loss = 0.11794
Step 203665: loss = 0.13411
Step 203670: loss = 0.05888
Step 203675: loss = 0.12812
Step 203680: loss = 0.09836
Step 203685: loss = 0.08289
Step 203690: loss = 0.02859
Step 203695: loss = 0.09844
Step 203700: loss = 0.06962
Step 203705: loss = 0.02142
Step 203710: loss = 0.44931
Step 203715: loss = 0.05268
Step 203720: loss = 0.03931
Step 203725: loss = 0.08728
Step 203730: loss = 0.07411
Step 203735: loss = 0.05750
Step 203740: loss = 0.06134
Step 203745: loss = 0.07755
Step 203750: loss = 0.13997
Step 203755: loss = 0.17931
Step 203760: loss = 0.04954
Step 203765: loss = 0.03880
Step 203770: loss = 0.12363
Step 203775: loss = 0.12036
Step 203780: loss = 0.14837
Step 203785: loss = 0.18265
Step 203790: loss = 0.11880
Step 203795: loss = 0.03279
Step 203800: loss = 0.04215
Step 203805: loss = 0.16623
Step 203810: loss = 0.57654
Step 203815: loss = 0.04326
Step 203820: loss = 0.09200
Step 203825: loss = 0.10041
Step 203830: loss = 0.08750
Step 203835: loss = 0.08755
Step 203840: loss = 0.01702
Step 203845: loss = 0.10169
Step 203850: loss = 0.09141
Step 203855: loss = 0.03967
Step 203860: loss = 0.08094
Step 203865: loss = 0.11722
Step 203870: loss = 0.08978
Step 203875: loss = 0.16890
Step 203880: loss = 0.08453
Step 203885: loss = 0.17501
Step 203890: loss = 0.13953
Step 203895: loss = 0.07415
Step 203900: loss = 0.06635
Step 203905: loss = 0.16711
Step 203910: loss = 0.02039
Step 203915: loss = 0.05998
Step 203920: loss = 0.12233
Step 203925: loss = 0.16913
Step 203930: loss = 0.08159
Step 203935: loss = 0.04125
Step 203940: loss = 0.06482
Step 203945: loss = 0.13225
Step 203950: loss = 0.09408
Step 203955: loss = 0.04685
Step 203960: loss = 0.05317
Step 203965: loss = 0.03006
Step 203970: loss = 0.31641
Step 203975: loss = 0.14157
Step 203980: loss = 0.04241
Step 203985: loss = 0.04687
Step 203990: loss = 0.02561
Step 203995: loss = 0.10420
Step 204000: loss = 0.03937
Training Data Eval:
  Num examples: 50000, Num correct: 48087, Precision @ 1: 0.9617
('Testing Data Eval: EPOCH->', 205)
  Num examples: 10000, Num correct: 6764, Precision @ 1: 0.6764
Step 204005: loss = 0.14217
Step 204010: loss = 0.13655
Step 204015: loss = 0.15724
Step 204020: loss = 0.05073
Step 204025: loss = 0.05221
Step 204030: loss = 0.05576
Step 204035: loss = 0.21526
Step 204040: loss = 0.04990
Step 204045: loss = 0.09373
Step 204050: loss = 0.09251
Step 204055: loss = 0.09325
Step 204060: loss = 0.01864
Step 204065: loss = 0.03253
Step 204070: loss = 0.25158
Step 204075: loss = 0.16157
Step 204080: loss = 0.16405
Step 204085: loss = 0.06286
Step 204090: loss = 0.06897
Step 204095: loss = 0.28254
Step 204100: loss = 0.17726
Step 204105: loss = 0.06902
Step 204110: loss = 0.19175
Step 204115: loss = 0.30446
Step 204120: loss = 0.09027
Step 204125: loss = 0.09457
Step 204130: loss = 0.10972
Step 204135: loss = 0.11708
Step 204140: loss = 0.07329
Step 204145: loss = 0.13754
Step 204150: loss = 0.10541
Step 204155: loss = 0.05803
Step 204160: loss = 0.10987
Step 204165: loss = 0.06571
Step 204170: loss = 0.12100
Step 204175: loss = 0.02274
Step 204180: loss = 0.03467
Step 204185: loss = 0.05964
Step 204190: loss = 0.05821
Step 204195: loss = 0.09235
Step 204200: loss = 0.03821
Step 204205: loss = 0.06961
Step 204210: loss = 0.04155
Step 204215: loss = 0.16187
Step 204220: loss = 0.04019
Step 204225: loss = 0.19617
Step 204230: loss = 0.08318
Step 204235: loss = 0.02558
Step 204240: loss = 0.04516
Step 204245: loss = 0.15028
Step 204250: loss = 0.06558
Step 204255: loss = 0.05013
Step 204260: loss = 0.16788
Step 204265: loss = 0.09208
Step 204270: loss = 0.18856
Step 204275: loss = 0.21984
Step 204280: loss = 0.04372
Step 204285: loss = 0.28961
Step 204290: loss = 0.13538
Step 204295: loss = 0.01636
Step 204300: loss = 0.09079
Step 204305: loss = 0.06347
Step 204310: loss = 0.14485
Step 204315: loss = 0.07017
Step 204320: loss = 0.06157
Step 204325: loss = 0.03286
Step 204330: loss = 0.13133
Step 204335: loss = 0.21156
Step 204340: loss = 0.03385
Step 204345: loss = 0.16635
Step 204350: loss = 0.10420
Step 204355: loss = 0.08359
Step 204360: loss = 0.01234
Step 204365: loss = 0.09984
Step 204370: loss = 0.12315
Step 204375: loss = 0.08493
Step 204380: loss = 0.05279
Step 204385: loss = 0.04654
Step 204390: loss = 0.04138
Step 204395: loss = 0.08449
Step 204400: loss = 0.02188
Step 204405: loss = 0.28604
Step 204410: loss = 0.05284
Step 204415: loss = 0.09626
Step 204420: loss = 0.02393
Step 204425: loss = 0.20429
Step 204430: loss = 0.07933
Step 204435: loss = 0.24105
Step 204440: loss = 0.04118
Step 204445: loss = 0.28513
Step 204450: loss = 0.11064
Step 204455: loss = 0.17850
Step 204460: loss = 0.12066
Step 204465: loss = 0.08228
Step 204470: loss = 0.23691
Step 204475: loss = 0.07295
Step 204480: loss = 0.11091
Step 204485: loss = 0.14252
Step 204490: loss = 0.10834
Step 204495: loss = 0.08554
Step 204500: loss = 0.01759
Step 204505: loss = 0.27591
Step 204510: loss = 0.09741
Step 204515: loss = 0.01931
Step 204520: loss = 0.03464
Step 204525: loss = 0.06586
Step 204530: loss = 0.02577
Step 204535: loss = 0.18278
Step 204540: loss = 0.07572
Step 204545: loss = 0.08213
Step 204550: loss = 0.09577
Step 204555: loss = 0.07273
Step 204560: loss = 0.19518
Step 204565: loss = 0.09577
Step 204570: loss = 0.05137
Step 204575: loss = 0.13048
Step 204580: loss = 0.15348
Step 204585: loss = 0.09789
Step 204590: loss = 0.11612
Step 204595: loss = 0.16746
Step 204600: loss = 0.02343
Step 204605: loss = 0.12174
Step 204610: loss = 0.02831
Step 204615: loss = 0.11549
Step 204620: loss = 0.15870
Step 204625: loss = 0.07977
Step 204630: loss = 0.32025
Step 204635: loss = 0.09123
Step 204640: loss = 0.21902
Step 204645: loss = 0.03186
Step 204650: loss = 0.27337
Step 204655: loss = 0.05293
Step 204660: loss = 0.20748
Step 204665: loss = 0.02583
Step 204670: loss = 0.12102
Step 204675: loss = 0.19502
Step 204680: loss = 0.05896
Step 204685: loss = 0.03672
Step 204690: loss = 0.18536
Step 204695: loss = 0.15776
Step 204700: loss = 0.03414
Step 204705: loss = 0.01572
Step 204710: loss = 0.07666
Step 204715: loss = 0.12232
Step 204720: loss = 0.04949
Step 204725: loss = 0.03441
Step 204730: loss = 0.16104
Step 204735: loss = 0.10426
Step 204740: loss = 0.03226
Step 204745: loss = 0.10969
Step 204750: loss = 0.01984
Step 204755: loss = 0.02476
Step 204760: loss = 0.20073
Step 204765: loss = 0.15064
Step 204770: loss = 0.07306
Step 204775: loss = 0.04543
Step 204780: loss = 0.18711
Step 204785: loss = 0.15141
Step 204790: loss = 0.07880
Step 204795: loss = 0.03997
Step 204800: loss = 0.08101
Step 204805: loss = 0.11105
Step 204810: loss = 0.07986
Step 204815: loss = 0.04908
Step 204820: loss = 0.04609
Step 204825: loss = 0.04315
Step 204830: loss = 0.14283
Step 204835: loss = 0.26440
Step 204840: loss = 0.04334
Step 204845: loss = 0.13574
Step 204850: loss = 0.07927
Step 204855: loss = 0.08566
Step 204860: loss = 0.12306
Step 204865: loss = 0.03783
Step 204870: loss = 0.07168
Step 204875: loss = 0.02594
Step 204880: loss = 0.24625
Step 204885: loss = 0.06638
Step 204890: loss = 0.06536
Step 204895: loss = 0.18908
Step 204900: loss = 0.08041
Step 204905: loss = 0.04014
Step 204910: loss = 0.07041
Step 204915: loss = 0.07476
Step 204920: loss = 0.04604
Step 204925: loss = 0.03052
Step 204930: loss = 0.04805
Step 204935: loss = 0.11381
Step 204940: loss = 0.15778
Step 204945: loss = 0.09387
Step 204950: loss = 0.07525
Step 204955: loss = 0.10953
Step 204960: loss = 0.07166
Step 204965: loss = 0.21044
Step 204970: loss = 0.03273
Step 204975: loss = 0.13052
Step 204980: loss = 0.21900
Step 204985: loss = 0.02037
Step 204990: loss = 0.08476
Step 204995: loss = 0.04003
Step 205000: loss = 0.13962
Training Data Eval:
  Num examples: 50000, Num correct: 48337, Precision @ 1: 0.9667
('Testing Data Eval: EPOCH->', 206)
  Num examples: 10000, Num correct: 6652, Precision @ 1: 0.6652
Step 205005: loss = 0.44037
Step 205010: loss = 0.04663
Step 205015: loss = 0.05888
Step 205020: loss = 0.12936
Step 205025: loss = 0.06735
Step 205030: loss = 0.02277
Step 205035: loss = 0.07065
Step 205040: loss = 0.05389
Step 205045: loss = 0.06625
Step 205050: loss = 0.11675
Step 205055: loss = 0.10766
Step 205060: loss = 0.07546
Step 205065: loss = 0.24992
Step 205070: loss = 0.07447
Step 205075: loss = 0.12209
Step 205080: loss = 0.03994
Step 205085: loss = 0.23361
Step 205090: loss = 0.06059
Step 205095: loss = 0.06912
Step 205100: loss = 0.06298
Step 205105: loss = 0.09899
Step 205110: loss = 0.10248
Step 205115: loss = 0.17489
Step 205120: loss = 0.03109
Step 205125: loss = 0.02464
Step 205130: loss = 0.04447
Step 205135: loss = 0.06151
Step 205140: loss = 0.06355
Step 205145: loss = 0.20276
Step 205150: loss = 0.05687
Step 205155: loss = 0.07167
Step 205160: loss = 0.09556
Step 205165: loss = 0.16083
Step 205170: loss = 0.04095
Step 205175: loss = 0.04045
Step 205180: loss = 0.22924
Step 205185: loss = 0.79954
Step 205190: loss = 0.15365
Step 205195: loss = 0.02816
Step 205200: loss = 0.15473
Step 205205: loss = 0.10339
Step 205210: loss = 0.11830
Step 205215: loss = 0.06511
Step 205220: loss = 0.11817
Step 205225: loss = 0.07009
Step 205230: loss = 0.06505
Step 205235: loss = 0.24760
Step 205240: loss = 0.14426
Step 205245: loss = 0.11316
Step 205250: loss = 0.48993
Step 205255: loss = 0.09129
Step 205260: loss = 0.03503
Step 205265: loss = 0.16532
Step 205270: loss = 0.15302
Step 205275: loss = 0.05726
Step 205280: loss = 0.51510
Step 205285: loss = 0.07612
Step 205290: loss = 0.09644
Step 205295: loss = 0.05417
Step 205300: loss = 0.07828
Step 205305: loss = 0.19741
Step 205310: loss = 0.12346
Step 205315: loss = 0.04164
Step 205320: loss = 0.33716
Step 205325: loss = 0.11162
Step 205330: loss = 0.18126
Step 205335: loss = 0.18728
Step 205340: loss = 0.17905
Step 205345: loss = 0.16671
Step 205350: loss = 0.07179
Step 205355: loss = 0.12865
Step 205360: loss = 0.08692
Step 205365: loss = 0.04654
Step 205370: loss = 0.05076
Step 205375: loss = 0.02580
Step 205380: loss = 0.24670
Step 205385: loss = 0.02471
Step 205390: loss = 0.18780
Step 205395: loss = 0.03009
Step 205400: loss = 0.02352
Step 205405: loss = 0.03885
Step 205410: loss = 0.05505
Step 205415: loss = 0.03130
Step 205420: loss = 0.09789
Step 205425: loss = 0.12973
Step 205430: loss = 0.06299
Step 205435: loss = 0.01907
Step 205440: loss = 0.02225
Step 205445: loss = 0.12989
Step 205450: loss = 0.03780
Step 205455: loss = 0.03230
Step 205460: loss = 0.11003
Step 205465: loss = 0.09111
Step 205470: loss = 0.15229
Step 205475: loss = 0.11112
Step 205480: loss = 0.08352
Step 205485: loss = 0.15078
Step 205490: loss = 0.07885
Step 205495: loss = 0.21385
Step 205500: loss = 0.13065
Step 205505: loss = 0.04057
Step 205510: loss = 0.09464
Step 205515: loss = 0.21605
Step 205520: loss = 0.05436
Step 205525: loss = 0.39055
Step 205530: loss = 0.09853
Step 205535: loss = 0.09251
Step 205540: loss = 0.07310
Step 205545: loss = 0.04761
Step 205550: loss = 0.07859
Step 205555: loss = 0.11676
Step 205560: loss = 0.12056
Step 205565: loss = 0.04209
Step 205570: loss = 0.02622
Step 205575: loss = 0.07395
Step 205580: loss = 0.24647
Step 205585: loss = 0.06733
Step 205590: loss = 0.22045
Step 205595: loss = 0.14198
Step 205600: loss = 0.02639
Step 205605: loss = 0.16863
Step 205610: loss = 0.06459
Step 205615: loss = 0.20465
Step 205620: loss = 0.20362
Step 205625: loss = 0.03214
Step 205630: loss = 0.16969
Step 205635: loss = 0.10472
Step 205640: loss = 0.12485
Step 205645: loss = 0.08177
Step 205650: loss = 0.26551
Step 205655: loss = 0.02555
Step 205660: loss = 0.07476
Step 205665: loss = 0.07838
Step 205670: loss = 0.06701
Step 205675: loss = 0.17238
Step 205680: loss = 0.14651
Step 205685: loss = 0.10435
Step 205690: loss = 0.11521
Step 205695: loss = 0.04073
Step 205700: loss = 0.07666
Step 205705: loss = 0.29264
Step 205710: loss = 0.12018
Step 205715: loss = 0.35073
Step 205720: loss = 0.12533
Step 205725: loss = 0.09339
Step 205730: loss = 0.03962
Step 205735: loss = 0.07745
Step 205740: loss = 0.10751
Step 205745: loss = 0.07353
Step 205750: loss = 0.18654
Step 205755: loss = 0.14375
Step 205760: loss = 0.19679
Step 205765: loss = 0.01427
Step 205770: loss = 0.09068
Step 205775: loss = 0.05579
Step 205780: loss = 0.07433
Step 205785: loss = 0.03765
Step 205790: loss = 0.12007
Step 205795: loss = 0.02993
Step 205800: loss = 0.12690
Step 205805: loss = 0.02305
Step 205810: loss = 0.03187
Step 205815: loss = 0.06742
Step 205820: loss = 0.07404
Step 205825: loss = 0.07337
Step 205830: loss = 0.08207
Step 205835: loss = 0.03871
Step 205840: loss = 0.01308
Step 205845: loss = 0.20699
Step 205850: loss = 0.15648
Step 205855: loss = 0.02665
Step 205860: loss = 0.17909
Step 205865: loss = 0.09715
Step 205870: loss = 0.05002
Step 205875: loss = 0.10026
Step 205880: loss = 0.30944
Step 205885: loss = 0.10315
Step 205890: loss = 0.02023
Step 205895: loss = 0.27898
Step 205900: loss = 0.21367
Step 205905: loss = 0.07749
Step 205910: loss = 0.06096
Step 205915: loss = 0.05055
Step 205920: loss = 0.10731
Step 205925: loss = 0.12076
Step 205930: loss = 0.12181
Step 205935: loss = 0.07189
Step 205940: loss = 0.08313
Step 205945: loss = 0.02899
Step 205950: loss = 0.04572
Step 205955: loss = 0.24976
Step 205960: loss = 0.10398
Step 205965: loss = 0.07926
Step 205970: loss = 0.12139
Step 205975: loss = 0.07973
Step 205980: loss = 0.31006
Step 205985: loss = 0.02675
Step 205990: loss = 0.13316
Step 205995: loss = 0.33800
Step 206000: loss = 0.04810
Training Data Eval:
  Num examples: 50000, Num correct: 48268, Precision @ 1: 0.9654
('Testing Data Eval: EPOCH->', 207)
  Num examples: 10000, Num correct: 6810, Precision @ 1: 0.6810
Step 206005: loss = 0.08109
Step 206010: loss = 0.14002
Step 206015: loss = 0.12360
Step 206020: loss = 0.08303
Step 206025: loss = 0.14719
Step 206030: loss = 0.05932
Step 206035: loss = 0.24978
Step 206040: loss = 0.04511
Step 206045: loss = 0.03384
Step 206050: loss = 0.12638
Step 206055: loss = 0.36621
Step 206060: loss = 0.06037
Step 206065: loss = 0.03685
Step 206070: loss = 0.10062
Step 206075: loss = 0.07654
Step 206080: loss = 0.05430
Step 206085: loss = 0.01685
Step 206090: loss = 0.10312
Step 206095: loss = 0.14844
Step 206100: loss = 0.01615
Step 206105: loss = 0.08408
Step 206110: loss = 0.12740
Step 206115: loss = 0.15607
Step 206120: loss = 0.03591
Step 206125: loss = 0.14980
Step 206130: loss = 0.02974
Step 206135: loss = 0.08320
Step 206140: loss = 0.09585
Step 206145: loss = 0.04715
Step 206150: loss = 0.08051
Step 206155: loss = 0.09463
Step 206160: loss = 0.04011
Step 206165: loss = 0.21866
Step 206170: loss = 0.15311
Step 206175: loss = 0.08208
Step 206180: loss = 0.08442
Step 206185: loss = 0.02071
Step 206190: loss = 0.06360
Step 206195: loss = 0.04803
Step 206200: loss = 0.06433
Step 206205: loss = 0.02978
Step 206210: loss = 0.11808
Step 206215: loss = 0.10781
Step 206220: loss = 0.12220
Step 206225: loss = 0.01645
Step 206230: loss = 0.03294
Step 206235: loss = 0.06345
Step 206240: loss = 0.09002
Step 206245: loss = 0.05918
Step 206250: loss = 0.08179
Step 206255: loss = 0.03775
Step 206260: loss = 0.04917
Step 206265: loss = 0.05734
Step 206270: loss = 0.11496
Step 206275: loss = 0.20702
Step 206280: loss = 0.06357
Step 206285: loss = 0.05047
Step 206290: loss = 0.05543
Step 206295: loss = 0.05569
Step 206300: loss = 0.16000
Step 206305: loss = 0.07262
Step 206310: loss = 0.14609
Step 206315: loss = 0.22313
Step 206320: loss = 0.05730
Step 206325: loss = 0.13654
Step 206330: loss = 0.14968
Step 206335: loss = 0.01802
Step 206340: loss = 0.02552
Step 206345: loss = 0.04550
Step 206350: loss = 0.14284
Step 206355: loss = 0.17376
Step 206360: loss = 0.15277
Step 206365: loss = 0.17848
Step 206370: loss = 0.03798
Step 206375: loss = 0.03990
Step 206380: loss = 0.17346
Step 206385: loss = 0.05027
Step 206390: loss = 0.02642
Step 206395: loss = 0.02366
Step 206400: loss = 0.21793
Step 206405: loss = 0.09528
Step 206410: loss = 0.03727
Step 206415: loss = 0.14036
Step 206420: loss = 0.09529
Step 206425: loss = 0.05718
Step 206430: loss = 0.03915
Step 206435: loss = 0.03508
Step 206440: loss = 0.05126
Step 206445: loss = 0.04478
Step 206450: loss = 0.05996
Step 206455: loss = 0.12043
Step 206460: loss = 0.02430
Step 206465: loss = 0.02291
Step 206470: loss = 0.15695
Step 206475: loss = 0.11067
Step 206480: loss = 0.13332
Step 206485: loss = 0.01647
Step 206490: loss = 0.07597
Step 206495: loss = 0.06793
Step 206500: loss = 0.24468
Step 206505: loss = 0.05248
Step 206510: loss = 0.04066
Step 206515: loss = 0.02464
Step 206520: loss = 0.03935
Step 206525: loss = 0.08562
Step 206530: loss = 0.06735
Step 206535: loss = 0.09995
Step 206540: loss = 0.02154
Step 206545: loss = 0.12281
Step 206550: loss = 0.05579
Step 206555: loss = 0.24154
Step 206560: loss = 0.04032
Step 206565: loss = 0.08296
Step 206570: loss = 0.10045
Step 206575: loss = 0.11319
Step 206580: loss = 0.02361
Step 206585: loss = 0.04900
Step 206590: loss = 0.61822
Step 206595: loss = 0.02813
Step 206600: loss = 0.07009
Step 206605: loss = 0.13945
Step 206610: loss = 0.13198
Step 206615: loss = 0.17111
Step 206620: loss = 0.25817
Step 206625: loss = 0.03549
Step 206630: loss = 0.03955
Step 206635: loss = 0.11912
Step 206640: loss = 0.02591
Step 206645: loss = 0.09245
Step 206650: loss = 0.20055
Step 206655: loss = 0.26708
Step 206660: loss = 0.07043
Step 206665: loss = 0.11435
Step 206670: loss = 0.14014
Step 206675: loss = 0.05021
Step 206680: loss = 0.03904
Step 206685: loss = 0.08459
Step 206690: loss = 0.07874
Step 206695: loss = 0.09866
Step 206700: loss = 0.16377
Step 206705: loss = 0.04776
Step 206710: loss = 0.17668
Step 206715: loss = 0.05997
Step 206720: loss = 0.06295
Step 206725: loss = 0.21237
Step 206730: loss = 0.02453
Step 206735: loss = 0.01819
Step 206740: loss = 0.13265
Step 206745: loss = 0.05812
Step 206750: loss = 0.12573
Step 206755: loss = 0.10264
Step 206760: loss = 0.05007
Step 206765: loss = 0.03248
Step 206770: loss = 0.17397
Step 206775: loss = 0.04302
Step 206780: loss = 0.28309
Step 206785: loss = 0.05249
Step 206790: loss = 0.11589
Step 206795: loss = 0.11521
Step 206800: loss = 0.07638
Step 206805: loss = 0.13195
Step 206810: loss = 0.23244
Step 206815: loss = 0.08251
Step 206820: loss = 0.04764
Step 206825: loss = 0.17854
Step 206830: loss = 0.12335
Step 206835: loss = 0.16699
Step 206840: loss = 0.04896
Step 206845: loss = 0.13249
Step 206850: loss = 0.04566
Step 206855: loss = 0.02671
Step 206860: loss = 0.05168
Step 206865: loss = 0.09579
Step 206870: loss = 0.02092
Step 206875: loss = 0.13356
Step 206880: loss = 0.12087
Step 206885: loss = 0.10304
Step 206890: loss = 0.11196
Step 206895: loss = 0.07907
Step 206900: loss = 0.11105
Step 206905: loss = 0.05413
Step 206910: loss = 0.10407
Step 206915: loss = 0.08451
Step 206920: loss = 0.04301
Step 206925: loss = 0.18227
Step 206930: loss = 0.11653
Step 206935: loss = 0.03160
Step 206940: loss = 0.04616
Step 206945: loss = 0.13168
Step 206950: loss = 0.06054
Step 206955: loss = 0.05566
Step 206960: loss = 0.03762
Step 206965: loss = 0.06259
Step 206970: loss = 0.09362
Step 206975: loss = 0.10702
Step 206980: loss = 0.15012
Step 206985: loss = 0.19196
Step 206990: loss = 0.21639
Step 206995: loss = 0.03257
Step 207000: loss = 0.24631
Training Data Eval:
  Num examples: 50000, Num correct: 48351, Precision @ 1: 0.9670
('Testing Data Eval: EPOCH->', 208)
  Num examples: 10000, Num correct: 6790, Precision @ 1: 0.6790
Step 207005: loss = 0.07258
Step 207010: loss = 0.02964
Step 207015: loss = 0.04999
Step 207020: loss = 0.25933
Step 207025: loss = 0.04874
Step 207030: loss = 0.19913
Step 207035: loss = 0.04875
Step 207040: loss = 0.04605
Step 207045: loss = 0.05201
Step 207050: loss = 0.04445
Step 207055: loss = 0.06940
Step 207060: loss = 0.04304
Step 207065: loss = 0.05192
Step 207070: loss = 0.15438
Step 207075: loss = 0.03006
Step 207080: loss = 0.16047
Step 207085: loss = 0.10259
Step 207090: loss = 0.04152
Step 207095: loss = 0.05220
Step 207100: loss = 0.15860
Step 207105: loss = 0.05053
Step 207110: loss = 0.05213
Step 207115: loss = 0.00879
Step 207120: loss = 0.10906
Step 207125: loss = 0.05012
Step 207130: loss = 0.01992
Step 207135: loss = 0.11332
Step 207140: loss = 0.09047
Step 207145: loss = 0.01247
Step 207150: loss = 0.09870
Step 207155: loss = 0.04337
Step 207160: loss = 0.14356
Step 207165: loss = 0.05008
Step 207170: loss = 0.08900
Step 207175: loss = 0.09967
Step 207180: loss = 0.06330
Step 207185: loss = 0.09729
Step 207190: loss = 0.07902
Step 207195: loss = 0.04716
Step 207200: loss = 0.05391
Step 207205: loss = 0.07630
Step 207210: loss = 0.27661
Step 207215: loss = 0.05645
Step 207220: loss = 0.02567
Step 207225: loss = 0.11225
Step 207230: loss = 0.07655
Step 207235: loss = 0.12333
Step 207240: loss = 0.15902
Step 207245: loss = 0.17970
Step 207250: loss = 0.04555
Step 207255: loss = 0.10031
Step 207260: loss = 0.09908
Step 207265: loss = 0.23362
Step 207270: loss = 0.14524
Step 207275: loss = 0.09487
Step 207280: loss = 0.15691
Step 207285: loss = 0.11465
Step 207290: loss = 0.11631
Step 207295: loss = 0.10369
Step 207300: loss = 0.02808
Step 207305: loss = 0.03037
Step 207310: loss = 0.12798
Step 207315: loss = 0.14017
Step 207320: loss = 0.22420
Step 207325: loss = 0.14782
Step 207330: loss = 0.06290
Step 207335: loss = 0.06861
Step 207340: loss = 0.06188
Step 207345: loss = 0.19238
Step 207350: loss = 0.08040
Step 207355: loss = 0.10845
Step 207360: loss = 0.01629
Step 207365: loss = 0.08072
Step 207370: loss = 0.25027
Step 207375: loss = 0.10750
Step 207380: loss = 0.08488
Step 207385: loss = 0.31298
Step 207390: loss = 0.03063
Step 207395: loss = 0.17631
Step 207400: loss = 0.02631
Step 207405: loss = 0.05385
Step 207410: loss = 0.38396
Step 207415: loss = 0.05804
Step 207420: loss = 0.14397
Step 207425: loss = 0.10232
Step 207430: loss = 0.11899
Step 207435: loss = 0.02462
Step 207440: loss = 0.09937
Step 207445: loss = 0.08675
Step 207450: loss = 0.02380
Step 207455: loss = 0.05170
Step 207460: loss = 0.04159
Step 207465: loss = 0.05406
Step 207470: loss = 0.02381
Step 207475: loss = 0.07593
Step 207480: loss = 0.06179
Step 207485: loss = 0.01975
Step 207490: loss = 0.10750
Step 207495: loss = 0.01519
Step 207500: loss = 0.03752
Step 207505: loss = 0.11865
Step 207510: loss = 0.12955
Step 207515: loss = 0.22016
Step 207520: loss = 0.02691
Step 207525: loss = 0.07547
Step 207530: loss = 0.12095
Step 207535: loss = 0.04653
Step 207540: loss = 0.28122
Step 207545: loss = 0.17095
Step 207550: loss = 0.04433
Step 207555: loss = 0.21691
Step 207560: loss = 0.16129
Step 207565: loss = 0.14104
Step 207570: loss = 0.25916
Step 207575: loss = 0.02087
Step 207580: loss = 0.08386
Step 207585: loss = 0.06092
Step 207590: loss = 0.03151
Step 207595: loss = 0.08743
Step 207600: loss = 0.04745
Step 207605: loss = 0.17395
Step 207610: loss = 0.07962
Step 207615: loss = 0.10016
Step 207620: loss = 0.06541
Step 207625: loss = 0.06780
Step 207630: loss = 0.11496
Step 207635: loss = 0.11454
Step 207640: loss = 0.10230
Step 207645: loss = 0.14608
Step 207650: loss = 0.06172
Step 207655: loss = 0.04149
Step 207660: loss = 0.08852
Step 207665: loss = 0.03026
Step 207670: loss = 0.04031
Step 207675: loss = 0.15447
Step 207680: loss = 0.14149
Step 207685: loss = 0.03651
Step 207690: loss = 0.17821
Step 207695: loss = 0.16005
Step 207700: loss = 0.18516
Step 207705: loss = 0.03076
Step 207710: loss = 0.12217
Step 207715: loss = 0.08714
Step 207720: loss = 0.10674
Step 207725: loss = 0.09611
Step 207730: loss = 0.03821
Step 207735: loss = 0.49412
Step 207740: loss = 0.09723
Step 207745: loss = 0.22064
Step 207750: loss = 0.05984
Step 207755: loss = 0.12216
Step 207760: loss = 0.05764
Step 207765: loss = 0.14609
Step 207770: loss = 0.16907
Step 207775: loss = 0.07889
Step 207780: loss = 0.03644
Step 207785: loss = 0.05026
Step 207790: loss = 0.08809
Step 207795: loss = 0.05759
Step 207800: loss = 0.14856
Step 207805: loss = 0.13021
Step 207810: loss = 0.07416
Step 207815: loss = 0.08615
Step 207820: loss = 0.11429
Step 207825: loss = 0.07694
Step 207830: loss = 0.16115
Step 207835: loss = 0.03947
Step 207840: loss = 0.20770
Step 207845: loss = 0.12338
Step 207850: loss = 0.03928
Step 207855: loss = 0.12938
Step 207860: loss = 0.01819
Step 207865: loss = 0.30431
Step 207870: loss = 0.03503
Step 207875: loss = 0.11265
Step 207880: loss = 0.10374
Step 207885: loss = 0.14018
Step 207890: loss = 0.05918
Step 207895: loss = 0.24231
Step 207900: loss = 0.10327
Step 207905: loss = 0.09768
Step 207910: loss = 0.04716
Step 207915: loss = 0.06206
Step 207920: loss = 0.07830
Step 207925: loss = 0.03776
Step 207930: loss = 0.05741
Step 207935: loss = 0.30022
Step 207940: loss = 0.09193
Step 207945: loss = 0.16743
Step 207950: loss = 0.11147
Step 207955: loss = 0.21013
Step 207960: loss = 0.05842
Step 207965: loss = 0.13583
Step 207970: loss = 0.10099
Step 207975: loss = 0.09983
Step 207980: loss = 0.09005
Step 207985: loss = 0.02492
Step 207990: loss = 0.18088
Step 207995: loss = 0.05430
Step 208000: loss = 0.03219
Training Data Eval:
  Num examples: 50000, Num correct: 48159, Precision @ 1: 0.9632
('Testing Data Eval: EPOCH->', 209)
  Num examples: 10000, Num correct: 6701, Precision @ 1: 0.6701
Step 208005: loss = 0.06588
Step 208010: loss = 0.04929
Step 208015: loss = 0.06941
Step 208020: loss = 0.11230
Step 208025: loss = 0.10048
Step 208030: loss = 0.03578
Step 208035: loss = 0.06848
Step 208040: loss = 0.02477
Step 208045: loss = 0.09276
Step 208050: loss = 0.09690
Step 208055: loss = 0.02570
Step 208060: loss = 0.11957
Step 208065: loss = 0.19218
Step 208070: loss = 0.09316
Step 208075: loss = 0.02455
Step 208080: loss = 0.05595
Step 208085: loss = 0.09713
Step 208090: loss = 0.04962
Step 208095: loss = 0.09762
Step 208100: loss = 0.18626
Step 208105: loss = 0.08868
Step 208110: loss = 0.06963
Step 208115: loss = 0.14790
Step 208120: loss = 0.03925
Step 208125: loss = 0.08479
Step 208130: loss = 0.04836
Step 208135: loss = 0.13509
Step 208140: loss = 0.05369
Step 208145: loss = 0.02717
Step 208150: loss = 0.04552
Step 208155: loss = 0.06619
Step 208160: loss = 0.11157
Step 208165: loss = 0.18572
Step 208170: loss = 0.05813
Step 208175: loss = 0.05309
Step 208180: loss = 0.19123
Step 208185: loss = 0.30483
Step 208190: loss = 0.01501
Step 208195: loss = 0.64891
Step 208200: loss = 0.15733
Step 208205: loss = 0.02208
Step 208210: loss = 0.05413
Step 208215: loss = 0.14902
Step 208220: loss = 0.17730
Step 208225: loss = 0.05445
Step 208230: loss = 0.13692
Step 208235: loss = 0.14009
Step 208240: loss = 0.25585
Step 208245: loss = 0.12647
Step 208250: loss = 0.14539
Step 208255: loss = 0.17175
Step 208260: loss = 0.05154
Step 208265: loss = 0.15302
Step 208270: loss = 0.05527
Step 208275: loss = 0.13110
Step 208280: loss = 0.12846
Step 208285: loss = 0.19096
Step 208290: loss = 0.07547
Step 208295: loss = 0.11071
Step 208300: loss = 0.02850
Step 208305: loss = 0.10725
Step 208310: loss = 0.20476
Step 208315: loss = 0.04344
Step 208320: loss = 0.07599
Step 208325: loss = 0.11925
Step 208330: loss = 0.34552
Step 208335: loss = 0.23570
Step 208340: loss = 0.07063
Step 208345: loss = 0.03243
Step 208350: loss = 0.11667
Step 208355: loss = 0.08315
Step 208360: loss = 0.14267
Step 208365: loss = 0.09824
Step 208370: loss = 0.09366
Step 208375: loss = 0.13224
Step 208380: loss = 0.13766
Step 208385: loss = 0.15331
Step 208390: loss = 0.08523
Step 208395: loss = 0.08822
Step 208400: loss = 0.40515
Step 208405: loss = 0.21017
Step 208410: loss = 0.09099
Step 208415: loss = 0.15912
Step 208420: loss = 0.10763
Step 208425: loss = 0.18551
Step 208430: loss = 0.01762
Step 208435: loss = 0.16441
Step 208440: loss = 0.07403
Step 208445: loss = 0.04210
Step 208450: loss = 0.11686
Step 208455: loss = 0.07210
Step 208460: loss = 0.11707
Step 208465: loss = 0.18046
Step 208470: loss = 0.30606
Step 208475: loss = 0.09989
Step 208480: loss = 0.13607
Step 208485: loss = 0.07209
Step 208490: loss = 0.07342
Step 208495: loss = 0.10909
Step 208500: loss = 0.10790
Step 208505: loss = 0.17241
Step 208510: loss = 0.19981
Step 208515: loss = 0.10726
Step 208520: loss = 0.02524
Step 208525: loss = 0.27299
Step 208530: loss = 0.13421
Step 208535: loss = 0.06565
Step 208540: loss = 0.05689
Step 208545: loss = 0.04516
Step 208550: loss = 0.04681
Step 208555: loss = 0.04557
Step 208560: loss = 0.07223
Step 208565: loss = 0.15090
Step 208570: loss = 0.21173
Step 208575: loss = 0.08303
Step 208580: loss = 0.05439
Step 208585: loss = 0.10198
Step 208590: loss = 0.07857
Step 208595: loss = 0.17652
Step 208600: loss = 0.25867
Step 208605: loss = 0.04005
Step 208610: loss = 0.11977
Step 208615: loss = 0.07444
Step 208620: loss = 0.09409
Step 208625: loss = 0.07153
Step 208630: loss = 0.07452
Step 208635: loss = 0.18986
Step 208640: loss = 0.02400
Step 208645: loss = 0.06344
Step 208650: loss = 0.11247
Step 208655: loss = 0.03302
Step 208660: loss = 0.15041
Step 208665: loss = 0.12473
Step 208670: loss = 0.06677
Step 208675: loss = 0.07893
Step 208680: loss = 0.04943
Step 208685: loss = 0.13366
Step 208690: loss = 0.18810
Step 208695: loss = 0.06090
Step 208700: loss = 0.00756
Step 208705: loss = 0.15435
Step 208710: loss = 0.18058
Step 208715: loss = 0.07531
Step 208720: loss = 0.04388
Step 208725: loss = 0.23858
Step 208730: loss = 0.13885
Step 208735: loss = 0.05255
Step 208740: loss = 0.09957
Step 208745: loss = 0.10813
Step 208750: loss = 0.02633
Step 208755: loss = 0.15991
Step 208760: loss = 0.26194
Step 208765: loss = 0.17576
Step 208770: loss = 0.02665
Step 208775: loss = 0.31005
Step 208780: loss = 0.05481
Step 208785: loss = 0.04433
Step 208790: loss = 0.19030
Step 208795: loss = 0.16420
Step 208800: loss = 0.03320
Step 208805: loss = 0.26709
Step 208810: loss = 0.34072
Step 208815: loss = 0.12578
Step 208820: loss = 0.13206
Step 208825: loss = 0.04275
Step 208830: loss = 0.04924
Step 208835: loss = 0.02973
Step 208840: loss = 0.02031
Step 208845: loss = 0.08639
Step 208850: loss = 0.03198
Step 208855: loss = 0.16252
Step 208860: loss = 0.02017
Step 208865: loss = 0.07193
Step 208870: loss = 0.03263
Step 208875: loss = 0.14201
Step 208880: loss = 0.05005
Step 208885: loss = 0.16117
Step 208890: loss = 0.10260
Step 208895: loss = 0.02333
Step 208900: loss = 0.30107
Step 208905: loss = 0.06217
Step 208910: loss = 0.11123
Step 208915: loss = 0.11627
Step 208920: loss = 0.12385
Step 208925: loss = 0.04631
Step 208930: loss = 0.11599
Step 208935: loss = 0.06912
Step 208940: loss = 0.04410
Step 208945: loss = 0.05584
Step 208950: loss = 0.15119
Step 208955: loss = 0.02583
Step 208960: loss = 0.05781
Step 208965: loss = 0.21240
Step 208970: loss = 0.22736
Step 208975: loss = 0.29125
Step 208980: loss = 0.14963
Step 208985: loss = 0.10788
Step 208990: loss = 0.19955
Step 208995: loss = 0.09193
Step 209000: loss = 0.04694
Training Data Eval:
  Num examples: 50000, Num correct: 48378, Precision @ 1: 0.9676
('Testing Data Eval: EPOCH->', 210)
  Num examples: 10000, Num correct: 6727, Precision @ 1: 0.6727
Step 209005: loss = 0.08499
Step 209010: loss = 0.09407
Step 209015: loss = 0.02761
Step 209020: loss = 0.02920
Step 209025: loss = 0.03004
Step 209030: loss = 0.09969
Step 209035: loss = 0.08121
Step 209040: loss = 0.12907
Step 209045: loss = 0.07731
Step 209050: loss = 0.06044
Step 209055: loss = 0.04252
Step 209060: loss = 0.02811
Step 209065: loss = 0.10773
Step 209070: loss = 0.06950
Step 209075: loss = 0.08961
Step 209080: loss = 0.11861
Step 209085: loss = 0.15518
Step 209090: loss = 0.17677
Step 209095: loss = 0.12557
Step 209100: loss = 0.04137
Step 209105: loss = 0.01636
Step 209110: loss = 0.05615
Step 209115: loss = 0.03845
Step 209120: loss = 0.07891
Step 209125: loss = 0.10659
Step 209130: loss = 0.24193
Step 209135: loss = 0.03025
Step 209140: loss = 0.02076
Step 209145: loss = 0.03536
Step 209150: loss = 0.15151
Step 209155: loss = 0.03311
Step 209160: loss = 0.20528
Step 209165: loss = 0.07250
Step 209170: loss = 0.08419
Step 209175: loss = 0.05908
Step 209180: loss = 0.06203
Step 209185: loss = 0.03414
Step 209190: loss = 0.11067
Step 209195: loss = 0.09390
Step 209200: loss = 0.08070
Step 209205: loss = 0.09054
Step 209210: loss = 0.11400
Step 209215: loss = 0.05594
Step 209220: loss = 0.06348
Step 209225: loss = 0.15099
Step 209230: loss = 0.03173
Step 209235: loss = 0.11738
Step 209240: loss = 0.01630
Step 209245: loss = 0.09307
Step 209250: loss = 0.03891
Step 209255: loss = 0.04219
Step 209260: loss = 0.02427
Step 209265: loss = 0.04738
Step 209270: loss = 0.03139
Step 209275: loss = 0.05731
Step 209280: loss = 0.03082
Step 209285: loss = 0.12324
Step 209290: loss = 0.04156
Step 209295: loss = 0.15041
Step 209300: loss = 0.25040
Step 209305: loss = 0.04524
Step 209310: loss = 0.02541
Step 209315: loss = 0.06850
Step 209320: loss = 0.17186
Step 209325: loss = 0.13165
Step 209330: loss = 0.04537
Step 209335: loss = 0.13169
Step 209340: loss = 0.31803
Step 209345: loss = 0.02814
Step 209350: loss = 0.07377
Step 209355: loss = 0.04038
Step 209360: loss = 0.14088
Step 209365: loss = 0.08164
Step 209370: loss = 0.10572
Step 209375: loss = 0.13549
Step 209380: loss = 0.25473
Step 209385: loss = 0.04623
Step 209390: loss = 0.11094
Step 209395: loss = 0.08431
Step 209400: loss = 0.03545
Step 209405: loss = 0.04151
Step 209410: loss = 0.06615
Step 209415: loss = 0.04693
Step 209420: loss = 0.19895
Step 209425: loss = 0.04996
Step 209430: loss = 0.12510
Step 209435: loss = 0.08820
Step 209440: loss = 0.05188
Step 209445: loss = 0.05127
Step 209450: loss = 0.12005
Step 209455: loss = 0.12421
Step 209460: loss = 0.10726
Step 209465: loss = 0.12691
Step 209470: loss = 0.17089
Step 209475: loss = 0.12104
Step 209480: loss = 0.03929
Step 209485: loss = 0.06095
Step 209490: loss = 0.09076
Step 209495: loss = 0.07672
Step 209500: loss = 0.03827
Step 209505: loss = 0.10548
Step 209510: loss = 0.08794
Step 209515: loss = 0.08177
Step 209520: loss = 0.02847
Step 209525: loss = 0.02694
Step 209530: loss = 0.22700
Step 209535: loss = 0.01792
Step 209540: loss = 0.02438
Step 209545: loss = 0.04667
Step 209550: loss = 0.05125
Step 209555: loss = 0.02453
Step 209560: loss = 0.23710
Step 209565: loss = 0.04265
Step 209570: loss = 0.13985
Step 209575: loss = 0.10753
Step 209580: loss = 0.14008
Step 209585: loss = 0.18803
Step 209590: loss = 0.03865
Step 209595: loss = 0.05342
Step 209600: loss = 0.15313
Step 209605: loss = 0.02398
Step 209610: loss = 0.02572
Step 209615: loss = 0.04400
Step 209620: loss = 0.13458
Step 209625: loss = 0.05146
Step 209630: loss = 0.10518
Step 209635: loss = 0.10712
Step 209640: loss = 0.05676
Step 209645: loss = 0.24894
Step 209650: loss = 0.07599
Step 209655: loss = 0.08542
Step 209660: loss = 0.15473
Step 209665: loss = 0.06150
Step 209670: loss = 0.11290
Step 209675: loss = 0.04008
Step 209680: loss = 0.01516
Step 209685: loss = 0.12135
Step 209690: loss = 0.09603
Step 209695: loss = 0.07537
Step 209700: loss = 0.03910
Step 209705: loss = 0.15975
Step 209710: loss = 0.20735
Step 209715: loss = 0.02314
Step 209720: loss = 0.07363
Step 209725: loss = 0.04537
Step 209730: loss = 0.09994
Step 209735: loss = 0.04853
Step 209740: loss = 0.04857
Step 209745: loss = 0.06196
Step 209750: loss = 0.07783
Step 209755: loss = 0.27642
Step 209760: loss = 0.10756
Step 209765: loss = 0.12027
Step 209770: loss = 0.24029
Step 209775: loss = 0.14678
Step 209780: loss = 0.03720
Step 209785: loss = 0.05489
Step 209790: loss = 0.10541
Step 209795: loss = 0.10207
Step 209800: loss = 0.16262
Step 209805: loss = 0.12355
Step 209810: loss = 0.09875
Step 209815: loss = 0.14613
Step 209820: loss = 0.09364
Step 209825: loss = 0.03386
Step 209830: loss = 0.03176
Step 209835: loss = 0.06519
Step 209840: loss = 0.22315
Step 209845: loss = 0.09482
Step 209850: loss = 0.12926
Step 209855: loss = 0.04425
Step 209860: loss = 0.03001
Step 209865: loss = 0.04260
Step 209870: loss = 0.07826
Step 209875: loss = 0.07894
Step 209880: loss = 0.05161
Step 209885: loss = 0.03601
Step 209890: loss = 0.03731
Step 209895: loss = 0.10024
Step 209900: loss = 0.10027
Step 209905: loss = 0.04330
Step 209910: loss = 0.09439
Step 209915: loss = 0.06541
Step 209920: loss = 0.04445
Step 209925: loss = 0.05866
Step 209930: loss = 0.10511
Step 209935: loss = 0.00819
Step 209940: loss = 0.13408
Step 209945: loss = 0.12130
Step 209950: loss = 0.09178
Step 209955: loss = 0.11940
Step 209960: loss = 0.02143
Step 209965: loss = 0.22744
Step 209970: loss = 0.06380
Step 209975: loss = 0.10087
Step 209980: loss = 0.03370
Step 209985: loss = 0.05704
Step 209990: loss = 0.14457
Step 209995: loss = 0.06559
Step 210000: loss = 0.30488
Training Data Eval:
  Num examples: 50000, Num correct: 48162, Precision @ 1: 0.9632
('Testing Data Eval: EPOCH->', 211)
  Num examples: 10000, Num correct: 6644, Precision @ 1: 0.6644
Step 210005: loss = 0.25844
Step 210010: loss = 0.04396
Step 210015: loss = 0.08442
Step 210020: loss = 0.10216
Step 210025: loss = 0.06114
Step 210030: loss = 0.04866
Step 210035: loss = 0.12789
Step 210040: loss = 0.05220
Step 210045: loss = 0.09169
Step 210050: loss = 0.07187
Step 210055: loss = 0.16940
Step 210060: loss = 0.27299
Step 210065: loss = 0.10693
Step 210070: loss = 0.22924
Step 210075: loss = 0.14962
Step 210080: loss = 0.10801
Step 210085: loss = 0.02744
Step 210090: loss = 0.17078
Step 210095: loss = 0.12546
Step 210100: loss = 0.07997
Step 210105: loss = 0.11450
Step 210110: loss = 0.04831
Step 210115: loss = 0.08498
Step 210120: loss = 0.04387
Step 210125: loss = 0.06450
Step 210130: loss = 0.11035
Step 210135: loss = 0.02982
Step 210140: loss = 0.06716
Step 210145: loss = 0.17736
Step 210150: loss = 0.10568
Step 210155: loss = 0.03912
Step 210160: loss = 0.16786
Step 210165: loss = 0.09966
Step 210170: loss = 0.03105
Step 210175: loss = 0.05349
Step 210180: loss = 0.12897
Step 210185: loss = 0.09650
Step 210190: loss = 0.07856
Step 210195: loss = 0.05592
Step 210200: loss = 0.04852
Step 210205: loss = 0.11762
Step 210210: loss = 0.10899
Step 210215: loss = 0.04079
Step 210220: loss = 0.05467
Step 210225: loss = 0.08198
Step 210230: loss = 0.12303
Step 210235: loss = 0.23735
Step 210240: loss = 0.14138
Step 210245: loss = 0.58541
Step 210250: loss = 0.03598
Step 210255: loss = 0.06382
Step 210260: loss = 0.09996
Step 210265: loss = 0.14238
Step 210270: loss = 0.25159
Step 210275: loss = 0.09332
Step 210280: loss = 0.06529
Step 210285: loss = 0.14298
Step 210290: loss = 0.13998
Step 210295: loss = 0.15153
Step 210300: loss = 0.13220
Step 210305: loss = 0.06783
Step 210310: loss = 0.33648
Step 210315: loss = 0.12727
Step 210320: loss = 0.13477
Step 210325: loss = 0.02759
Step 210330: loss = 0.04750
Step 210335: loss = 0.29982
Step 210340: loss = 0.05341
Step 210345: loss = 0.04655
Step 210350: loss = 0.12129
Step 210355: loss = 0.10682
Step 210360: loss = 0.14789
Step 210365: loss = 0.07519
Step 210370: loss = 0.09510
Step 210375: loss = 0.10241
Step 210380: loss = 0.02842
Step 210385: loss = 0.04092
Step 210390: loss = 0.19313
Step 210395: loss = 0.02766
Step 210400: loss = 0.12856
Step 210405: loss = 0.07746
Step 210410: loss = 0.09814
Step 210415: loss = 0.01489
Step 210420: loss = 0.03428
Step 210425: loss = 0.09341
Step 210430: loss = 0.11353
Step 210435: loss = 0.12167
Step 210440: loss = 0.04921
Step 210445: loss = 0.14681
Step 210450: loss = 0.06854
Step 210455: loss = 0.14704
Step 210460: loss = 0.06316
Step 210465: loss = 0.17277
Step 210470: loss = 0.03085
Step 210475: loss = 0.04541
Step 210480: loss = 0.20533
Step 210485: loss = 0.23664
Step 210490: loss = 0.07268
Step 210495: loss = 0.28699
Step 210500: loss = 0.06093
Step 210505: loss = 0.08274
Step 210510: loss = 0.05012
Step 210515: loss = 0.02080
Step 210520: loss = 0.01717
Step 210525: loss = 0.06189
Step 210530: loss = 0.31696
Step 210535: loss = 0.33723
Step 210540: loss = 0.14899
Step 210545: loss = 0.16436
Step 210550: loss = 0.18798
Step 210555: loss = 0.13569
Step 210560: loss = 0.07012
Step 210565: loss = 0.12696
Step 210570: loss = 0.09453
Step 210575: loss = 0.07687
Step 210580: loss = 0.16339
Step 210585: loss = 0.15946
Step 210590: loss = 0.03635
Step 210595: loss = 0.03845
Step 210600: loss = 0.03935
Step 210605: loss = 0.06991
Step 210610: loss = 0.12548
Step 210615: loss = 0.15836
Step 210620: loss = 0.05843
Step 210625: loss = 0.02727
Step 210630: loss = 0.03855
Step 210635: loss = 0.07594
Step 210640: loss = 0.09282
Step 210645: loss = 0.05554
Step 210650: loss = 0.08405
Step 210655: loss = 0.02794
Step 210660: loss = 0.07184
Step 210665: loss = 0.07327
Step 210670: loss = 0.10328
Step 210675: loss = 0.06003
Step 210680: loss = 0.17296
Step 210685: loss = 0.04450
Step 210690: loss = 0.05960
Step 210695: loss = 0.26204
Step 210700: loss = 0.22886
Step 210705: loss = 0.05020
Step 210710: loss = 0.03069
Step 210715: loss = 0.11106
Step 210720: loss = 0.15000
Step 210725: loss = 0.05647
Step 210730: loss = 0.08787
Step 210735: loss = 0.11572
Step 210740: loss = 0.10614
Step 210745: loss = 0.02612
Step 210750: loss = 0.14607
Step 210755: loss = 0.11634
Step 210760: loss = 0.17572
Step 210765: loss = 0.21627
Step 210770: loss = 0.11615
Step 210775: loss = 0.02896
Step 210780: loss = 0.13983
Step 210785: loss = 0.01695
Step 210790: loss = 0.30413
Step 210795: loss = 0.03706
Step 210800: loss = 0.07799
Step 210805: loss = 0.16588
Step 210810: loss = 0.15530
Step 210815: loss = 0.09278
Step 210820: loss = 0.17776
Step 210825: loss = 0.18872
Step 210830: loss = 0.05451
Step 210835: loss = 0.13326
Step 210840: loss = 0.32650
Step 210845: loss = 0.02769
Step 210850: loss = 0.04145
Step 210855: loss = 0.17876
Step 210860: loss = 0.07180
Step 210865: loss = 0.03628
Step 210870: loss = 0.02632
Step 210875: loss = 0.02756
Step 210880: loss = 0.07782
Step 210885: loss = 0.19745
Step 210890: loss = 0.17144
Step 210895: loss = 0.04052
Step 210900: loss = 0.07876
Step 210905: loss = 0.06377
Step 210910: loss = 0.09812
Step 210915: loss = 0.06199
Step 210920: loss = 0.14124
Step 210925: loss = 0.03999
Step 210930: loss = 0.13877
Step 210935: loss = 0.04472
Step 210940: loss = 0.02105
Step 210945: loss = 0.08289
Step 210950: loss = 0.12477
Step 210955: loss = 0.03710
Step 210960: loss = 0.19724
Step 210965: loss = 0.07587
Step 210970: loss = 0.14310
Step 210975: loss = 0.05116
Step 210980: loss = 0.07952
Step 210985: loss = 0.11344
Step 210990: loss = 0.10082
Step 210995: loss = 0.10407
Step 211000: loss = 0.02890
Training Data Eval:
  Num examples: 50000, Num correct: 48390, Precision @ 1: 0.9678
('Testing Data Eval: EPOCH->', 212)
  Num examples: 10000, Num correct: 6761, Precision @ 1: 0.6761
Step 211005: loss = 0.02429
Step 211010: loss = 0.10718
Step 211015: loss = 0.05109
Step 211020: loss = 0.08828
Step 211025: loss = 0.13753
Step 211030: loss = 0.05785
Step 211035: loss = 0.09055
Step 211040: loss = 0.06430
Step 211045: loss = 0.15037
Step 211050: loss = 0.07038
Step 211055: loss = 0.05871
Step 211060: loss = 0.18272
Step 211065: loss = 0.06478
Step 211070: loss = 0.08735
Step 211075: loss = 0.19096
Step 211080: loss = 0.08786
Step 211085: loss = 0.14439
Step 211090: loss = 0.03049
Step 211095: loss = 0.11621
Step 211100: loss = 0.03603
Step 211105: loss = 0.11076
Step 211110: loss = 0.03103
Step 211115: loss = 0.16790
Step 211120: loss = 0.14790
Step 211125: loss = 0.05086
Step 211130: loss = 0.18331
Step 211135: loss = 0.08231
Step 211140: loss = 0.13075
Step 211145: loss = 0.07204
Step 211150: loss = 0.02444
Step 211155: loss = 0.12420
Step 211160: loss = 0.11470
Step 211165: loss = 0.04392
Step 211170: loss = 0.44702
Step 211175: loss = 0.07065
Step 211180: loss = 0.08426
Step 211185: loss = 0.04033
Step 211190: loss = 0.16707
Step 211195: loss = 0.05843
Step 211200: loss = 0.13616
Step 211205: loss = 0.05300
Step 211210: loss = 0.09060
Step 211215: loss = 0.04334
Step 211220: loss = 0.03308
Step 211225: loss = 0.13299
Step 211230: loss = 0.09613
Step 211235: loss = 0.05820
Step 211240: loss = 0.15848
Step 211245: loss = 0.07552
Step 211250: loss = 0.03009
Step 211255: loss = 0.05877
Step 211260: loss = 0.08258
Step 211265: loss = 0.25496
Step 211270: loss = 0.08815
Step 211275: loss = 0.06033
Step 211280: loss = 0.02080
Step 211285: loss = 0.11437
Step 211290: loss = 0.03112
Step 211295: loss = 0.03834
Step 211300: loss = 0.05481
Step 211305: loss = 0.06681
Step 211310: loss = 0.14967
Step 211315: loss = 0.06239
Step 211320: loss = 0.16978
Step 211325: loss = 0.11998
Step 211330: loss = 0.07762
Step 211335: loss = 0.02258
Step 211340: loss = 0.10796
Step 211345: loss = 0.10813
Step 211350: loss = 0.16450
Step 211355: loss = 0.06214
Step 211360: loss = 0.08719
Step 211365: loss = 0.05250
Step 211370: loss = 0.02925
Step 211375: loss = 0.04322
Step 211380: loss = 0.18482
Step 211385: loss = 0.10787
Step 211390: loss = 0.09081
Step 211395: loss = 0.06360
Step 211400: loss = 0.24420
Step 211405: loss = 0.15915
Step 211410: loss = 0.13993
Step 211415: loss = 0.07241
Step 211420: loss = 0.08953
Step 211425: loss = 0.13150
Step 211430: loss = 0.24460
Step 211435: loss = 0.10144
Step 211440: loss = 0.18831
Step 211445: loss = 0.13951
Step 211450: loss = 0.17476
Step 211455: loss = 0.09027
Step 211460: loss = 0.05921
Step 211465: loss = 0.06906
Step 211470: loss = 0.08008
Step 211475: loss = 0.21581
Step 211480: loss = 0.01869
Step 211485: loss = 0.05964
Step 211490: loss = 0.09793
Step 211495: loss = 0.06393
Step 211500: loss = 0.10934
Step 211505: loss = 0.04967
Step 211510: loss = 0.18466
Step 211515: loss = 0.02489
Step 211520: loss = 0.12675
Step 211525: loss = 0.07739
Step 211530: loss = 0.05011
Step 211535: loss = 0.03961
Step 211540: loss = 0.08719
Step 211545: loss = 0.06575
Step 211550: loss = 0.23326
Step 211555: loss = 0.09354
Step 211560: loss = 0.07948
Step 211565: loss = 0.10261
Step 211570: loss = 0.09069
Step 211575: loss = 0.04545
Step 211580: loss = 0.22593
Step 211585: loss = 0.09967
Step 211590: loss = 0.04768
Step 211595: loss = 0.02427
Step 211600: loss = 0.15071
Step 211605: loss = 0.05645
Step 211610: loss = 0.03009
Step 211615: loss = 0.05589
Step 211620: loss = 0.06505
Step 211625: loss = 0.05251
Step 211630: loss = 0.11477
Step 211635: loss = 0.06186
Step 211640: loss = 0.11274
Step 211645: loss = 0.12731
Step 211650: loss = 0.04820
Step 211655: loss = 0.09461
Step 211660: loss = 0.18277
Step 211665: loss = 0.05662
Step 211670: loss = 0.04232
Step 211675: loss = 0.04369
Step 211680: loss = 0.04581
Step 211685: loss = 0.26999
Step 211690: loss = 0.08119
Step 211695: loss = 0.03872
Step 211700: loss = 0.23154
Step 211705: loss = 0.06132
Step 211710: loss = 0.03492
Step 211715: loss = 0.13899
Step 211720: loss = 0.02170
Step 211725: loss = 0.12370
Step 211730: loss = 0.07550
Step 211735: loss = 0.07910
Step 211740: loss = 0.12974
Step 211745: loss = 0.04303
Step 211750: loss = 0.03552
Step 211755: loss = 0.05671
Step 211760: loss = 0.14043
Step 211765: loss = 0.12739
Step 211770: loss = 0.01721
Step 211775: loss = 0.03429
Step 211780: loss = 0.20603
Step 211785: loss = 0.23566
Step 211790: loss = 0.16916
Step 211795: loss = 0.11707
Step 211800: loss = 0.35068
Step 211805: loss = 0.06020
Step 211810: loss = 0.11230
Step 211815: loss = 0.10011
Step 211820: loss = 0.21775
Step 211825: loss = 0.14739
Step 211830: loss = 0.05685
Step 211835: loss = 0.09429
Step 211840: loss = 0.12564
Step 211845: loss = 0.08497
Step 211850: loss = 0.02429
Step 211855: loss = 0.07824
Step 211860: loss = 0.03457
Step 211865: loss = 0.05858
Step 211870: loss = 0.29873
Step 211875: loss = 0.05266
Step 211880: loss = 0.11754
Step 211885: loss = 0.05639
Step 211890: loss = 0.11703
Step 211895: loss = 0.05331
Step 211900: loss = 0.02592
Step 211905: loss = 0.18942
Step 211910: loss = 0.21351
Step 211915: loss = 0.19572
Step 211920: loss = 0.08674
Step 211925: loss = 0.01662
Step 211930: loss = 0.07562
Step 211935: loss = 0.02380
Step 211940: loss = 0.03120
Step 211945: loss = 0.07408
Step 211950: loss = 0.03283
Step 211955: loss = 0.15658
Step 211960: loss = 0.07396
Step 211965: loss = 0.25711
Step 211970: loss = 0.08610
Step 211975: loss = 0.03668
Step 211980: loss = 0.05563
Step 211985: loss = 0.08840
Step 211990: loss = 0.07225
Step 211995: loss = 0.14154
Step 212000: loss = 0.14125
Training Data Eval:
  Num examples: 50000, Num correct: 48210, Precision @ 1: 0.9642
('Testing Data Eval: EPOCH->', 213)
  Num examples: 10000, Num correct: 6729, Precision @ 1: 0.6729
Step 212005: loss = 0.10030
Step 212010: loss = 0.25470
Step 212015: loss = 0.02775
Step 212020: loss = 0.22383
Step 212025: loss = 0.06005
Step 212030: loss = 0.10533
Step 212035: loss = 0.05740
Step 212040: loss = 0.05919
Step 212045: loss = 0.15830
Step 212050: loss = 0.03370
Step 212055: loss = 0.34264
Step 212060: loss = 0.15340
Step 212065: loss = 0.06854
Step 212070: loss = 0.01738
Step 212075: loss = 0.06038
Step 212080: loss = 0.01704
Step 212085: loss = 0.08272
Step 212090: loss = 0.18421
Step 212095: loss = 0.06643
Step 212100: loss = 0.07116
Step 212105: loss = 0.16928
Step 212110: loss = 0.01412
Step 212115: loss = 0.22249
Step 212120: loss = 0.17245
Step 212125: loss = 0.10614
Step 212130: loss = 0.13463
Step 212135: loss = 0.08490
Step 212140: loss = 0.23195
Step 212145: loss = 0.12438
Step 212150: loss = 0.02151
Step 212155: loss = 0.03867
Step 212160: loss = 0.03794
Step 212165: loss = 0.19696
Step 212170: loss = 0.24578
Step 212175: loss = 0.07745
Step 212180: loss = 0.10003
Step 212185: loss = 0.12310
Step 212190: loss = 0.05454
Step 212195: loss = 0.05621
Step 212200: loss = 0.21464
Step 212205: loss = 0.13356
Step 212210: loss = 0.04490
Step 212215: loss = 0.29294
Step 212220: loss = 0.13854
Step 212225: loss = 0.10217
Step 212230: loss = 0.02524
Step 212235: loss = 0.21538
Step 212240: loss = 0.08045
Step 212245: loss = 0.18039
Step 212250: loss = 0.04597
Step 212255: loss = 0.14603
Step 212260: loss = 0.04659
Step 212265: loss = 0.03095
Step 212270: loss = 0.27759
Step 212275: loss = 0.17929
Step 212280: loss = 0.17866
Step 212285: loss = 0.06544
Step 212290: loss = 0.18723
Step 212295: loss = 0.14033
Step 212300: loss = 0.02334
Step 212305: loss = 0.04276
Step 212310: loss = 0.06579
Step 212315: loss = 0.11747
Step 212320: loss = 0.11444
Step 212325: loss = 0.01464
Step 212330: loss = 0.19635
Step 212335: loss = 0.27560
Step 212340: loss = 0.06357
Step 212345: loss = 0.04012
Step 212350: loss = 0.13496
Step 212355: loss = 0.04556
Step 212360: loss = 0.06225
Step 212365: loss = 0.08479
Step 212370: loss = 0.05345
Step 212375: loss = 0.16377
Step 212380: loss = 0.03666
Step 212385: loss = 0.27090
Step 212390: loss = 0.02748
Step 212395: loss = 0.05810
Step 212400: loss = 0.21375
Step 212405: loss = 0.21922
Step 212410: loss = 0.04284
Step 212415: loss = 0.06897
Step 212420: loss = 0.07619
Step 212425: loss = 0.06623
Step 212430: loss = 0.03729
Step 212435: loss = 0.12151
Step 212440: loss = 0.14783
Step 212445: loss = 0.10984
Step 212450: loss = 0.22339
Step 212455: loss = 0.07289
Step 212460: loss = 0.04705
Step 212465: loss = 0.03568
Step 212470: loss = 0.10739
Step 212475: loss = 0.23325
Step 212480: loss = 0.27496
Step 212485: loss = 0.12343
Step 212490: loss = 0.08868
Step 212495: loss = 0.04954
Step 212500: loss = 0.04243
Step 212505: loss = 0.03770
Step 212510: loss = 0.03583
Step 212515: loss = 0.02172
Step 212520: loss = 0.14622
Step 212525: loss = 0.14233
Step 212530: loss = 0.11616
Step 212535: loss = 0.04956
Step 212540: loss = 0.09574
Step 212545: loss = 0.10795
Step 212550: loss = 0.02674
Step 212555: loss = 0.04246
Step 212560: loss = 0.03335
Step 212565: loss = 0.03020
Step 212570: loss = 0.20211
Step 212575: loss = 0.09325
Step 212580: loss = 0.07005
Step 212585: loss = 0.15936
Step 212590: loss = 0.18478
Step 212595: loss = 0.14160
Step 212600: loss = 0.04275
Step 212605: loss = 0.09876
Step 212610: loss = 0.05389
Step 212615: loss = 0.06953
Step 212620: loss = 0.12712
Step 212625: loss = 0.05406
Step 212630: loss = 0.05851
Step 212635: loss = 0.08388
Step 212640: loss = 0.21028
Step 212645: loss = 0.14777
Step 212650: loss = 0.04919
Step 212655: loss = 0.10314
Step 212660: loss = 0.14733
Step 212665: loss = 0.07169
Step 212670: loss = 0.03342
Step 212675: loss = 0.05139
Step 212680: loss = 0.02906
Step 212685: loss = 0.05291
Step 212690: loss = 0.03425
Step 212695: loss = 0.07370
Step 212700: loss = 0.03128
Step 212705: loss = 0.05580
Step 212710: loss = 0.06944
Step 212715: loss = 0.07688
Step 212720: loss = 0.31344
Step 212725: loss = 0.11245
Step 212730: loss = 0.05797
Step 212735: loss = 0.16181
Step 212740: loss = 0.05549
Step 212745: loss = 0.08581
Step 212750: loss = 0.13484
Step 212755: loss = 0.02295
Step 212760: loss = 0.25564
Step 212765: loss = 0.02498
Step 212770: loss = 0.10686
Step 212775: loss = 0.08350
Step 212780: loss = 0.10100
Step 212785: loss = 0.08565
Step 212790: loss = 0.03522
Step 212795: loss = 0.03344
Step 212800: loss = 0.13795
Step 212805: loss = 0.08890
Step 212810: loss = 0.07515
Step 212815: loss = 0.06899
Step 212820: loss = 0.04566
Step 212825: loss = 0.02838
Step 212830: loss = 0.09209
Step 212835: loss = 0.11932
Step 212840: loss = 0.03695
Step 212845: loss = 0.02281
Step 212850: loss = 0.19461
Step 212855: loss = 0.30073
Step 212860: loss = 0.03546
Step 212865: loss = 0.01586
Step 212870: loss = 0.09702
Step 212875: loss = 0.08563
Step 212880: loss = 0.08965
Step 212885: loss = 0.03465
Step 212890: loss = 0.05526
Step 212895: loss = 0.13468
Step 212900: loss = 0.02494
Step 212905: loss = 0.08074
Step 212910: loss = 0.04526
Step 212915: loss = 0.21009
Step 212920: loss = 0.05572
Step 212925: loss = 0.13520
Step 212930: loss = 0.20314
Step 212935: loss = 0.06031
Step 212940: loss = 0.02578
Step 212945: loss = 0.02308
Step 212950: loss = 0.05582
Step 212955: loss = 0.18348
Step 212960: loss = 0.22264
Step 212965: loss = 0.09005
Step 212970: loss = 0.09174
Step 212975: loss = 0.04955
Step 212980: loss = 0.01667
Step 212985: loss = 0.05446
Step 212990: loss = 0.09046
Step 212995: loss = 0.10415
Step 213000: loss = 0.19839
Training Data Eval:
  Num examples: 50000, Num correct: 48420, Precision @ 1: 0.9684
('Testing Data Eval: EPOCH->', 214)
  Num examples: 10000, Num correct: 6743, Precision @ 1: 0.6743
Step 213005: loss = 0.02830
Step 213010: loss = 0.03975
Step 213015: loss = 0.07571
Step 213020: loss = 0.03778
Step 213025: loss = 0.06501
Step 213030: loss = 0.10647
Step 213035: loss = 0.02025
Step 213040: loss = 0.03340
Step 213045: loss = 0.08379
Step 213050: loss = 0.18966
Step 213055: loss = 0.01016
Step 213060: loss = 0.11610
Step 213065: loss = 0.05064
Step 213070: loss = 0.07272
Step 213075: loss = 0.03222
Step 213080: loss = 0.04316
Step 213085: loss = 0.02492
Step 213090: loss = 0.04967
Step 213095: loss = 0.09312
Step 213100: loss = 0.16466
Step 213105: loss = 0.06546
Step 213110: loss = 0.09601
Step 213115: loss = 0.13994
Step 213120: loss = 0.05736
Step 213125: loss = 0.05881
Step 213130: loss = 0.18323
Step 213135: loss = 0.03417
Step 213140: loss = 0.08923
Step 213145: loss = 0.06376
Step 213150: loss = 0.06229
Step 213155: loss = 0.05175
Step 213160: loss = 0.24752
Step 213165: loss = 0.02327
Step 213170: loss = 0.19209
Step 213175: loss = 0.08446
Step 213180: loss = 0.18496
Step 213185: loss = 0.07978
Step 213190: loss = 0.03511
Step 213195: loss = 0.08849
Step 213200: loss = 0.08374
Step 213205: loss = 0.05829
Step 213210: loss = 0.09651
Step 213215: loss = 0.12172
Step 213220: loss = 0.07430
Step 213225: loss = 0.06284
Step 213230: loss = 0.12106
Step 213235: loss = 0.07033
Step 213240: loss = 0.08985
Step 213245: loss = 0.03818
Step 213250: loss = 0.05870
Step 213255: loss = 0.03611
Step 213260: loss = 0.02135
Step 213265: loss = 0.01554
Step 213270: loss = 0.12286
Step 213275: loss = 0.09253
Step 213280: loss = 0.04481
Step 213285: loss = 0.06263
Step 213290: loss = 0.04366
Step 213295: loss = 0.05747
Step 213300: loss = 0.06372
Step 213305: loss = 0.22980
Step 213310: loss = 0.01089
Step 213315: loss = 0.16377
Step 213320: loss = 0.09439
Step 213325: loss = 0.02627
Step 213330: loss = 0.04093
Step 213335: loss = 0.08480
Step 213340: loss = 0.04765
Step 213345: loss = 0.06541
Step 213350: loss = 0.01771
Step 213355: loss = 0.07034
Step 213360: loss = 0.02079
Step 213365: loss = 0.28005
Step 213370: loss = 0.08589
Step 213375: loss = 0.02242
Step 213380: loss = 0.01287
Step 213385: loss = 0.19366
Step 213390: loss = 0.16797
Step 213395: loss = 0.19635
Step 213400: loss = 0.16144
Step 213405: loss = 0.12677
Step 213410: loss = 0.06263
Step 213415: loss = 0.06440
Step 213420: loss = 0.05691
Step 213425: loss = 0.04919
Step 213430: loss = 0.08004
Step 213435: loss = 0.14299
Step 213440: loss = 0.09564
Step 213445: loss = 0.14050
Step 213450: loss = 0.08246
Step 213455: loss = 0.02719
Step 213460: loss = 0.08412
Step 213465: loss = 0.06104
Step 213470: loss = 0.09275
Step 213475: loss = 0.16035
Step 213480: loss = 0.05834
Step 213485: loss = 0.13856
Step 213490: loss = 0.08881
Step 213495: loss = 0.06649
Step 213500: loss = 0.01932
Step 213505: loss = 0.23341
Step 213510: loss = 0.02853
Step 213515: loss = 0.09958
Step 213520: loss = 0.04729
Step 213525: loss = 0.03100
Step 213530: loss = 0.08245
Step 213535: loss = 0.03779
Step 213540: loss = 0.05135
Step 213545: loss = 0.06855
Step 213550: loss = 0.13817
Step 213555: loss = 0.08576
Step 213560: loss = 0.18533
Step 213565: loss = 0.06263
Step 213570: loss = 0.14246
Step 213575: loss = 0.13484
Step 213580: loss = 0.05909
Step 213585: loss = 0.17649
Step 213590: loss = 0.11584
Step 213595: loss = 0.14993
Step 213600: loss = 0.07220
Step 213605: loss = 0.05567
Step 213610: loss = 0.38642
Step 213615: loss = 0.07498
Step 213620: loss = 0.04319
Step 213625: loss = 0.12109
Step 213630: loss = 0.11795
Step 213635: loss = 0.03678
Step 213640: loss = 0.11397
Step 213645: loss = 0.09818
Step 213650: loss = 0.16176
Step 213655: loss = 0.07250
Step 213660: loss = 0.10046
Step 213665: loss = 0.12462
Step 213670: loss = 0.14431
Step 213675: loss = 0.06214
Step 213680: loss = 0.14632
Step 213685: loss = 0.16855
Step 213690: loss = 0.09463
Step 213695: loss = 0.08233
Step 213700: loss = 0.14809
Step 213705: loss = 0.12375
Step 213710: loss = 0.07359
Step 213715: loss = 0.30076
Step 213720: loss = 0.18567
Step 213725: loss = 0.16523
Step 213730: loss = 0.14219
Step 213735: loss = 0.21570
Step 213740: loss = 0.06834
Step 213745: loss = 0.09064
Step 213750: loss = 0.19497
Step 213755: loss = 0.04037
Step 213760: loss = 0.16169
Step 213765: loss = 0.02973
Step 213770: loss = 0.06891
Step 213775: loss = 0.14827
Step 213780: loss = 0.13465
Step 213785: loss = 0.20604
Step 213790: loss = 0.17436
Step 213795: loss = 0.19240
Step 213800: loss = 0.06293
Step 213805: loss = 0.03926
Step 213810: loss = 0.21839
Step 213815: loss = 0.17626
Step 213820: loss = 0.02003
Step 213825: loss = 0.19620
Step 213830: loss = 0.07221
Step 213835: loss = 0.12201
Step 213840: loss = 0.10372
Step 213845: loss = 0.09107
Step 213850: loss = 0.07158
Step 213855: loss = 0.05495
Step 213860: loss = 0.03337
Step 213865: loss = 0.07441
Step 213870: loss = 0.11765
Step 213875: loss = 0.14405
Step 213880: loss = 0.20174
Step 213885: loss = 0.11800
Step 213890: loss = 0.04111
Step 213895: loss = 0.01901
Step 213900: loss = 0.02510
Step 213905: loss = 0.05987
Step 213910: loss = 0.06536
Step 213915: loss = 0.08821
Step 213920: loss = 0.13757
Step 213925: loss = 0.14109
Step 213930: loss = 0.03427
Step 213935: loss = 0.02696
Step 213940: loss = 0.21517
Step 213945: loss = 0.04238
Step 213950: loss = 0.02143
Step 213955: loss = 0.11589
Step 213960: loss = 0.15611
Step 213965: loss = 0.15338
Step 213970: loss = 0.24840
Step 213975: loss = 0.12392
Step 213980: loss = 0.20666
Step 213985: loss = 0.03193
Step 213990: loss = 0.10368
Step 213995: loss = 0.03694
Step 214000: loss = 0.05308
Training Data Eval:
  Num examples: 50000, Num correct: 48260, Precision @ 1: 0.9652
('Testing Data Eval: EPOCH->', 215)
  Num examples: 10000, Num correct: 6684, Precision @ 1: 0.6684
Step 214005: loss = 0.09652
Step 214010: loss = 0.04467
Step 214015: loss = 0.08458
Step 214020: loss = 0.10332
Step 214025: loss = 0.08641
Step 214030: loss = 0.08551
Step 214035: loss = 0.05344
Step 214040: loss = 0.08223
Step 214045: loss = 0.16074
Step 214050: loss = 0.01901
Step 214055: loss = 0.08615
Step 214060: loss = 0.02272
Step 214065: loss = 0.07045
Step 214070: loss = 0.08061
Step 214075: loss = 0.03396
Step 214080: loss = 0.28385
Step 214085: loss = 0.14851
Step 214090: loss = 0.07133
Step 214095: loss = 0.13849
Step 214100: loss = 0.12218
Step 214105: loss = 0.05371
Step 214110: loss = 0.13873
Step 214115: loss = 0.13745
Step 214120: loss = 0.03825
Step 214125: loss = 0.03790
Step 214130: loss = 0.14706
Step 214135: loss = 0.07211
Step 214140: loss = 0.03805
Step 214145: loss = 0.14317
Step 214150: loss = 0.07186
Step 214155: loss = 0.07432
Step 214160: loss = 0.19879
Step 214165: loss = 0.14762
Step 214170: loss = 0.03046
Step 214175: loss = 0.21836
Step 214180: loss = 0.02490
Step 214185: loss = 0.09436
Step 214190: loss = 0.08901
Step 214195: loss = 0.15335
Step 214200: loss = 0.05573
Step 214205: loss = 0.02234
Step 214210: loss = 0.21456
Step 214215: loss = 0.18281
Step 214220: loss = 0.11313
Step 214225: loss = 0.13189
Step 214230: loss = 0.08546
Step 214235: loss = 0.09020
Step 214240: loss = 0.07130
Step 214245: loss = 0.05209
Step 214250: loss = 0.05174
Step 214255: loss = 0.07318
Step 214260: loss = 0.08135
Step 214265: loss = 0.01637
Step 214270: loss = 0.03084
Step 214275: loss = 0.06670
Step 214280: loss = 0.06433
Step 214285: loss = 0.15756
Step 214290: loss = 0.04853
Step 214295: loss = 0.15077
Step 214300: loss = 0.13712
Step 214305: loss = 0.03023
Step 214310: loss = 0.13323
Step 214315: loss = 0.05097
Step 214320: loss = 0.02965
Step 214325: loss = 0.26448
Step 214330: loss = 0.16220
Step 214335: loss = 0.11328
Step 214340: loss = 0.20832
Step 214345: loss = 0.13227
Step 214350: loss = 0.20140
Step 214355: loss = 0.05399
Step 214360: loss = 0.02544
Step 214365: loss = 0.06913
Step 214370: loss = 0.17332
Step 214375: loss = 0.06628
Step 214380: loss = 0.09836
Step 214385: loss = 0.14540
Step 214390: loss = 0.10874
Step 214395: loss = 0.13028
Step 214400: loss = 0.14194
Step 214405: loss = 0.09009
Step 214410: loss = 0.13908
Step 214415: loss = 0.12220
Step 214420: loss = 0.12122
Step 214425: loss = 0.44309
Step 214430: loss = 0.14718
Step 214435: loss = 0.04248
Step 214440: loss = 0.13310
Step 214445: loss = 0.03800
Step 214450: loss = 0.02933
Step 214455: loss = 0.02660
Step 214460: loss = 0.06805
Step 214465: loss = 0.09249
Step 214470: loss = 0.02027
Step 214475: loss = 0.19974
Step 214480: loss = 0.61801
Step 214485: loss = 0.07839
Step 214490: loss = 0.21557
Step 214495: loss = 0.04890
Step 214500: loss = 0.07186
Step 214505: loss = 0.03707
Step 214510: loss = 0.06911
Step 214515: loss = 0.27319
Step 214520: loss = 0.03732
Step 214525: loss = 0.03396
Step 214530: loss = 0.02271
Step 214535: loss = 0.04415
Step 214540: loss = 0.02411
Step 214545: loss = 0.17876
Step 214550: loss = 0.08755
Step 214555: loss = 0.09134
Step 214560: loss = 0.13714
Step 214565: loss = 0.20245
Step 214570: loss = 0.11803
Step 214575: loss = 0.03329
Step 214580: loss = 0.07516
Step 214585: loss = 0.03921
Step 214590: loss = 0.05512
Step 214595: loss = 0.13817
Step 214600: loss = 0.05457
Step 214605: loss = 0.03687
Step 214610: loss = 0.14983
Step 214615: loss = 0.03139
Step 214620: loss = 0.13268
Step 214625: loss = 0.08110
Step 214630: loss = 0.34457
Step 214635: loss = 0.03135
Step 214640: loss = 0.08726
Step 214645: loss = 0.13371
Step 214650: loss = 0.11514
Step 214655: loss = 0.08280
Step 214660: loss = 0.20122
Step 214665: loss = 0.14095
Step 214670: loss = 0.08216
Step 214675: loss = 0.07350
Step 214680: loss = 0.15492
Step 214685: loss = 0.07725
Step 214690: loss = 0.05255
Step 214695: loss = 0.07511
Step 214700: loss = 0.07611
Step 214705: loss = 0.10380
Step 214710: loss = 0.17381
Step 214715: loss = 0.18191
Step 214720: loss = 0.13322
Step 214725: loss = 0.03119
Step 214730: loss = 0.11405
Step 214735: loss = 0.05260
Step 214740: loss = 0.13584
Step 214745: loss = 0.07277
Step 214750: loss = 0.06264
Step 214755: loss = 0.10183
Step 214760: loss = 0.11693
Step 214765: loss = 0.10965
Step 214770: loss = 0.07881
Step 214775: loss = 0.16602
Step 214780: loss = 0.14469
Step 214785: loss = 0.06179
Step 214790: loss = 0.06927
Step 214795: loss = 0.13711
Step 214800: loss = 0.04817
Step 214805: loss = 0.06009
Step 214810: loss = 0.02025
Step 214815: loss = 0.03845
Step 214820: loss = 0.06939
Step 214825: loss = 0.25722
Step 214830: loss = 0.04368
Step 214835: loss = 0.08101
Step 214840: loss = 0.01832
Step 214845: loss = 0.10554
Step 214850: loss = 0.10418
Step 214855: loss = 0.07586
Step 214860: loss = 0.10173
Step 214865: loss = 0.05691
Step 214870: loss = 0.07379
Step 214875: loss = 0.14483
Step 214880: loss = 0.10610
Step 214885: loss = 0.12647
Step 214890: loss = 0.15793
Step 214895: loss = 0.07952
Step 214900: loss = 0.07432
Step 214905: loss = 0.06795
Step 214910: loss = 0.02466
Step 214915: loss = 0.05788
Step 214920: loss = 0.04889
Step 214925: loss = 0.03668
Step 214930: loss = 0.18931
Step 214935: loss = 0.05598
Step 214940: loss = 0.12680
Step 214945: loss = 0.19052
Step 214950: loss = 0.02900
Step 214955: loss = 0.12414
Step 214960: loss = 0.06839
Step 214965: loss = 0.03350
Step 214970: loss = 0.13632
Step 214975: loss = 0.07736
Step 214980: loss = 0.08603
Step 214985: loss = 0.11258
Step 214990: loss = 0.17274
Step 214995: loss = 0.06075
Step 215000: loss = 0.14681
Training Data Eval:
  Num examples: 50000, Num correct: 48272, Precision @ 1: 0.9654
('Testing Data Eval: EPOCH->', 216)
  Num examples: 10000, Num correct: 6642, Precision @ 1: 0.6642
Step 215005: loss = 0.10574
Step 215010: loss = 0.22674
Step 215015: loss = 0.12133
Step 215020: loss = 0.05846
Step 215025: loss = 0.03776
Step 215030: loss = 0.02241
Step 215035: loss = 0.06712
Step 215040: loss = 0.05282
Step 215045: loss = 0.13949
Step 215050: loss = 0.12226
Step 215055: loss = 0.10129
Step 215060: loss = 0.14739
Step 215065: loss = 0.04529
Step 215070: loss = 0.08994
Step 215075: loss = 0.12070
Step 215080: loss = 0.08387
Step 215085: loss = 0.12168
Step 215090: loss = 0.10683
Step 215095: loss = 0.07000
Step 215100: loss = 0.07631
Step 215105: loss = 0.04145
Step 215110: loss = 0.02856
Step 215115: loss = 0.10225
Step 215120: loss = 0.12052
Step 215125: loss = 1.80401
Step 215130: loss = 0.11646
Step 215135: loss = 0.29278
Step 215140: loss = 0.23257
Step 215145: loss = 0.08177
Step 215150: loss = 0.09835
Step 215155: loss = 0.25422
Step 215160: loss = 0.10177
Step 215165: loss = 0.25379
Step 215170: loss = 0.44579
Step 215175: loss = 0.15546
Step 215180: loss = 0.24380
Step 215185: loss = 0.09617
Step 215190: loss = 0.11809
Step 215195: loss = 0.07664
Step 215200: loss = 0.30431
Step 215205: loss = 0.11171
Step 215210: loss = 0.11315
Step 215215: loss = 0.13675
Step 215220: loss = 0.20244
Step 215225: loss = 0.13308
Step 215230: loss = 0.22060
Step 215235: loss = 0.03619
Step 215240: loss = 0.13071
Step 215245: loss = 0.03436
Step 215250: loss = 0.03673
Step 215255: loss = 0.43958
Step 215260: loss = 0.03788
Step 215265: loss = 0.08896
Step 215270: loss = 0.03487
Step 215275: loss = 0.06951
Step 215280: loss = 0.07674
Step 215285: loss = 0.06163
Step 215290: loss = 0.06122
Step 215295: loss = 0.11879
Step 215300: loss = 0.06709
Step 215305: loss = 0.41613
Step 215310: loss = 0.15435
Step 215315: loss = 0.03931
Step 215320: loss = 0.12774
Step 215325: loss = 0.15587
Step 215330: loss = 0.17124
Step 215335: loss = 0.40692
Step 215340: loss = 0.07025
Step 215345: loss = 0.08068
Step 215350: loss = 0.09163
Step 215355: loss = 0.03738
Step 215360: loss = 0.18854
Step 215365: loss = 0.17103
Step 215370: loss = 0.04004
Step 215375: loss = 0.17270
Step 215380: loss = 0.07404
Step 215385: loss = 0.06089
Step 215390: loss = 0.02823
Step 215395: loss = 0.05568
Step 215400: loss = 0.16353
Step 215405: loss = 0.03570
Step 215410: loss = 0.11907
Step 215415: loss = 0.08898
Step 215420: loss = 0.10661
Step 215425: loss = 0.09863
Step 215430: loss = 0.04871
Step 215435: loss = 0.14130
Step 215440: loss = 0.14633
Step 215445: loss = 0.07938
Step 215450: loss = 0.23228
Step 215455: loss = 0.07623
Step 215460: loss = 0.03924
Step 215465: loss = 0.03158
Step 215470: loss = 0.18566
Step 215475: loss = 0.17451
Step 215480: loss = 0.19385
Step 215485: loss = 0.08225
Step 215490: loss = 0.19421
Step 215495: loss = 0.15944
Step 215500: loss = 0.12212
Step 215505: loss = 0.07300
Step 215510: loss = 0.16058
Step 215515: loss = 0.13792
Step 215520: loss = 0.23152
Step 215525: loss = 0.12573
Step 215530: loss = 0.15103
Step 215535: loss = 0.14714
Step 215540: loss = 0.15919
Step 215545: loss = 0.05780
Step 215550: loss = 0.05550
Step 215555: loss = 0.06504
Step 215560: loss = 0.03149
Step 215565: loss = 0.05490
Step 215570: loss = 0.13515
Step 215575: loss = 0.07011
Step 215580: loss = 0.02302
Step 215585: loss = 0.15144
Step 215590: loss = 0.05119
Step 215595: loss = 0.36973
Step 215600: loss = 0.05012
Step 215605: loss = 0.03050
Step 215610: loss = 0.02692
Step 215615: loss = 0.05350
Step 215620: loss = 0.17299
Step 215625: loss = 0.05722
Step 215630: loss = 0.31499
Step 215635: loss = 0.10136
Step 215640: loss = 0.08290
Step 215645: loss = 0.06322
Step 215650: loss = 0.24596
Step 215655: loss = 0.08951
Step 215660: loss = 0.04710
Step 215665: loss = 0.08625
Step 215670: loss = 0.02621
Step 215675: loss = 0.14962
Step 215680: loss = 0.06499
Step 215685: loss = 0.07264
Step 215690: loss = 0.03171
Step 215695: loss = 0.17930
Step 215700: loss = 0.16495
Step 215705: loss = 0.11777
Step 215710: loss = 0.09198
Step 215715: loss = 0.05682
Step 215720: loss = 0.19418
Step 215725: loss = 0.18521
Step 215730: loss = 0.14107
Step 215735: loss = 0.03922
Step 215740: loss = 0.03199
Step 215745: loss = 0.07929
Step 215750: loss = 0.06464
Step 215755: loss = 0.09870
Step 215760: loss = 0.15719
Step 215765: loss = 0.19752
Step 215770: loss = 0.20609
Step 215775: loss = 0.11356
Step 215780: loss = 0.10084
Step 215785: loss = 0.23124
Step 215790: loss = 0.02601
Step 215795: loss = 0.13169
Step 215800: loss = 0.06320
Step 215805: loss = 0.07872
Step 215810: loss = 0.18785
Step 215815: loss = 0.08466
Step 215820: loss = 0.02626
Step 215825: loss = 0.14504
Step 215830: loss = 0.48275
Step 215835: loss = 0.19622
Step 215840: loss = 0.05177
Step 215845: loss = 0.15067
Step 215850: loss = 0.17946
Step 215855: loss = 0.03919
Step 215860: loss = 0.05974
Step 215865: loss = 0.06942
Step 215870: loss = 0.28383
Step 215875: loss = 0.03654
Step 215880: loss = 0.19871
Step 215885: loss = 0.13451
Step 215890: loss = 0.08440
Step 215895: loss = 0.08741
Step 215900: loss = 0.10944
Step 215905: loss = 0.05278
Step 215910: loss = 0.07903
Step 215915: loss = 0.01815
Step 215920: loss = 0.03856
Step 215925: loss = 0.10958
Step 215930: loss = 0.10097
Step 215935: loss = 0.09092
Step 215940: loss = 0.07159
Step 215945: loss = 0.10640
Step 215950: loss = 0.03378
Step 215955: loss = 0.05568
Step 215960: loss = 0.02782
Step 215965: loss = 0.10650
Step 215970: loss = 0.05322
Step 215975: loss = 0.13752
Step 215980: loss = 0.09882
Step 215985: loss = 0.06918
Step 215990: loss = 0.08278
Step 215995: loss = 0.07338
Step 216000: loss = 0.03817
Training Data Eval:
  Num examples: 50000, Num correct: 48407, Precision @ 1: 0.9681
('Testing Data Eval: EPOCH->', 217)
  Num examples: 10000, Num correct: 6758, Precision @ 1: 0.6758
Step 216005: loss = 0.02331
Step 216010: loss = 0.08803
Step 216015: loss = 0.05448
Step 216020: loss = 0.02747
Step 216025: loss = 0.03108
Step 216030: loss = 0.04668
Step 216035: loss = 0.09264
Step 216040: loss = 0.05381
Step 216045: loss = 0.06313
Step 216050: loss = 0.09071
Step 216055: loss = 0.07749
Step 216060: loss = 0.12490
Step 216065: loss = 0.09009
Step 216070: loss = 0.01853
Step 216075: loss = 0.06191
Step 216080: loss = 0.34314
Step 216085: loss = 0.18399
Step 216090: loss = 0.06145
Step 216095: loss = 0.15671
Step 216100: loss = 0.08464
Step 216105: loss = 0.04241
Step 216110: loss = 0.16482
Step 216115: loss = 0.11309
Step 216120: loss = 0.06711
Step 216125: loss = 0.22856
Step 216130: loss = 0.04865
Step 216135: loss = 0.01817
Step 216140: loss = 0.19045
Step 216145: loss = 0.02895
Step 216150: loss = 0.12463
Step 216155: loss = 0.07583
Step 216160: loss = 0.14091
Step 216165: loss = 0.01268
Step 216170: loss = 0.11576
Step 216175: loss = 0.02057
Step 216180: loss = 0.10259
Step 216185: loss = 0.03029
Step 216190: loss = 0.09821
Step 216195: loss = 0.06450
Step 216200: loss = 0.05361
Step 216205: loss = 0.11583
Step 216210: loss = 0.03549
Step 216215: loss = 0.37175
Step 216220: loss = 0.01164
Step 216225: loss = 0.04660
Step 216230: loss = 0.03256
Step 216235: loss = 0.16424
Step 216240: loss = 0.10375
Step 216245: loss = 0.10251
Step 216250: loss = 0.18254
Step 216255: loss = 0.02525
Step 216260: loss = 0.05793
Step 216265: loss = 0.15768
Step 216270: loss = 0.16001
Step 216275: loss = 0.06041
Step 216280: loss = 0.07696
Step 216285: loss = 0.07028
Step 216290: loss = 0.13378
Step 216295: loss = 0.27296
Step 216300: loss = 0.04857
Step 216305: loss = 0.04916
Step 216310: loss = 0.03663
Step 216315: loss = 0.14248
Step 216320: loss = 0.11782
Step 216325: loss = 0.05710
Step 216330: loss = 0.09883
Step 216335: loss = 0.01811
Step 216340: loss = 0.03320
Step 216345: loss = 0.06270
Step 216350: loss = 0.12454
Step 216355: loss = 0.16916
Step 216360: loss = 0.04774
Step 216365: loss = 0.08307
Step 216370: loss = 0.12031
Step 216375: loss = 0.02985
Step 216380: loss = 0.06432
Step 216385: loss = 0.05325
Step 216390: loss = 0.06842
Step 216395: loss = 0.06735
Step 216400: loss = 0.03644
Step 216405: loss = 0.07617
Step 216410: loss = 0.02896
Step 216415: loss = 0.08819
Step 216420: loss = 0.12706
Step 216425: loss = 0.06201
Step 216430: loss = 0.02105
Step 216435: loss = 0.13277
Step 216440: loss = 0.17584
Step 216445: loss = 0.06838
Step 216450: loss = 0.27789
Step 216455: loss = 0.18119
Step 216460: loss = 0.07728
Step 216465: loss = 0.03500
Step 216470: loss = 0.06463
Step 216475: loss = 0.26344
Step 216480: loss = 0.04213
Step 216485: loss = 0.03630
Step 216490: loss = 0.05154
Step 216495: loss = 0.09039
Step 216500: loss = 0.09471
Step 216505: loss = 0.03050
Step 216510: loss = 0.11539
Step 216515: loss = 0.37205
Step 216520: loss = 0.13254
Step 216525: loss = 0.01571
Step 216530: loss = 0.08172
Step 216535: loss = 0.10080
Step 216540: loss = 0.04277
Step 216545: loss = 0.05205
Step 216550: loss = 0.09224
Step 216555: loss = 0.03639
Step 216560: loss = 0.07158
Step 216565: loss = 0.07513
Step 216570: loss = 0.09121
Step 216575: loss = 0.16558
Step 216580: loss = 0.12726
Step 216585: loss = 0.04643
Step 216590: loss = 0.18379
Step 216595: loss = 0.16636
Step 216600: loss = 0.17728
Step 216605: loss = 0.21081
Step 216610: loss = 0.07774
Step 216615: loss = 0.09815
Step 216620: loss = 0.12433
Step 216625: loss = 0.21091
Step 216630: loss = 0.25111
Step 216635: loss = 0.06782
Step 216640: loss = 0.17504
Step 216645: loss = 0.13920
Step 216650: loss = 0.08275
Step 216655: loss = 0.06720
Step 216660: loss = 0.09298
Step 216665: loss = 0.07085
Step 216670: loss = 0.02774
Step 216675: loss = 0.11580
Step 216680: loss = 0.03367
Step 216685: loss = 0.09100
Step 216690: loss = 0.15928
Step 216695: loss = 0.02819
Step 216700: loss = 0.11762
Step 216705: loss = 0.16369
Step 216710: loss = 0.07477
Step 216715: loss = 0.09063
Step 216720: loss = 0.04481
Step 216725: loss = 0.18373
Step 216730: loss = 0.22155
Step 216735: loss = 0.13947
Step 216740: loss = 0.06929
Step 216745: loss = 0.17601
Step 216750: loss = 0.24259
Step 216755: loss = 0.26098
Step 216760: loss = 0.06582
Step 216765: loss = 0.08335
Step 216770: loss = 0.08224
Step 216775: loss = 0.07192
Step 216780: loss = 0.15483
Step 216785: loss = 0.09778
Step 216790: loss = 0.21392
Step 216795: loss = 0.06734
Step 216800: loss = 0.07229
Step 216805: loss = 0.09438
Step 216810: loss = 0.03617
Step 216815: loss = 0.14212
Step 216820: loss = 0.05449
Step 216825: loss = 0.02210
Step 216830: loss = 0.06730
Step 216835: loss = 0.05354
Step 216840: loss = 0.08721
Step 216845: loss = 0.26186
Step 216850: loss = 0.05706
Step 216855: loss = 0.10125
Step 216860: loss = 0.08296
Step 216865: loss = 0.07308
Step 216870: loss = 0.02561
Step 216875: loss = 0.12130
Step 216880: loss = 0.09576
Step 216885: loss = 0.12029
Step 216890: loss = 0.08376
Step 216895: loss = 0.05119
Step 216900: loss = 0.10255
Step 216905: loss = 0.06510
Step 216910: loss = 0.15307
Step 216915: loss = 0.02048
Step 216920: loss = 0.14262
Step 216925: loss = 0.14630
Step 216930: loss = 0.14942
Step 216935: loss = 0.03846
Step 216940: loss = 0.14891
Step 216945: loss = 0.05816
Step 216950: loss = 0.08319
Step 216955: loss = 0.04171
Step 216960: loss = 0.17824
Step 216965: loss = 0.13922
Step 216970: loss = 0.04426
Step 216975: loss = 0.10710
Step 216980: loss = 0.14907
Step 216985: loss = 0.05900
Step 216990: loss = 0.23438
Step 216995: loss = 0.05037
Step 217000: loss = 0.04438
Training Data Eval:
  Num examples: 50000, Num correct: 48312, Precision @ 1: 0.9662
('Testing Data Eval: EPOCH->', 218)
  Num examples: 10000, Num correct: 6797, Precision @ 1: 0.6797
Step 217005: loss = 0.14249
Step 217010: loss = 0.06756
Step 217015: loss = 0.03473
Step 217020: loss = 0.03993
Step 217025: loss = 0.09263
Step 217030: loss = 0.11805
Step 217035: loss = 0.06146
Step 217040: loss = 0.13118
Step 217045: loss = 0.09373
Step 217050: loss = 0.05800
Step 217055: loss = 0.02036
Step 217060: loss = 0.09167
Step 217065: loss = 0.17484
Step 217070: loss = 0.10695
Step 217075: loss = 0.11385
Step 217080: loss = 0.07521
Step 217085: loss = 0.02799
Step 217090: loss = 0.03918
Step 217095: loss = 0.06073
Step 217100: loss = 0.06213
Step 217105: loss = 0.04369
Step 217110: loss = 0.12135
Step 217115: loss = 0.08452
Step 217120: loss = 0.17364
Step 217125: loss = 0.11090
Step 217130: loss = 0.06563
Step 217135: loss = 0.06389
Step 217140: loss = 0.04549
Step 217145: loss = 0.19476
Step 217150: loss = 0.38487
Step 217155: loss = 0.14227
Step 217160: loss = 0.16338
Step 217165: loss = 0.04478
Step 217170: loss = 0.13390
Step 217175: loss = 0.05953
Step 217180: loss = 0.09443
Step 217185: loss = 0.11129
Step 217190: loss = 0.09280
Step 217195: loss = 0.15692
Step 217200: loss = 0.02965
Step 217205: loss = 0.07078
Step 217210: loss = 0.12968
Step 217215: loss = 0.10641
Step 217220: loss = 0.21002
Step 217225: loss = 0.05639
Step 217230: loss = 0.08490
Step 217235: loss = 0.03831
Step 217240: loss = 0.02840
Step 217245: loss = 0.03194
Step 217250: loss = 0.05081
Step 217255: loss = 0.18278
Step 217260: loss = 0.10266
Step 217265: loss = 0.15551
Step 217270: loss = 0.10521
Step 217275: loss = 0.13161
Step 217280: loss = 0.14796
Step 217285: loss = 0.14978
Step 217290: loss = 0.07851
Step 217295: loss = 0.02177
Step 217300: loss = 0.08348
Step 217305: loss = 0.14907
Step 217310: loss = 0.10558
Step 217315: loss = 0.03067
Step 217320: loss = 0.27112
Step 217325: loss = 0.08992
Step 217330: loss = 0.13218
Step 217335: loss = 0.13314
Step 217340: loss = 0.09615
Step 217345: loss = 0.12981
Step 217350: loss = 0.11408
Step 217355: loss = 0.06331
Step 217360: loss = 0.21456
Step 217365: loss = 0.29630
Step 217370: loss = 0.04016
Step 217375: loss = 0.08354
Step 217380: loss = 0.26073
Step 217385: loss = 0.06467
Step 217390: loss = 0.13408
Step 217395: loss = 0.06571
Step 217400: loss = 0.06615
Step 217405: loss = 0.04923
Step 217410: loss = 0.05297
Step 217415: loss = 0.04769
Step 217420: loss = 0.16397
Step 217425: loss = 0.04769
Step 217430: loss = 0.01466
Step 217435: loss = 0.20392
Step 217440: loss = 0.10871
Step 217445: loss = 0.06720
Step 217450: loss = 0.06954
Step 217455: loss = 0.15152
Step 217460: loss = 0.13936
Step 217465: loss = 0.19759
Step 217470: loss = 0.18513
Step 217475: loss = 0.02814
Step 217480: loss = 0.14836
Step 217485: loss = 0.03532
Step 217490: loss = 0.06692
Step 217495: loss = 0.08655
Step 217500: loss = 0.13731
Step 217505: loss = 0.12427
Step 217510: loss = 0.17484
Step 217515: loss = 0.13975
Step 217520: loss = 0.11459
Step 217525: loss = 0.20775
Step 217530: loss = 0.10125
Step 217535: loss = 0.13828
Step 217540: loss = 0.14087
Step 217545: loss = 0.13361
Step 217550: loss = 0.04481
Step 217555: loss = 0.07367
Step 217560: loss = 0.13504
Step 217565: loss = 0.06110
Step 217570: loss = 0.19523
Step 217575: loss = 0.11055
Step 217580: loss = 0.14314
Step 217585: loss = 0.19880
Step 217590: loss = 0.29887
Step 217595: loss = 0.15281
Step 217600: loss = 0.08708
Step 217605: loss = 0.02374
Step 217610: loss = 0.09512
Step 217615: loss = 0.01775
Step 217620: loss = 0.09875
Step 217625: loss = 0.06135
Step 217630: loss = 0.05915
Step 217635: loss = 0.09740
Step 217640: loss = 0.22265
Step 217645: loss = 0.06408
Step 217650: loss = 0.20052
Step 217655: loss = 0.18695
Step 217660: loss = 0.04995
Step 217665: loss = 0.08432
Step 217670: loss = 0.10617
Step 217675: loss = 0.14146
Step 217680: loss = 0.13065
Step 217685: loss = 0.05851
Step 217690: loss = 0.10541
Step 217695: loss = 0.12749
Step 217700: loss = 0.06970
Step 217705: loss = 0.01444
Step 217710: loss = 0.10122
Step 217715: loss = 0.05663
Step 217720: loss = 0.12848
Step 217725: loss = 0.25625
Step 217730: loss = 0.01199
Step 217735: loss = 0.07968
Step 217740: loss = 0.03075
Step 217745: loss = 0.08091
Step 217750: loss = 0.12599
Step 217755: loss = 0.01329
Step 217760: loss = 0.13700
Step 217765: loss = 0.07201
Step 217770: loss = 0.03538
Step 217775: loss = 0.03686
Step 217780: loss = 0.09954
Step 217785: loss = 0.18239
Step 217790: loss = 0.01994
Step 217795: loss = 0.53935
Step 217800: loss = 0.03797
Step 217805: loss = 0.20355
Step 217810: loss = 0.14118
Step 217815: loss = 0.21322
Step 217820: loss = 0.18286
Step 217825: loss = 0.10038
Step 217830: loss = 0.05220
Step 217835: loss = 0.03295
Step 217840: loss = 0.02176
Step 217845: loss = 0.11715
Step 217850: loss = 0.10323
Step 217855: loss = 0.05367
Step 217860: loss = 0.09950
Step 217865: loss = 0.06294
Step 217870: loss = 0.18171
Step 217875: loss = 0.16110
Step 217880: loss = 0.21599
Step 217885: loss = 0.14516
Step 217890: loss = 0.18472
Step 217895: loss = 0.19629
Step 217900: loss = 0.20470
Step 217905: loss = 0.03570
Step 217910: loss = 0.02729
Step 217915: loss = 0.08057
Step 217920: loss = 0.08772
Step 217925: loss = 0.08403
Step 217930: loss = 0.09526
Step 217935: loss = 0.05270
Step 217940: loss = 0.02832
Step 217945: loss = 0.05295
Step 217950: loss = 0.06941
Step 217955: loss = 0.10958
Step 217960: loss = 0.12179
Step 217965: loss = 0.19131
Step 217970: loss = 0.04125
Step 217975: loss = 0.37211
Step 217980: loss = 0.11227
Step 217985: loss = 0.04954
Step 217990: loss = 0.06955
Step 217995: loss = 0.13041
Step 218000: loss = 0.08086
Training Data Eval:
  Num examples: 50000, Num correct: 48346, Precision @ 1: 0.9669
('Testing Data Eval: EPOCH->', 219)
  Num examples: 10000, Num correct: 6685, Precision @ 1: 0.6685
Step 218005: loss = 0.30066
Step 218010: loss = 0.16797
Step 218015: loss = 0.08948
Step 218020: loss = 0.05890
Step 218025: loss = 0.07120
Step 218030: loss = 0.05421
Step 218035: loss = 0.05507
Step 218040: loss = 0.02098
Step 218045: loss = 0.09675
Step 218050: loss = 0.13516
Step 218055: loss = 0.02308
Step 218060: loss = 0.10898
Step 218065: loss = 0.17354
Step 218070: loss = 0.07788
Step 218075: loss = 0.06465
Step 218080: loss = 0.04091
Step 218085: loss = 0.08135
Step 218090: loss = 0.03144
Step 218095: loss = 0.03294
Step 218100: loss = 0.16421
Step 218105: loss = 0.05470
Step 218110: loss = 0.06161
Step 218115: loss = 0.02225
Step 218120: loss = 0.11048
Step 218125: loss = 0.03653
Step 218130: loss = 0.14164
Step 218135: loss = 0.15542
Step 218140: loss = 0.08755
Step 218145: loss = 0.05867
Step 218150: loss = 0.11220
Step 218155: loss = 0.11184
Step 218160: loss = 0.08043
Step 218165: loss = 0.01789
Step 218170: loss = 0.04338
Step 218175: loss = 0.05350
Step 218180: loss = 0.11589
Step 218185: loss = 0.06506
Step 218190: loss = 0.05898
Step 218195: loss = 0.07726
Step 218200: loss = 0.02146
Step 218205: loss = 0.10960
Step 218210: loss = 0.04344
Step 218215: loss = 0.25345
Step 218220: loss = 0.21597
Step 218225: loss = 0.02177
Step 218230: loss = 0.06290
Step 218235: loss = 0.05084
Step 218240: loss = 0.11489
Step 218245: loss = 0.20840
Step 218250: loss = 0.19994
Step 218255: loss = 0.06556
Step 218260: loss = 0.01728
Step 218265: loss = 0.11667
Step 218270: loss = 0.08174
Step 218275: loss = 0.05949
Step 218280: loss = 0.07366
Step 218285: loss = 0.05838
Step 218290: loss = 0.07469
Step 218295: loss = 0.02686
Step 218300: loss = 0.17476
Step 218305: loss = 0.09657
Step 218310: loss = 0.16732
Step 218315: loss = 0.25705
Step 218320: loss = 0.17068
Step 218325: loss = 0.03075
Step 218330: loss = 0.07374
Step 218335: loss = 0.03122
Step 218340: loss = 0.04508
Step 218345: loss = 0.16069
Step 218350: loss = 0.10218
Step 218355: loss = 0.08027
Step 218360: loss = 0.04016
Step 218365: loss = 0.05694
Step 218370: loss = 0.09936
Step 218375: loss = 0.16003
Step 218380: loss = 0.05891
Step 218385: loss = 0.03410
Step 218390: loss = 0.15690
Step 218395: loss = 0.12476
Step 218400: loss = 0.32930
Step 218405: loss = 0.04742
Step 218410: loss = 0.06070
Step 218415: loss = 0.07869
Step 218420: loss = 0.13055
Step 218425: loss = 0.22855
Step 218430: loss = 0.11670
Step 218435: loss = 0.18158
Step 218440: loss = 0.05562
Step 218445: loss = 0.06196
Step 218450: loss = 0.04206
Step 218455: loss = 0.12198
Step 218460: loss = 0.12015
Step 218465: loss = 0.05844
Step 218470: loss = 0.08436
Step 218475: loss = 0.14127
Step 218480: loss = 0.17965
Step 218485: loss = 0.09836
Step 218490: loss = 0.07654
Step 218495: loss = 0.11605
Step 218500: loss = 0.01887
Step 218505: loss = 0.17226
Step 218510: loss = 0.07196
Step 218515: loss = 0.02991
Step 218520: loss = 0.03242
Step 218525: loss = 0.12102
Step 218530: loss = 0.05910
Step 218535: loss = 0.11096
Step 218540: loss = 0.04281
Step 218545: loss = 0.02717
Step 218550: loss = 0.04044
Step 218555: loss = 0.02916
Step 218560: loss = 0.11124
Step 218565: loss = 0.30536
Step 218570: loss = 0.02029
Step 218575: loss = 0.00996
Step 218580: loss = 0.08313
Step 218585: loss = 0.45412
Step 218590: loss = 0.03807
Step 218595: loss = 0.07386
Step 218600: loss = 0.01426
Step 218605: loss = 0.04918
Step 218610: loss = 0.02985
Step 218615: loss = 0.13913
Step 218620: loss = 0.02258
Step 218625: loss = 0.14885
Step 218630: loss = 0.08653
Step 218635: loss = 0.13899
Step 218640: loss = 0.23636
Step 218645: loss = 0.20177
Step 218650: loss = 0.06539
Step 218655: loss = 0.06271
Step 218660: loss = 0.06666
Step 218665: loss = 0.02002
Step 218670: loss = 0.08089
Step 218675: loss = 0.10186
Step 218680: loss = 0.05570
Step 218685: loss = 0.05766
Step 218690: loss = 0.08904
Step 218695: loss = 0.10066
Step 218700: loss = 0.07012
Step 218705: loss = 0.11979
Step 218710: loss = 0.06739
Step 218715: loss = 0.04032
Step 218720: loss = 0.07042
Step 218725: loss = 0.02614
Step 218730: loss = 0.07236
Step 218735: loss = 0.06063
Step 218740: loss = 0.10128
Step 218745: loss = 0.07020
Step 218750: loss = 0.04864
Step 218755: loss = 0.10624
Step 218760: loss = 0.24611
Step 218765: loss = 0.05052
Step 218770: loss = 0.01917
Step 218775: loss = 0.04445
Step 218780: loss = 0.15442
Step 218785: loss = 0.07476
Step 218790: loss = 0.07780
Step 218795: loss = 0.02817
Step 218800: loss = 0.07534
Step 218805: loss = 0.06140
Step 218810: loss = 0.07901
Step 218815: loss = 0.02753
Step 218820: loss = 0.15982
Step 218825: loss = 0.05463
Step 218830: loss = 0.18937
Step 218835: loss = 0.04776
Step 218840: loss = 0.18395
Step 218845: loss = 0.05916
Step 218850: loss = 0.16172
Step 218855: loss = 0.04434
Step 218860: loss = 0.06341
Step 218865: loss = 0.05124
Step 218870: loss = 0.14727
Step 218875: loss = 0.11881
Step 218880: loss = 0.03507
Step 218885: loss = 0.05960
Step 218890: loss = 0.19807
Step 218895: loss = 0.06655
Step 218900: loss = 0.05033
Step 218905: loss = 0.18842
Step 218910: loss = 0.17903
Step 218915: loss = 0.15603
Step 218920: loss = 0.03684
Step 218925: loss = 0.02453
Step 218930: loss = 0.08902
Step 218935: loss = 0.02722
Step 218940: loss = 0.26836
Step 218945: loss = 0.21828
Step 218950: loss = 0.31643
Step 218955: loss = 0.12082
Step 218960: loss = 0.12071
Step 218965: loss = 0.04373
Step 218970: loss = 0.27945
Step 218975: loss = 0.05769
Step 218980: loss = 0.04770
Step 218985: loss = 0.09292
Step 218990: loss = 0.02482
Step 218995: loss = 0.09362
Step 219000: loss = 0.04970
Training Data Eval:
  Num examples: 50000, Num correct: 48203, Precision @ 1: 0.9641
('Testing Data Eval: EPOCH->', 220)
  Num examples: 10000, Num correct: 6658, Precision @ 1: 0.6658
Step 219005: loss = 0.03648
Step 219010: loss = 0.04961
Step 219015: loss = 0.03469
Step 219020: loss = 0.06430
Step 219025: loss = 0.00235
Step 219030: loss = 0.04061
Step 219035: loss = 0.08281
Step 219040: loss = 0.09391
Step 219045: loss = 0.11086
Step 219050: loss = 0.09690
Step 219055: loss = 0.04689
Step 219060: loss = 0.09818
Step 219065: loss = 0.08399
Step 219070: loss = 0.06111
Step 219075: loss = 0.19380
Step 219080: loss = 0.10341
Step 219085: loss = 0.07742
Step 219090: loss = 0.06400
Step 219095: loss = 0.05109
Step 219100: loss = 0.37711
Step 219105: loss = 0.06435
Step 219110: loss = 0.14848
Step 219115: loss = 0.03641
Step 219120: loss = 0.04785
Step 219125: loss = 0.17008
Step 219130: loss = 0.09170
Step 219135: loss = 0.07786
Step 219140: loss = 0.11486
Step 219145: loss = 0.17181
Step 219150: loss = 0.06910
Step 219155: loss = 0.03321
Step 219160: loss = 0.17969
Step 219165: loss = 0.07651
Step 219170: loss = 0.09050
Step 219175: loss = 0.10568
Step 219180: loss = 0.08498
Step 219185: loss = 0.05073
Step 219190: loss = 0.05443
Step 219195: loss = 0.08910
Step 219200: loss = 0.07774
Step 219205: loss = 0.07581
Step 219210: loss = 0.10773
Step 219215: loss = 0.15717
Step 219220: loss = 0.27829
Step 219225: loss = 0.09874
Step 219230: loss = 0.05876
Step 219235: loss = 0.07234
Step 219240: loss = 0.04598
Step 219245: loss = 0.12123
Step 219250: loss = 0.07266
Step 219255: loss = 0.13959
Step 219260: loss = 0.03676
Step 219265: loss = 0.02205
Step 219270: loss = 0.03995
Step 219275: loss = 0.08589
Step 219280: loss = 0.03301
Step 219285: loss = 0.06145
Step 219290: loss = 0.24663
Step 219295: loss = 0.06374
Step 219300: loss = 0.17731
Step 219305: loss = 0.06938
Step 219310: loss = 0.12432
Step 219315: loss = 0.15439
Step 219320: loss = 0.02843
Step 219325: loss = 0.17521
Step 219330: loss = 0.10341
Step 219335: loss = 0.05278
Step 219340: loss = 0.08128
Step 219345: loss = 0.05026
Step 219350: loss = 0.04445
Step 219355: loss = 0.07387
Step 219360: loss = 0.05926
Step 219365: loss = 0.05865
Step 219370: loss = 0.05679
Step 219375: loss = 0.08469
Step 219380: loss = 0.04866
Step 219385: loss = 0.05242
Step 219390: loss = 0.11555
Step 219395: loss = 0.09287
Step 219400: loss = 0.07931
Step 219405: loss = 0.12248
Step 219410: loss = 0.13658
Step 219415: loss = 0.34510
Step 219420: loss = 0.06945
Step 219425: loss = 0.12916
Step 219430: loss = 0.16311
Step 219435: loss = 0.20427
Step 219440: loss = 0.06032
Step 219445: loss = 0.07042
Step 219450: loss = 0.04680
Step 219455: loss = 0.04822
Step 219460: loss = 0.03678
Step 219465: loss = 0.11894
Step 219470: loss = 0.02225
Step 219475: loss = 0.05057
Step 219480: loss = 0.06722
Step 219485: loss = 0.14688
Step 219490: loss = 0.04752
Step 219495: loss = 0.01424
Step 219500: loss = 0.04163
Step 219505: loss = 0.04063
Step 219510: loss = 0.06519
Step 219515: loss = 0.17954
Step 219520: loss = 0.04775
Step 219525: loss = 0.11284
Step 219530: loss = 0.01339
Step 219535: loss = 0.04830
Step 219540: loss = 0.04910
Step 219545: loss = 0.11689
Step 219550: loss = 0.21175
Step 219555: loss = 0.12965
Step 219560: loss = 0.17716
Step 219565: loss = 0.06241
Step 219570: loss = 0.05734
Step 219575: loss = 0.08242
Step 219580: loss = 0.05257
Step 219585: loss = 0.31603
Step 219590: loss = 0.05848
Step 219595: loss = 0.12418
Step 219600: loss = 0.43649
Step 219605: loss = 0.16230
Step 219610: loss = 0.13456
Step 219615: loss = 0.11736
Step 219620: loss = 0.07899
Step 219625: loss = 0.19065
Step 219630: loss = 0.05115
Step 219635: loss = 0.09902
Step 219640: loss = 0.06854
Step 219645: loss = 0.02719
Step 219650: loss = 0.17593
Step 219655: loss = 0.03938
Step 219660: loss = 0.42584
Step 219665: loss = 0.10460
Step 219670: loss = 0.09561
Step 219675: loss = 0.02807
Step 219680: loss = 0.17674
Step 219685: loss = 0.02608
Step 219690: loss = 0.11500
Step 219695: loss = 0.18542
Step 219700: loss = 0.07008
Step 219705: loss = 0.08196
Step 219710: loss = 0.11601
Step 219715: loss = 0.07703
Step 219720: loss = 0.26043
Step 219725: loss = 0.06979
Step 219730: loss = 0.11776
Step 219735: loss = 0.07186
Step 219740: loss = 0.07937
Step 219745: loss = 0.14517
Step 219750: loss = 0.19659
Step 219755: loss = 0.07847
Step 219760: loss = 0.01212
Step 219765: loss = 0.03330
Step 219770: loss = 0.14184
Step 219775: loss = 0.07195
Step 219780: loss = 0.04206
Step 219785: loss = 0.13188
Step 219790: loss = 0.04714
Step 219795: loss = 0.11742
Step 219800: loss = 0.03494
Step 219805: loss = 0.09070
Step 219810: loss = 0.04415
Step 219815: loss = 0.20249
Step 219820: loss = 0.01847
Step 219825: loss = 0.15733
Step 219830: loss = 0.10430
Step 219835: loss = 0.02556
Step 219840: loss = 0.11537
Step 219845: loss = 0.03285
Step 219850: loss = 0.03804
Step 219855: loss = 0.16599
Step 219860: loss = 0.05406
Step 219865: loss = 0.02441
Step 219870: loss = 0.27165
Step 219875: loss = 0.09422
Step 219880: loss = 0.06436
Step 219885: loss = 0.32545
Step 219890: loss = 0.09660
Step 219895: loss = 0.06041
Step 219900: loss = 0.07175
Step 219905: loss = 0.12042
Step 219910: loss = 0.05603
Step 219915: loss = 0.03955
Step 219920: loss = 0.04264
Step 219925: loss = 0.09879
Step 219930: loss = 0.28516
Step 219935: loss = 0.04503
Step 219940: loss = 0.03866
Step 219945: loss = 0.04679
Step 219950: loss = 0.08315
Step 219955: loss = 0.10688
Step 219960: loss = 0.14250
Step 219965: loss = 0.03394
Step 219970: loss = 0.05454
Step 219975: loss = 0.20630
Step 219980: loss = 0.01361
Step 219985: loss = 0.11396
Step 219990: loss = 0.38316
Step 219995: loss = 0.23571
Step 220000: loss = 0.11428
Training Data Eval:
  Num examples: 50000, Num correct: 48339, Precision @ 1: 0.9668
('Testing Data Eval: EPOCH->', 221)
  Num examples: 10000, Num correct: 6747, Precision @ 1: 0.6747
Step 220005: loss = 0.06302
Step 220010: loss = 0.07892
Step 220015: loss = 0.02266
Step 220020: loss = 0.13590
Step 220025: loss = 0.02281
Step 220030: loss = 0.06308
Step 220035: loss = 0.11504
Step 220040: loss = 0.06049
Step 220045: loss = 0.06902
Step 220050: loss = 0.01824
Step 220055: loss = 0.18728
Step 220060: loss = 0.10945
Step 220065: loss = 0.03418
Step 220070: loss = 0.02433
Step 220075: loss = 0.03031
Step 220080: loss = 0.23608
Step 220085: loss = 0.04610
Step 220090: loss = 0.15270
Step 220095: loss = 0.13292
Step 220100: loss = 0.06720
Step 220105: loss = 0.04079
Step 220110: loss = 0.02282
Step 220115: loss = 0.05865
Step 220120: loss = 0.11954
Step 220125: loss = 0.09960
Step 220130: loss = 0.07193
Step 220135: loss = 0.02385
Step 220140: loss = 0.16772
Step 220145: loss = 0.09381
Step 220150: loss = 0.03845
Step 220155: loss = 0.03632
Step 220160: loss = 0.14541
Step 220165: loss = 0.15891
Step 220170: loss = 0.10756
Step 220175: loss = 0.07237
Step 220180: loss = 0.09160
Step 220185: loss = 0.17068
Step 220190: loss = 0.06063
Step 220195: loss = 0.23170
Step 220200: loss = 0.18179
Step 220205: loss = 0.21127
Step 220210: loss = 0.03176
Step 220215: loss = 0.07452
Step 220220: loss = 0.27329
Step 220225: loss = 0.17910
Step 220230: loss = 0.04893
Step 220235: loss = 0.08425
Step 220240: loss = 0.04783
Step 220245: loss = 0.06881
Step 220250: loss = 0.48278
Step 220255: loss = 0.24006
Step 220260: loss = 0.08199
Step 220265: loss = 0.05020
Step 220270: loss = 0.09300
Step 220275: loss = 0.11756
Step 220280: loss = 0.07362
Step 220285: loss = 0.11059
Step 220290: loss = 0.20373
Step 220295: loss = 0.07110
Step 220300: loss = 0.07941
Step 220305: loss = 0.05263
Step 220310: loss = 0.16295
Step 220315: loss = 0.04528
Step 220320: loss = 0.06573
Step 220325: loss = 0.22805
Step 220330: loss = 0.06453
Step 220335: loss = 0.04351
Step 220340: loss = 0.06407
Step 220345: loss = 0.03469
Step 220350: loss = 0.12735
Step 220355: loss = 0.16871
Step 220360: loss = 0.07721
Step 220365: loss = 0.12915
Step 220370: loss = 0.02718
Step 220375: loss = 0.11783
Step 220380: loss = 0.07434
Step 220385: loss = 0.06216
Step 220390: loss = 0.19972
Step 220395: loss = 0.09581
Step 220400: loss = 0.44269
Step 220405: loss = 0.09322
Step 220410: loss = 0.18771
Step 220415: loss = 0.01314
Step 220420: loss = 0.04668
Step 220425: loss = 0.11023
Step 220430: loss = 0.03633
Step 220435: loss = 0.12813
Step 220440: loss = 0.06960
Step 220445: loss = 0.04501
Step 220450: loss = 0.10456
Step 220455: loss = 0.12381
Step 220460: loss = 0.05148
Step 220465: loss = 0.10338
Step 220470: loss = 0.11200
Step 220475: loss = 0.09493
Step 220480: loss = 0.14290
Step 220485: loss = 0.14729
Step 220490: loss = 0.25325
Step 220495: loss = 0.17055
Step 220500: loss = 0.13360
Step 220505: loss = 0.02652
Step 220510: loss = 0.08423
Step 220515: loss = 0.20682
Step 220520: loss = 0.05970
Step 220525: loss = 0.02508
Step 220530: loss = 0.05998
Step 220535: loss = 0.05880
Step 220540: loss = 0.24390
Step 220545: loss = 0.16567
Step 220550: loss = 0.07956
Step 220555: loss = 0.12290
Step 220560: loss = 0.19991
Step 220565: loss = 0.01560
Step 220570: loss = 0.16608
Step 220575: loss = 0.05092
Step 220580: loss = 0.06263
Step 220585: loss = 0.15603
Step 220590: loss = 0.17785
Step 220595: loss = 0.08481
Step 220600: loss = 0.09052
Step 220605: loss = 0.35926
Step 220610: loss = 0.03160
Step 220615: loss = 0.03446
Step 220620: loss = 0.07149
Step 220625: loss = 0.06057
Step 220630: loss = 0.05181
Step 220635: loss = 0.07986
Step 220640: loss = 0.05453
Step 220645: loss = 0.10590
Step 220650: loss = 0.15699
Step 220655: loss = 0.19166
Step 220660: loss = 0.21813
Step 220665: loss = 0.05609
Step 220670: loss = 0.20166
Step 220675: loss = 0.15309
Step 220680: loss = 0.05576
Step 220685: loss = 0.13258
Step 220690: loss = 0.11569
Step 220695: loss = 0.08552
Step 220700: loss = 0.18278
Step 220705: loss = 0.05549
Step 220710: loss = 0.07418
Step 220715: loss = 0.11036
Step 220720: loss = 0.10119
Step 220725: loss = 0.07798
Step 220730: loss = 0.03713
Step 220735: loss = 0.10078
Step 220740: loss = 0.04730
Step 220745: loss = 0.02570
Step 220750: loss = 0.15748
Step 220755: loss = 0.20553
Step 220760: loss = 0.08679
Step 220765: loss = 0.07565
Step 220770: loss = 0.05179
Step 220775: loss = 0.07781
Step 220780: loss = 0.06454
Step 220785: loss = 0.06657
Step 220790: loss = 0.09074
Step 220795: loss = 0.17730
Step 220800: loss = 0.08010
Step 220805: loss = 0.07194
Step 220810: loss = 0.11118
Step 220815: loss = 0.07098
Step 220820: loss = 0.03049
Step 220825: loss = 0.09839
Step 220830: loss = 0.03956
Step 220835: loss = 0.05389
Step 220840: loss = 0.09327
Step 220845: loss = 0.05074
Step 220850: loss = 0.23244
Step 220855: loss = 0.16981
Step 220860: loss = 0.05592
Step 220865: loss = 0.13295
Step 220870: loss = 0.12741
Step 220875: loss = 0.12766
Step 220880: loss = 0.05435
Step 220885: loss = 0.07730
Step 220890: loss = 0.18440
Step 220895: loss = 0.05749
Step 220900: loss = 0.01257
Step 220905: loss = 0.02902
Step 220910: loss = 0.09214
Step 220915: loss = 0.04689
Step 220920: loss = 0.04630
Step 220925: loss = 0.05697
Step 220930: loss = 0.02606
Step 220935: loss = 0.02573
Step 220940: loss = 0.03899
Step 220945: loss = 0.07864
Step 220950: loss = 0.05302
Step 220955: loss = 0.11572
Step 220960: loss = 0.11922
Step 220965: loss = 0.02337
Step 220970: loss = 0.06948
Step 220975: loss = 0.01721
Step 220980: loss = 0.02997
Step 220985: loss = 0.07478
Step 220990: loss = 0.07751
Step 220995: loss = 0.03730
Step 221000: loss = 0.05535
Training Data Eval:
  Num examples: 50000, Num correct: 48432, Precision @ 1: 0.9686
('Testing Data Eval: EPOCH->', 222)
  Num examples: 10000, Num correct: 6768, Precision @ 1: 0.6768
Step 221005: loss = 0.06916
Step 221010: loss = 0.09178
Step 221015: loss = 0.27384
Step 221020: loss = 0.06368
Step 221025: loss = 0.04307
Step 221030: loss = 0.20027
Step 221035: loss = 0.03453
Step 221040: loss = 0.11125
Step 221045: loss = 0.02082
Step 221050: loss = 0.08284
Step 221055: loss = 0.17973
Step 221060: loss = 0.16575
Step 221065: loss = 0.10515
Step 221070: loss = 0.06800
Step 221075: loss = 0.03924
Step 221080: loss = 0.03389
Step 221085: loss = 0.11177
Step 221090: loss = 0.24590
Step 221095: loss = 0.14511
Step 221100: loss = 0.14628
Step 221105: loss = 0.20817
Step 221110: loss = 0.16468
Step 221115: loss = 0.14670
Step 221120: loss = 0.05176
Step 221125: loss = 0.43234
Step 221130: loss = 0.02440
Step 221135: loss = 0.11599
Step 221140: loss = 0.12473
Step 221145: loss = 0.03007
Step 221150: loss = 0.07921
Step 221155: loss = 0.13172
Step 221160: loss = 0.05959
Step 221165: loss = 0.14195
Step 221170: loss = 0.02799
Step 221175: loss = 0.03832
Step 221180: loss = 0.06198
Step 221185: loss = 0.04816
Step 221190: loss = 0.15717
Step 221195: loss = 0.19184
Step 221200: loss = 0.27941
Step 221205: loss = 0.06781
Step 221210: loss = 0.03534
Step 221215: loss = 0.26041
Step 221220: loss = 0.22669
Step 221225: loss = 0.22829
Step 221230: loss = 0.28095
Step 221235: loss = 0.10639
Step 221240: loss = 0.06123
Step 221245: loss = 0.02178
Step 221250: loss = 0.06288
Step 221255: loss = 0.07788
Step 221260: loss = 0.11323
Step 221265: loss = 0.07635
Step 221270: loss = 0.14921
Step 221275: loss = 0.08889
Step 221280: loss = 0.05797
Step 221285: loss = 0.03377
Step 221290: loss = 0.11783
Step 221295: loss = 0.05059
Step 221300: loss = 0.18472
Step 221305: loss = 0.01000
Step 221310: loss = 0.04256
Step 221315: loss = 0.04964
Step 221320: loss = 0.13564
Step 221325: loss = 0.03549
Step 221330: loss = 0.11570
Step 221335: loss = 0.14900
Step 221340: loss = 0.07405
Step 221345: loss = 0.14875
Step 221350: loss = 0.08524
Step 221355: loss = 0.04011
Step 221360: loss = 0.06997
Step 221365: loss = 0.12224
Step 221370: loss = 0.03074
Step 221375: loss = 0.02730
Step 221380: loss = 0.01922
Step 221385: loss = 0.03401
Step 221390: loss = 0.15296
Step 221395: loss = 0.06941
Step 221400: loss = 0.02007
Step 221405: loss = 0.07927
Step 221410: loss = 0.20185
Step 221415: loss = 0.01879
Step 221420: loss = 0.06290
Step 221425: loss = 0.08619
Step 221430: loss = 0.03799
Step 221435: loss = 0.14699
Step 221440: loss = 0.10410
Step 221445: loss = 0.05339
Step 221450: loss = 0.11123
Step 221455: loss = 0.07498
Step 221460: loss = 0.07438
Step 221465: loss = 0.14329
Step 221470: loss = 0.09205
Step 221475: loss = 0.12176
Step 221480: loss = 0.04034
Step 221485: loss = 0.05198
Step 221490: loss = 0.05748
Step 221495: loss = 0.04982
Step 221500: loss = 0.15706
Step 221505: loss = 0.03086
Step 221510: loss = 0.04075
Step 221515: loss = 0.03749
Step 221520: loss = 0.10784
Step 221525: loss = 0.14753
Step 221530: loss = 0.13440
Step 221535: loss = 0.16126
Step 221540: loss = 0.01725
Step 221545: loss = 0.12867
Step 221550: loss = 0.12326
Step 221555: loss = 0.14659
Step 221560: loss = 0.19461
Step 221565: loss = 0.05967
Step 221570: loss = 0.14992
Step 221575: loss = 0.12098
Step 221580: loss = 0.03027
Step 221585: loss = 0.09948
Step 221590: loss = 0.03806
Step 221595: loss = 0.08663
Step 221600: loss = 0.01666
Step 221605: loss = 0.08960
Step 221610: loss = 0.07447
Step 221615: loss = 0.06340
Step 221620: loss = 0.06406
Step 221625: loss = 0.04789
Step 221630: loss = 0.16302
Step 221635: loss = 0.05032
Step 221640: loss = 0.06658
Step 221645: loss = 0.04778
Step 221650: loss = 0.02802
Step 221655: loss = 0.06568
Step 221660: loss = 0.02701
Step 221665: loss = 0.07009
Step 221670: loss = 0.17583
Step 221675: loss = 0.04651
Step 221680: loss = 0.26909
Step 221685: loss = 0.10824
Step 221690: loss = 0.03536
Step 221695: loss = 0.15977
Step 221700: loss = 0.11115
Step 221705: loss = 0.05788
Step 221710: loss = 0.05009
Step 221715: loss = 0.04659
Step 221720: loss = 0.21803
Step 221725: loss = 0.15127
Step 221730: loss = 0.04889
Step 221735: loss = 0.03987
Step 221740: loss = 0.08480
Step 221745: loss = 0.04661
Step 221750: loss = 0.08379
Step 221755: loss = 0.06176
Step 221760: loss = 0.10904
Step 221765: loss = 0.03356
Step 221770: loss = 0.25467
Step 221775: loss = 0.11047
Step 221780: loss = 0.04146
Step 221785: loss = 0.07687
Step 221790: loss = 0.16612
Step 221795: loss = 0.02342
Step 221800: loss = 0.07128
Step 221805: loss = 0.13276
Step 221810: loss = 0.07869
Step 221815: loss = 0.10818
Step 221820: loss = 0.09870
Step 221825: loss = 0.07050
Step 221830: loss = 0.02858
Step 221835: loss = 0.29180
Step 221840: loss = 0.09449
Step 221845: loss = 0.14506
Step 221850: loss = 0.10933
Step 221855: loss = 0.10945
Step 221860: loss = 0.12152
Step 221865: loss = 0.09872
Step 221870: loss = 0.08533
Step 221875: loss = 0.05345
Step 221880: loss = 0.18832
Step 221885: loss = 0.10349
Step 221890: loss = 0.10169
Step 221895: loss = 0.16391
Step 221900: loss = 0.07328
Step 221905: loss = 0.26445
Step 221910: loss = 0.31905
Step 221915: loss = 0.19463
Step 221920: loss = 0.03665
Step 221925: loss = 0.10970
Step 221930: loss = 0.12937
Step 221935: loss = 0.16920
Step 221940: loss = 0.08135
Step 221945: loss = 0.10239
Step 221950: loss = 0.07017
Step 221955: loss = 0.04409
Step 221960: loss = 0.04927
Step 221965: loss = 0.06544
Step 221970: loss = 0.14438
Step 221975: loss = 0.03639
Step 221980: loss = 0.04649
Step 221985: loss = 0.28674
Step 221990: loss = 0.10003
Step 221995: loss = 0.11999
Step 222000: loss = 0.13868
Training Data Eval:
  Num examples: 50000, Num correct: 48262, Precision @ 1: 0.9652
('Testing Data Eval: EPOCH->', 223)
  Num examples: 10000, Num correct: 6722, Precision @ 1: 0.6722
Step 222005: loss = 0.36794
Step 222010: loss = 0.05006
Step 222015: loss = 0.10767
Step 222020: loss = 0.29800
Step 222025: loss = 0.05543
Step 222030: loss = 0.06887
Step 222035: loss = 0.03124
Step 222040: loss = 0.03989
Step 222045: loss = 0.24022
Step 222050: loss = 0.08389
Step 222055: loss = 0.09374
Step 222060: loss = 0.14316
Step 222065: loss = 0.05736
Step 222070: loss = 0.12571
Step 222075: loss = 0.07804
Step 222080: loss = 0.09206
Step 222085: loss = 0.11216
Step 222090: loss = 0.03897
Step 222095: loss = 0.03204
Step 222100: loss = 0.24191
Step 222105: loss = 0.06462
Step 222110: loss = 0.22331
Step 222115: loss = 0.04372
Step 222120: loss = 0.06230
Step 222125: loss = 0.05058
Step 222130: loss = 0.13205
Step 222135: loss = 0.19340
Step 222140: loss = 0.07725
Step 222145: loss = 0.05396
Step 222150: loss = 0.07096
Step 222155: loss = 0.21048
Step 222160: loss = 0.04557
Step 222165: loss = 0.15200
Step 222170: loss = 0.05498
Step 222175: loss = 0.03482
Step 222180: loss = 0.05981
Step 222185: loss = 0.36180
Step 222190: loss = 0.13740
Step 222195: loss = 0.05089
Step 222200: loss = 0.07389
Step 222205: loss = 0.04312
Step 222210: loss = 0.32808
Step 222215: loss = 0.02971
Step 222220: loss = 0.11584
Step 222225: loss = 0.06321
Step 222230: loss = 0.02770
Step 222235: loss = 0.18223
Step 222240: loss = 0.15730
Step 222245: loss = 0.15840
Step 222250: loss = 0.16115
Step 222255: loss = 0.03278
Step 222260: loss = 0.06322
Step 222265: loss = 0.06642
Step 222270: loss = 0.07759
Step 222275: loss = 0.04145
Step 222280: loss = 0.08702
Step 222285: loss = 0.05809
Step 222290: loss = 0.16448
Step 222295: loss = 0.10574
Step 222300: loss = 0.05337
Step 222305: loss = 0.02555
Step 222310: loss = 0.10009
Step 222315: loss = 0.11399
Step 222320: loss = 0.27573
Step 222325: loss = 0.04563
Step 222330: loss = 0.05155
Step 222335: loss = 0.14975
Step 222340: loss = 0.06803
Step 222345: loss = 0.17154
Step 222350: loss = 0.16000
Step 222355: loss = 0.29290
Step 222360: loss = 0.03827
Step 222365: loss = 0.02316
Step 222370: loss = 0.14586
Step 222375: loss = 0.20524
Step 222380: loss = 0.07787
Step 222385: loss = 0.10744
Step 222390: loss = 0.05314
Step 222395: loss = 0.09042
Step 222400: loss = 0.04050
Step 222405: loss = 0.08509
Step 222410: loss = 0.08273
Step 222415: loss = 0.01635
Step 222420: loss = 0.13608
Step 222425: loss = 0.13214
Step 222430: loss = 0.09645
Step 222435: loss = 0.05236
Step 222440: loss = 0.12444
Step 222445: loss = 0.01759
Step 222450: loss = 0.18127
Step 222455: loss = 0.01422
Step 222460: loss = 0.08765
Step 222465: loss = 0.10962
Step 222470: loss = 0.22694
Step 222475: loss = 0.03342
Step 222480: loss = 0.10677
Step 222485: loss = 0.03563
Step 222490: loss = 0.03860
Step 222495: loss = 0.13690
Step 222500: loss = 0.09292
Step 222505: loss = 0.02201
Step 222510: loss = 0.11302
Step 222515: loss = 0.31368
Step 222520: loss = 0.02101
Step 222525: loss = 0.07296
Step 222530: loss = 0.10995
Step 222535: loss = 0.05962
Step 222540: loss = 0.09436
Step 222545: loss = 0.09220
Step 222550: loss = 0.12938
Step 222555: loss = 0.10708
Step 222560: loss = 0.01644
Step 222565: loss = 0.09911
Step 222570: loss = 0.03521
Step 222575: loss = 0.08804
Step 222580: loss = 0.13675
Step 222585: loss = 0.17358
Step 222590: loss = 0.15032
Step 222595: loss = 0.13282
Step 222600: loss = 0.05032
Step 222605: loss = 0.12282
Step 222610: loss = 0.06584
Step 222615: loss = 0.30751
Step 222620: loss = 0.23292
Step 222625: loss = 0.26477
Step 222630: loss = 0.30718
Step 222635: loss = 0.01729
Step 222640: loss = 0.16401
Step 222645: loss = 0.03356
Step 222650: loss = 0.02154
Step 222655: loss = 0.02467
Step 222660: loss = 0.14923
Step 222665: loss = 0.09677
Step 222670: loss = 0.16788
Step 222675: loss = 0.13299
Step 222680: loss = 0.09091
Step 222685: loss = 0.07430
Step 222690: loss = 0.10571
Step 222695: loss = 0.14223
Step 222700: loss = 0.02325
Step 222705: loss = 0.09982
Step 222710: loss = 0.16070
Step 222715: loss = 0.07437
Step 222720: loss = 0.33963
Step 222725: loss = 0.18105
Step 222730: loss = 0.10281
Step 222735: loss = 0.09591
Step 222740: loss = 0.04944
Step 222745: loss = 0.07040
Step 222750: loss = 0.04084
Step 222755: loss = 0.06590
Step 222760: loss = 0.11767
Step 222765: loss = 0.13063
Step 222770: loss = 0.04108
Step 222775: loss = 0.16664
Step 222780: loss = 0.17941
Step 222785: loss = 0.06367
Step 222790: loss = 0.41746
Step 222795: loss = 0.04235
Step 222800: loss = 0.13520
Step 222805: loss = 0.01747
Step 222810: loss = 0.11217
Step 222815: loss = 0.03813
Step 222820: loss = 0.06623
Step 222825: loss = 0.05503
Step 222830: loss = 0.05492
Step 222835: loss = 0.26063
Step 222840: loss = 0.04445
Step 222845: loss = 0.09248
Step 222850: loss = 0.08513
Step 222855: loss = 0.11474
Step 222860: loss = 0.08325
Step 222865: loss = 0.13306
Step 222870: loss = 0.08180
Step 222875: loss = 0.02155
Step 222880: loss = 0.08164
Step 222885: loss = 0.04531
Step 222890: loss = 0.13724
Step 222895: loss = 0.15597
Step 222900: loss = 0.09194
Step 222905: loss = 0.03611
Step 222910: loss = 0.03340
Step 222915: loss = 0.13730
Step 222920: loss = 0.16765
Step 222925: loss = 0.34768
Step 222930: loss = 0.14853
Step 222935: loss = 0.16999
Step 222940: loss = 0.02224
Step 222945: loss = 0.16989
Step 222950: loss = 0.09793
Step 222955: loss = 0.05590
Step 222960: loss = 0.03798
Step 222965: loss = 0.03494
Step 222970: loss = 0.09200
Step 222975: loss = 0.04527
Step 222980: loss = 0.10702
Step 222985: loss = 0.04441
Step 222990: loss = 0.12585
Step 222995: loss = 0.05919
Step 223000: loss = 0.02256
Training Data Eval:
  Num examples: 50000, Num correct: 48225, Precision @ 1: 0.9645
('Testing Data Eval: EPOCH->', 224)
  Num examples: 10000, Num correct: 6708, Precision @ 1: 0.6708
Step 223005: loss = 0.02300
Step 223010: loss = 0.03188
Step 223015: loss = 0.05995
Step 223020: loss = 0.09567
Step 223025: loss = 0.05263
Step 223030: loss = 0.02915
Step 223035: loss = 0.03764
Step 223040: loss = 0.07768
Step 223045: loss = 0.20888
Step 223050: loss = 0.11847
Step 223055: loss = 0.03728
Step 223060: loss = 0.03819
Step 223065: loss = 0.05123
Step 223070: loss = 0.16997
Step 223075: loss = 0.07817
Step 223080: loss = 0.10547
Step 223085: loss = 0.03696
Step 223090: loss = 0.09156
Step 223095: loss = 0.08005
Step 223100: loss = 0.04942
Step 223105: loss = 0.14875
Step 223110: loss = 0.07337
Step 223115: loss = 0.06128
Step 223120: loss = 0.08110
Step 223125: loss = 0.14553
Step 223130: loss = 0.01852
Step 223135: loss = 0.14097
Step 223140: loss = 0.09635
Step 223145: loss = 0.01870
Step 223150: loss = 0.05662
Step 223155: loss = 0.12414
Step 223160: loss = 0.06634
Step 223165: loss = 0.15611
Step 223170: loss = 0.14384
Step 223175: loss = 0.12788
Step 223180: loss = 0.04713
Step 223185: loss = 0.05607
Step 223190: loss = 0.10074
Step 223195: loss = 0.11908
Step 223200: loss = 0.04995
Step 223205: loss = 0.04175
Step 223210: loss = 0.02491
Step 223215: loss = 0.10173
Step 223220: loss = 0.14540
Step 223225: loss = 0.01912
Step 223230: loss = 0.06195
Step 223235: loss = 0.06093
Step 223240: loss = 0.05636
Step 223245: loss = 0.10489
Step 223250: loss = 0.09618
Step 223255: loss = 0.04465
Step 223260: loss = 0.09964
Step 223265: loss = 0.05548
Step 223270: loss = 0.23960
Step 223275: loss = 0.03663
Step 223280: loss = 0.11512
Step 223285: loss = 0.08542
Step 223290: loss = 0.13195
Step 223295: loss = 0.01876
Step 223300: loss = 0.02777
Step 223305: loss = 0.13520
Step 223310: loss = 0.10497
Step 223315: loss = 0.13981
Step 223320: loss = 0.09690
Step 223325: loss = 0.01659
Step 223330: loss = 0.03944
Step 223335: loss = 0.03639
Step 223340: loss = 0.05626
Step 223345: loss = 0.22602
Step 223350: loss = 0.06325
Step 223355: loss = 0.14664
Step 223360: loss = 0.25729
Step 223365: loss = 0.04465
Step 223370: loss = 0.04479
Step 223375: loss = 0.04368
Step 223380: loss = 0.02530
Step 223385: loss = 0.07595
Step 223390: loss = 0.22258
Step 223395: loss = 0.14002
Step 223400: loss = 0.08051
Step 223405: loss = 0.01567
Step 223410: loss = 0.03189
Step 223415: loss = 0.09899
Step 223420: loss = 0.07634
Step 223425: loss = 0.09187
Step 223430: loss = 0.04200
Step 223435: loss = 0.06154
Step 223440: loss = 0.04442
Step 223445: loss = 0.13163
Step 223450: loss = 0.03115
Step 223455: loss = 0.10157
Step 223460: loss = 0.04527
Step 223465: loss = 0.17123
Step 223470: loss = 0.14971
Step 223475: loss = 0.10093
Step 223480: loss = 0.08396
Step 223485: loss = 0.03002
Step 223490: loss = 0.14145
Step 223495: loss = 0.02455
Step 223500: loss = 0.02369
Step 223505: loss = 0.02491
Step 223510: loss = 0.03780
Step 223515: loss = 0.07238
Step 223520: loss = 0.03976
Step 223525: loss = 0.03163
Step 223530: loss = 0.07018
Step 223535: loss = 0.09572
Step 223540: loss = 0.09279
Step 223545: loss = 0.08139
Step 223550: loss = 0.09036
Step 223555: loss = 0.04962
Step 223560: loss = 0.15432
Step 223565: loss = 0.04643
Step 223570: loss = 0.09519
Step 223575: loss = 0.07142
Step 223580: loss = 0.08651
Step 223585: loss = 0.01419
Step 223590: loss = 0.04928
Step 223595: loss = 0.23488
Step 223600: loss = 0.04188
Step 223605: loss = 0.05165
Step 223610: loss = 0.05777
Step 223615: loss = 0.15028
Step 223620: loss = 0.05886
Step 223625: loss = 0.12501
Step 223630: loss = 0.06600
Step 223635: loss = 0.03128
Step 223640: loss = 0.11489
Step 223645: loss = 0.06893
Step 223650: loss = 0.08350
Step 223655: loss = 0.02700
Step 223660: loss = 0.23653
Step 223665: loss = 0.02904
Step 223670: loss = 0.04784
Step 223675: loss = 0.07688
Step 223680: loss = 0.11324
Step 223685: loss = 0.15595
Step 223690: loss = 0.08345
Step 223695: loss = 0.18624
Step 223700: loss = 0.20664
Step 223705: loss = 0.15445
Step 223710: loss = 0.04874
Step 223715: loss = 0.03449
Step 223720: loss = 0.04780
Step 223725: loss = 0.02183
Step 223730: loss = 0.06693
Step 223735: loss = 0.05459
Step 223740: loss = 0.10134
Step 223745: loss = 0.09797
Step 223750: loss = 0.15177
Step 223755: loss = 0.02171
Step 223760: loss = 0.06868
Step 223765: loss = 0.02424
Step 223770: loss = 0.17014
Step 223775: loss = 0.10293
Step 223780: loss = 0.12952
Step 223785: loss = 0.06168
Step 223790: loss = 0.20026
Step 223795: loss = 0.08406
Step 223800: loss = 0.05766
Step 223805: loss = 0.18080
Step 223810: loss = 0.04787
Step 223815: loss = 0.12172
Step 223820: loss = 0.11330
Step 223825: loss = 0.09101
Step 223830: loss = 0.09529
Step 223835: loss = 0.13454
Step 223840: loss = 0.14331
Step 223845: loss = 0.11072
Step 223850: loss = 0.29581
Step 223855: loss = 0.08594
Step 223860: loss = 0.03650
Step 223865: loss = 0.40888
Step 223870: loss = 0.10559
Step 223875: loss = 0.04693
Step 223880: loss = 0.15925
Step 223885: loss = 0.10119
Step 223890: loss = 0.17948
Step 223895: loss = 0.12158
Step 223900: loss = 0.11709
Step 223905: loss = 0.19308
Step 223910: loss = 0.15185
Step 223915: loss = 0.13762
Step 223920: loss = 0.04994
Step 223925: loss = 0.09026
Step 223930: loss = 0.13814
Step 223935: loss = 0.10056
Step 223940: loss = 0.06402
Step 223945: loss = 0.07475
Step 223950: loss = 0.12847
Step 223955: loss = 0.20609
Step 223960: loss = 0.02977
Step 223965: loss = 0.02722
Step 223970: loss = 0.35433
Step 223975: loss = 0.33201
Step 223980: loss = 0.03594
Step 223985: loss = 0.04700
Step 223990: loss = 0.06581
Step 223995: loss = 0.09384
Step 224000: loss = 0.26813
Training Data Eval:
  Num examples: 50000, Num correct: 48208, Precision @ 1: 0.9642
('Testing Data Eval: EPOCH->', 225)
  Num examples: 10000, Num correct: 6693, Precision @ 1: 0.6693
Step 224005: loss = 0.10105
Step 224010: loss = 0.07795
Step 224015: loss = 0.20618
Step 224020: loss = 0.18566
Step 224025: loss = 0.03100
Step 224030: loss = 0.05352
Step 224035: loss = 0.02041
Step 224040: loss = 0.28604
Step 224045: loss = 0.01642
Step 224050: loss = 0.02276
Step 224055: loss = 0.13771
Step 224060: loss = 0.02354
Step 224065: loss = 0.69339
Step 224070: loss = 0.06042
Step 224075: loss = 0.07343
Step 224080: loss = 0.04767
Step 224085: loss = 0.12732
Step 224090: loss = 0.24104
Step 224095: loss = 0.19740
Step 224100: loss = 0.07055
Step 224105: loss = 0.09314
Step 224110: loss = 0.14492
Step 224115: loss = 0.08766
Step 224120: loss = 0.12837
Step 224125: loss = 0.23647
Step 224130: loss = 0.11551
Step 224135: loss = 0.05806
Step 224140: loss = 0.06112
Step 224145: loss = 0.04092
Step 224150: loss = 0.04345
Step 224155: loss = 0.06110
Step 224160: loss = 0.02440
Step 224165: loss = 0.14470
Step 224170: loss = 0.03644
Step 224175: loss = 0.11365
Step 224180: loss = 0.05068
Step 224185: loss = 0.04882
Step 224190: loss = 0.05168
Step 224195: loss = 0.04820
Step 224200: loss = 0.02725
Step 224205: loss = 0.11461
Step 224210: loss = 0.08653
Step 224215: loss = 0.11782
Step 224220: loss = 0.02397
Step 224225: loss = 0.15437
Step 224230: loss = 0.06405
Step 224235: loss = 0.16908
Step 224240: loss = 0.04643
Step 224245: loss = 0.03890
Step 224250: loss = 0.10086
Step 224255: loss = 0.20198
Step 224260: loss = 0.04362
Step 224265: loss = 0.11401
Step 224270: loss = 0.09434
Step 224275: loss = 0.08327
Step 224280: loss = 0.04582
Step 224285: loss = 0.08912
Step 224290: loss = 0.07978
Step 224295: loss = 0.07454
Step 224300: loss = 0.05176
Step 224305: loss = 0.01892
Step 224310: loss = 0.05680
Step 224315: loss = 0.08535
Step 224320: loss = 0.07094
Step 224325: loss = 0.04639
Step 224330: loss = 0.09980
Step 224335: loss = 0.05732
Step 224340: loss = 0.02675
Step 224345: loss = 0.05751
Step 224350: loss = 0.04642
Step 224355: loss = 0.08769
Step 224360: loss = 0.04002
Step 224365: loss = 0.11825
Step 224370: loss = 0.06069
Step 224375: loss = 0.23158
Step 224380: loss = 0.23868
Step 224385: loss = 0.05654
Step 224390: loss = 0.12579
Step 224395: loss = 0.04503
Step 224400: loss = 0.09772
Step 224405: loss = 0.09265
Step 224410: loss = 0.11417
Step 224415: loss = 0.12872
Step 224420: loss = 0.05771
Step 224425: loss = 0.04952
Step 224430: loss = 0.11852
Step 224435: loss = 0.05335
Step 224440: loss = 0.07403
Step 224445: loss = 0.12389
Step 224450: loss = 0.19060
Step 224455: loss = 0.09113
Step 224460: loss = 0.16549
Step 224465: loss = 0.08339
Step 224470: loss = 0.07559
Step 224475: loss = 0.05523
Step 224480: loss = 0.14826
Step 224485: loss = 0.09781
Step 224490: loss = 0.06215
Step 224495: loss = 0.09965
Step 224500: loss = 0.09670
Step 224505: loss = 0.12811
Step 224510: loss = 0.12577
Step 224515: loss = 0.11104
Step 224520: loss = 0.04306
Step 224525: loss = 0.02098
Step 224530: loss = 0.06987
Step 224535: loss = 0.01260
Step 224540: loss = 0.24127
Step 224545: loss = 0.08755
Step 224550: loss = 0.11579
Step 224555: loss = 0.03239
Step 224560: loss = 0.10351
Step 224565: loss = 0.05324
Step 224570: loss = 0.04350
Step 224575: loss = 0.04782
Step 224580: loss = 0.17463
Step 224585: loss = 0.01575
Step 224590: loss = 0.06370
Step 224595: loss = 0.10786
Step 224600: loss = 0.19268
Step 224605: loss = 0.10796
Step 224610: loss = 0.22158
Step 224615: loss = 0.16277
Step 224620: loss = 0.10795
Step 224625: loss = 0.05842
Step 224630: loss = 0.19509
Step 224635: loss = 0.11801
Step 224640: loss = 0.03852
Step 224645: loss = 0.04680
Step 224650: loss = 0.18202
Step 224655: loss = 0.03950
Step 224660: loss = 0.06995
Step 224665: loss = 0.04724
Step 224670: loss = 0.07766
Step 224675: loss = 0.07647
Step 224680: loss = 0.03250
Step 224685: loss = 0.20717
Step 224690: loss = 0.11801
Step 224695: loss = 0.05014
Step 224700: loss = 0.07186
Step 224705: loss = 0.55455
Step 224710: loss = 0.22389
Step 224715: loss = 0.08931
Step 224720: loss = 0.01846
Step 224725: loss = 0.09063
Step 224730: loss = 0.03217
Step 224735: loss = 0.12787
Step 224740: loss = 0.04029
Step 224745: loss = 0.08367
Step 224750: loss = 0.15286
Step 224755: loss = 0.26137
Step 224760: loss = 0.02867
Step 224765: loss = 0.07425
Step 224770: loss = 0.04841
Step 224775: loss = 0.00812
Step 224780: loss = 0.06206
Step 224785: loss = 0.24376
Step 224790: loss = 0.16726
Step 224795: loss = 0.07137
Step 224800: loss = 0.06285
Step 224805: loss = 0.02457
Step 224810: loss = 0.09540
Step 224815: loss = 0.30291
Step 224820: loss = 0.06953
Step 224825: loss = 0.02806
Step 224830: loss = 0.10599
Step 224835: loss = 0.27448
Step 224840: loss = 0.10278
Step 224845: loss = 0.08177
Step 224850: loss = 0.13443
Step 224855: loss = 0.05345
Step 224860: loss = 0.13076
Step 224865: loss = 0.11290
Step 224870: loss = 0.06177
Step 224875: loss = 0.10795
Step 224880: loss = 0.04996
Step 224885: loss = 0.13621
Step 224890: loss = 0.11846
Step 224895: loss = 0.03333
Step 224900: loss = 0.13262
Step 224905: loss = 0.06519
Step 224910: loss = 0.10355
Step 224915: loss = 0.15790
Step 224920: loss = 0.04200
Step 224925: loss = 0.04829
Step 224930: loss = 0.08166
Step 224935: loss = 0.05229
Step 224940: loss = 0.02399
Step 224945: loss = 0.03143
Step 224950: loss = 0.10831
Step 224955: loss = 0.12828
Step 224960: loss = 0.14990
Step 224965: loss = 0.04637
Step 224970: loss = 0.05207
Step 224975: loss = 0.06322
Step 224980: loss = 0.53360
Step 224985: loss = 0.07069
Step 224990: loss = 0.10812
Step 224995: loss = 0.06358
Step 225000: loss = 0.12193
Training Data Eval:
  Num examples: 50000, Num correct: 48365, Precision @ 1: 0.9673
('Testing Data Eval: EPOCH->', 226)
  Num examples: 10000, Num correct: 6673, Precision @ 1: 0.6673
Step 225005: loss = 0.19678
Step 225010: loss = 0.06899
Step 225015: loss = 0.02742
Step 225020: loss = 0.29804
Step 225025: loss = 0.12400
Step 225030: loss = 0.03489
Step 225035: loss = 0.19900
Step 225040: loss = 0.14920
Step 225045: loss = 0.05890
Step 225050: loss = 0.07433
Step 225055: loss = 0.04925
Step 225060: loss = 0.15416
Step 225065: loss = 0.03732
Step 225070: loss = 0.05013
Step 225075: loss = 0.09954
Step 225080: loss = 0.06196
Step 225085: loss = 0.12033
Step 225090: loss = 0.09907
Step 225095: loss = 0.07253
Step 225100: loss = 0.09005
Step 225105: loss = 0.08060
Step 225110: loss = 0.09731
Step 225115: loss = 0.06745
Step 225120: loss = 0.06972
Step 225125: loss = 0.07901
Step 225130: loss = 0.03917
Step 225135: loss = 0.03410
Step 225140: loss = 0.13562
Step 225145: loss = 0.09662
Step 225150: loss = 0.08368
Step 225155: loss = 0.08249
Step 225160: loss = 0.05737
Step 225165: loss = 0.03861
Step 225170: loss = 0.11014
Step 225175: loss = 0.01461
Step 225180: loss = 0.10096
Step 225185: loss = 0.08673
Step 225190: loss = 0.16007
Step 225195: loss = 0.08768
Step 225200: loss = 0.29799
Step 225205: loss = 0.09425
Step 225210: loss = 0.06290
Step 225215: loss = 0.06672
Step 225220: loss = 0.06799
Step 225225: loss = 0.11440
Step 225230: loss = 0.06147
Step 225235: loss = 0.05486
Step 225240: loss = 0.05474
Step 225245: loss = 0.12429
Step 225250: loss = 0.09673
Step 225255: loss = 0.03501
Step 225260: loss = 0.07156
Step 225265: loss = 0.13664
Step 225270: loss = 0.09109
Step 225275: loss = 0.08462
Step 225280: loss = 0.01629
Step 225285: loss = 0.15504
Step 225290: loss = 0.29496
Step 225295: loss = 0.07060
Step 225300: loss = 0.10927
Step 225305: loss = 0.12170
Step 225310: loss = 0.02991
Step 225315: loss = 0.06259
Step 225320: loss = 0.04773
Step 225325: loss = 0.05399
Step 225330: loss = 0.03144
Step 225335: loss = 0.12129
Step 225340: loss = 0.02698
Step 225345: loss = 0.06650
Step 225350: loss = 0.06662
Step 225355: loss = 0.06237
Step 225360: loss = 0.05531
Step 225365: loss = 0.12501
Step 225370: loss = 0.04455
Step 225375: loss = 0.09226
Step 225380: loss = 0.01974
Step 225385: loss = 0.11792
Step 225390: loss = 0.05242
Step 225395: loss = 0.04798
Step 225400: loss = 0.07763
Step 225405: loss = 0.03750
Step 225410: loss = 0.10630
Step 225415: loss = 0.10224
Step 225420: loss = 0.05088
Step 225425: loss = 0.07283
Step 225430: loss = 0.15344
Step 225435: loss = 0.03248
Step 225440: loss = 0.04085
Step 225445: loss = 0.24706
Step 225450: loss = 0.08528
Step 225455: loss = 0.18069
Step 225460: loss = 0.04903
Step 225465: loss = 0.07348
Step 225470: loss = 0.05233
Step 225475: loss = 0.05570
Step 225480: loss = 0.09660
Step 225485: loss = 0.38383
Step 225490: loss = 0.08277
Step 225495: loss = 0.18006
Step 225500: loss = 0.06625
Step 225505: loss = 0.11904
Step 225510: loss = 0.05827
Step 225515: loss = 0.08403
Step 225520: loss = 0.05203
Step 225525: loss = 0.18479
Step 225530: loss = 0.14940
Step 225535: loss = 0.06686
Step 225540: loss = 0.11424
Step 225545: loss = 0.10295
Step 225550: loss = 0.13761
Step 225555: loss = 0.20259
Step 225560: loss = 0.03349
Step 225565: loss = 0.07736
Step 225570: loss = 0.16361
Step 225575: loss = 0.10533
Step 225580: loss = 0.10032
Step 225585: loss = 0.09378
Step 225590: loss = 0.14970
Step 225595: loss = 0.05763
Step 225600: loss = 0.03741
Step 225605: loss = 0.02785
Step 225610: loss = 0.12459
Step 225615: loss = 0.03561
Step 225620: loss = 0.02596
Step 225625: loss = 0.11523
Step 225630: loss = 0.04553
Step 225635: loss = 0.03180
Step 225640: loss = 0.10652
Step 225645: loss = 0.06173
Step 225650: loss = 0.03392
Step 225655: loss = 0.09981
Step 225660: loss = 0.04152
Step 225665: loss = 0.15150
Step 225670: loss = 0.04593
Step 225675: loss = 0.06576
Step 225680: loss = 0.09747
Step 225685: loss = 0.08685
Step 225690: loss = 0.06513
Step 225695: loss = 0.14204
Step 225700: loss = 0.06365
Step 225705: loss = 0.02922
Step 225710: loss = 0.15441
Step 225715: loss = 0.03323
Step 225720: loss = 0.09572
Step 225725: loss = 0.32925
Step 225730: loss = 0.03753
Step 225735: loss = 0.12987
Step 225740: loss = 0.02256
Step 225745: loss = 0.03286
Step 225750: loss = 0.08062
Step 225755: loss = 0.06665
Step 225760: loss = 0.13772
Step 225765: loss = 0.09606
Step 225770: loss = 0.05152
Step 225775: loss = 0.05225
Step 225780: loss = 0.10922
Step 225785: loss = 0.02115
Step 225790: loss = 0.19037
Step 225795: loss = 0.23172
Step 225800: loss = 0.02968
Step 225805: loss = 0.04910
Step 225810: loss = 0.09123
Step 225815: loss = 0.12763
Step 225820: loss = 0.17168
Step 225825: loss = 0.29523
Step 225830: loss = 0.13738
Step 225835: loss = 0.06928
Step 225840: loss = 0.09080
Step 225845: loss = 0.03909
Step 225850: loss = 0.08376
Step 225855: loss = 0.04613
Step 225860: loss = 0.04802
Step 225865: loss = 0.10808
Step 225870: loss = 0.09913
Step 225875: loss = 0.18014
Step 225880: loss = 0.11714
Step 225885: loss = 0.06784
Step 225890: loss = 0.02897
Step 225895: loss = 0.15479
Step 225900: loss = 0.06983
Step 225905: loss = 0.17581
Step 225910: loss = 0.10223
Step 225915: loss = 0.10446
Step 225920: loss = 0.09658
Step 225925: loss = 0.11842
Step 225930: loss = 0.06456
Step 225935: loss = 0.04071
Step 225940: loss = 0.04691
Step 225945: loss = 0.07311
Step 225950: loss = 0.01696
Step 225955: loss = 0.17734
Step 225960: loss = 0.05115
Step 225965: loss = 0.02319
Step 225970: loss = 0.06182
Step 225975: loss = 0.16522
Step 225980: loss = 0.04195
Step 225985: loss = 0.04591
Step 225990: loss = 0.04698
Step 225995: loss = 0.05251
Step 226000: loss = 0.04630
Training Data Eval:
  Num examples: 50000, Num correct: 48378, Precision @ 1: 0.9676
('Testing Data Eval: EPOCH->', 227)
  Num examples: 10000, Num correct: 6836, Precision @ 1: 0.6836
Step 226005: loss = 0.13471
Step 226010: loss = 0.03618
Step 226015: loss = 0.05539
Step 226020: loss = 0.07150
Step 226025: loss = 0.19009
Step 226030: loss = 0.04697
Step 226035: loss = 0.16888
Step 226040: loss = 0.08461
Step 226045: loss = 0.09852
Step 226050: loss = 0.01365
Step 226055: loss = 0.05125
Step 226060: loss = 0.11998
Step 226065: loss = 0.05363
Step 226070: loss = 0.02863
Step 226075: loss = 0.08707
Step 226080: loss = 0.07322
Step 226085: loss = 0.13084
Step 226090: loss = 0.05070
Step 226095: loss = 0.16644
Step 226100: loss = 0.16772
Step 226105: loss = 0.10443
Step 226110: loss = 0.04485
Step 226115: loss = 0.07396
Step 226120: loss = 0.38299
Step 226125: loss = 0.11895
Step 226130: loss = 0.03361
Step 226135: loss = 0.05230
Step 226140: loss = 0.04883
Step 226145: loss = 0.06835
Step 226150: loss = 0.05146
Step 226155: loss = 0.15764
Step 226160: loss = 0.07172
Step 226165: loss = 0.19496
Step 226170: loss = 0.18730
Step 226175: loss = 0.05229
Step 226180: loss = 0.04186
Step 226185: loss = 0.02620
Step 226190: loss = 0.06097
Step 226195: loss = 0.16742
Step 226200: loss = 0.07177
Step 226205: loss = 0.15679
Step 226210: loss = 0.04254
Step 226215: loss = 0.02844
Step 226220: loss = 0.12300
Step 226225: loss = 0.09793
Step 226230: loss = 0.13104
Step 226235: loss = 0.03841
Step 226240: loss = 0.13752
Step 226245: loss = 0.08115
Step 226250: loss = 0.02593
Step 226255: loss = 0.07961
Step 226260: loss = 0.03148
Step 226265: loss = 0.05014
Step 226270: loss = 0.07064
Step 226275: loss = 0.11695
Step 226280: loss = 0.15392
Step 226285: loss = 0.05055
Step 226290: loss = 0.02585
Step 226295: loss = 0.07799
Step 226300: loss = 0.04425
Step 226305: loss = 0.11093
Step 226310: loss = 0.06219
Step 226315: loss = 0.06394
Step 226320: loss = 0.06856
Step 226325: loss = 0.02223
Step 226330: loss = 0.07313
Step 226335: loss = 0.04283
Step 226340: loss = 0.13076
Step 226345: loss = 0.01288
Step 226350: loss = 0.25490
Step 226355: loss = 0.09330
Step 226360: loss = 0.09132
Step 226365: loss = 0.02187
Step 226370: loss = 0.02138
Step 226375: loss = 0.05462
Step 226380: loss = 0.25683
Step 226385: loss = 0.08220
Step 226390: loss = 0.12343
Step 226395: loss = 0.17340
Step 226400: loss = 0.02359
Step 226405: loss = 0.04967
Step 226410: loss = 0.04862
Step 226415: loss = 0.13028
Step 226420: loss = 0.13190
Step 226425: loss = 0.02153
Step 226430: loss = 0.05613
Step 226435: loss = 0.06459
Step 226440: loss = 0.06304
Step 226445: loss = 0.08023
Step 226450: loss = 0.02477
Step 226455: loss = 0.05641
Step 226460: loss = 0.16396
Step 226465: loss = 0.05890
Step 226470: loss = 0.04130
Step 226475: loss = 0.07069
Step 226480: loss = 0.29887
Step 226485: loss = 0.13592
Step 226490: loss = 0.07616
Step 226495: loss = 0.25745
Step 226500: loss = 0.03547
Step 226505: loss = 0.10375
Step 226510: loss = 0.12589
Step 226515: loss = 0.02685
Step 226520: loss = 0.10643
Step 226525: loss = 0.18330
Step 226530: loss = 0.17749
Step 226535: loss = 0.09117
Step 226540: loss = 0.17833
Step 226545: loss = 0.04874
Step 226550: loss = 0.11321
Step 226555: loss = 0.08384
Step 226560: loss = 0.03926
Step 226565: loss = 0.10181
Step 226570: loss = 0.06582
Step 226575: loss = 0.20448
Step 226580: loss = 0.10486
Step 226585: loss = 0.21645
Step 226590: loss = 0.11276
Step 226595: loss = 0.06932
Step 226600: loss = 0.18427
Step 226605: loss = 0.02945
Step 226610: loss = 0.08697
Step 226615: loss = 0.07335
Step 226620: loss = 0.01281
Step 226625: loss = 0.23885
Step 226630: loss = 0.03066
Step 226635: loss = 0.22289
Step 226640: loss = 0.06017
Step 226645: loss = 0.11492
Step 226650: loss = 0.11940
Step 226655: loss = 0.29892
Step 226660: loss = 0.03418
Step 226665: loss = 0.05128
Step 226670: loss = 0.24776
Step 226675: loss = 0.17328
Step 226680: loss = 0.53917
Step 226685: loss = 0.04967
Step 226690: loss = 0.04355
Step 226695: loss = 0.28551
Step 226700: loss = 0.04070
Step 226705: loss = 0.14812
Step 226710: loss = 0.19607
Step 226715: loss = 0.06774
Step 226720: loss = 0.16605
Step 226725: loss = 0.09849
Step 226730: loss = 0.03214
Step 226735: loss = 0.28245
Step 226740: loss = 0.11232
Step 226745: loss = 0.03144
Step 226750: loss = 0.27231
Step 226755: loss = 0.03538
Step 226760: loss = 0.07990
Step 226765: loss = 0.04777
Step 226770: loss = 0.16071
Step 226775: loss = 0.04885
Step 226780: loss = 0.08218
Step 226785: loss = 0.22908
Step 226790: loss = 0.04008
Step 226795: loss = 0.01628
Step 226800: loss = 0.06194
Step 226805: loss = 0.03159
Step 226810: loss = 0.05710
Step 226815: loss = 0.12260
Step 226820: loss = 0.47010
Step 226825: loss = 0.13238
Step 226830: loss = 0.03326
Step 226835: loss = 0.09671
Step 226840: loss = 0.04026
Step 226845: loss = 0.10496
Step 226850: loss = 0.04423
Step 226855: loss = 0.05743
Step 226860: loss = 0.18341
Step 226865: loss = 0.04939
Step 226870: loss = 0.09040
Step 226875: loss = 0.04567
Step 226880: loss = 0.08890
Step 226885: loss = 0.05554
Step 226890: loss = 0.04058
Step 226895: loss = 0.05238
Step 226900: loss = 0.10453
Step 226905: loss = 0.04363
Step 226910: loss = 0.07512
Step 226915: loss = 0.12117
Step 226920: loss = 0.08292
Step 226925: loss = 0.14781
Step 226930: loss = 0.10553
Step 226935: loss = 0.02993
Step 226940: loss = 0.06237
Step 226945: loss = 0.03490
Step 226950: loss = 0.12604
Step 226955: loss = 0.10631
Step 226960: loss = 0.03066
Step 226965: loss = 0.17867
Step 226970: loss = 0.03406
Step 226975: loss = 0.03989
Step 226980: loss = 0.11581
Step 226985: loss = 0.03159
Step 226990: loss = 0.08364
Step 226995: loss = 0.03151
Step 227000: loss = 0.11830
Training Data Eval:
  Num examples: 50000, Num correct: 48308, Precision @ 1: 0.9662
('Testing Data Eval: EPOCH->', 228)
  Num examples: 10000, Num correct: 6696, Precision @ 1: 0.6696
Step 227005: loss = 0.05051
Step 227010: loss = 0.03602
Step 227015: loss = 0.02250
Step 227020: loss = 0.04778
Step 227025: loss = 0.02580
Step 227030: loss = 0.02457
Step 227035: loss = 0.13366
Step 227040: loss = 0.07749
Step 227045: loss = 0.05067
Step 227050: loss = 0.05334
Step 227055: loss = 0.17694
Step 227060: loss = 0.02500
Step 227065: loss = 0.12140
Step 227070: loss = 0.02845
Step 227075: loss = 0.04286
Step 227080: loss = 0.14857
Step 227085: loss = 0.04108
Step 227090: loss = 0.06786
Step 227095: loss = 0.04906
Step 227100: loss = 0.12994
Step 227105: loss = 0.17487
Step 227110: loss = 0.03336
Step 227115: loss = 0.03231
Step 227120: loss = 0.05412
Step 227125: loss = 0.02473
Step 227130: loss = 0.02906
Step 227135: loss = 0.02309
Step 227140: loss = 0.09624
Step 227145: loss = 0.09640
Step 227150: loss = 0.03646
Step 227155: loss = 0.08170
Step 227160: loss = 0.06316
Step 227165: loss = 0.03676
Step 227170: loss = 0.05821
Step 227175: loss = 0.10540
Step 227180: loss = 0.14435
Step 227185: loss = 0.02853
Step 227190: loss = 0.27454
Step 227195: loss = 0.01687
Step 227200: loss = 0.13769
Step 227205: loss = 0.10303
Step 227210: loss = 0.04266
Step 227215: loss = 0.06463
Step 227220: loss = 0.27919
Step 227225: loss = 0.10431
Step 227230: loss = 0.10213
Step 227235: loss = 0.14126
Step 227240: loss = 0.06113
Step 227245: loss = 0.35935
Step 227250: loss = 0.13096
Step 227255: loss = 0.04402
Step 227260: loss = 0.04674
Step 227265: loss = 0.10776
Step 227270: loss = 0.07075
Step 227275: loss = 0.39847
Step 227280: loss = 0.04530
Step 227285: loss = 0.02460
Step 227290: loss = 0.17262
Step 227295: loss = 0.25369
Step 227300: loss = 0.06905
Step 227305: loss = 0.09698
Step 227310: loss = 0.03400
Step 227315: loss = 0.04729
Step 227320: loss = 0.04357
Step 227325: loss = 0.21635
Step 227330: loss = 0.08852
Step 227335: loss = 0.13304
Step 227340: loss = 0.03495
Step 227345: loss = 0.07258
Step 227350: loss = 0.03508
Step 227355: loss = 0.04761
Step 227360: loss = 0.09548
Step 227365: loss = 0.03279
Step 227370: loss = 0.03321
Step 227375: loss = 0.08948
Step 227380: loss = 0.04518
Step 227385: loss = 0.13710
Step 227390: loss = 0.08843
Step 227395: loss = 0.04099
Step 227400: loss = 0.10127
Step 227405: loss = 0.01283
Step 227410: loss = 0.13946
Step 227415: loss = 0.13486
Step 227420: loss = 0.09225
Step 227425: loss = 0.07523
Step 227430: loss = 0.14679
Step 227435: loss = 0.15855
Step 227440: loss = 0.07701
Step 227445: loss = 0.08746
Step 227450: loss = 0.12203
Step 227455: loss = 0.05758
Step 227460: loss = 0.05443
Step 227465: loss = 0.14141
Step 227470: loss = 0.06592
Step 227475: loss = 0.10044
Step 227480: loss = 0.05784
Step 227485: loss = 0.03306
Step 227490: loss = 0.03276
Step 227495: loss = 0.11564
Step 227500: loss = 0.08612
Step 227505: loss = 0.05504
Step 227510: loss = 0.10798
Step 227515: loss = 0.13554
Step 227520: loss = 0.01834
Step 227525: loss = 0.09960
Step 227530: loss = 0.03766
Step 227535: loss = 0.05420
Step 227540: loss = 0.13025
Step 227545: loss = 0.13695
Step 227550: loss = 0.16752
Step 227555: loss = 0.03935
Step 227560: loss = 0.05230
Step 227565: loss = 0.12899
Step 227570: loss = 0.06956
Step 227575: loss = 0.15228
Step 227580: loss = 0.06547
Step 227585: loss = 0.24472
Step 227590: loss = 0.05787
Step 227595: loss = 0.14872
Step 227600: loss = 0.09884
Step 227605: loss = 0.04284
Step 227610: loss = 0.02650
Step 227615: loss = 0.06361
Step 227620: loss = 0.03245
Step 227625: loss = 0.02562
Step 227630: loss = 0.07389
Step 227635: loss = 0.03252
Step 227640: loss = 0.09865
Step 227645: loss = 0.03618
Step 227650: loss = 0.25607
Step 227655: loss = 0.06120
Step 227660: loss = 0.02779
Step 227665: loss = 0.10101
Step 227670: loss = 0.01128
Step 227675: loss = 0.04504
Step 227680: loss = 0.06278
Step 227685: loss = 0.07952
Step 227690: loss = 0.06768
Step 227695: loss = 0.08858
Step 227700: loss = 0.02506
Step 227705: loss = 0.06126
Step 227710: loss = 0.10757
Step 227715: loss = 0.08561
Step 227720: loss = 0.05746
Step 227725: loss = 0.08789
Step 227730: loss = 0.13608
Step 227735: loss = 0.11850
Step 227740: loss = 0.20614
Step 227745: loss = 0.06119
Step 227750: loss = 0.09017
Step 227755: loss = 0.06008
Step 227760: loss = 0.10887
Step 227765: loss = 0.03353
Step 227770: loss = 0.02409
Step 227775: loss = 0.17992
Step 227780: loss = 0.02783
Step 227785: loss = 0.06425
Step 227790: loss = 0.19005
Step 227795: loss = 0.10372
Step 227800: loss = 0.01885
Step 227805: loss = 0.06421
Step 227810: loss = 0.07028
Step 227815: loss = 0.05740
Step 227820: loss = 0.06329
Step 227825: loss = 0.02942
Step 227830: loss = 0.06474
Step 227835: loss = 0.08201
Step 227840: loss = 0.06785
Step 227845: loss = 0.08056
Step 227850: loss = 0.22959
Step 227855: loss = 0.01800
Step 227860: loss = 0.09119
Step 227865: loss = 0.06483
Step 227870: loss = 0.08923
Step 227875: loss = 0.04991
Step 227880: loss = 0.11019
Step 227885: loss = 0.06880
Step 227890: loss = 0.10249
Step 227895: loss = 0.04289
Step 227900: loss = 0.03475
Step 227905: loss = 0.02737
Step 227910: loss = 0.11899
Step 227915: loss = 0.03005
Step 227920: loss = 0.22257
Step 227925: loss = 0.19516
Step 227930: loss = 0.16404
Step 227935: loss = 0.13394
Step 227940: loss = 0.06970
Step 227945: loss = 0.15070
Step 227950: loss = 0.27184
Step 227955: loss = 0.06840
Step 227960: loss = 0.46114
Step 227965: loss = 0.06906
Step 227970: loss = 0.16823
Step 227975: loss = 0.04412
Step 227980: loss = 0.08417
Step 227985: loss = 0.07676
Step 227990: loss = 0.09912
Step 227995: loss = 0.03160
Step 228000: loss = 0.09149
Training Data Eval:
  Num examples: 50000, Num correct: 48484, Precision @ 1: 0.9697
('Testing Data Eval: EPOCH->', 229)
  Num examples: 10000, Num correct: 6825, Precision @ 1: 0.6825
Step 228005: loss = 0.16775
Step 228010: loss = 0.16565
Step 228015: loss = 0.20535
Step 228020: loss = 0.05853
Step 228025: loss = 0.16915
Step 228030: loss = 0.16345
Step 228035: loss = 0.34398
Step 228040: loss = 0.03346
Step 228045: loss = 0.04695
Step 228050: loss = 0.01367
Step 228055: loss = 0.04918
Step 228060: loss = 0.07042
Step 228065: loss = 0.07116
Step 228070: loss = 0.10354
Step 228075: loss = 0.02421
Step 228080: loss = 0.05522
Step 228085: loss = 0.09470
Step 228090: loss = 0.09387
Step 228095: loss = 0.09442
Step 228100: loss = 0.03813
Step 228105: loss = 0.11423
Step 228110: loss = 0.09605
Step 228115: loss = 0.07171
Step 228120: loss = 0.05169
Step 228125: loss = 0.06244
Step 228130: loss = 0.08301
Step 228135: loss = 0.03401
Step 228140: loss = 0.03937
Step 228145: loss = 0.08785
Step 228150: loss = 0.13152
Step 228155: loss = 0.04109
Step 228160: loss = 0.03300
Step 228165: loss = 0.06373
Step 228170: loss = 0.01157
Step 228175: loss = 0.14281
Step 228180: loss = 0.11657
Step 228185: loss = 0.06271
Step 228190: loss = 0.07458
Step 228195: loss = 0.03155
Step 228200: loss = 0.09300
Step 228205: loss = 0.04887
Step 228210: loss = 0.03308
Step 228215: loss = 0.06101
Step 228220: loss = 0.09573
Step 228225: loss = 0.09850
Step 228230: loss = 0.02384
Step 228235: loss = 0.03004
Step 228240: loss = 0.05656
Step 228245: loss = 0.02517
Step 228250: loss = 0.12798
Step 228255: loss = 0.15663
Step 228260: loss = 0.04793
Step 228265: loss = 0.02997
Step 228270: loss = 0.07265
Step 228275: loss = 0.12626
Step 228280: loss = 0.10324
Step 228285: loss = 0.37702
Step 228290: loss = 0.09168
Step 228295: loss = 0.15735
Step 228300: loss = 0.11191
Step 228305: loss = 0.16774
Step 228310: loss = 0.13903
Step 228315: loss = 0.05513
Step 228320: loss = 0.07802
Step 228325: loss = 0.17551
Step 228330: loss = 0.20392
Step 228335: loss = 0.11292
Step 228340: loss = 0.14417
Step 228345: loss = 0.05824
Step 228350: loss = 0.05751
Step 228355: loss = 0.05801
Step 228360: loss = 0.13444
Step 228365: loss = 0.04468
Step 228370: loss = 0.04215
Step 228375: loss = 0.25846
Step 228380: loss = 0.07152
Step 228385: loss = 0.06870
Step 228390: loss = 0.07566
Step 228395: loss = 0.11183
Step 228400: loss = 0.05567
Step 228405: loss = 0.04054
Step 228410: loss = 0.12336
Step 228415: loss = 0.05266
Step 228420: loss = 0.05072
Step 228425: loss = 0.08326
Step 228430: loss = 0.14351
Step 228435: loss = 0.06381
Step 228440: loss = 0.08578
Step 228445: loss = 0.07330
Step 228450: loss = 0.10611
Step 228455: loss = 0.14745
Step 228460: loss = 0.09065
Step 228465: loss = 0.33371
Step 228470: loss = 0.08849
Step 228475: loss = 0.05205
Step 228480: loss = 0.07734
Step 228485: loss = 0.10129
Step 228490: loss = 0.07966
Step 228495: loss = 0.06643
Step 228500: loss = 0.20691
Step 228505: loss = 0.05552
Step 228510: loss = 0.25688
Step 228515: loss = 0.03476
Step 228520: loss = 0.08915
Step 228525: loss = 0.02148
Step 228530: loss = 0.03369
Step 228535: loss = 0.09539
Step 228540: loss = 0.00927
Step 228545: loss = 0.02866
Step 228550: loss = 0.07820
Step 228555: loss = 0.07877
Step 228560: loss = 0.05247
Step 228565: loss = 0.05583
Step 228570: loss = 0.02425
Step 228575: loss = 0.04036
Step 228580: loss = 0.10577
Step 228585: loss = 0.03608
Step 228590: loss = 0.05509
Step 228595: loss = 0.07523
Step 228600: loss = 0.02942
Step 228605: loss = 0.04039
Step 228610: loss = 0.03791
Step 228615: loss = 0.14924
Step 228620: loss = 0.14560
Step 228625: loss = 0.16027
Step 228630: loss = 0.03663
Step 228635: loss = 0.09015
Step 228640: loss = 0.04079
Step 228645: loss = 0.10006
Step 228650: loss = 0.34940
Step 228655: loss = 0.18581
Step 228660: loss = 0.07009
Step 228665: loss = 0.10051
Step 228670: loss = 0.01718
Step 228675: loss = 0.06674
Step 228680: loss = 0.08727
Step 228685: loss = 0.07918
Step 228690: loss = 0.06369
Step 228695: loss = 0.34875
Step 228700: loss = 0.22452
Step 228705: loss = 0.15186
Step 228710: loss = 0.14302
Step 228715: loss = 0.16381
Step 228720: loss = 0.21366
Step 228725: loss = 0.22941
Step 228730: loss = 0.14635
Step 228735: loss = 0.03908
Step 228740: loss = 0.25245
Step 228745: loss = 0.04480
Step 228750: loss = 0.06518
Step 228755: loss = 0.04771
Step 228760: loss = 0.08304
Step 228765: loss = 0.20086
Step 228770: loss = 0.05381
Step 228775: loss = 0.03629
Step 228780: loss = 0.07063
Step 228785: loss = 0.16400
Step 228790: loss = 0.10062
Step 228795: loss = 0.11188
Step 228800: loss = 0.04399
Step 228805: loss = 0.12161
Step 228810: loss = 0.02956
Step 228815: loss = 0.13673
Step 228820: loss = 0.02480
Step 228825: loss = 0.08062
Step 228830: loss = 0.11568
Step 228835: loss = 0.05721
Step 228840: loss = 0.03250
Step 228845: loss = 0.03594
Step 228850: loss = 0.05723
Step 228855: loss = 0.39861
Step 228860: loss = 0.07729
Step 228865: loss = 0.04126
Step 228870: loss = 0.08358
Step 228875: loss = 0.08139
Step 228880: loss = 0.18447
Step 228885: loss = 0.07824
Step 228890: loss = 0.21402
Step 228895: loss = 0.08560
Step 228900: loss = 0.09989
Step 228905: loss = 0.05627
Step 228910: loss = 0.24550
Step 228915: loss = 0.08320
Step 228920: loss = 0.04774
Step 228925: loss = 0.20687
Step 228930: loss = 0.14962
Step 228935: loss = 0.08035
Step 228940: loss = 0.15022
Step 228945: loss = 0.03686
Step 228950: loss = 0.10206
Step 228955: loss = 0.02791
Step 228960: loss = 0.10301
Step 228965: loss = 0.11200
Step 228970: loss = 0.02191
Step 228975: loss = 0.25868
Step 228980: loss = 0.14430
Step 228985: loss = 0.02628
Step 228990: loss = 0.10260
Step 228995: loss = 0.16649
Step 229000: loss = 0.16168
Training Data Eval:
  Num examples: 50000, Num correct: 48397, Precision @ 1: 0.9679
('Testing Data Eval: EPOCH->', 230)
  Num examples: 10000, Num correct: 6670, Precision @ 1: 0.6670
Step 229005: loss = 0.07123
Step 229010: loss = 0.05040
Step 229015: loss = 0.09661
Step 229020: loss = 0.03767
Step 229025: loss = 0.21078
Step 229030: loss = 0.02562
Step 229035: loss = 0.07400
Step 229040: loss = 0.02190
Step 229045: loss = 0.11327
Step 229050: loss = 0.17729
Step 229055: loss = 0.04679
Step 229060: loss = 0.25013
Step 229065: loss = 0.08204
Step 229070: loss = 0.07892
Step 229075: loss = 0.10903
Step 229080: loss = 0.05990
Step 229085: loss = 0.05042
Step 229090: loss = 0.13237
Step 229095: loss = 0.16587
Step 229100: loss = 0.05004
Step 229105: loss = 0.14507
Step 229110: loss = 0.05503
Step 229115: loss = 0.07611
Step 229120: loss = 0.18596
Step 229125: loss = 0.11742
Step 229130: loss = 0.08515
Step 229135: loss = 0.05080
Step 229140: loss = 0.07799
Step 229145: loss = 0.13092
Step 229150: loss = 0.07769
Step 229155: loss = 0.03494
Step 229160: loss = 0.10758
Step 229165: loss = 0.03319
Step 229170: loss = 0.04403
Step 229175: loss = 0.04220
Step 229180: loss = 0.02369
Step 229185: loss = 0.03114
Step 229190: loss = 0.01973
Step 229195: loss = 0.09800
Step 229200: loss = 0.12644
Step 229205: loss = 0.09894
Step 229210: loss = 0.05806
Step 229215: loss = 0.06955
Step 229220: loss = 0.09230
Step 229225: loss = 0.04223
Step 229230: loss = 0.22253
Step 229235: loss = 0.03783
Step 229240: loss = 0.11300
Step 229245: loss = 0.26610
Step 229250: loss = 0.09091
Step 229255: loss = 0.05839
Step 229260: loss = 0.30063
Step 229265: loss = 0.09453
Step 229270: loss = 0.13159
Step 229275: loss = 0.10270
Step 229280: loss = 0.04499
Step 229285: loss = 0.17410
Step 229290: loss = 0.04158
Step 229295: loss = 0.04048
Step 229300: loss = 0.15895
Step 229305: loss = 0.05712
Step 229310: loss = 0.14922
Step 229315: loss = 0.05348
Step 229320: loss = 0.22522
Step 229325: loss = 0.01570
Step 229330: loss = 0.09752
Step 229335: loss = 0.03967
Step 229340: loss = 0.07111
Step 229345: loss = 0.11038
Step 229350: loss = 0.09255
Step 229355: loss = 0.11841
Step 229360: loss = 0.12164
Step 229365: loss = 0.04610
Step 229370: loss = 0.10116
Step 229375: loss = 0.06920
Step 229380: loss = 0.06266
Step 229385: loss = 0.04178
Step 229390: loss = 0.11406
Step 229395: loss = 0.11302
Step 229400: loss = 0.02173
Step 229405: loss = 0.10051
Step 229410: loss = 0.08272
Step 229415: loss = 0.02958
Step 229420: loss = 0.08427
Step 229425: loss = 0.12851
Step 229430: loss = 0.04672
Step 229435: loss = 0.02821
Step 229440: loss = 0.14971
Step 229445: loss = 0.01241
Step 229450: loss = 0.05269
Step 229455: loss = 0.15790
Step 229460: loss = 0.05479
Step 229465: loss = 0.05637
Step 229470: loss = 0.16220
Step 229475: loss = 0.09962
Step 229480: loss = 0.20472
Step 229485: loss = 0.08816
Step 229490: loss = 0.05863
Step 229495: loss = 0.14826
Step 229500: loss = 0.10092
Step 229505: loss = 0.01497
Step 229510: loss = 0.04276
Step 229515: loss = 0.10448
Step 229520: loss = 0.06399
Step 229525: loss = 0.02470
Step 229530: loss = 0.02969
Step 229535: loss = 0.04225
Step 229540: loss = 0.11091
Step 229545: loss = 0.11794
Step 229550: loss = 0.04749
Step 229555: loss = 0.04000
Step 229560: loss = 0.03736
Step 229565: loss = 0.13673
Step 229570: loss = 0.02607
Step 229575: loss = 0.05254
Step 229580: loss = 0.08733
Step 229585: loss = 0.05163
Step 229590: loss = 0.06723
Step 229595: loss = 0.02714
Step 229600: loss = 0.06290
Step 229605: loss = 0.06719
Step 229610: loss = 0.19850
Step 229615: loss = 0.10233
Step 229620: loss = 0.04677
Step 229625: loss = 0.18596
Step 229630: loss = 0.03634
Step 229635: loss = 0.06873
Step 229640: loss = 0.12294
Step 229645: loss = 0.12132
Step 229650: loss = 0.02425
Step 229655: loss = 0.19949
Step 229660: loss = 0.20597
Step 229665: loss = 0.09156
Step 229670: loss = 0.05371
Step 229675: loss = 0.04102
Step 229680: loss = 0.12658
Step 229685: loss = 0.02283
Step 229690: loss = 0.05033
Step 229695: loss = 0.08319
Step 229700: loss = 0.11737
Step 229705: loss = 0.05894
Step 229710: loss = 0.11676
Step 229715: loss = 0.17586
Step 229720: loss = 0.03791
Step 229725: loss = 0.18361
Step 229730: loss = 0.08996
Step 229735: loss = 0.25432
Step 229740: loss = 0.13455
Step 229745: loss = 0.10510
Step 229750: loss = 0.11609
Step 229755: loss = 0.16652
Step 229760: loss = 0.05609
Step 229765: loss = 0.07678
Step 229770: loss = 0.03785
Step 229775: loss = 0.19986
Step 229780: loss = 0.17551
Step 229785: loss = 0.03030
Step 229790: loss = 0.07601
Step 229795: loss = 0.09369
Step 229800: loss = 0.02170
Step 229805: loss = 0.10775
Step 229810: loss = 0.04458
Step 229815: loss = 0.06447
Step 229820: loss = 0.05257
Step 229825: loss = 0.05504
Step 229830: loss = 0.12124
Step 229835: loss = 0.05823
Step 229840: loss = 0.11028
Step 229845: loss = 0.12201
Step 229850: loss = 0.23122
Step 229855: loss = 0.03599
Step 229860: loss = 0.07139
Step 229865: loss = 0.05609
Step 229870: loss = 0.05432
Step 229875: loss = 0.14190
Step 229880: loss = 0.17277
Step 229885: loss = 0.09495
Step 229890: loss = 0.20469
Step 229895: loss = 0.07834
Step 229900: loss = 0.23721
Step 229905: loss = 0.07181
Step 229910: loss = 0.08482
Step 229915: loss = 0.17874
Step 229920: loss = 0.09774
Step 229925: loss = 0.15530
Step 229930: loss = 0.12854
Step 229935: loss = 0.02598
Step 229940: loss = 0.11683
Step 229945: loss = 0.09940
Step 229950: loss = 0.17599
Step 229955: loss = 0.16164
Step 229960: loss = 0.12831
Step 229965: loss = 0.20367
Step 229970: loss = 0.08477
Step 229975: loss = 0.13234
Step 229980: loss = 0.05564
Step 229985: loss = 0.02074
Step 229990: loss = 0.05761
Step 229995: loss = 0.11798
Step 230000: loss = 0.06033
Training Data Eval:
  Num examples: 50000, Num correct: 48354, Precision @ 1: 0.9671
('Testing Data Eval: EPOCH->', 231)
  Num examples: 10000, Num correct: 6686, Precision @ 1: 0.6686
Step 230005: loss = 0.24172
Step 230010: loss = 0.04319
Step 230015: loss = 0.20377
Step 230020: loss = 0.13658
Step 230025: loss = 0.06608
Step 230030: loss = 0.01218
Step 230035: loss = 0.02174
Step 230040: loss = 0.05981
Step 230045: loss = 0.45578
Step 230050: loss = 0.15403
Step 230055: loss = 0.14080
Step 230060: loss = 0.10753
Step 230065: loss = 0.11649
Step 230070: loss = 0.09953
Step 230075: loss = 0.04610
Step 230080: loss = 0.07964
Step 230085: loss = 0.11693
Step 230090: loss = 0.06461
Step 230095: loss = 0.05444
Step 230100: loss = 0.14544
Step 230105: loss = 0.12819
Step 230110: loss = 0.03418
Step 230115: loss = 0.07039
Step 230120: loss = 0.05867
Step 230125: loss = 0.08275
Step 230130: loss = 0.08154
Step 230135: loss = 0.21369
Step 230140: loss = 0.15168
Step 230145: loss = 0.03943
Step 230150: loss = 0.05844
Step 230155: loss = 0.21935
Step 230160: loss = 0.10541
Step 230165: loss = 0.06494
Step 230170: loss = 0.09691
Step 230175: loss = 0.02939
Step 230180: loss = 0.04489
Step 230185: loss = 0.05438
Step 230190: loss = 0.15022
Step 230195: loss = 0.03893
Step 230200: loss = 0.13306
Step 230205: loss = 0.12101
Step 230210: loss = 0.21192
Step 230215: loss = 0.03399
Step 230220: loss = 0.09766
Step 230225: loss = 0.12433
Step 230230: loss = 0.11097
Step 230235: loss = 0.24157
Step 230240: loss = 0.10159
Step 230245: loss = 0.04156
Step 230250: loss = 0.02720
Step 230255: loss = 0.02555
Step 230260: loss = 0.04956
Step 230265: loss = 0.04324
Step 230270: loss = 0.19944
Step 230275: loss = 0.09731
Step 230280: loss = 0.07275
Step 230285: loss = 0.09627
Step 230290: loss = 0.12439
Step 230295: loss = 0.12373
Step 230300: loss = 0.03262
Step 230305: loss = 0.03694
Step 230310: loss = 0.13745
Step 230315: loss = 0.06981
Step 230320: loss = 0.03426
Step 230325: loss = 0.02983
Step 230330: loss = 0.04983
Step 230335: loss = 0.05120
Step 230340: loss = 0.03800
Step 230345: loss = 0.15007
Step 230350: loss = 0.02162
Step 230355: loss = 0.18388
Step 230360: loss = 0.17417
Step 230365: loss = 0.15318
Step 230370: loss = 0.11748
Step 230375: loss = 0.06749
Step 230380: loss = 0.10198
Step 230385: loss = 0.19407
Step 230390: loss = 0.03097
Step 230395: loss = 0.38530
Step 230400: loss = 0.02351
Step 230405: loss = 0.06343
Step 230410: loss = 0.17641
Step 230415: loss = 0.10274
Step 230420: loss = 0.13304
Step 230425: loss = 0.03343
Step 230430: loss = 0.03229
Step 230435: loss = 0.11774
Step 230440: loss = 0.13477
Step 230445: loss = 0.02544
Step 230450: loss = 0.27038
Step 230455: loss = 0.04870
Step 230460: loss = 0.08977
Step 230465: loss = 0.10306
Step 230470: loss = 0.11339
Step 230475: loss = 0.08475
Step 230480: loss = 0.12425
Step 230485: loss = 0.17628
Step 230490: loss = 0.01945
Step 230495: loss = 0.07995
Step 230500: loss = 0.11796
Step 230505: loss = 0.04257
Step 230510: loss = 0.06062
Step 230515: loss = 0.01965
Step 230520: loss = 0.06632
Step 230525: loss = 0.10111
Step 230530: loss = 0.06656
Step 230535: loss = 0.10145
Step 230540: loss = 0.07606
Step 230545: loss = 0.02102
Step 230550: loss = 0.09547
Step 230555: loss = 0.03352
Step 230560: loss = 0.14075
Step 230565: loss = 0.05142
Step 230570: loss = 0.04196
Step 230575: loss = 0.10876
Step 230580: loss = 0.01465
Step 230585: loss = 0.12500
Step 230590: loss = 0.38072
Step 230595: loss = 0.11497
Step 230600: loss = 0.03608
Step 230605: loss = 0.04030
Step 230610: loss = 0.08314
Step 230615: loss = 0.04272
Step 230620: loss = 0.07591
Step 230625: loss = 0.06933
Step 230630: loss = 0.12925
Step 230635: loss = 0.05822
Step 230640: loss = 0.02245
Step 230645: loss = 0.06671
Step 230650: loss = 0.05137
Step 230655: loss = 0.05331
Step 230660: loss = 0.01318
Step 230665: loss = 0.02305
Step 230670: loss = 0.15325
Step 230675: loss = 0.05487
Step 230680: loss = 0.14907
Step 230685: loss = 0.02211
Step 230690: loss = 0.02761
Step 230695: loss = 0.13261
Step 230700: loss = 0.06260
Step 230705: loss = 0.02132
Step 230710: loss = 0.04112
Step 230715: loss = 0.25015
Step 230720: loss = 0.11450
Step 230725: loss = 0.26652
Step 230730: loss = 0.05823
Step 230735: loss = 0.09278
Step 230740: loss = 0.07487
Step 230745: loss = 0.03879
Step 230750: loss = 0.06325
Step 230755: loss = 0.08060
Step 230760: loss = 0.06013
Step 230765: loss = 0.27935
Step 230770: loss = 0.10294
Step 230775: loss = 0.06233
Step 230780: loss = 0.10661
Step 230785: loss = 0.04444
Step 230790: loss = 0.02246
Step 230795: loss = 0.02417
Step 230800: loss = 0.10006
Step 230805: loss = 0.09495
Step 230810: loss = 0.01895
Step 230815: loss = 0.15334
Step 230820: loss = 0.14755
Step 230825: loss = 0.19773
Step 230830: loss = 0.04889
Step 230835: loss = 0.29208
Step 230840: loss = 0.05427
Step 230845: loss = 0.05695
Step 230850: loss = 0.05344
Step 230855: loss = 0.02401
Step 230860: loss = 0.03702
Step 230865: loss = 0.21305
Step 230870: loss = 0.05308
Step 230875: loss = 0.15129
Step 230880: loss = 0.12361
Step 230885: loss = 0.04645
Step 230890: loss = 0.11499
Step 230895: loss = 0.15335
Step 230900: loss = 0.10250
Step 230905: loss = 0.20861
Step 230910: loss = 0.09989
Step 230915: loss = 0.01246
Step 230920: loss = 0.10451
Step 230925: loss = 0.17627
Step 230930: loss = 0.15981
Step 230935: loss = 0.12987
Step 230940: loss = 0.10108
Step 230945: loss = 0.09244
Step 230950: loss = 0.26364
Step 230955: loss = 0.09662
Step 230960: loss = 0.07776
Step 230965: loss = 0.15114
Step 230970: loss = 0.34514
Step 230975: loss = 0.26302
Step 230980: loss = 0.02869
Step 230985: loss = 0.11324
Step 230990: loss = 0.07685
Step 230995: loss = 0.07253
Step 231000: loss = 0.10661
Training Data Eval:
  Num examples: 50000, Num correct: 48289, Precision @ 1: 0.9658
('Testing Data Eval: EPOCH->', 232)
  Num examples: 10000, Num correct: 6842, Precision @ 1: 0.6842
Step 231005: loss = 0.03415
Step 231010: loss = 0.11121
Step 231015: loss = 0.20936
Step 231020: loss = 0.16882
Step 231025: loss = 0.04543
Step 231030: loss = 0.03927
Step 231035: loss = 0.08097
Step 231040: loss = 0.03617
Step 231045: loss = 0.06984
Step 231050: loss = 0.11109
Step 231055: loss = 0.09352
Step 231060: loss = 0.07510
Step 231065: loss = 0.05029
Step 231070: loss = 0.11845
Step 231075: loss = 0.10106
Step 231080: loss = 0.20751
Step 231085: loss = 0.04705
Step 231090: loss = 0.08457
Step 231095: loss = 0.03571
Step 231100: loss = 0.37334
Step 231105: loss = 0.01646
Step 231110: loss = 0.06413
Step 231115: loss = 0.10803
Step 231120: loss = 0.13987
Step 231125: loss = 0.02458
Step 231130: loss = 0.04887
Step 231135: loss = 0.08249
Step 231140: loss = 0.05979
Step 231145: loss = 0.28377
Step 231150: loss = 0.16803
Step 231155: loss = 0.11816
Step 231160: loss = 0.10428
Step 231165: loss = 0.08334
Step 231170: loss = 0.16467
Step 231175: loss = 0.04748
Step 231180: loss = 0.07522
Step 231185: loss = 0.13439
Step 231190: loss = 0.07181
Step 231195: loss = 0.17191
Step 231200: loss = 0.07602
Step 231205: loss = 0.16445
Step 231210: loss = 0.09357
Step 231215: loss = 0.08898
Step 231220: loss = 0.02165
Step 231225: loss = 0.10920
Step 231230: loss = 0.04001
Step 231235: loss = 0.05148
Step 231240: loss = 0.03571
Step 231245: loss = 0.09356
Step 231250: loss = 0.12589
Step 231255: loss = 0.05972
Step 231260: loss = 0.01009
Step 231265: loss = 0.03430
Step 231270: loss = 0.12924
Step 231275: loss = 0.02877
Step 231280: loss = 0.05393
Step 231285: loss = 0.01795
Step 231290: loss = 0.15366
Step 231295: loss = 0.17054
Step 231300: loss = 0.04505
Step 231305: loss = 0.08434
Step 231310: loss = 0.09726
Step 231315: loss = 0.13117
Step 231320: loss = 0.06824
Step 231325: loss = 0.04877
Step 231330: loss = 0.02533
Step 231335: loss = 0.07472
Step 231340: loss = 0.05234
Step 231345: loss = 0.06446
Step 231350: loss = 0.17044
Step 231355: loss = 0.03904
Step 231360: loss = 0.04325
Step 231365: loss = 0.08035
Step 231370: loss = 0.04337
Step 231375: loss = 0.07725
Step 231380: loss = 0.06323
Step 231385: loss = 0.14633
Step 231390: loss = 0.04397
Step 231395: loss = 0.07226
Step 231400: loss = 0.13810
Step 231405: loss = 0.03205
Step 231410: loss = 0.03084
Step 231415: loss = 0.06816
Step 231420: loss = 0.01632
Step 231425: loss = 0.04312
Step 231430: loss = 0.25327
Step 231435: loss = 0.02989
Step 231440: loss = 0.02547
Step 231445: loss = 0.13438
Step 231450: loss = 0.03173
Step 231455: loss = 0.08659
Step 231460: loss = 0.04840
Step 231465: loss = 0.13142
Step 231470: loss = 0.26355
Step 231475: loss = 0.08567
Step 231480: loss = 0.15250
Step 231485: loss = 0.07429
Step 231490: loss = 0.23723
Step 231495: loss = 0.26324
Step 231500: loss = 0.03948
Step 231505: loss = 0.03634
Step 231510: loss = 0.16926
Step 231515: loss = 0.08446
Step 231520: loss = 0.25140
Step 231525: loss = 0.04416
Step 231530: loss = 0.10810
Step 231535: loss = 0.10562
Step 231540: loss = 0.04439
Step 231545: loss = 0.04354
Step 231550: loss = 0.01792
Step 231555: loss = 0.09073
Step 231560: loss = 0.12270
Step 231565: loss = 0.04044
Step 231570: loss = 0.12084
Step 231575: loss = 0.04322
Step 231580: loss = 0.15257
Step 231585: loss = 0.01803
Step 231590: loss = 0.05566
Step 231595: loss = 0.01383
Step 231600: loss = 0.05495
Step 231605: loss = 0.07465
Step 231610: loss = 0.09590
Step 231615: loss = 0.08547
Step 231620: loss = 0.04671
Step 231625: loss = 0.05591
Step 231630: loss = 0.07228
Step 231635: loss = 0.12291
Step 231640: loss = 0.14419
Step 231645: loss = 0.05157
Step 231650: loss = 0.07156
Step 231655: loss = 0.08088
Step 231660: loss = 0.08356
Step 231665: loss = 0.16625
Step 231670: loss = 0.15857
Step 231675: loss = 0.06151
Step 231680: loss = 0.12649
Step 231685: loss = 0.01660
Step 231690: loss = 0.14902
Step 231695: loss = 0.03311
Step 231700: loss = 0.31903
Step 231705: loss = 0.01209
Step 231710: loss = 0.09800
Step 231715: loss = 0.19758
Step 231720: loss = 0.06281
Step 231725: loss = 0.01993
Step 231730: loss = 0.06456
Step 231735: loss = 0.09856
Step 231740: loss = 0.02422
Step 231745: loss = 0.01717
Step 231750: loss = 0.10716
Step 231755: loss = 0.06248
Step 231760: loss = 0.15199
Step 231765: loss = 0.09210
Step 231770: loss = 0.04020
Step 231775: loss = 0.09746
Step 231780: loss = 0.07768
Step 231785: loss = 0.06923
Step 231790: loss = 0.12061
Step 231795: loss = 0.08065
Step 231800: loss = 0.10489
Step 231805: loss = 0.03032
Step 231810: loss = 0.09416
Step 231815: loss = 0.02117
Step 231820: loss = 0.03352
Step 231825: loss = 0.14918
Step 231830: loss = 0.11167
Step 231835: loss = 0.08041
Step 231840: loss = 0.17833
Step 231845: loss = 0.03500
Step 231850: loss = 0.07894
Step 231855: loss = 0.10907
Step 231860: loss = 0.14072
Step 231865: loss = 0.02507
Step 231870: loss = 0.02750
Step 231875: loss = 0.10596
Step 231880: loss = 0.06619
Step 231885: loss = 0.02947
Step 231890: loss = 0.18198
Step 231895: loss = 0.07169
Step 231900: loss = 0.13340
Step 231905: loss = 0.02640
Step 231910: loss = 0.04218
Step 231915: loss = 0.41900
Step 231920: loss = 0.04857
Step 231925: loss = 0.16092
Step 231930: loss = 0.13954
Step 231935: loss = 0.21866
Step 231940: loss = 0.14122
Step 231945: loss = 0.07571
Step 231950: loss = 0.09995
Step 231955: loss = 0.11752
Step 231960: loss = 0.06847
Step 231965: loss = 0.28997
Step 231970: loss = 0.07346
Step 231975: loss = 0.03528
Step 231980: loss = 0.19524
Step 231985: loss = 0.01252
Step 231990: loss = 0.05123
Step 231995: loss = 0.02758
Step 232000: loss = 0.04445
Training Data Eval:
  Num examples: 50000, Num correct: 48457, Precision @ 1: 0.9691
('Testing Data Eval: EPOCH->', 233)
  Num examples: 10000, Num correct: 6670, Precision @ 1: 0.6670
Step 232005: loss = 0.04512
Step 232010: loss = 0.08350
Step 232015: loss = 0.04840
Step 232020: loss = 0.16868
Step 232025: loss = 0.20824
Step 232030: loss = 0.15270
Step 232035: loss = 0.10057
Step 232040: loss = 0.12221
Step 232045: loss = 0.08116
Step 232050: loss = 0.23222
Step 232055: loss = 0.05374
Step 232060: loss = 0.08440
Step 232065: loss = 0.07882
Step 232070: loss = 0.24594
Step 232075: loss = 0.02857
Step 232080: loss = 0.07862
Step 232085: loss = 0.10364
Step 232090: loss = 0.13632
Step 232095: loss = 0.07530
Step 232100: loss = 0.11247
Step 232105: loss = 0.14367
Step 232110: loss = 0.16013
Step 232115: loss = 0.21850
Step 232120: loss = 0.12598
Step 232125: loss = 0.04280
Step 232130: loss = 0.09536
Step 232135: loss = 0.04451
Step 232140: loss = 0.02867
Step 232145: loss = 0.05697
Step 232150: loss = 0.04638
Step 232155: loss = 0.23234
Step 232160: loss = 0.38051
Step 232165: loss = 0.09378
Step 232170: loss = 0.08609
Step 232175: loss = 0.11366
Step 232180: loss = 0.06141
Step 232185: loss = 0.07289
Step 232190: loss = 0.05228
Step 232195: loss = 0.01524
Step 232200: loss = 0.26828
Step 232205: loss = 0.04765
Step 232210: loss = 0.03974
Step 232215: loss = 0.10165
Step 232220: loss = 0.05898
Step 232225: loss = 0.05322
Step 232230: loss = 0.05355
Step 232235: loss = 0.08160
Step 232240: loss = 0.01886
Step 232245: loss = 0.07712
Step 232250: loss = 0.11658
Step 232255: loss = 0.12865
Step 232260: loss = 0.00543
Step 232265: loss = 0.05457
Step 232270: loss = 0.02361
Step 232275: loss = 0.05134
Step 232280: loss = 0.02577
Step 232285: loss = 0.06806
Step 232290: loss = 0.05537
Step 232295: loss = 0.03589
Step 232300: loss = 0.04360
Step 232305: loss = 0.03183
Step 232310: loss = 0.01729
Step 232315: loss = 0.10719
Step 232320: loss = 0.03977
Step 232325: loss = 0.04688
Step 232330: loss = 0.10694
Step 232335: loss = 0.03875
Step 232340: loss = 0.03179
Step 232345: loss = 0.23906
Step 232350: loss = 0.02041
Step 232355: loss = 0.04649
Step 232360: loss = 0.05673
Step 232365: loss = 0.19093
Step 232370: loss = 0.23441
Step 232375: loss = 0.06473
Step 232380: loss = 0.05259
Step 232385: loss = 0.20479
Step 232390: loss = 0.17663
Step 232395: loss = 0.15091
Step 232400: loss = 0.12967
Step 232405: loss = 0.03544
Step 232410: loss = 0.07783
Step 232415: loss = 0.06255
Step 232420: loss = 0.06373
Step 232425: loss = 0.07729
Step 232430: loss = 0.22666
Step 232435: loss = 0.10953
Step 232440: loss = 0.04457
Step 232445: loss = 0.08873
Step 232450: loss = 0.11119
Step 232455: loss = 0.03172
Step 232460: loss = 0.12507
Step 232465: loss = 0.03328
Step 232470: loss = 0.03356
Step 232475: loss = 0.14295
Step 232480: loss = 0.10824
Step 232485: loss = 0.11311
Step 232490: loss = 0.03390
Step 232495: loss = 0.01875
Step 232500: loss = 0.07581
Step 232505: loss = 0.12736
Step 232510: loss = 0.03669
Step 232515: loss = 0.04134
Step 232520: loss = 0.06458
Step 232525: loss = 0.16484
Step 232530: loss = 0.05840
Step 232535: loss = 0.11326
Step 232540: loss = 0.07531
Step 232545: loss = 0.05646
Step 232550: loss = 0.08008
Step 232555: loss = 0.05781
Step 232560: loss = 0.21855
Step 232565: loss = 0.05143
Step 232570: loss = 0.06738
Step 232575: loss = 0.02268
Step 232580: loss = 0.04994
Step 232585: loss = 0.02989
Step 232590: loss = 0.23632
Step 232595: loss = 0.04967
Step 232600: loss = 0.08463
Step 232605: loss = 0.04694
Step 232610: loss = 0.10584
Step 232615: loss = 0.04005
Step 232620: loss = 0.02057
Step 232625: loss = 0.03497
Step 232630: loss = 0.08981
Step 232635: loss = 0.12463
Step 232640: loss = 0.06296
Step 232645: loss = 0.05187
Step 232650: loss = 0.17688
Step 232655: loss = 0.01798
Step 232660: loss = 0.31061
Step 232665: loss = 0.12348
Step 232670: loss = 0.09386
Step 232675: loss = 0.08404
Step 232680: loss = 0.06717
Step 232685: loss = 0.13343
Step 232690: loss = 0.08840
Step 232695: loss = 0.05127
Step 232700: loss = 0.03542
Step 232705: loss = 0.24815
Step 232710: loss = 0.31649
Step 232715: loss = 0.05207
Step 232720: loss = 0.02934
Step 232725: loss = 0.04079
Step 232730: loss = 0.08648
Step 232735: loss = 0.03698
Step 232740: loss = 0.08779
Step 232745: loss = 0.09319
Step 232750: loss = 0.10190
Step 232755: loss = 0.10786
Step 232760: loss = 0.14818
Step 232765: loss = 0.16888
Step 232770: loss = 0.11563
Step 232775: loss = 0.04506
Step 232780: loss = 0.06777
Step 232785: loss = 0.09615
Step 232790: loss = 0.07923
Step 232795: loss = 0.06138
Step 232800: loss = 0.26557
Step 232805: loss = 0.10637
Step 232810: loss = 0.15768
Step 232815: loss = 0.04567
Step 232820: loss = 0.05547
Step 232825: loss = 0.10281
Step 232830: loss = 0.13765
Step 232835: loss = 0.06909
Step 232840: loss = 0.07258
Step 232845: loss = 0.06518
Step 232850: loss = 0.27869
Step 232855: loss = 0.10402
Step 232860: loss = 0.02240
Step 232865: loss = 0.02546
Step 232870: loss = 0.04793
Step 232875: loss = 0.02892
Step 232880: loss = 0.21175
Step 232885: loss = 0.08179
Step 232890: loss = 0.13942
Step 232895: loss = 0.07445
Step 232900: loss = 0.04005
Step 232905: loss = 0.13597
Step 232910: loss = 0.09986
Step 232915: loss = 0.04028
Step 232920: loss = 0.03488
Step 232925: loss = 0.04293
Step 232930: loss = 0.03814
Step 232935: loss = 0.15381
Step 232940: loss = 0.06328
Step 232945: loss = 0.07902
Step 232950: loss = 0.22890
Step 232955: loss = 0.07400
Step 232960: loss = 0.25235
Step 232965: loss = 0.24099
Step 232970: loss = 0.14698
Step 232975: loss = 0.10516
Step 232980: loss = 0.16697
Step 232985: loss = 0.21752
Step 232990: loss = 0.05654
Step 232995: loss = 0.09376
Step 233000: loss = 0.02845
Training Data Eval:
  Num examples: 50000, Num correct: 48267, Precision @ 1: 0.9653
('Testing Data Eval: EPOCH->', 234)
  Num examples: 10000, Num correct: 6669, Precision @ 1: 0.6669
Step 233005: loss = 0.08117
Step 233010: loss = 0.11204
Step 233015: loss = 0.08867
Step 233020: loss = 0.01912
Step 233025: loss = 0.19629
Step 233030: loss = 0.12949
Step 233035: loss = 0.03423
Step 233040: loss = 0.12435
Step 233045: loss = 0.06354
Step 233050: loss = 0.12990
Step 233055: loss = 0.02499
Step 233060: loss = 0.14881
Step 233065: loss = 0.02540
Step 233070: loss = 0.06877
Step 233075: loss = 0.02782
Step 233080: loss = 0.01547
Step 233085: loss = 0.19321
Step 233090: loss = 0.10826
Step 233095: loss = 0.05790
Step 233100: loss = 0.29775
Step 233105: loss = 0.10676
Step 233110: loss = 0.03670
Step 233115: loss = 0.03737
Step 233120: loss = 0.07086
Step 233125: loss = 0.09788
Step 233130: loss = 0.27522
Step 233135: loss = 0.10563
Step 233140: loss = 0.06102
Step 233145: loss = 0.17454
Step 233150: loss = 0.04890
Step 233155: loss = 0.05982
Step 233160: loss = 0.18001
Step 233165: loss = 0.05484
Step 233170: loss = 0.05252
Step 233175: loss = 0.09686
Step 233180: loss = 0.00811
Step 233185: loss = 0.03071
Step 233190: loss = 0.11126
Step 233195: loss = 0.02829
Step 233200: loss = 0.30102
Step 233205: loss = 0.05936
Step 233210: loss = 0.20177
Step 233215: loss = 0.03801
Step 233220: loss = 0.08302
Step 233225: loss = 0.07015
Step 233230: loss = 0.22532
Step 233235: loss = 0.02772
Step 233240: loss = 0.01834
Step 233245: loss = 0.08036
Step 233250: loss = 0.19540
Step 233255: loss = 0.01298
Step 233260: loss = 0.19140
Step 233265: loss = 0.05302
Step 233270: loss = 0.03665
Step 233275: loss = 0.11515
Step 233280: loss = 0.10820
Step 233285: loss = 0.17364
Step 233290: loss = 0.03815
Step 233295: loss = 0.22076
Step 233300: loss = 0.06682
Step 233305: loss = 0.21921
Step 233310: loss = 0.05887
Step 233315: loss = 0.18159
Step 233320: loss = 0.03913
Step 233325: loss = 0.04804
Step 233330: loss = 0.11341
Step 233335: loss = 0.11001
Step 233340: loss = 0.14835
Step 233345: loss = 0.04792
Step 233350: loss = 0.01320
Step 233355: loss = 0.20487
Step 233360: loss = 0.10110
Step 233365: loss = 0.04743
Step 233370: loss = 0.13051
Step 233375: loss = 0.13357
Step 233380: loss = 0.03444
Step 233385: loss = 0.09567
Step 233390: loss = 0.06084
Step 233395: loss = 0.07033
Step 233400: loss = 0.02746
Step 233405: loss = 0.08209
Step 233410: loss = 0.11420
Step 233415: loss = 0.17939
Step 233420: loss = 0.22033
Step 233425: loss = 0.04788
Step 233430: loss = 0.07485
Step 233435: loss = 0.09330
Step 233440: loss = 0.15983
Step 233445: loss = 0.09804
Step 233450: loss = 0.05871
Step 233455: loss = 0.04590
Step 233460: loss = 0.04492
Step 233465: loss = 0.04783
Step 233470: loss = 0.28211
Step 233475: loss = 0.04842
Step 233480: loss = 0.01499
Step 233485: loss = 0.01917
Step 233490: loss = 0.16673
Step 233495: loss = 0.14781
Step 233500: loss = 0.06141
Step 233505: loss = 0.02535
Step 233510: loss = 0.04414
Step 233515: loss = 0.15856
Step 233520: loss = 0.12242
Step 233525: loss = 0.06892
Step 233530: loss = 0.06031
Step 233535: loss = 0.12926
Step 233540: loss = 0.00866
Step 233545: loss = 0.19190
Step 233550: loss = 0.11432
Step 233555: loss = 0.01360
Step 233560: loss = 0.29500
Step 233565: loss = 0.05901
Step 233570: loss = 0.15329
Step 233575: loss = 0.10476
Step 233580: loss = 0.04674
Step 233585: loss = 0.04192
Step 233590: loss = 0.10702
Step 233595: loss = 0.15202
Step 233600: loss = 0.04412
Step 233605: loss = 0.05978
Step 233610: loss = 0.03581
Step 233615: loss = 0.06497
Step 233620: loss = 0.04045
Step 233625: loss = 0.12243
Step 233630: loss = 0.06959
Step 233635: loss = 0.01472
Step 233640: loss = 0.07240
Step 233645: loss = 0.06637
Step 233650: loss = 0.11489
Step 233655: loss = 0.09256
Step 233660: loss = 0.14539
Step 233665: loss = 0.24086
Step 233670: loss = 0.22430
Step 233675: loss = 0.02901
Step 233680: loss = 0.07221
Step 233685: loss = 0.21636
Step 233690: loss = 0.08529
Step 233695: loss = 0.05227
Step 233700: loss = 0.08109
Step 233705: loss = 0.10404
Step 233710: loss = 0.03813
Step 233715: loss = 0.01981
Step 233720: loss = 0.07254
Step 233725: loss = 0.09036
Step 233730: loss = 0.10682
Step 233735: loss = 0.10363
Step 233740: loss = 0.15583
Step 233745: loss = 0.06908
Step 233750: loss = 0.05873
Step 233755: loss = 0.11034
Step 233760: loss = 0.04273
Step 233765: loss = 0.15620
Step 233770: loss = 0.03213
Step 233775: loss = 0.15886
Step 233780: loss = 0.18020
Step 233785: loss = 0.20383
Step 233790: loss = 0.06098
Step 233795: loss = 0.07333
Step 233800: loss = 0.13868
Step 233805: loss = 0.09922
Step 233810: loss = 0.03353
Step 233815: loss = 0.05405
Step 233820: loss = 0.07218
Step 233825: loss = 0.21898
Step 233830: loss = 0.07424
Step 233835: loss = 0.03039
Step 233840: loss = 0.06006
Step 233845: loss = 0.10784
Step 233850: loss = 0.06663
Step 233855: loss = 0.01797
Step 233860: loss = 0.04162
Step 233865: loss = 0.02984
Step 233870: loss = 0.13453
Step 233875: loss = 0.04838
Step 233880: loss = 0.14549
Step 233885: loss = 0.04472
Step 233890: loss = 0.12928
Step 233895: loss = 0.13710
Step 233900: loss = 0.18834
Step 233905: loss = 0.03743
Step 233910: loss = 0.04229
Step 233915: loss = 0.05469
Step 233920: loss = 0.08457
Step 233925: loss = 0.02543
Step 233930: loss = 0.20354
Step 233935: loss = 0.15410
Step 233940: loss = 0.04621
Step 233945: loss = 0.07910
Step 233950: loss = 0.09014
Step 233955: loss = 0.08414
Step 233960: loss = 0.05691
Step 233965: loss = 0.03944
Step 233970: loss = 0.08971
Step 233975: loss = 0.03231
Step 233980: loss = 0.06696
Step 233985: loss = 0.28489
Step 233990: loss = 0.13761
Step 233995: loss = 0.09705
Step 234000: loss = 0.06807
Training Data Eval:
  Num examples: 50000, Num correct: 48162, Precision @ 1: 0.9632
('Testing Data Eval: EPOCH->', 235)
  Num examples: 10000, Num correct: 6644, Precision @ 1: 0.6644
Step 234005: loss = 0.03504
Step 234010: loss = 0.06082
Step 234015: loss = 0.07347
Step 234020: loss = 0.03083
Step 234025: loss = 0.26830
Step 234030: loss = 0.09491
Step 234035: loss = 0.08571
Step 234040: loss = 0.07526
Step 234045: loss = 0.13287
Step 234050: loss = 0.07563
Step 234055: loss = 0.16044
Step 234060: loss = 0.04748
Step 234065: loss = 0.15219
Step 234070: loss = 0.06683
Step 234075: loss = 0.23511
Step 234080: loss = 0.01100
Step 234085: loss = 0.07250
Step 234090: loss = 0.19693
Step 234095: loss = 0.28932
Step 234100: loss = 0.03689
Step 234105: loss = 0.08975
Step 234110: loss = 0.07711
Step 234115: loss = 0.05865
Step 234120: loss = 0.27488
Step 234125: loss = 0.05896
Step 234130: loss = 0.09954
Step 234135: loss = 0.06101
Step 234140: loss = 0.05958
Step 234145: loss = 0.09605
Step 234150: loss = 0.05532
Step 234155: loss = 0.17177
Step 234160: loss = 0.05657
Step 234165: loss = 0.08033
Step 234170: loss = 0.12836
Step 234175: loss = 0.05756
Step 234180: loss = 0.10074
Step 234185: loss = 0.05382
Step 234190: loss = 0.03340
Step 234195: loss = 0.05900
Step 234200: loss = 0.05656
Step 234205: loss = 0.07591
Step 234210: loss = 0.07929
Step 234215: loss = 0.02984
Step 234220: loss = 0.08204
Step 234225: loss = 0.05237
Step 234230: loss = 0.12394
Step 234235: loss = 0.28825
Step 234240: loss = 0.01516
Step 234245: loss = 0.20798
Step 234250: loss = 0.12688
Step 234255: loss = 0.07206
Step 234260: loss = 0.08069
Step 234265: loss = 0.05394
Step 234270: loss = 0.06216
Step 234275: loss = 0.09951
Step 234280: loss = 0.10478
Step 234285: loss = 0.04980
Step 234290: loss = 0.06874
Step 234295: loss = 0.09920
Step 234300: loss = 0.06621
Step 234305: loss = 0.19496
Step 234310: loss = 0.12636
Step 234315: loss = 0.06250
Step 234320: loss = 0.08551
Step 234325: loss = 0.03780
Step 234330: loss = 0.04154
Step 234335: loss = 0.15857
Step 234340: loss = 0.02369
Step 234345: loss = 0.17673
Step 234350: loss = 0.13593
Step 234355: loss = 0.30594
Step 234360: loss = 0.11616
Step 234365: loss = 0.05137
Step 234370: loss = 0.08632
Step 234375: loss = 0.02511
Step 234380: loss = 0.04787
Step 234385: loss = 0.03730
Step 234390: loss = 0.11438
Step 234395: loss = 0.04420
Step 234400: loss = 0.04024
Step 234405: loss = 0.04457
Step 234410: loss = 0.16412
Step 234415: loss = 0.05723
Step 234420: loss = 0.04140
Step 234425: loss = 0.12492
Step 234430: loss = 0.05484
Step 234435: loss = 0.06196
Step 234440: loss = 0.03075
Step 234445: loss = 0.06306
Step 234450: loss = 0.03977
Step 234455: loss = 0.05076
Step 234460: loss = 0.02366
Step 234465: loss = 0.13442
Step 234470: loss = 0.10262
Step 234475: loss = 0.13986
Step 234480: loss = 0.03749
Step 234485: loss = 0.11307
Step 234490: loss = 0.34659
Step 234495: loss = 0.11071
Step 234500: loss = 0.07804
Step 234505: loss = 0.12568
Step 234510: loss = 0.26902
Step 234515: loss = 0.18009
Step 234520: loss = 0.11586
Step 234525: loss = 0.10690
Step 234530: loss = 0.03373
Step 234535: loss = 0.05873
Step 234540: loss = 0.04503
Step 234545: loss = 0.04731
Step 234550: loss = 0.12377
Step 234555: loss = 0.02477
Step 234560: loss = 0.11399
Step 234565: loss = 0.05943
Step 234570: loss = 0.05840
Step 234575: loss = 0.23814
Step 234580: loss = 0.01702
Step 234585: loss = 0.05208
Step 234590: loss = 0.09716
Step 234595: loss = 0.10049
Step 234600: loss = 0.13523
Step 234605: loss = 0.07848
Step 234610: loss = 0.16377
Step 234615: loss = 0.05686
Step 234620: loss = 0.01609
Step 234625: loss = 0.06944
Step 234630: loss = 0.11343
Step 234635: loss = 0.04944
Step 234640: loss = 0.04195
Step 234645: loss = 0.08845
Step 234650: loss = 0.04502
Step 234655: loss = 0.09192
Step 234660: loss = 0.23291
Step 234665: loss = 0.26249
Step 234670: loss = 0.18576
Step 234675: loss = 0.08200
Step 234680: loss = 0.12043
Step 234685: loss = 0.08611
Step 234690: loss = 0.22324
Step 234695: loss = 0.07391
Step 234700: loss = 0.04630
Step 234705: loss = 0.05584
Step 234710: loss = 0.03158
Step 234715: loss = 0.01836
Step 234720: loss = 0.07335
Step 234725: loss = 0.04669
Step 234730: loss = 0.19546
Step 234735: loss = 0.02709
Step 234740: loss = 0.06161
Step 234745: loss = 0.20160
Step 234750: loss = 0.25998
Step 234755: loss = 0.10154
Step 234760: loss = 0.10809
Step 234765: loss = 0.09981
Step 234770: loss = 0.02622
Step 234775: loss = 0.11368
Step 234780: loss = 0.13606
Step 234785: loss = 0.08794
Step 234790: loss = 0.10333
Step 234795: loss = 0.03827
Step 234800: loss = 0.07797
Step 234805: loss = 0.08776
Step 234810: loss = 0.03707
Step 234815: loss = 0.03523
Step 234820: loss = 0.01764
Step 234825: loss = 0.12342
Step 234830: loss = 0.15212
Step 234835: loss = 0.13347
Step 234840: loss = 0.01757
Step 234845: loss = 0.10441
Step 234850: loss = 0.06905
Step 234855: loss = 0.02439
Step 234860: loss = 0.05399
Step 234865: loss = 0.05704
Step 234870: loss = 0.07939
Step 234875: loss = 0.04683
Step 234880: loss = 0.08270
Step 234885: loss = 0.04395
Step 234890: loss = 0.12572
Step 234895: loss = 0.06896
Step 234900: loss = 0.03509
Step 234905: loss = 0.08248
Step 234910: loss = 0.08454
Step 234915: loss = 0.13394
Step 234920: loss = 0.18028
Step 234925: loss = 0.09000
Step 234930: loss = 0.15120
Step 234935: loss = 0.05977
Step 234940: loss = 0.73502
Step 234945: loss = 0.07659
Step 234950: loss = 0.11139
Step 234955: loss = 0.07732
Step 234960: loss = 0.03132
Step 234965: loss = 0.05927
Step 234970: loss = 0.29046
Step 234975: loss = 0.04976
Step 234980: loss = 0.08868
Step 234985: loss = 0.05641
Step 234990: loss = 0.03992
Step 234995: loss = 0.08814
Step 235000: loss = 0.05796
Training Data Eval:
  Num examples: 50000, Num correct: 48224, Precision @ 1: 0.9645
('Testing Data Eval: EPOCH->', 236)
  Num examples: 10000, Num correct: 6747, Precision @ 1: 0.6747
Step 235005: loss = 0.12765
Step 235010: loss = 0.04085
Step 235015: loss = 0.25164
Step 235020: loss = 0.05609
Step 235025: loss = 0.06097
Step 235030: loss = 0.10395
Step 235035: loss = 0.04739
Step 235040: loss = 0.13893
Step 235045: loss = 0.05570
Step 235050: loss = 0.05087
Step 235055: loss = 0.25058
Step 235060: loss = 0.12840
Step 235065: loss = 0.13914
Step 235070: loss = 0.03745
Step 235075: loss = 0.07141
Step 235080: loss = 0.07493
Step 235085: loss = 0.11761
Step 235090: loss = 0.01420
Step 235095: loss = 0.02483
Step 235100: loss = 0.09178
Step 235105: loss = 0.08946
Step 235110: loss = 0.05468
Step 235115: loss = 0.24508
Step 235120: loss = 0.05897
Step 235125: loss = 0.01237
Step 235130: loss = 0.08735
Step 235135: loss = 0.06687
Step 235140: loss = 0.02523
Step 235145: loss = 0.12829
Step 235150: loss = 0.05870
Step 235155: loss = 0.09735
Step 235160: loss = 0.08097
Step 235165: loss = 0.05410
Step 235170: loss = 0.07457
Step 235175: loss = 0.01212
Step 235180: loss = 0.17211
Step 235185: loss = 0.01961
Step 235190: loss = 0.03588
Step 235195: loss = 0.11437
Step 235200: loss = 0.08339
Step 235205: loss = 0.19928
Step 235210: loss = 0.07089
Step 235215: loss = 0.06470
Step 235220: loss = 0.03044
Step 235225: loss = 0.31334
Step 235230: loss = 0.07096
Step 235235: loss = 0.06790
Step 235240: loss = 0.06280
Step 235245: loss = 0.18560
Step 235250: loss = 0.06977
Step 235255: loss = 0.10627
Step 235260: loss = 0.09427
Step 235265: loss = 0.11368
Step 235270: loss = 0.05428
Step 235275: loss = 0.36015
Step 235280: loss = 0.03039
Step 235285: loss = 0.09456
Step 235290: loss = 0.05533
Step 235295: loss = 0.16564
Step 235300: loss = 0.13776
Step 235305: loss = 0.04736
Step 235310: loss = 0.20222
Step 235315: loss = 0.06255
Step 235320: loss = 0.08672
Step 235325: loss = 0.09988
Step 235330: loss = 0.13870
Step 235335: loss = 0.03292
Step 235340: loss = 0.07853
Step 235345: loss = 0.02180
Step 235350: loss = 0.18606
Step 235355: loss = 0.09266
Step 235360: loss = 0.07104
Step 235365: loss = 0.04180
Step 235370: loss = 0.09756
Step 235375: loss = 0.13770
Step 235380: loss = 0.02673
Step 235385: loss = 0.06914
Step 235390: loss = 0.03168
Step 235395: loss = 0.08282
Step 235400: loss = 0.10535
Step 235405: loss = 0.04955
Step 235410: loss = 0.01693
Step 235415: loss = 0.09520
Step 235420: loss = 0.08202
Step 235425: loss = 0.03682
Step 235430: loss = 0.16860
Step 235435: loss = 0.02532
Step 235440: loss = 0.07909
Step 235445: loss = 0.03775
Step 235450: loss = 0.05558
Step 235455: loss = 0.20808
Step 235460: loss = 0.05371
Step 235465: loss = 0.07375
Step 235470: loss = 0.10399
Step 235475: loss = 0.02569
Step 235480: loss = 0.04500
Step 235485: loss = 0.12893
Step 235490: loss = 0.15866
Step 235495: loss = 0.02162
Step 235500: loss = 0.04070
Step 235505: loss = 0.20930
Step 235510: loss = 0.06822
Step 235515: loss = 0.16212
Step 235520: loss = 0.09197
Step 235525: loss = 0.06907
Step 235530: loss = 0.04673
Step 235535: loss = 0.06373
Step 235540: loss = 0.03688
Step 235545: loss = 0.06873
Step 235550: loss = 0.03910
Step 235555: loss = 0.14965
Step 235560: loss = 0.11509
Step 235565: loss = 0.02005
Step 235570: loss = 0.14890
Step 235575: loss = 0.02787
Step 235580: loss = 0.03053
Step 235585: loss = 0.11421
Step 235590: loss = 0.18670
Step 235595: loss = 0.02456
Step 235600: loss = 0.05946
Step 235605: loss = 0.04306
Step 235610: loss = 0.19447
Step 235615: loss = 0.09054
Step 235620: loss = 0.02460
Step 235625: loss = 0.04254
Step 235630: loss = 0.05238
Step 235635: loss = 0.08586
Step 235640: loss = 0.04311
Step 235645: loss = 0.06166
Step 235650: loss = 0.04410
Step 235655: loss = 0.09692
Step 235660: loss = 0.02132
Step 235665: loss = 0.08691
Step 235670: loss = 0.01547
Step 235675: loss = 0.07856
Step 235680: loss = 0.03564
Step 235685: loss = 0.07402
Step 235690: loss = 0.13102
Step 235695: loss = 0.05866
Step 235700: loss = 0.03516
Step 235705: loss = 0.09866
Step 235710: loss = 0.07992
Step 235715: loss = 0.04472
Step 235720: loss = 0.06750
Step 235725: loss = 0.02970
Step 235730: loss = 0.34989
Step 235735: loss = 0.09254
Step 235740: loss = 0.04705
Step 235745: loss = 0.12751
Step 235750: loss = 0.09350
Step 235755: loss = 0.03989
Step 235760: loss = 0.21301
Step 235765: loss = 0.11585
Step 235770: loss = 0.23615
Step 235775: loss = 0.04675
Step 235780: loss = 0.05274
Step 235785: loss = 0.09697
Step 235790: loss = 0.07259
Step 235795: loss = 0.13014
Step 235800: loss = 0.16183
Step 235805: loss = 0.17053
Step 235810: loss = 0.22606
Step 235815: loss = 0.06516
Step 235820: loss = 0.05218
Step 235825: loss = 0.16426
Step 235830: loss = 0.12892
Step 235835: loss = 0.07100
Step 235840: loss = 0.20399
Step 235845: loss = 0.13297
Step 235850: loss = 0.02909
Step 235855: loss = 0.27857
Step 235860: loss = 0.04137
Step 235865: loss = 0.02262
Step 235870: loss = 0.05492
Step 235875: loss = 0.11924
Step 235880: loss = 0.19301
Step 235885: loss = 0.02828
Step 235890: loss = 0.05032
Step 235895: loss = 0.05272
Step 235900: loss = 0.03082
Step 235905: loss = 0.04645
Step 235910: loss = 0.06677
Step 235915: loss = 0.30503
Step 235920: loss = 0.14897
Step 235925: loss = 0.14769
Step 235930: loss = 0.10189
Step 235935: loss = 0.03131
Step 235940: loss = 0.10244
Step 235945: loss = 0.05758
Step 235950: loss = 0.06150
Step 235955: loss = 0.19207
Step 235960: loss = 0.04910
Step 235965: loss = 0.06267
Step 235970: loss = 0.20884
Step 235975: loss = 0.12332
Step 235980: loss = 0.07703
Step 235985: loss = 0.19480
Step 235990: loss = 0.06169
Step 235995: loss = 0.10503
Step 236000: loss = 0.12577
Training Data Eval:
  Num examples: 50000, Num correct: 48437, Precision @ 1: 0.9687
('Testing Data Eval: EPOCH->', 237)
  Num examples: 10000, Num correct: 6739, Precision @ 1: 0.6739
Step 236005: loss = 0.11567
Step 236010: loss = 0.22319
Step 236015: loss = 0.09060
Step 236020: loss = 0.10240
Step 236025: loss = 0.12408
Step 236030: loss = 0.07223
Step 236035: loss = 0.04139
Step 236040: loss = 0.06202
Step 236045: loss = 0.01536
Step 236050: loss = 0.08130
Step 236055: loss = 0.02942
Step 236060: loss = 0.07097
Step 236065: loss = 0.05121
Step 236070: loss = 0.02466
Step 236075: loss = 0.13488
Step 236080: loss = 0.04293
Step 236085: loss = 0.07525
Step 236090: loss = 0.05394
Step 236095: loss = 0.03917
Step 236100: loss = 0.13307
Step 236105: loss = 0.09307
Step 236110: loss = 0.04374
Step 236115: loss = 0.02640
Step 236120: loss = 0.03268
Step 236125: loss = 0.11264
Step 236130: loss = 0.18678
Step 236135: loss = 0.03013
Step 236140: loss = 0.19454
Step 236145: loss = 0.10695
Step 236150: loss = 0.07372
Step 236155: loss = 0.01731
Step 236160: loss = 0.04970
Step 236165: loss = 0.13788
Step 236170: loss = 0.15740
Step 236175: loss = 0.03310
Step 236180: loss = 0.04378
Step 236185: loss = 0.10925
Step 236190: loss = 0.07330
Step 236195: loss = 0.07963
Step 236200: loss = 0.19063
Step 236205: loss = 0.04791
Step 236210: loss = 0.07103
Step 236215: loss = 0.03568
Step 236220: loss = 0.07843
Step 236225: loss = 0.16786
Step 236230: loss = 0.13790
Step 236235: loss = 0.14101
Step 236240: loss = 0.08360
Step 236245: loss = 0.23249
Step 236250: loss = 0.07740
Step 236255: loss = 0.05758
Step 236260: loss = 0.04366
Step 236265: loss = 0.20873
Step 236270: loss = 0.08995
Step 236275: loss = 0.08797
Step 236280: loss = 0.09891
Step 236285: loss = 0.07040
Step 236290: loss = 0.14345
Step 236295: loss = 0.02184
Step 236300: loss = 0.14129
Step 236305: loss = 0.11026
Step 236310: loss = 0.15462
Step 236315: loss = 0.07043
Step 236320: loss = 0.06017
Step 236325: loss = 0.12395
Step 236330: loss = 0.04763
Step 236335: loss = 0.04569
Step 236340: loss = 0.31780
Step 236345: loss = 0.12598
Step 236350: loss = 0.05502
Step 236355: loss = 0.11719
Step 236360: loss = 0.02737
Step 236365: loss = 0.25218
Step 236370: loss = 0.05195
Step 236375: loss = 0.02723
Step 236380: loss = 0.02977
Step 236385: loss = 0.05623
Step 236390: loss = 0.10273
Step 236395: loss = 0.13392
Step 236400: loss = 0.08622
Step 236405: loss = 0.09709
Step 236410: loss = 0.02245
Step 236415: loss = 0.06989
Step 236420: loss = 0.06190
Step 236425: loss = 0.08289
Step 236430: loss = 0.03555
Step 236435: loss = 0.16515
Step 236440: loss = 0.07844
Step 236445: loss = 0.07077
Step 236450: loss = 0.10762
Step 236455: loss = 0.02645
Step 236460: loss = 0.10415
Step 236465: loss = 0.02815
Step 236470: loss = 0.08310
Step 236475: loss = 0.11247
Step 236480: loss = 0.06377
Step 236485: loss = 0.14750
Step 236490: loss = 0.08835
Step 236495: loss = 0.11254
Step 236500: loss = 0.10150
Step 236505: loss = 0.13766
Step 236510: loss = 0.06662
Step 236515: loss = 0.10442
Step 236520: loss = 0.05384
Step 236525: loss = 0.07125
Step 236530: loss = 0.14502
Step 236535: loss = 0.04470
Step 236540: loss = 0.02669
Step 236545: loss = 0.02358
Step 236550: loss = 0.02238
Step 236555: loss = 0.04019
Step 236560: loss = 0.03447
Step 236565: loss = 0.03251
Step 236570: loss = 0.13183
Step 236575: loss = 0.23077
Step 236580: loss = 0.09513
Step 236585: loss = 0.08144
Step 236590: loss = 0.07959
Step 236595: loss = 0.10123
Step 236600: loss = 0.11757
Step 236605: loss = 0.03564
Step 236610: loss = 0.07406
Step 236615: loss = 0.05056
Step 236620: loss = 0.08996
Step 236625: loss = 0.09196
Step 236630: loss = 0.09239
Step 236635: loss = 0.02402
Step 236640: loss = 0.03609
Step 236645: loss = 0.03196
Step 236650: loss = 0.05397
Step 236655: loss = 0.28300
Step 236660: loss = 0.15015
Step 236665: loss = 0.05530
Step 236670: loss = 0.02643
Step 236675: loss = 0.32158
Step 236680: loss = 0.20910
Step 236685: loss = 0.19797
Step 236690: loss = 0.02621
Step 236695: loss = 0.06309
Step 236700: loss = 0.03950
Step 236705: loss = 0.17606
Step 236710: loss = 0.15725
Step 236715: loss = 0.09927
Step 236720: loss = 0.11285
Step 236725: loss = 0.06373
Step 236730: loss = 0.19405
Step 236735: loss = 0.05159
Step 236740: loss = 0.03129
Step 236745: loss = 0.03123
Step 236750: loss = 0.09736
Step 236755: loss = 0.04374
Step 236760: loss = 0.09590
Step 236765: loss = 0.04283
Step 236770: loss = 0.18658
Step 236775: loss = 0.28108
Step 236780: loss = 0.05408
Step 236785: loss = 0.26916
Step 236790: loss = 0.13170
Step 236795: loss = 0.18460
Step 236800: loss = 0.08128
Step 236805: loss = 0.17785
Step 236810: loss = 0.03277
Step 236815: loss = 0.10737
Step 236820: loss = 0.01620
Step 236825: loss = 0.13587
Step 236830: loss = 0.04965
Step 236835: loss = 0.04204
Step 236840: loss = 0.15484
Step 236845: loss = 0.05769
Step 236850: loss = 0.09075
Step 236855: loss = 0.03697
Step 236860: loss = 0.08258
Step 236865: loss = 0.13956
Step 236870: loss = 0.04425
Step 236875: loss = 0.07886
Step 236880: loss = 0.05633
Step 236885: loss = 0.02520
Step 236890: loss = 0.05160
Step 236895: loss = 0.15903
Step 236900: loss = 0.04365
Step 236905: loss = 0.06037
Step 236910: loss = 0.20923
Step 236915: loss = 0.22485
Step 236920: loss = 0.11677
Step 236925: loss = 0.07813
Step 236930: loss = 0.11109
Step 236935: loss = 0.04997
Step 236940: loss = 0.02770
Step 236945: loss = 0.16017
Step 236950: loss = 0.09096
Step 236955: loss = 0.10896
Step 236960: loss = 0.10936
Step 236965: loss = 0.15765
Step 236970: loss = 0.08751
Step 236975: loss = 0.13556
Step 236980: loss = 0.03149
Step 236985: loss = 0.05837
Step 236990: loss = 0.04673
Step 236995: loss = 0.14441
Step 237000: loss = 0.05614
Training Data Eval:
  Num examples: 50000, Num correct: 48444, Precision @ 1: 0.9689
('Testing Data Eval: EPOCH->', 238)
  Num examples: 10000, Num correct: 6715, Precision @ 1: 0.6715
Step 237005: loss = 0.09165
Step 237010: loss = 0.06414
Step 237015: loss = 0.02663
Step 237020: loss = 0.05502
Step 237025: loss = 0.04919
Step 237030: loss = 0.08903
Step 237035: loss = 0.08942
Step 237040: loss = 0.03380
Step 237045: loss = 0.01691
Step 237050: loss = 0.22424
Step 237055: loss = 0.17910
Step 237060: loss = 0.04616
Step 237065: loss = 0.27756
Step 237070: loss = 0.06584
Step 237075: loss = 0.11620
Step 237080: loss = 0.05246
Step 237085: loss = 0.22257
Step 237090: loss = 0.09580
Step 237095: loss = 0.11302
Step 237100: loss = 0.11245
Step 237105: loss = 0.06143
Step 237110: loss = 0.02880
Step 237115: loss = 0.43553
Step 237120: loss = 0.20779
Step 237125: loss = 0.11864
Step 237130: loss = 0.02642
Step 237135: loss = 0.02403
Step 237140: loss = 0.05991
Step 237145: loss = 0.08778
Step 237150: loss = 0.05728
Step 237155: loss = 0.18900
Step 237160: loss = 0.03405
Step 237165: loss = 0.18443
Step 237170: loss = 0.06071
Step 237175: loss = 0.07698
Step 237180: loss = 0.04918
Step 237185: loss = 0.03903
Step 237190: loss = 0.02728
Step 237195: loss = 0.12969
Step 237200: loss = 0.07775
Step 237205: loss = 0.04950
Step 237210: loss = 0.04333
Step 237215: loss = 0.01712
Step 237220: loss = 0.06326
Step 237225: loss = 0.03506
Step 237230: loss = 0.08630
Step 237235: loss = 0.14282
Step 237240: loss = 0.05130
Step 237245: loss = 0.10942
Step 237250: loss = 0.07476
Step 237255: loss = 0.08554
Step 237260: loss = 0.05664
Step 237265: loss = 0.03141
Step 237270: loss = 0.06152
Step 237275: loss = 0.12340
Step 237280: loss = 0.09105
Step 237285: loss = 0.03759
Step 237290: loss = 0.30010
Step 237295: loss = 0.02802
Step 237300: loss = 0.02799
Step 237305: loss = 0.11670
Step 237310: loss = 0.10954
Step 237315: loss = 0.09242
Step 237320: loss = 0.00702
Step 237325: loss = 0.11954
Step 237330: loss = 0.02577
Step 237335: loss = 0.02839
Step 237340: loss = 0.06044
Step 237345: loss = 0.04692
Step 237350: loss = 0.24339
Step 237355: loss = 0.08984
Step 237360: loss = 0.05587
Step 237365: loss = 0.03695
Step 237370: loss = 0.17274
Step 237375: loss = 0.04635
Step 237380: loss = 0.03482
Step 237385: loss = 0.04808
Step 237390: loss = 0.08817
Step 237395: loss = 0.06365
Step 237400: loss = 0.13222
Step 237405: loss = 0.08302
Step 237410: loss = 0.02967
Step 237415: loss = 0.06134
Step 237420: loss = 0.05467
Step 237425: loss = 0.23709
Step 237430: loss = 0.04655
Step 237435: loss = 0.09417
Step 237440: loss = 0.04052
Step 237445: loss = 0.08445
Step 237450: loss = 0.03065
Step 237455: loss = 0.05113
Step 237460: loss = 0.04990
Step 237465: loss = 0.03541
Step 237470: loss = 0.17648
Step 237475: loss = 0.09075
Step 237480: loss = 0.04776
Step 237485: loss = 0.33473
Step 237490: loss = 0.26868
Step 237495: loss = 0.06597
Step 237500: loss = 0.08844
Step 237505: loss = 0.12325
Step 237510: loss = 0.01362
Step 237515: loss = 0.01077
Step 237520: loss = 0.02994
Step 237525: loss = 0.05009
Step 237530: loss = 0.06536
Step 237535: loss = 0.26175
Step 237540: loss = 0.08545
Step 237545: loss = 0.03421
Step 237550: loss = 0.13141
Step 237555: loss = 0.02961
Step 237560: loss = 0.06287
Step 237565: loss = 0.05963
Step 237570: loss = 0.12293
Step 237575: loss = 0.03950
Step 237580: loss = 0.06071
Step 237585: loss = 0.33092
Step 237590: loss = 0.01560
Step 237595: loss = 0.14610
Step 237600: loss = 0.12118
Step 237605: loss = 0.19882
Step 237610: loss = 0.28106
Step 237615: loss = 0.05447
Step 237620: loss = 0.03855
Step 237625: loss = 0.08050
Step 237630: loss = 0.04183
Step 237635: loss = 0.06049
Step 237640: loss = 0.09453
Step 237645: loss = 0.13014
Step 237650: loss = 0.04854
Step 237655: loss = 0.03225
Step 237660: loss = 0.03813
Step 237665: loss = 0.06512
Step 237670: loss = 0.07030
Step 237675: loss = 0.06177
Step 237680: loss = 0.17827
Step 237685: loss = 0.04674
Step 237690: loss = 0.02956
Step 237695: loss = 0.08595
Step 237700: loss = 0.04059
Step 237705: loss = 0.07833
Step 237710: loss = 0.22282
Step 237715: loss = 0.06003
Step 237720: loss = 0.10197
Step 237725: loss = 0.12888
Step 237730: loss = 0.10465
Step 237735: loss = 0.05566
Step 237740: loss = 0.15125
Step 237745: loss = 0.03928
Step 237750: loss = 0.06888
Step 237755: loss = 0.07663
Step 237760: loss = 0.17349
Step 237765: loss = 0.01898
Step 237770: loss = 0.15019
Step 237775: loss = 0.02994
Step 237780: loss = 0.06166
Step 237785: loss = 0.11415
Step 237790: loss = 0.09051
Step 237795: loss = 0.26278
Step 237800: loss = 0.15286
Step 237805: loss = 0.24870
Step 237810: loss = 0.02516
Step 237815: loss = 0.07399
Step 237820: loss = 0.18709
Step 237825: loss = 0.17529
Step 237830: loss = 0.05657
Step 237835: loss = 0.06451
Step 237840: loss = 0.05821
Step 237845: loss = 0.02755
Step 237850: loss = 0.11167
Step 237855: loss = 0.19955
Step 237860: loss = 0.10107
Step 237865: loss = 0.06816
Step 237870: loss = 0.08031
Step 237875: loss = 0.38975
Step 237880: loss = 0.05876
Step 237885: loss = 0.02420
Step 237890: loss = 0.07079
Step 237895: loss = 0.05015
Step 237900: loss = 0.06436
Step 237905: loss = 0.07640
Step 237910: loss = 0.10922
Step 237915: loss = 0.03950
Step 237920: loss = 0.08197
Step 237925: loss = 0.04105
Step 237930: loss = 0.10029
Step 237935: loss = 0.08110
Step 237940: loss = 0.24458
Step 237945: loss = 0.04148
Step 237950: loss = 0.03032
Step 237955: loss = 0.17738
Step 237960: loss = 0.06875
Step 237965: loss = 0.20292
Step 237970: loss = 0.02625
Step 237975: loss = 0.10032
Step 237980: loss = 0.18960
Step 237985: loss = 0.18443
Step 237990: loss = 0.16582
Step 237995: loss = 0.02619
Step 238000: loss = 0.13019
Training Data Eval:
  Num examples: 50000, Num correct: 48519, Precision @ 1: 0.9704
('Testing Data Eval: EPOCH->', 239)
  Num examples: 10000, Num correct: 6640, Precision @ 1: 0.6640
Step 238005: loss = 0.10547
Step 238010: loss = 0.13730
Step 238015: loss = 0.08855
Step 238020: loss = 0.01694
Step 238025: loss = 0.12960
Step 238030: loss = 0.14081
Step 238035: loss = 0.10017
Step 238040: loss = 0.14942
Step 238045: loss = 0.05970
Step 238050: loss = 0.04635
Step 238055: loss = 0.09218
Step 238060: loss = 0.07203
Step 238065: loss = 0.04449
Step 238070: loss = 0.01625
Step 238075: loss = 0.01385
Step 238080: loss = 0.20945
Step 238085: loss = 0.03181
Step 238090: loss = 0.02067
Step 238095: loss = 0.17316
Step 238100: loss = 0.04567
Step 238105: loss = 0.04935
Step 238110: loss = 0.14021
Step 238115: loss = 0.08237
Step 238120: loss = 0.08575
Step 238125: loss = 0.04942
Step 238130: loss = 0.06412
Step 238135: loss = 0.02773
Step 238140: loss = 0.13450
Step 238145: loss = 0.06073
Step 238150: loss = 0.02692
Step 238155: loss = 0.02801
Step 238160: loss = 0.04185
Step 238165: loss = 0.01759
Step 238170: loss = 0.02362
Step 238175: loss = 0.11380
Step 238180: loss = 0.02352
Step 238185: loss = 0.08936
Step 238190: loss = 0.03880
Step 238195: loss = 0.10109
Step 238200: loss = 0.07249
Step 238205: loss = 0.06050
Step 238210: loss = 0.11967
Step 238215: loss = 0.05850
Step 238220: loss = 0.03608
Step 238225: loss = 0.04391
Step 238230: loss = 0.11204
Step 238235: loss = 0.10783
Step 238240: loss = 0.03535
Step 238245: loss = 0.18379
Step 238250: loss = 0.09557
Step 238255: loss = 0.17351
Step 238260: loss = 0.14257
Step 238265: loss = 0.13005
Step 238270: loss = 0.06961
Step 238275: loss = 0.09846
Step 238280: loss = 0.05148
Step 238285: loss = 0.03438
Step 238290: loss = 0.07442
Step 238295: loss = 0.02268
Step 238300: loss = 0.08722
Step 238305: loss = 0.19095
Step 238310: loss = 0.09533
Step 238315: loss = 0.11569
Step 238320: loss = 0.28082
Step 238325: loss = 0.10197
Step 238330: loss = 0.05870
Step 238335: loss = 0.00956
Step 238340: loss = 0.52724
Step 238345: loss = 0.05438
Step 238350: loss = 0.05279
Step 238355: loss = 0.01468
Step 238360: loss = 0.18654
Step 238365: loss = 0.03882
Step 238370: loss = 0.08437
Step 238375: loss = 0.22923
Step 238380: loss = 0.09176
Step 238385: loss = 0.02260
Step 238390: loss = 0.06626
Step 238395: loss = 0.12030
Step 238400: loss = 0.07671
Step 238405: loss = 0.12985
Step 238410: loss = 0.20822
Step 238415: loss = 0.07784
Step 238420: loss = 0.17212
Step 238425: loss = 0.16945
Step 238430: loss = 0.16685
Step 238435: loss = 0.04986
Step 238440: loss = 0.14538
Step 238445: loss = 0.03453
Step 238450: loss = 0.06455
Step 238455: loss = 0.12452
Step 238460: loss = 0.05627
Step 238465: loss = 0.10339
Step 238470: loss = 0.03825
Step 238475: loss = 0.03327
Step 238480: loss = 0.07051
Step 238485: loss = 0.11004
Step 238490: loss = 0.05171
Step 238495: loss = 0.05993
Step 238500: loss = 0.15675
Step 238505: loss = 0.03642
Step 238510: loss = 0.09464
Step 238515: loss = 0.15560
Step 238520: loss = 0.04927
Step 238525: loss = 0.08661
Step 238530: loss = 0.07744
Step 238535: loss = 0.27130
Step 238540: loss = 0.04849
Step 238545: loss = 0.06982
Step 238550: loss = 0.11203
Step 238555: loss = 0.12886
Step 238560: loss = 0.03603
Step 238565: loss = 0.07293
Step 238570: loss = 0.08589
Step 238575: loss = 0.17969
Step 238580: loss = 0.17299
Step 238585: loss = 0.13085
Step 238590: loss = 0.03851
Step 238595: loss = 0.07065
Step 238600: loss = 0.10990
Step 238605: loss = 0.19817
Step 238610: loss = 0.09547
Step 238615: loss = 0.10211
Step 238620: loss = 0.01089
Step 238625: loss = 0.13529
Step 238630: loss = 0.07157
Step 238635: loss = 0.01804
Step 238640: loss = 0.03366
Step 238645: loss = 0.01040
Step 238650: loss = 0.03407
Step 238655: loss = 0.08842
Step 238660: loss = 0.17522
Step 238665: loss = 0.11228
Step 238670: loss = 0.04604
Step 238675: loss = 0.21842
Step 238680: loss = 0.12643
Step 238685: loss = 0.03584
Step 238690: loss = 0.16512
Step 238695: loss = 0.09241
Step 238700: loss = 0.07224
Step 238705: loss = 0.16711
Step 238710: loss = 0.08131
Step 238715: loss = 0.06736
Step 238720: loss = 0.13202
Step 238725: loss = 0.04251
Step 238730: loss = 0.19762
Step 238735: loss = 0.03923
Step 238740: loss = 0.08819
Step 238745: loss = 0.06561
Step 238750: loss = 0.14971
Step 238755: loss = 0.05002
Step 238760: loss = 0.10090
Step 238765: loss = 0.08940
Step 238770: loss = 0.11633
Step 238775: loss = 0.12816
Step 238780: loss = 0.01923
Step 238785: loss = 0.07305
Step 238790: loss = 0.04919
Step 238795: loss = 0.11749
Step 238800: loss = 0.18746
Step 238805: loss = 0.05294
Step 238810: loss = 0.05108
Step 238815: loss = 0.04093
Step 238820: loss = 0.12436
Step 238825: loss = 0.13508
Step 238830: loss = 0.26333
Step 238835: loss = 0.24434
Step 238840: loss = 0.03926
Step 238845: loss = 0.14947
Step 238850: loss = 0.02707
Step 238855: loss = 0.13166
Step 238860: loss = 0.07971
Step 238865: loss = 0.07239
Step 238870: loss = 0.04527
Step 238875: loss = 0.06643
Step 238880: loss = 0.04359
Step 238885: loss = 0.08356
Step 238890: loss = 0.11218
Step 238895: loss = 0.04483
Step 238900: loss = 0.16530
Step 238905: loss = 0.05181
Step 238910: loss = 0.20551
Step 238915: loss = 0.03760
Step 238920: loss = 0.03371
Step 238925: loss = 0.06059
Step 238930: loss = 0.06714
Step 238935: loss = 0.19062
Step 238940: loss = 0.24499
Step 238945: loss = 0.02463
Step 238950: loss = 0.10337
Step 238955: loss = 0.14337
Step 238960: loss = 0.12417
Step 238965: loss = 0.04817
Step 238970: loss = 0.01370
Step 238975: loss = 0.06523
Step 238980: loss = 0.28480
Step 238985: loss = 0.10820
Step 238990: loss = 0.04620
Step 238995: loss = 0.05335
Step 239000: loss = 0.03389
Training Data Eval:
  Num examples: 50000, Num correct: 48581, Precision @ 1: 0.9716
('Testing Data Eval: EPOCH->', 240)
  Num examples: 10000, Num correct: 6805, Precision @ 1: 0.6805
Step 239005: loss = 0.05951
Step 239010: loss = 0.07971
Step 239015: loss = 0.13191
Step 239020: loss = 0.07905
Step 239025: loss = 0.18747
Step 239030: loss = 0.08382
Step 239035: loss = 0.03443
Step 239040: loss = 0.09251
Step 239045: loss = 0.03911
Step 239050: loss = 0.03673
Step 239055: loss = 0.08073
Step 239060: loss = 0.02407
Step 239065: loss = 0.03593
Step 239070: loss = 0.17743
Step 239075: loss = 0.07049
Step 239080: loss = 0.02340
Step 239085: loss = 0.39633
Step 239090: loss = 0.05907
Step 239095: loss = 0.08249
Step 239100: loss = 0.03760
Step 239105: loss = 0.09840
Step 239110: loss = 0.08016
Step 239115: loss = 0.03359
Step 239120: loss = 0.10610
Step 239125: loss = 0.06455
Step 239130: loss = 0.34298
Step 239135: loss = 0.12250
Step 239140: loss = 0.04884
Step 239145: loss = 0.04268
Step 239150: loss = 0.11420
Step 239155: loss = 0.33964
Step 239160: loss = 0.07731
Step 239165: loss = 0.02706
Step 239170: loss = 0.12886
Step 239175: loss = 0.02085
Step 239180: loss = 0.08113
Step 239185: loss = 0.23430
Step 239190: loss = 0.04129
Step 239195: loss = 0.05825
Step 239200: loss = 0.10387
Step 239205: loss = 0.04634
Step 239210: loss = 0.32361
Step 239215: loss = 0.10708
Step 239220: loss = 0.06354
Step 239225: loss = 0.04044
Step 239230: loss = 0.03421
Step 239235: loss = 0.08775
Step 239240: loss = 0.15973
Step 239245: loss = 0.08344
Step 239250: loss = 0.02385
Step 239255: loss = 0.03531
Step 239260: loss = 0.02988
Step 239265: loss = 0.09405
Step 239270: loss = 0.19398
Step 239275: loss = 0.02965
Step 239280: loss = 0.07724
Step 239285: loss = 0.03694
Step 239290: loss = 0.20454
Step 239295: loss = 0.08125
Step 239300: loss = 0.06604
Step 239305: loss = 0.24914
Step 239310: loss = 0.12721
Step 239315: loss = 0.03067
Step 239320: loss = 0.07999
Step 239325: loss = 0.04899
Step 239330: loss = 0.03505
Step 239335: loss = 0.06445
Step 239340: loss = 0.03482
Step 239345: loss = 0.10723
Step 239350: loss = 0.03698
Step 239355: loss = 0.04855
Step 239360: loss = 0.09610
Step 239365: loss = 0.02130
Step 239370: loss = 0.08859
Step 239375: loss = 0.25060
Step 239380: loss = 0.32298
Step 239385: loss = 0.03136
Step 239390: loss = 0.25452
Step 239395: loss = 0.05245
Step 239400: loss = 0.10028
Step 239405: loss = 0.18390
Step 239410: loss = 0.02652
Step 239415: loss = 0.08342
Step 239420: loss = 0.02773
Step 239425: loss = 0.03770
Step 239430: loss = 0.03686
Step 239435: loss = 0.07877
Step 239440: loss = 0.05812
Step 239445: loss = 0.03092
Step 239450: loss = 0.08343
Step 239455: loss = 0.11900
Step 239460: loss = 0.05313
Step 239465: loss = 0.06606
Step 239470: loss = 0.14151
Step 239475: loss = 0.06701
Step 239480: loss = 0.10005
Step 239485: loss = 0.13769
Step 239490: loss = 0.13768
Step 239495: loss = 0.07237
Step 239500: loss = 0.04376
Step 239505: loss = 0.21474
Step 239510: loss = 0.12064
Step 239515: loss = 0.10147
Step 239520: loss = 0.06074
Step 239525: loss = 0.06934
Step 239530: loss = 0.28041
Step 239535: loss = 0.06705
Step 239540: loss = 0.04555
Step 239545: loss = 0.04130
Step 239550: loss = 0.16924
Step 239555: loss = 0.03531
Step 239560: loss = 0.08502
Step 239565: loss = 0.13570
Step 239570: loss = 0.03737
Step 239575: loss = 0.14618
Step 239580: loss = 0.03615
Step 239585: loss = 0.07392
Step 239590: loss = 0.10026
Step 239595: loss = 0.13820
Step 239600: loss = 0.03506
Step 239605: loss = 0.12983
Step 239610: loss = 0.02624
Step 239615: loss = 0.09020
Step 239620: loss = 0.08641
Step 239625: loss = 0.05242
Step 239630: loss = 0.04524
Step 239635: loss = 0.08499
Step 239640: loss = 0.11179
Step 239645: loss = 0.06949
Step 239650: loss = 0.08852
Step 239655: loss = 0.04502
Step 239660: loss = 0.18086
Step 239665: loss = 0.04740
Step 239670: loss = 0.12367
Step 239675: loss = 0.09310
Step 239680: loss = 0.05096
Step 239685: loss = 0.22732
Step 239690: loss = 0.05582
Step 239695: loss = 0.06374
Step 239700: loss = 0.01908
Step 239705: loss = 0.09813
Step 239710: loss = 0.03776
Step 239715: loss = 0.28596
Step 239720: loss = 0.02922
Step 239725: loss = 0.29081
Step 239730: loss = 0.07364
Step 239735: loss = 0.03565
Step 239740: loss = 0.06492
Step 239745: loss = 0.11165
Step 239750: loss = 0.09402
Step 239755: loss = 0.10421
Step 239760: loss = 0.08185
Step 239765: loss = 0.06253
Step 239770: loss = 0.08830
Step 239775: loss = 0.04646
Step 239780: loss = 0.07706
Step 239785: loss = 0.04372
Step 239790: loss = 0.10819
Step 239795: loss = 0.04971
Step 239800: loss = 0.11375
Step 239805: loss = 0.05601
Step 239810: loss = 0.30080
Step 239815: loss = 0.13789
Step 239820: loss = 0.30169
Step 239825: loss = 0.12194
Step 239830: loss = 0.07472
Step 239835: loss = 0.13476
Step 239840: loss = 0.09717
Step 239845: loss = 0.00858
Step 239850: loss = 0.03639
Step 239855: loss = 0.07391
Step 239860: loss = 0.16124
Step 239865: loss = 0.06779
Step 239870: loss = 0.12797
Step 239875: loss = 0.02270
Step 239880: loss = 0.03584
Step 239885: loss = 0.10537
Step 239890: loss = 0.07996
Step 239895: loss = 0.06860
Step 239900: loss = 0.08328
Step 239905: loss = 0.23244
Step 239910: loss = 0.05458
Step 239915: loss = 0.07213
Step 239920: loss = 0.13182
Step 239925: loss = 0.03964
Step 239930: loss = 0.10155
Step 239935: loss = 0.06541
Step 239940: loss = 0.03034
Step 239945: loss = 0.02917
Step 239950: loss = 0.04242
Step 239955: loss = 0.05849
Step 239960: loss = 0.05651
Step 239965: loss = 0.09738
Step 239970: loss = 0.23054
Step 239975: loss = 0.05416
Step 239980: loss = 0.10883
Step 239985: loss = 0.17614
Step 239990: loss = 0.11204
Step 239995: loss = 0.02140
Step 240000: loss = 0.05417
Training Data Eval:
  Num examples: 50000, Num correct: 48577, Precision @ 1: 0.9715
('Testing Data Eval: EPOCH->', 241)
  Num examples: 10000, Num correct: 6791, Precision @ 1: 0.6791
Step 240005: loss = 0.11131
Step 240010: loss = 0.18819
Step 240015: loss = 0.03881
Step 240020: loss = 0.04970
Step 240025: loss = 0.03477
Step 240030: loss = 0.03654
Step 240035: loss = 0.09903
Step 240040: loss = 0.07067
Step 240045: loss = 0.05156
Step 240050: loss = 0.03080
Step 240055: loss = 0.03068
Step 240060: loss = 0.16837
Step 240065: loss = 0.09846
Step 240070: loss = 0.09011
Step 240075: loss = 0.15424
Step 240080: loss = 0.08294
Step 240085: loss = 0.23674
Step 240090: loss = 0.11722
Step 240095: loss = 0.12745
Step 240100: loss = 0.04430
Step 240105: loss = 0.03232
Step 240110: loss = 0.06522
Step 240115: loss = 0.04776
Step 240120: loss = 0.05179
Step 240125: loss = 0.02805
Step 240130: loss = 0.02087
Step 240135: loss = 0.02513
Step 240140: loss = 0.08666
Step 240145: loss = 0.02247
Step 240150: loss = 0.11680
Step 240155: loss = 0.07566
Step 240160: loss = 0.04175
Step 240165: loss = 0.04097
Step 240170: loss = 0.01088
Step 240175: loss = 0.03469
Step 240180: loss = 0.12895
Step 240185: loss = 0.01784
Step 240190: loss = 0.11918
Step 240195: loss = 0.06368
Step 240200: loss = 0.30715
Step 240205: loss = 0.12631
Step 240210: loss = 0.10685
Step 240215: loss = 0.08356
Step 240220: loss = 0.07714
Step 240225: loss = 0.05949
Step 240230: loss = 0.01970
Step 240235: loss = 0.07676
Step 240240: loss = 0.14166
Step 240245: loss = 0.17077
Step 240250: loss = 0.14591
Step 240255: loss = 0.23632
Step 240260: loss = 0.18737
Step 240265: loss = 0.05115
Step 240270: loss = 0.22792
Step 240275: loss = 0.03084
Step 240280: loss = 0.23636
Step 240285: loss = 0.07231
Step 240290: loss = 0.31127
Step 240295: loss = 0.04326
Step 240300: loss = 0.07657
Step 240305: loss = 0.27830
Step 240310: loss = 0.05799
Step 240315: loss = 0.14946
Step 240320: loss = 0.02733
Step 240325: loss = 0.06830
Step 240330: loss = 0.27283
Step 240335: loss = 0.03737
Step 240340: loss = 0.15000
Step 240345: loss = 0.03214
Step 240350: loss = 0.04290
Step 240355: loss = 0.07751
Step 240360: loss = 0.20676
Step 240365: loss = 0.07814
Step 240370: loss = 0.12196
Step 240375: loss = 0.11292
Step 240380: loss = 0.05197
Step 240385: loss = 0.07379
Step 240390: loss = 0.02129
Step 240395: loss = 0.11457
Step 240400: loss = 0.01381
Step 240405: loss = 0.24425
Step 240410: loss = 0.01669
Step 240415: loss = 0.08115
Step 240420: loss = 0.01980
Step 240425: loss = 0.18130
Step 240430: loss = 0.08071
Step 240435: loss = 0.11031
Step 240440: loss = 0.03223
Step 240445: loss = 0.03075
Step 240450: loss = 0.10317
Step 240455: loss = 0.09656
Step 240460: loss = 0.09477
Step 240465: loss = 0.05255
Step 240470: loss = 0.08716
Step 240475: loss = 0.02149
Step 240480: loss = 0.05196
Step 240485: loss = 0.10065
Step 240490: loss = 0.06003
Step 240495: loss = 0.13338
Step 240500: loss = 0.04051
Step 240505: loss = 0.14210
Step 240510: loss = 0.20274
Step 240515: loss = 0.07290
Step 240520: loss = 0.03854
Step 240525: loss = 0.10051
Step 240530: loss = 0.11807
Step 240535: loss = 0.06906
Step 240540: loss = 0.03830
Step 240545: loss = 0.05143
Step 240550: loss = 0.05080
Step 240555: loss = 0.01858
Step 240560: loss = 0.05985
Step 240565: loss = 0.17309
Step 240570: loss = 0.04100
Step 240575: loss = 0.18084
Step 240580: loss = 0.10157
Step 240585: loss = 0.15336
Step 240590: loss = 0.05086
Step 240595: loss = 0.09517
Step 240600: loss = 0.04883
Step 240605: loss = 0.12472
Step 240610: loss = 0.05902
Step 240615: loss = 0.11009
Step 240620: loss = 0.12835
Step 240625: loss = 0.13427
Step 240630: loss = 0.09481
Step 240635: loss = 0.06628
Step 240640: loss = 0.11606
Step 240645: loss = 0.12482
Step 240650: loss = 0.20132
Step 240655: loss = 0.10675
Step 240660: loss = 0.28897
Step 240665: loss = 0.05542
Step 240670: loss = 0.06212
Step 240675: loss = 0.02981
Step 240680: loss = 0.09094
Step 240685: loss = 0.04051
Step 240690: loss = 0.02410
Step 240695: loss = 0.01952
Step 240700: loss = 0.15206
Step 240705: loss = 0.02518
Step 240710: loss = 0.13230
Step 240715: loss = 0.17405
Step 240720: loss = 0.11526
Step 240725: loss = 0.19776
Step 240730: loss = 0.09762
Step 240735: loss = 0.02158
Step 240740: loss = 0.07991
Step 240745: loss = 0.13812
Step 240750: loss = 0.03855
Step 240755: loss = 0.01308
Step 240760: loss = 0.09854
Step 240765: loss = 0.04407
Step 240770: loss = 0.05256
Step 240775: loss = 0.03348
Step 240780: loss = 0.03816
Step 240785: loss = 0.17947
Step 240790: loss = 0.19680
Step 240795: loss = 0.06312
Step 240800: loss = 0.09943
Step 240805: loss = 0.06886
Step 240810: loss = 0.07705
Step 240815: loss = 0.11484
Step 240820: loss = 0.07621
Step 240825: loss = 0.17305
Step 240830: loss = 0.26670
Step 240835: loss = 0.06411
Step 240840: loss = 0.01597
Step 240845: loss = 0.04370
Step 240850: loss = 0.21045
Step 240855: loss = 0.28489
Step 240860: loss = 0.08477
Step 240865: loss = 0.08535
Step 240870: loss = 0.11550
Step 240875: loss = 0.09965
Step 240880: loss = 0.03740
Step 240885: loss = 0.14254
Step 240890: loss = 0.02331
Step 240895: loss = 0.12264
Step 240900: loss = 0.15522
Step 240905: loss = 0.09855
Step 240910: loss = 0.18620
Step 240915: loss = 0.05722
Step 240920: loss = 0.30519
Step 240925: loss = 0.17322
Step 240930: loss = 0.02787
Step 240935: loss = 0.08343
Step 240940: loss = 0.04952
Step 240945: loss = 0.13268
Step 240950: loss = 0.06037
Step 240955: loss = 0.13142
Step 240960: loss = 0.12418
Step 240965: loss = 0.04905
Step 240970: loss = 0.04221
Step 240975: loss = 0.34521
Step 240980: loss = 0.03284
Step 240985: loss = 0.08867
Step 240990: loss = 0.18857
Step 240995: loss = 0.09553
Step 241000: loss = 0.05536
Training Data Eval:
  Num examples: 50000, Num correct: 48541, Precision @ 1: 0.9708
('Testing Data Eval: EPOCH->', 242)
  Num examples: 10000, Num correct: 6745, Precision @ 1: 0.6745
Step 241005: loss = 0.05684
Step 241010: loss = 0.25265
Step 241015: loss = 0.26768
Step 241020: loss = 0.09558
Step 241025: loss = 0.03707
Step 241030: loss = 0.12897
Step 241035: loss = 0.01218
Step 241040: loss = 0.06546
Step 241045: loss = 0.19634
Step 241050: loss = 0.15004
Step 241055: loss = 0.04460
Step 241060: loss = 0.06844
Step 241065: loss = 0.11687
Step 241070: loss = 0.03910
Step 241075: loss = 0.14467
Step 241080: loss = 0.07078
Step 241085: loss = 0.05482
Step 241090: loss = 0.03703
Step 241095: loss = 0.12010
Step 241100: loss = 0.01980
Step 241105: loss = 0.05002
Step 241110: loss = 0.01701
Step 241115: loss = 0.07957
Step 241120: loss = 0.08925
Step 241125: loss = 0.11056
Step 241130: loss = 0.01376
Step 241135: loss = 0.03086
Step 241140: loss = 0.06690
Step 241145: loss = 0.19360
Step 241150: loss = 0.02837
Step 241155: loss = 0.07675
Step 241160: loss = 0.08541
Step 241165: loss = 0.04381
Step 241170: loss = 0.08910
Step 241175: loss = 0.15752
Step 241180: loss = 0.05258
Step 241185: loss = 0.07864
Step 241190: loss = 0.10951
Step 241195: loss = 0.05149
Step 241200: loss = 0.08547
Step 241205: loss = 0.20304
Step 241210: loss = 0.07206
Step 241215: loss = 0.04972
Step 241220: loss = 0.06301
Step 241225: loss = 0.06583
Step 241230: loss = 0.16255
Step 241235: loss = 0.09035
Step 241240: loss = 0.02496
Step 241245: loss = 0.06724
Step 241250: loss = 0.01596
Step 241255: loss = 0.10168
Step 241260: loss = 0.02355
Step 241265: loss = 0.08762
Step 241270: loss = 0.04974
Step 241275: loss = 0.06792
Step 241280: loss = 0.00654
Step 241285: loss = 0.07524
Step 241290: loss = 0.03913
Step 241295: loss = 0.13280
Step 241300: loss = 0.08838
Step 241305: loss = 0.10895
Step 241310: loss = 0.02186
Step 241315: loss = 0.04881
Step 241320: loss = 0.07820
Step 241325: loss = 0.03269
Step 241330: loss = 0.07396
Step 241335: loss = 0.09701
Step 241340: loss = 0.06653
Step 241345: loss = 0.04877
Step 241350: loss = 0.07606
Step 241355: loss = 0.01308
Step 241360: loss = 0.06156
Step 241365: loss = 0.02867
Step 241370: loss = 0.05588
Step 241375: loss = 0.01730
Step 241380: loss = 0.04248
Step 241385: loss = 0.06535
Step 241390: loss = 0.11757
Step 241395: loss = 0.03751
Step 241400: loss = 0.11539
Step 241405: loss = 0.03199
Step 241410: loss = 0.22949
Step 241415: loss = 0.13550
Step 241420: loss = 0.05505
Step 241425: loss = 0.05181
Step 241430: loss = 0.07763
Step 241435: loss = 0.11378
Step 241440: loss = 0.03619
Step 241445: loss = 0.13496
Step 241450: loss = 0.05008
Step 241455: loss = 0.10683
Step 241460: loss = 0.06465
Step 241465: loss = 0.05863
Step 241470: loss = 0.08188
Step 241475: loss = 0.29309
Step 241480: loss = 0.05681
Step 241485: loss = 0.01505
Step 241490: loss = 0.17577
Step 241495: loss = 0.03600
Step 241500: loss = 0.07961
Step 241505: loss = 0.07706
Step 241510: loss = 0.04376
Step 241515: loss = 0.07903
Step 241520: loss = 0.05144
Step 241525: loss = 0.13055
Step 241530: loss = 0.03943
Step 241535: loss = 0.08205
Step 241540: loss = 0.13146
Step 241545: loss = 0.03019
Step 241550: loss = 0.17499
Step 241555: loss = 0.01339
Step 241560: loss = 0.07784
Step 241565: loss = 0.05003
Step 241570: loss = 0.03054
Step 241575: loss = 0.02302
Step 241580: loss = 0.17523
Step 241585: loss = 0.06118
Step 241590: loss = 0.06941
Step 241595: loss = 0.15364
Step 241600: loss = 0.04905
Step 241605: loss = 0.05404
Step 241610: loss = 0.07717
Step 241615: loss = 0.28463
Step 241620: loss = 0.08523
Step 241625: loss = 0.10918
Step 241630: loss = 0.14676
Step 241635: loss = 0.04120
Step 241640: loss = 0.11445
Step 241645: loss = 0.13631
Step 241650: loss = 0.21477
Step 241655: loss = 0.04348
Step 241660: loss = 0.16751
Step 241665: loss = 0.02286
Step 241670: loss = 0.05374
Step 241675: loss = 0.01524
Step 241680: loss = 0.09510
Step 241685: loss = 0.02196
Step 241690: loss = 0.04935
Step 241695: loss = 0.05120
Step 241700: loss = 0.06283
Step 241705: loss = 0.02622
Step 241710: loss = 0.03085
Step 241715: loss = 0.01859
Step 241720: loss = 0.20090
Step 241725: loss = 0.10616
Step 241730: loss = 0.01798
Step 241735: loss = 0.12284
Step 241740: loss = 0.13301
Step 241745: loss = 0.09945
Step 241750: loss = 0.07221
Step 241755: loss = 0.22388
Step 241760: loss = 0.14702
Step 241765: loss = 0.07789
Step 241770: loss = 0.12096
Step 241775: loss = 0.07906
Step 241780: loss = 0.07452
Step 241785: loss = 0.06034
Step 241790: loss = 0.15150
Step 241795: loss = 0.07852
Step 241800: loss = 0.06411
Step 241805: loss = 0.05397
Step 241810: loss = 0.03853
Step 241815: loss = 0.05988
Step 241820: loss = 0.11769
Step 241825: loss = 0.04367
Step 241830: loss = 0.25718
Step 241835: loss = 0.25472
Step 241840: loss = 0.18842
Step 241845: loss = 0.12490
Step 241850: loss = 0.03674
Step 241855: loss = 0.10317
Step 241860: loss = 0.09108
Step 241865: loss = 0.05403
Step 241870: loss = 0.03505
Step 241875: loss = 0.12559
Step 241880: loss = 0.13746
Step 241885: loss = 0.04353
Step 241890: loss = 0.11848
Step 241895: loss = 0.08461
Step 241900: loss = 0.16452
Step 241905: loss = 0.10391
Step 241910: loss = 0.09742
Step 241915: loss = 0.06861
Step 241920: loss = 0.04469
Step 241925: loss = 0.21814
Step 241930: loss = 0.05130
Step 241935: loss = 0.16727
Step 241940: loss = 0.19530
Step 241945: loss = 0.03687
Step 241950: loss = 0.01190
Step 241955: loss = 0.02047
Step 241960: loss = 0.04691
Step 241965: loss = 0.04766
Step 241970: loss = 0.04497
Step 241975: loss = 0.06094
Step 241980: loss = 0.15440
Step 241985: loss = 0.09953
Step 241990: loss = 0.06099
Step 241995: loss = 0.08172
Step 242000: loss = 0.03517
Training Data Eval:
  Num examples: 50000, Num correct: 48451, Precision @ 1: 0.9690
('Testing Data Eval: EPOCH->', 243)
  Num examples: 10000, Num correct: 6806, Precision @ 1: 0.6806
Step 242005: loss = 0.03189
Step 242010: loss = 0.23810
Step 242015: loss = 0.03900
Step 242020: loss = 0.33735
Step 242025: loss = 0.11082
Step 242030: loss = 0.12755
Step 242035: loss = 0.11513
Step 242040: loss = 0.15138
Step 242045: loss = 0.09977
Step 242050: loss = 0.01180
Step 242055: loss = 0.23792
Step 242060: loss = 0.03049
Step 242065: loss = 0.05548
Step 242070: loss = 0.02933
Step 242075: loss = 0.03076
Step 242080: loss = 0.04481
Step 242085: loss = 0.04338
Step 242090: loss = 0.07681
Step 242095: loss = 0.12699
Step 242100: loss = 0.13933
Step 242105: loss = 0.09127
Step 242110: loss = 0.04404
Step 242115: loss = 0.06626
Step 242120: loss = 0.04075
Step 242125: loss = 0.01073
Step 242130: loss = 0.12368
Step 242135: loss = 0.08250
Step 242140: loss = 0.08740
Step 242145: loss = 0.11396
Step 242150: loss = 0.06093
Step 242155: loss = 0.04036
Step 242160: loss = 0.13212
Step 242165: loss = 0.03866
Step 242170: loss = 0.14116
Step 242175: loss = 0.18426
Step 242180: loss = 0.05868
Step 242185: loss = 0.09324
Step 242190: loss = 0.05846
Step 242195: loss = 0.05470
Step 242200: loss = 0.05732
Step 242205: loss = 0.12591
Step 242210: loss = 0.08176
Step 242215: loss = 0.08666
Step 242220: loss = 0.09005
Step 242225: loss = 0.10559
Step 242230: loss = 0.10751
Step 242235: loss = 0.20897
Step 242240: loss = 0.22482
Step 242245: loss = 0.04389
Step 242250: loss = 0.21223
Step 242255: loss = 0.03507
Step 242260: loss = 0.16138
Step 242265: loss = 0.19211
Step 242270: loss = 0.07684
Step 242275: loss = 0.04303
Step 242280: loss = 0.09322
Step 242285: loss = 0.07121
Step 242290: loss = 0.09531
Step 242295: loss = 0.08658
Step 242300: loss = 0.03580
Step 242305: loss = 0.03508
Step 242310: loss = 0.08081
Step 242315: loss = 0.07821
Step 242320: loss = 0.17745
Step 242325: loss = 0.20353
Step 242330: loss = 0.12229
Step 242335: loss = 0.09837
Step 242340: loss = 0.05131
Step 242345: loss = 0.07491
Step 242350: loss = 0.04386
Step 242355: loss = 0.03454
Step 242360: loss = 0.08267
Step 242365: loss = 0.07138
Step 242370: loss = 0.01486
Step 242375: loss = 0.03780
Step 242380: loss = 0.07140
Step 242385: loss = 0.02616
Step 242390: loss = 0.01805
Step 242395: loss = 0.03327
Step 242400: loss = 0.11297
Step 242405: loss = 0.10240
Step 242410: loss = 0.01222
Step 242415: loss = 0.18631
Step 242420: loss = 0.20465
Step 242425: loss = 0.07345
Step 242430: loss = 0.06660
Step 242435: loss = 0.08832
Step 242440: loss = 0.31461
Step 242445: loss = 0.03247
Step 242450: loss = 0.03607
Step 242455: loss = 0.01309
Step 242460: loss = 0.08964
Step 242465: loss = 0.21023
Step 242470: loss = 0.05974
Step 242475: loss = 0.03637
Step 242480: loss = 0.15974
Step 242485: loss = 0.02428
Step 242490: loss = 0.06026
Step 242495: loss = 0.37813
Step 242500: loss = 0.09808
Step 242505: loss = 0.09481
Step 242510: loss = 0.09671
Step 242515: loss = 0.09097
Step 242520: loss = 0.19267
Step 242525: loss = 0.04909
Step 242530: loss = 0.01860
Step 242535: loss = 0.09260
Step 242540: loss = 0.13580
Step 242545: loss = 0.03174
Step 242550: loss = 0.09300
Step 242555: loss = 0.03695
Step 242560: loss = 0.17284
Step 242565: loss = 0.03658
Step 242570: loss = 0.01394
Step 242575: loss = 0.06653
Step 242580: loss = 0.08532
Step 242585: loss = 0.11805
Step 242590: loss = 0.04676
Step 242595: loss = 0.15846
Step 242600: loss = 0.02999
Step 242605: loss = 0.05948
Step 242610: loss = 0.04394
Step 242615: loss = 0.07245
Step 242620: loss = 0.05777
Step 242625: loss = 0.06238
Step 242630: loss = 0.19641
Step 242635: loss = 0.20232
Step 242640: loss = 0.02845
Step 242645: loss = 0.04320
Step 242650: loss = 0.06451
Step 242655: loss = 0.22968
Step 242660: loss = 0.03286
Step 242665: loss = 0.03644
Step 242670: loss = 0.16093
Step 242675: loss = 0.04050
Step 242680: loss = 0.10123
Step 242685: loss = 0.09749
Step 242690: loss = 0.05070
Step 242695: loss = 0.05940
Step 242700: loss = 0.13919
Step 242705: loss = 0.10581
Step 242710: loss = 0.09417
Step 242715: loss = 0.05637
Step 242720: loss = 0.13367
Step 242725: loss = 0.09572
Step 242730: loss = 0.03556
Step 242735: loss = 0.02251
Step 242740: loss = 0.11167
Step 242745: loss = 0.06857
Step 242750: loss = 0.10929
Step 242755: loss = 0.02803
Step 242760: loss = 0.07535
Step 242765: loss = 0.07753
Step 242770: loss = 0.21910
Step 242775: loss = 0.02939
Step 242780: loss = 0.09140
Step 242785: loss = 0.25801
Step 242790: loss = 0.08285
Step 242795: loss = 0.22057
Step 242800: loss = 0.22328
Step 242805: loss = 0.09730
Step 242810: loss = 0.12175
Step 242815: loss = 0.13265
Step 242820: loss = 0.02487
Step 242825: loss = 0.13491
Step 242830: loss = 0.04450
Step 242835: loss = 0.04696
Step 242840: loss = 0.05348
Step 242845: loss = 0.12416
Step 242850: loss = 0.13634
Step 242855: loss = 0.02370
Step 242860: loss = 0.04781
Step 242865: loss = 0.10787
Step 242870: loss = 0.08202
Step 242875: loss = 0.05727
Step 242880: loss = 0.13397
Step 242885: loss = 0.07184
Step 242890: loss = 0.04279
Step 242895: loss = 0.13823
Step 242900: loss = 0.16017
Step 242905: loss = 0.03418
Step 242910: loss = 0.07598
Step 242915: loss = 0.02745
Step 242920: loss = 0.02666
Step 242925: loss = 0.02420
Step 242930: loss = 0.15784
Step 242935: loss = 0.07118
Step 242940: loss = 0.05590
Step 242945: loss = 0.01691
Step 242950: loss = 0.05636
Step 242955: loss = 0.06094
Step 242960: loss = 0.03316
Step 242965: loss = 0.03580
Step 242970: loss = 0.03875
Step 242975: loss = 0.17384
Step 242980: loss = 0.19853
Step 242985: loss = 0.01783
Step 242990: loss = 0.10372
Step 242995: loss = 0.19626
Step 243000: loss = 0.22201
Training Data Eval:
  Num examples: 50000, Num correct: 48511, Precision @ 1: 0.9702
('Testing Data Eval: EPOCH->', 244)
  Num examples: 10000, Num correct: 6749, Precision @ 1: 0.6749
Step 243005: loss = 0.06358
Step 243010: loss = 0.20287
Step 243015: loss = 0.03987
Step 243020: loss = 0.07149
Step 243025: loss = 0.19545
Step 243030: loss = 0.06550
Step 243035: loss = 0.10100
Step 243040: loss = 0.17764
Step 243045: loss = 0.18849
Step 243050: loss = 0.03442
Step 243055: loss = 0.06065
Step 243060: loss = 0.06246
Step 243065: loss = 0.11042
Step 243070: loss = 0.11563
Step 243075: loss = 0.02502
Step 243080: loss = 0.06048
Step 243085: loss = 0.05163
Step 243090: loss = 0.04054
Step 243095: loss = 0.11209
Step 243100: loss = 0.06284
Step 243105: loss = 0.04193
Step 243110: loss = 0.03452
Step 243115: loss = 0.10053
Step 243120: loss = 0.03627
Step 243125: loss = 0.14958
Step 243130: loss = 0.13934
Step 243135: loss = 0.02320
Step 243140: loss = 0.09320
Step 243145: loss = 0.05110
Step 243150: loss = 0.10923
Step 243155: loss = 0.29688
Step 243160: loss = 0.10636
Step 243165: loss = 0.05856
Step 243170: loss = 0.06334
Step 243175: loss = 0.06493
Step 243180: loss = 0.07587
Step 243185: loss = 0.09169
Step 243190: loss = 0.03715
Step 243195: loss = 0.28975
Step 243200: loss = 0.10484
Step 243205: loss = 0.03703
Step 243210: loss = 0.13719
Step 243215: loss = 0.03874
Step 243220: loss = 0.13696
Step 243225: loss = 0.04040
Step 243230: loss = 0.18354
Step 243235: loss = 0.17293
Step 243240: loss = 0.08484
Step 243245: loss = 0.00868
Step 243250: loss = 0.07838
Step 243255: loss = 0.15584
Step 243260: loss = 0.04755
Step 243265: loss = 0.02551
Step 243270: loss = 0.11233
Step 243275: loss = 0.28012
Step 243280: loss = 0.11680
Step 243285: loss = 0.08182
Step 243290: loss = 0.19242
Step 243295: loss = 0.16539
Step 243300: loss = 0.13211
Step 243305: loss = 0.11099
Step 243310: loss = 0.20702
Step 243315: loss = 0.06008
Step 243320: loss = 0.05448
Step 243325: loss = 0.03050
Step 243330: loss = 0.07593
Step 243335: loss = 0.12964
Step 243340: loss = 0.15965
Step 243345: loss = 0.03145
Step 243350: loss = 0.07525
Step 243355: loss = 0.03990
Step 243360: loss = 0.13461
Step 243365: loss = 0.14859
Step 243370: loss = 0.04472
Step 243375: loss = 0.13729
Step 243380: loss = 0.07221
Step 243385: loss = 0.02265
Step 243390: loss = 0.07924
Step 243395: loss = 0.03321
Step 243400: loss = 0.02443
Step 243405: loss = 0.07078
Step 243410: loss = 0.18634
Step 243415: loss = 0.16602
Step 243420: loss = 0.10594
Step 243425: loss = 0.06632
Step 243430: loss = 0.09334
Step 243435: loss = 0.03446
Step 243440: loss = 0.04085
Step 243445: loss = 0.03608
Step 243450: loss = 0.04645
Step 243455: loss = 0.11454
Step 243460: loss = 0.09839
Step 243465: loss = 0.16715
Step 243470: loss = 0.32640
Step 243475: loss = 0.03725
Step 243480: loss = 0.05195
Step 243485: loss = 0.03116
Step 243490: loss = 0.04153
Step 243495: loss = 0.09348
Step 243500: loss = 0.32110
Step 243505: loss = 0.21676
Step 243510: loss = 0.06138
Step 243515: loss = 0.21073
Step 243520: loss = 0.04797
Step 243525: loss = 0.02013
Step 243530: loss = 0.03143
Step 243535: loss = 0.10990
Step 243540: loss = 0.03734
Step 243545: loss = 0.03807
Step 243550: loss = 0.20139
Step 243555: loss = 0.04531
Step 243560: loss = 0.03252
Step 243565: loss = 0.11142
Step 243570: loss = 0.14652
Step 243575: loss = 0.04159
Step 243580: loss = 0.06564
Step 243585: loss = 0.05715
Step 243590: loss = 0.24017
Step 243595: loss = 0.06087
Step 243600: loss = 0.10681
Step 243605: loss = 0.17159
Step 243610: loss = 0.02925
Step 243615: loss = 0.10798
Step 243620: loss = 0.08775
Step 243625: loss = 0.31279
Step 243630: loss = 0.19349
Step 243635: loss = 0.06763
Step 243640: loss = 0.13797
Step 243645: loss = 0.07504
Step 243650: loss = 0.04654
Step 243655: loss = 0.06107
Step 243660: loss = 0.04834
Step 243665: loss = 0.15186
Step 243670: loss = 0.53335
Step 243675: loss = 0.04459
Step 243680: loss = 0.27945
Step 243685: loss = 0.09561
Step 243690: loss = 0.09236
Step 243695: loss = 0.10182
Step 243700: loss = 0.40271
Step 243705: loss = 0.20167
Step 243710: loss = 0.05865
Step 243715: loss = 0.06196
Step 243720: loss = 0.11014
Step 243725: loss = 0.02303
Step 243730: loss = 0.14508
Step 243735: loss = 0.08318
Step 243740: loss = 0.15615
Step 243745: loss = 0.20666
Step 243750: loss = 0.02292
Step 243755: loss = 0.03526
Step 243760: loss = 0.14003
Step 243765: loss = 0.03380
Step 243770: loss = 0.01780
Step 243775: loss = 0.07564
Step 243780: loss = 0.12513
Step 243785: loss = 0.16048
Step 243790: loss = 0.03635
Step 243795: loss = 0.01509
Step 243800: loss = 0.01722
Step 243805: loss = 0.20011
Step 243810: loss = 0.11789
Step 243815: loss = 0.18673
Step 243820: loss = 0.06047
Step 243825: loss = 0.06716
Step 243830: loss = 0.19521
Step 243835: loss = 0.19407
Step 243840: loss = 0.13310
Step 243845: loss = 0.06007
Step 243850: loss = 0.06302
Step 243855: loss = 0.18161
Step 243860: loss = 0.34745
Step 243865: loss = 0.05063
Step 243870: loss = 0.05184
Step 243875: loss = 0.08189
Step 243880: loss = 0.02958
Step 243885: loss = 0.25625
Step 243890: loss = 0.01720
Step 243895: loss = 0.06666
Step 243900: loss = 0.06605
Step 243905: loss = 0.10989
Step 243910: loss = 0.07483
Step 243915: loss = 0.15639
Step 243920: loss = 0.16243
Step 243925: loss = 0.09471
Step 243930: loss = 0.07300
Step 243935: loss = 0.07506
Step 243940: loss = 0.13405
Step 243945: loss = 0.08533
Step 243950: loss = 0.13600
Step 243955: loss = 0.12065
Step 243960: loss = 0.09114
Step 243965: loss = 0.17498
Step 243970: loss = 0.12673
Step 243975: loss = 0.08173
Step 243980: loss = 0.04702
Step 243985: loss = 0.11213
Step 243990: loss = 0.03372
Step 243995: loss = 0.07342
Step 244000: loss = 0.08136
Training Data Eval:
  Num examples: 50000, Num correct: 48555, Precision @ 1: 0.9711
('Testing Data Eval: EPOCH->', 245)
  Num examples: 10000, Num correct: 6630, Precision @ 1: 0.6630
Step 244005: loss = 0.08279
Step 244010: loss = 0.07367
Step 244015: loss = 0.14329
Step 244020: loss = 0.06940
Step 244025: loss = 0.05450
Step 244030: loss = 0.05864
Step 244035: loss = 0.22308
Step 244040: loss = 0.04066
Step 244045: loss = 0.04778
Step 244050: loss = 0.15691
Step 244055: loss = 0.05466
Step 244060: loss = 0.08346
Step 244065: loss = 0.04337
Step 244070: loss = 0.06446
Step 244075: loss = 0.03750
Step 244080: loss = 0.03599
Step 244085: loss = 0.06025
Step 244090: loss = 0.08642
Step 244095: loss = 0.05096
Step 244100: loss = 0.02783
Step 244105: loss = 0.02444
Step 244110: loss = 0.14337
Step 244115: loss = 0.05035
Step 244120: loss = 0.06314
Step 244125: loss = 0.22877
Step 244130: loss = 0.03266
Step 244135: loss = 0.06046
Step 244140: loss = 0.04279
Step 244145: loss = 0.07957
Step 244150: loss = 0.03831
Step 244155: loss = 0.03140
Step 244160: loss = 0.04348
Step 244165: loss = 0.01753
Step 244170: loss = 0.02311
Step 244175: loss = 0.07226
Step 244180: loss = 0.07145
Step 244185: loss = 0.10063
Step 244190: loss = 0.03666
Step 244195: loss = 0.03048
Step 244200: loss = 0.18658
Step 244205: loss = 0.09799
Step 244210: loss = 0.15524
Step 244215: loss = 0.12734
Step 244220: loss = 0.01300
Step 244225: loss = 0.05398
Step 244230: loss = 0.01314
Step 244235: loss = 0.11146
Step 244240: loss = 0.02720
Step 244245: loss = 0.12992
Step 244250: loss = 0.12682
Step 244255: loss = 0.01272
Step 244260: loss = 0.03250
Step 244265: loss = 0.06977
Step 244270: loss = 0.11095
Step 244275: loss = 0.04184
Step 244280: loss = 0.04583
Step 244285: loss = 0.34014
Step 244290: loss = 0.09427
Step 244295: loss = 0.02700
Step 244300: loss = 0.10624
Step 244305: loss = 0.02516
Step 244310: loss = 0.02334
Step 244315: loss = 0.04752
Step 244320: loss = 0.10109
Step 244325: loss = 0.19888
Step 244330: loss = 0.06654
Step 244335: loss = 0.19042
Step 244340: loss = 0.06970
Step 244345: loss = 0.19880
Step 244350: loss = 0.08220
Step 244355: loss = 0.22071
Step 244360: loss = 0.02721
Step 244365: loss = 0.06134
Step 244370: loss = 0.09488
Step 244375: loss = 0.10197
Step 244380: loss = 0.09763
Step 244385: loss = 0.03170
Step 244390: loss = 0.01345
Step 244395: loss = 0.06264
Step 244400: loss = 0.07183
Step 244405: loss = 0.12199
Step 244410: loss = 0.11865
Step 244415: loss = 0.06956
Step 244420: loss = 0.11093
Step 244425: loss = 0.15439
Step 244430: loss = 0.07524
Step 244435: loss = 0.07554
Step 244440: loss = 0.02107
Step 244445: loss = 0.07834
Step 244450: loss = 0.06585
Step 244455: loss = 0.21938
Step 244460: loss = 0.05999
Step 244465: loss = 0.30932
Step 244470: loss = 0.02629
Step 244475: loss = 0.04301
Step 244480: loss = 0.04822
Step 244485: loss = 0.10261
Step 244490: loss = 0.30508
Step 244495: loss = 0.52438
Step 244500: loss = 0.05266
Step 244505: loss = 0.17469
Step 244510: loss = 0.06532
Step 244515: loss = 0.09652
Step 244520: loss = 0.21587
Step 244525: loss = 0.17863
Step 244530: loss = 0.20379
Step 244535: loss = 0.02194
Step 244540: loss = 0.04311
Step 244545: loss = 0.06604
Step 244550: loss = 0.12908
Step 244555: loss = 0.00652
Step 244560: loss = 0.04048
Step 244565: loss = 0.06599
Step 244570: loss = 0.05938
Step 244575: loss = 0.13094
Step 244580: loss = 0.04487
Step 244585: loss = 0.09269
Step 244590: loss = 0.05088
Step 244595: loss = 0.13899
Step 244600: loss = 0.03467
Step 244605: loss = 0.05033
Step 244610: loss = 0.10745
Step 244615: loss = 0.05243
Step 244620: loss = 0.03685
Step 244625: loss = 0.17143
Step 244630: loss = 0.09121
Step 244635: loss = 0.04615
Step 244640: loss = 0.09074
Step 244645: loss = 0.09113
Step 244650: loss = 0.03823
Step 244655: loss = 0.03616
Step 244660: loss = 0.03479
Step 244665: loss = 0.27915
Step 244670: loss = 0.11204
Step 244675: loss = 0.01823
Step 244680: loss = 0.12403
Step 244685: loss = 0.18130
Step 244690: loss = 0.13193
Step 244695: loss = 0.06813
Step 244700: loss = 0.10448
Step 244705: loss = 0.17267
Step 244710: loss = 0.15392
Step 244715: loss = 0.15017
Step 244720: loss = 0.08818
Step 244725: loss = 0.09850
Step 244730: loss = 0.07950
Step 244735: loss = 0.05466
Step 244740: loss = 0.07952
Step 244745: loss = 0.06988
Step 244750: loss = 0.03293
Step 244755: loss = 0.04208
Step 244760: loss = 0.08114
Step 244765: loss = 0.11810
Step 244770: loss = 0.14647
Step 244775: loss = 0.05783
Step 244780: loss = 0.06739
Step 244785: loss = 0.05065
Step 244790: loss = 0.07568
Step 244795: loss = 0.13058
Step 244800: loss = 0.03610
Step 244805: loss = 0.05972
Step 244810: loss = 0.23321
Step 244815: loss = 0.06412
Step 244820: loss = 0.02705
Step 244825: loss = 0.09275
Step 244830: loss = 0.08144
Step 244835: loss = 0.08294
Step 244840: loss = 0.10470
Step 244845: loss = 0.10738
Step 244850: loss = 0.17319
Step 244855: loss = 0.04906
Step 244860: loss = 0.06876
Step 244865: loss = 0.09280
Step 244870: loss = 0.13057
Step 244875: loss = 0.07060
Step 244880: loss = 0.07047
Step 244885: loss = 0.15391
Step 244890: loss = 0.11011
Step 244895: loss = 0.02066
Step 244900: loss = 0.03744
Step 244905: loss = 0.01317
Step 244910: loss = 0.05565
Step 244915: loss = 0.15758
Step 244920: loss = 0.01974
Step 244925: loss = 0.07880
Step 244930: loss = 0.02942
Step 244935: loss = 0.07605
Step 244940: loss = 0.04481
Step 244945: loss = 0.03224
Step 244950: loss = 0.05817
Step 244955: loss = 0.17057
Step 244960: loss = 0.05767
Step 244965: loss = 0.16035
Step 244970: loss = 0.06922
Step 244975: loss = 0.06807
Step 244980: loss = 0.05268
Step 244985: loss = 0.13353
Step 244990: loss = 0.11531
Step 244995: loss = 0.09849
Step 245000: loss = 0.03589
Training Data Eval:
  Num examples: 50000, Num correct: 48361, Precision @ 1: 0.9672
('Testing Data Eval: EPOCH->', 246)
  Num examples: 10000, Num correct: 6663, Precision @ 1: 0.6663
Step 245005: loss = 0.03843
Step 245010: loss = 0.01701
Step 245015: loss = 0.13449
Step 245020: loss = 0.06483
Step 245025: loss = 0.05053
Step 245030: loss = 0.09509
Step 245035: loss = 0.13954
Step 245040: loss = 0.18084
Step 245045: loss = 0.10317
Step 245050: loss = 0.16480
Step 245055: loss = 0.08591
Step 245060: loss = 0.18938
Step 245065: loss = 0.05997
Step 245070: loss = 0.06920
Step 245075: loss = 0.04664
Step 245080: loss = 0.14857
Step 245085: loss = 0.06054
Step 245090: loss = 0.04533
Step 245095: loss = 0.02281
Step 245100: loss = 0.01586
Step 245105: loss = 0.16213
Step 245110: loss = 0.26032
Step 245115: loss = 0.02874
Step 245120: loss = 0.17640
Step 245125: loss = 0.10329
Step 245130: loss = 0.06739
Step 245135: loss = 0.07725
Step 245140: loss = 0.18710
Step 245145: loss = 0.05305
Step 245150: loss = 0.20194
Step 245155: loss = 0.04143
Step 245160: loss = 0.03448
Step 245165: loss = 0.15287
Step 245170: loss = 0.09366
Step 245175: loss = 0.06781
Step 245180: loss = 0.12394
Step 245185: loss = 0.29331
Step 245190: loss = 0.03500
Step 245195: loss = 0.21039
Step 245200: loss = 0.06275
Step 245205: loss = 0.16465
Step 245210: loss = 0.04204
Step 245215: loss = 0.12747
Step 245220: loss = 0.02625
Step 245225: loss = 0.14935
Step 245230: loss = 0.08912
Step 245235: loss = 0.13461
Step 245240: loss = 0.02322
Step 245245: loss = 0.02844
Step 245250: loss = 0.18830
Step 245255: loss = 0.03971
Step 245260: loss = 0.05955
Step 245265: loss = 0.15956
Step 245270: loss = 0.03928
Step 245275: loss = 0.13397
Step 245280: loss = 0.11706
Step 245285: loss = 0.02162
Step 245290: loss = 0.12022
Step 245295: loss = 0.07754
Step 245300: loss = 0.21227
Step 245305: loss = 0.17873
Step 245310: loss = 0.05875
Step 245315: loss = 0.24191
Step 245320: loss = 0.12382
Step 245325: loss = 0.15432
Step 245330: loss = 0.07463
Step 245335: loss = 0.03433
Step 245340: loss = 0.06677
Step 245345: loss = 0.03000
Step 245350: loss = 0.10044
Step 245355: loss = 0.06431
Step 245360: loss = 0.15163
Step 245365: loss = 0.18954
Step 245370: loss = 0.06128
Step 245375: loss = 0.00512
Step 245380: loss = 0.02661
Step 245385: loss = 0.08687
Step 245390: loss = 0.02201
Step 245395: loss = 0.05368
Step 245400: loss = 0.09220
Step 245405: loss = 0.15934
Step 245410: loss = 0.01327
Step 245415: loss = 0.06557
Step 245420: loss = 0.07672
Step 245425: loss = 0.05856
Step 245430: loss = 0.05868
Step 245435: loss = 0.02996
Step 245440: loss = 0.02665
Step 245445: loss = 0.06959
Step 245450: loss = 0.16561
Step 245455: loss = 0.06723
Step 245460: loss = 0.02727
Step 245465: loss = 0.25211
Step 245470: loss = 0.45033
Step 245475: loss = 0.07091
Step 245480: loss = 0.13436
Step 245485: loss = 0.19032
Step 245490: loss = 0.09780
Step 245495: loss = 0.18169
Step 245500: loss = 0.09398
Step 245505: loss = 0.06239
Step 245510: loss = 0.09961
Step 245515: loss = 0.08055
Step 245520: loss = 0.36468
Step 245525: loss = 0.01985
Step 245530: loss = 0.15278
Step 245535: loss = 0.05630
Step 245540: loss = 0.04072
Step 245545: loss = 0.13534
Step 245550: loss = 0.16967
Step 245555: loss = 0.04460
Step 245560: loss = 0.07494
Step 245565: loss = 0.06735
Step 245570: loss = 0.05542
Step 245575: loss = 0.11385
Step 245580: loss = 0.06881
Step 245585: loss = 0.08256
Step 245590: loss = 0.07807
Step 245595: loss = 0.11235
Step 245600: loss = 0.02434
Step 245605: loss = 0.11311
Step 245610: loss = 0.06390
Step 245615: loss = 0.25287
Step 245620: loss = 0.14842
Step 245625: loss = 0.22703
Step 245630: loss = 0.02363
Step 245635: loss = 0.08564
Step 245640: loss = 0.07383
Step 245645: loss = 0.08011
Step 245650: loss = 0.06507
Step 245655: loss = 0.04696
Step 245660: loss = 0.12029
Step 245665: loss = 0.03214
Step 245670: loss = 0.03052
Step 245675: loss = 0.14338
Step 245680: loss = 0.01885
Step 245685: loss = 0.03488
Step 245690: loss = 0.04414
Step 245695: loss = 0.08896
Step 245700: loss = 0.06340
Step 245705: loss = 0.04621
Step 245710: loss = 0.03117
Step 245715: loss = 0.18671
Step 245720: loss = 0.07378
Step 245725: loss = 0.06511
Step 245730: loss = 0.06640
Step 245735: loss = 0.11091
Step 245740: loss = 0.11219
Step 245745: loss = 0.06854
Step 245750: loss = 0.27823
Step 245755: loss = 0.02857
Step 245760: loss = 0.08583
Step 245765: loss = 0.16335
Step 245770: loss = 0.09608
Step 245775: loss = 0.11127
Step 245780: loss = 0.11625
Step 245785: loss = 0.02282
Step 245790: loss = 0.07172
Step 245795: loss = 0.06964
Step 245800: loss = 0.04750
Step 245805: loss = 0.10959
Step 245810: loss = 0.31750
Step 245815: loss = 0.21375
Step 245820: loss = 0.02636
Step 245825: loss = 0.09088
Step 245830: loss = 0.11283
Step 245835: loss = 0.03341
Step 245840: loss = 0.04399
Step 245845: loss = 0.02554
Step 245850: loss = 0.05978
Step 245855: loss = 0.45786
Step 245860: loss = 0.05129
Step 245865: loss = 0.02781
Step 245870: loss = 0.17972
Step 245875: loss = 0.05247
Step 245880: loss = 0.05053
Step 245885: loss = 0.05181
Step 245890: loss = 0.30374
Step 245895: loss = 0.09913
Step 245900: loss = 0.10556
Step 245905: loss = 0.13599
Step 245910: loss = 0.06402
Step 245915: loss = 0.05101
Step 245920: loss = 0.28300
Step 245925: loss = 0.04478
Step 245930: loss = 0.02215
Step 245935: loss = 0.02830
Step 245940: loss = 0.07018
Step 245945: loss = 0.04242
Step 245950: loss = 0.16475
Step 245955: loss = 0.26865
Step 245960: loss = 0.01293
Step 245965: loss = 0.33594
Step 245970: loss = 0.04991
Step 245975: loss = 0.04785
Step 245980: loss = 0.13171
Step 245985: loss = 0.03698
Step 245990: loss = 0.06023
Step 245995: loss = 0.08615
Step 246000: loss = 0.03038
Training Data Eval:
  Num examples: 50000, Num correct: 48553, Precision @ 1: 0.9711
('Testing Data Eval: EPOCH->', 247)
  Num examples: 10000, Num correct: 6784, Precision @ 1: 0.6784
Step 246005: loss = 0.03125
Step 246010: loss = 0.09751
Step 246015: loss = 0.02950
Step 246020: loss = 0.06390
Step 246025: loss = 0.19855
Step 246030: loss = 0.05104
Step 246035: loss = 0.05264
Step 246040: loss = 0.07788
Step 246045: loss = 0.14242
Step 246050: loss = 0.15498
Step 246055: loss = 0.21143
Step 246060: loss = 0.03719
Step 246065: loss = 0.12915
Step 246070: loss = 0.09070
Step 246075: loss = 0.00983
Step 246080: loss = 0.09537
Step 246085: loss = 0.05326
Step 246090: loss = 0.14561
Step 246095: loss = 0.03642
Step 246100: loss = 0.03067
Step 246105: loss = 0.01835
Step 246110: loss = 0.09445
Step 246115: loss = 0.00949
Step 246120: loss = 0.05900
Step 246125: loss = 0.05585
Step 246130: loss = 0.14070
Step 246135: loss = 0.11685
Step 246140: loss = 0.10219
Step 246145: loss = 0.02435
Step 246150: loss = 0.05237
Step 246155: loss = 0.16165
Step 246160: loss = 0.09378
Step 246165: loss = 0.05681
Step 246170: loss = 0.13736
Step 246175: loss = 0.16149
Step 246180: loss = 0.07516
Step 246185: loss = 0.04970
Step 246190: loss = 0.07867
Step 246195: loss = 0.09774
Step 246200: loss = 0.04975
Step 246205: loss = 0.16103
Step 246210: loss = 0.07209
Step 246215: loss = 0.08762
Step 246220: loss = 0.04056
Step 246225: loss = 0.10501
Step 246230: loss = 0.02791
Step 246235: loss = 0.06657
Step 246240: loss = 0.12566
Step 246245: loss = 0.13730
Step 246250: loss = 0.05539
Step 246255: loss = 0.06006
Step 246260: loss = 0.09816
Step 246265: loss = 0.11198
Step 246270: loss = 0.04356
Step 246275: loss = 0.01402
Step 246280: loss = 0.05297
Step 246285: loss = 0.10666
Step 246290: loss = 0.02671
Step 246295: loss = 0.02727
Step 246300: loss = 0.01017
Step 246305: loss = 0.02639
Step 246310: loss = 0.12860
Step 246315: loss = 0.02641
Step 246320: loss = 0.02675
Step 246325: loss = 0.04373
Step 246330: loss = 0.02057
Step 246335: loss = 0.05408
Step 246340: loss = 0.21663
Step 246345: loss = 0.02218
Step 246350: loss = 0.15415
Step 246355: loss = 0.14887
Step 246360: loss = 0.09332
Step 246365: loss = 0.10831
Step 246370: loss = 0.18869
Step 246375: loss = 0.03290
Step 246380: loss = 0.06335
Step 246385: loss = 0.04270
Step 246390: loss = 0.04989
Step 246395: loss = 0.21825
Step 246400: loss = 0.02987
Step 246405: loss = 0.07056
Step 246410: loss = 0.09510
Step 246415: loss = 0.03548
Step 246420: loss = 0.03517
Step 246425: loss = 0.12621
Step 246430: loss = 0.01955
Step 246435: loss = 0.03390
Step 246440: loss = 0.03419
Step 246445: loss = 0.15994
Step 246450: loss = 0.15140
Step 246455: loss = 0.07854
Step 246460: loss = 0.01761
Step 246465: loss = 0.08107
Step 246470: loss = 0.03681
Step 246475: loss = 0.04407
Step 246480: loss = 0.02610
Step 246485: loss = 0.01451
Step 246490: loss = 0.08548
Step 246495: loss = 0.02066
Step 246500: loss = 0.04912
Step 246505: loss = 0.13785
Step 246510: loss = 0.02515
Step 246515: loss = 0.03811
Step 246520: loss = 0.04581
Step 246525: loss = 0.03068
Step 246530: loss = 0.04809
Step 246535: loss = 0.08014
Step 246540: loss = 0.07834
Step 246545: loss = 0.02034
Step 246550: loss = 0.12450
Step 246555: loss = 0.01662
Step 246560: loss = 0.03650
Step 246565: loss = 0.11112
Step 246570: loss = 0.05574
Step 246575: loss = 0.07056
Step 246580: loss = 0.10501
Step 246585: loss = 0.20337
Step 246590: loss = 0.03836
Step 246595: loss = 0.13683
Step 246600: loss = 0.09598
Step 246605: loss = 0.06677
Step 246610: loss = 0.16205
Step 246615: loss = 0.12526
Step 246620: loss = 0.05644
Step 246625: loss = 0.11523
Step 246630: loss = 0.05500
Step 246635: loss = 0.02874
Step 246640: loss = 0.05350
Step 246645: loss = 0.03663
Step 246650: loss = 0.05745
Step 246655: loss = 0.03466
Step 246660: loss = 0.16750
Step 246665: loss = 0.05657
Step 246670: loss = 0.05069
Step 246675: loss = 0.03684
Step 246680: loss = 0.07301
Step 246685: loss = 0.03618
Step 246690: loss = 0.04062
Step 246695: loss = 0.08860
Step 246700: loss = 0.07727
Step 246705: loss = 0.10453
Step 246710: loss = 0.05272
Step 246715: loss = 0.04658
Step 246720: loss = 0.07609
Step 246725: loss = 0.18611
Step 246730: loss = 0.21177
Step 246735: loss = 0.08927
Step 246740: loss = 0.06641
Step 246745: loss = 0.05795
Step 246750: loss = 0.07276
Step 246755: loss = 0.02594
Step 246760: loss = 0.02634
Step 246765: loss = 0.02324
Step 246770: loss = 0.19357
Step 246775: loss = 0.01263
Step 246780: loss = 0.04493
Step 246785: loss = 0.01313
Step 246790: loss = 0.03004
Step 246795: loss = 0.07952
Step 246800: loss = 0.04566
Step 246805: loss = 0.02916
Step 246810: loss = 0.07616
Step 246815: loss = 0.09863
Step 246820: loss = 0.03614
Step 246825: loss = 0.15447
Step 246830: loss = 0.09323
Step 246835: loss = 0.18836
Step 246840: loss = 0.02507
Step 246845: loss = 0.03419
Step 246850: loss = 0.04554
Step 246855: loss = 0.05312
Step 246860: loss = 0.06426
Step 246865: loss = 0.05595
Step 246870: loss = 0.13233
Step 246875: loss = 0.08332
Step 246880: loss = 0.01657
Step 246885: loss = 0.18230
Step 246890: loss = 0.07605
Step 246895: loss = 0.19928
Step 246900: loss = 0.09132
Step 246905: loss = 0.15631
Step 246910: loss = 0.01578
Step 246915: loss = 0.13613
Step 246920: loss = 0.08052
Step 246925: loss = 0.07152
Step 246930: loss = 0.02954
Step 246935: loss = 0.05203
Step 246940: loss = 0.03908
Step 246945: loss = 0.10951
Step 246950: loss = 0.00447
Step 246955: loss = 0.12329
Step 246960: loss = 0.11142
Step 246965: loss = 0.12977
Step 246970: loss = 0.02213
Step 246975: loss = 0.05342
Step 246980: loss = 0.02674
Step 246985: loss = 0.11664
Step 246990: loss = 0.03691
Step 246995: loss = 0.00995
Step 247000: loss = 0.14803
Training Data Eval:
  Num examples: 50000, Num correct: 48492, Precision @ 1: 0.9698
('Testing Data Eval: EPOCH->', 248)
  Num examples: 10000, Num correct: 6864, Precision @ 1: 0.6864
Step 247005: loss = 0.00391
Step 247010: loss = 0.04370
Step 247015: loss = 0.02050
Step 247020: loss = 0.04720
Step 247025: loss = 0.03539
Step 247030: loss = 0.23756
Step 247035: loss = 0.17259
Step 247040: loss = 0.01710
Step 247045: loss = 0.04231
Step 247050: loss = 0.14868
Step 247055: loss = 0.12428
Step 247060: loss = 0.03643
Step 247065: loss = 0.19648
Step 247070: loss = 0.09199
Step 247075: loss = 0.09169
Step 247080: loss = 0.03261
Step 247085: loss = 0.12874
Step 247090: loss = 0.05028
Step 247095: loss = 0.07881
Step 247100: loss = 0.16691
Step 247105: loss = 0.03793
Step 247110: loss = 0.08616
Step 247115: loss = 0.07206
Step 247120: loss = 0.07317
Step 247125: loss = 0.34455
Step 247130: loss = 0.07050
Step 247135: loss = 0.01671
Step 247140: loss = 0.06327
Step 247145: loss = 0.05688
Step 247150: loss = 0.11530
Step 247155: loss = 0.04572
Step 247160: loss = 0.27165
Step 247165: loss = 0.08884
Step 247170: loss = 0.08070
Step 247175: loss = 0.24829
Step 247180: loss = 0.19466
Step 247185: loss = 0.14838
Step 247190: loss = 0.10935
Step 247195: loss = 0.09799
Step 247200: loss = 0.03586
Step 247205: loss = 0.04684
Step 247210: loss = 0.02849
Step 247215: loss = 0.02591
Step 247220: loss = 0.01878
Step 247225: loss = 0.04440
Step 247230: loss = 0.03869
Step 247235: loss = 0.12900
Step 247240: loss = 0.03026
Step 247245: loss = 0.11328
Step 247250: loss = 0.18134
Step 247255: loss = 0.08260
Step 247260: loss = 0.06553
Step 247265: loss = 0.13181
Step 247270: loss = 0.04570
Step 247275: loss = 0.03243
Step 247280: loss = 0.03154
Step 247285: loss = 0.12638
Step 247290: loss = 0.03346
Step 247295: loss = 0.15459
Step 247300: loss = 0.20201
Step 247305: loss = 0.03921
Step 247310: loss = 0.03399
Step 247315: loss = 0.02308
Step 247320: loss = 0.19882
Step 247325: loss = 0.08099
Step 247330: loss = 0.02012
Step 247335: loss = 0.01794
Step 247340: loss = 0.11099
Step 247345: loss = 0.05587
Step 247350: loss = 0.07474
Step 247355: loss = 0.02253
Step 247360: loss = 0.06409
Step 247365: loss = 0.13202
Step 247370: loss = 0.14011
Step 247375: loss = 0.01648
Step 247380: loss = 0.18921
Step 247385: loss = 0.36718
Step 247390: loss = 0.07613
Step 247395: loss = 0.03688
Step 247400: loss = 0.01834
Step 247405: loss = 0.06793
Step 247410: loss = 0.05462
Step 247415: loss = 0.27953
Step 247420: loss = 0.07620
Step 247425: loss = 0.05533
Step 247430: loss = 0.06536
Step 247435: loss = 0.17257
Step 247440: loss = 0.09729
Step 247445: loss = 0.04883
Step 247450: loss = 0.08832
Step 247455: loss = 0.01838
Step 247460: loss = 0.01751
Step 247465: loss = 0.01005
Step 247470: loss = 0.09343
Step 247475: loss = 0.17729
Step 247480: loss = 0.26976
Step 247485: loss = 0.05123
Step 247490: loss = 0.11447
Step 247495: loss = 0.00572
Step 247500: loss = 0.10880
Step 247505: loss = 0.05237
Step 247510: loss = 0.05961
Step 247515: loss = 0.09577
Step 247520: loss = 0.17275
Step 247525: loss = 0.04697
Step 247530: loss = 0.23660
Step 247535: loss = 0.07327
Step 247540: loss = 0.23253
Step 247545: loss = 0.01633
Step 247550: loss = 0.08492
Step 247555: loss = 0.05767
Step 247560: loss = 0.04999
Step 247565: loss = 0.08794
Step 247570: loss = 0.26867
Step 247575: loss = 0.04509
Step 247580: loss = 0.08667
Step 247585: loss = 0.10146
Step 247590: loss = 0.14668
Step 247595: loss = 0.01177
Step 247600: loss = 0.14943
Step 247605: loss = 0.22490
Step 247610: loss = 0.12811
Step 247615: loss = 0.04867
Step 247620: loss = 0.11905
Step 247625: loss = 0.09624
Step 247630: loss = 0.06081
Step 247635: loss = 0.15750
Step 247640: loss = 0.11140
Step 247645: loss = 0.19336
Step 247650: loss = 0.12629
Step 247655: loss = 0.17380
Step 247660: loss = 0.04886
Step 247665: loss = 0.04509
Step 247670: loss = 0.08769
Step 247675: loss = 0.02787
Step 247680: loss = 0.10192
Step 247685: loss = 0.09022
Step 247690: loss = 0.33365
Step 247695: loss = 0.01779
Step 247700: loss = 0.05480
Step 247705: loss = 0.15311
Step 247710: loss = 0.04482
Step 247715: loss = 0.19352
Step 247720: loss = 0.11897
Step 247725: loss = 0.12052
Step 247730: loss = 0.06666
Step 247735: loss = 0.09815
Step 247740: loss = 0.09123
Step 247745: loss = 0.20208
Step 247750: loss = 0.04212
Step 247755: loss = 0.11731
Step 247760: loss = 0.04719
Step 247765: loss = 0.09446
Step 247770: loss = 0.03691
Step 247775: loss = 0.04299
Step 247780: loss = 0.01004
Step 247785: loss = 0.05040
Step 247790: loss = 0.09277
Step 247795: loss = 0.03741
Step 247800: loss = 0.04442
Step 247805: loss = 0.07467
Step 247810: loss = 0.12584
Step 247815: loss = 0.07820
Step 247820: loss = 0.23565
Step 247825: loss = 0.03943
Step 247830: loss = 0.21470
Step 247835: loss = 0.10476
Step 247840: loss = 0.04121
Step 247845: loss = 0.01737
Step 247850: loss = 0.10274
Step 247855: loss = 0.01452
Step 247860: loss = 0.01814
Step 247865: loss = 0.27369
Step 247870: loss = 0.06485
Step 247875: loss = 0.04979
Step 247880: loss = 0.41880
Step 247885: loss = 0.09061
Step 247890: loss = 0.15783
Step 247895: loss = 0.19618
Step 247900: loss = 0.17616
Step 247905: loss = 0.06548
Step 247910: loss = 0.14839
Step 247915: loss = 0.05937
Step 247920: loss = 0.06306
Step 247925: loss = 0.10530
Step 247930: loss = 0.04619
Step 247935: loss = 0.19759
Step 247940: loss = 0.11827
Step 247945: loss = 0.03455
Step 247950: loss = 0.34385
Step 247955: loss = 0.06081
Step 247960: loss = 0.04507
Step 247965: loss = 0.11562
Step 247970: loss = 0.06923
Step 247975: loss = 0.03616
Step 247980: loss = 0.18713
Step 247985: loss = 0.07260
Step 247990: loss = 0.05052
Step 247995: loss = 0.07393
Step 248000: loss = 0.13010
Training Data Eval:
  Num examples: 50000, Num correct: 48701, Precision @ 1: 0.9740
('Testing Data Eval: EPOCH->', 249)
  Num examples: 10000, Num correct: 6754, Precision @ 1: 0.6754
Step 248005: loss = 0.04099
Step 248010: loss = 0.24024
Step 248015: loss = 0.09141
Step 248020: loss = 0.06269
Step 248025: loss = 0.08972
Step 248030: loss = 0.10308
Step 248035: loss = 0.06005
Step 248040: loss = 0.02365
Step 248045: loss = 0.09613
Step 248050: loss = 0.31008
Step 248055: loss = 0.08664
Step 248060: loss = 0.05599
Step 248065: loss = 0.09679
Step 248070: loss = 0.05812
Step 248075: loss = 0.03155
Step 248080: loss = 0.11322
Step 248085: loss = 0.08111
Step 248090: loss = 0.01947
Step 248095: loss = 0.02896
Step 248100: loss = 0.13715
Step 248105: loss = 0.07150
Step 248110: loss = 0.08601
Step 248115: loss = 0.10006
Step 248120: loss = 0.15802
Step 248125: loss = 0.13741
Step 248130: loss = 0.05966
Step 248135: loss = 0.05453
Step 248140: loss = 0.36185
Step 248145: loss = 0.08165
Step 248150: loss = 0.14665
Step 248155: loss = 0.03796
Step 248160: loss = 0.07305
Step 248165: loss = 0.10967
Step 248170: loss = 0.26880
Step 248175: loss = 0.06623
Step 248180: loss = 0.07088
Step 248185: loss = 0.16333
Step 248190: loss = 0.11596
Step 248195: loss = 0.18532
Step 248200: loss = 0.28778
Step 248205: loss = 0.05216
Step 248210: loss = 0.06860
Step 248215: loss = 0.19622
Step 248220: loss = 0.03979
Step 248225: loss = 0.04029
Step 248230: loss = 0.04221
Step 248235: loss = 0.05749
Step 248240: loss = 0.13783
Step 248245: loss = 0.05383
Step 248250: loss = 0.03912
Step 248255: loss = 0.23861
Step 248260: loss = 0.06971
Step 248265: loss = 0.07997
Step 248270: loss = 0.02511
Step 248275: loss = 0.04087
Step 248280: loss = 0.10805
Step 248285: loss = 0.10891
Step 248290: loss = 0.07245
Step 248295: loss = 0.03486
Step 248300: loss = 0.03721
Step 248305: loss = 0.12593
Step 248310: loss = 0.01098
Step 248315: loss = 0.18719
Step 248320: loss = 0.26190
Step 248325: loss = 0.18984
Step 248330: loss = 0.08147
Step 248335: loss = 0.07071
Step 248340: loss = 0.01924
Step 248345: loss = 0.25975
Step 248350: loss = 0.16003
Step 248355: loss = 0.03772
Step 248360: loss = 0.03374
Step 248365: loss = 0.19640
Step 248370: loss = 0.16748
Step 248375: loss = 0.16264
Step 248380: loss = 0.06089
Step 248385: loss = 0.09373
Step 248390: loss = 0.10805
Step 248395: loss = 0.05126
Step 248400: loss = 0.11825
Step 248405: loss = 0.08559
Step 248410: loss = 0.06739
Step 248415: loss = 0.12989
Step 248420: loss = 0.20473
Step 248425: loss = 0.17345
Step 248430: loss = 0.02378
Step 248435: loss = 0.17205
Step 248440: loss = 0.15973
Step 248445: loss = 0.20643
Step 248450: loss = 0.03814
Step 248455: loss = 0.05254
Step 248460: loss = 0.04625
Step 248465: loss = 0.05563
Step 248470: loss = 0.15621
Step 248475: loss = 0.06932
Step 248480: loss = 0.05813
Step 248485: loss = 0.03994
Step 248490: loss = 0.08052
Step 248495: loss = 0.08998
Step 248500: loss = 0.00900
Step 248505: loss = 0.10008
Step 248510: loss = 0.21515
Step 248515: loss = 0.14063
Step 248520: loss = 0.01694
Step 248525: loss = 0.06155
Step 248530: loss = 0.01458
Step 248535: loss = 0.13741
Step 248540: loss = 0.05275
Step 248545: loss = 0.07842
Step 248550: loss = 0.02355
Step 248555: loss = 0.04466
Step 248560: loss = 0.10429
Step 248565: loss = 0.04227
Step 248570: loss = 0.07868
Step 248575: loss = 0.04090
Step 248580: loss = 0.13707
Step 248585: loss = 0.02492
Step 248590: loss = 0.16004
Step 248595: loss = 0.03100
Step 248600: loss = 0.02458
Step 248605: loss = 0.10871
Step 248610: loss = 0.02371
Step 248615: loss = 0.01338
Step 248620: loss = 0.11038
Step 248625: loss = 0.04549
Step 248630: loss = 0.03037
Step 248635: loss = 0.09754
Step 248640: loss = 0.10719
Step 248645: loss = 0.16517
Step 248650: loss = 0.07704
Step 248655: loss = 0.02723
Step 248660: loss = 0.01772
Step 248665: loss = 0.05085
Step 248670: loss = 0.02673
Step 248675: loss = 0.09941
Step 248680: loss = 0.07902
Step 248685: loss = 0.09578
Step 248690: loss = 0.06949
Step 248695: loss = 0.07748
Step 248700: loss = 0.06517
Step 248705: loss = 0.18470
Step 248710: loss = 0.17060
Step 248715: loss = 0.09595
Step 248720: loss = 0.08926
Step 248725: loss = 0.04401
Step 248730: loss = 0.03660
Step 248735: loss = 0.03037
Step 248740: loss = 0.11723
Step 248745: loss = 0.14086
Step 248750: loss = 0.12604
Step 248755: loss = 0.03846
Step 248760: loss = 0.04207
Step 248765: loss = 0.02143
Step 248770: loss = 0.02349
Step 248775: loss = 0.13177
Step 248780: loss = 0.10019
Step 248785: loss = 0.05127
Step 248790: loss = 0.15961
Step 248795: loss = 0.11048
Step 248800: loss = 0.08804
Step 248805: loss = 0.07245
Step 248810: loss = 0.07212
Step 248815: loss = 0.05311
Step 248820: loss = 0.07556
Step 248825: loss = 0.02475
Step 248830: loss = 0.14570
Step 248835: loss = 0.04976
Step 248840: loss = 0.09847
Step 248845: loss = 0.04497
Step 248850: loss = 0.08128
Step 248855: loss = 0.18617
Step 248860: loss = 0.12420
Step 248865: loss = 0.08162
Step 248870: loss = 0.09733
Step 248875: loss = 0.02192
Step 248880: loss = 0.03310
Step 248885: loss = 0.05746
Step 248890: loss = 0.09360
Step 248895: loss = 0.05988
Step 248900: loss = 0.02186
Step 248905: loss = 0.02233
Step 248910: loss = 0.07726
Step 248915: loss = 0.18071
Step 248920: loss = 0.18868
Step 248925: loss = 0.59308
Step 248930: loss = 0.01767
Step 248935: loss = 0.10164
Step 248940: loss = 0.31810
Step 248945: loss = 0.15569
Step 248950: loss = 0.05950
Step 248955: loss = 0.04343
Step 248960: loss = 0.28543
Step 248965: loss = 0.03130
Step 248970: loss = 0.08186
Step 248975: loss = 0.16758
Step 248980: loss = 0.09144
Step 248985: loss = 0.03176
Step 248990: loss = 0.16419
Step 248995: loss = 0.03560
Step 249000: loss = 0.05266
Training Data Eval:
  Num examples: 50000, Num correct: 48481, Precision @ 1: 0.9696
('Testing Data Eval: EPOCH->', 250)
  Num examples: 10000, Num correct: 6701, Precision @ 1: 0.6701
Step 249005: loss = 0.05345
Step 249010: loss = 0.07263
Step 249015: loss = 0.04437
Step 249020: loss = 0.33487
Step 249025: loss = 0.03319
Step 249030: loss = 0.03829
Step 249035: loss = 0.08040
Step 249040: loss = 0.17905
Step 249045: loss = 0.01951
Step 249050: loss = 0.08698
Step 249055: loss = 0.01243
Step 249060: loss = 0.02439
Step 249065: loss = 0.06402
Step 249070: loss = 0.05002
Step 249075: loss = 0.05051
Step 249080: loss = 0.06546
Step 249085: loss = 0.02492
Step 249090: loss = 0.12002
Step 249095: loss = 0.10131
Step 249100: loss = 0.17406
Step 249105: loss = 0.12133
Step 249110: loss = 0.03366
Step 249115: loss = 0.02326
Step 249120: loss = 0.05500
Step 249125: loss = 0.08048
Step 249130: loss = 0.01479
Step 249135: loss = 0.09743
Step 249140: loss = 0.04838
Step 249145: loss = 0.25637
Step 249150: loss = 0.02835
Step 249155: loss = 0.07717
Step 249160: loss = 0.10300
Step 249165: loss = 0.16481
Step 249170: loss = 0.06440
Step 249175: loss = 0.04048
Step 249180: loss = 0.16353
Step 249185: loss = 0.04592
Step 249190: loss = 0.11786
Step 249195: loss = 0.03430
Step 249200: loss = 0.19459
Step 249205: loss = 0.08572
Step 249210: loss = 0.14163
Step 249215: loss = 0.02728
Step 249220: loss = 0.20857
Step 249225: loss = 0.13900
Step 249230: loss = 0.16818
Step 249235: loss = 0.03170
Step 249240: loss = 0.10386
Step 249245: loss = 0.05415
Step 249250: loss = 0.11321
Step 249255: loss = 0.14914
Step 249260: loss = 0.12476
Step 249265: loss = 0.02209
Step 249270: loss = 0.02806
Step 249275: loss = 0.03585
Step 249280: loss = 0.13694
Step 249285: loss = 0.28843
Step 249290: loss = 0.26955
Step 249295: loss = 0.07739
Step 249300: loss = 0.02351
Step 249305: loss = 0.04692
Step 249310: loss = 0.11684
Step 249315: loss = 0.01851
Step 249320: loss = 0.03113
Step 249325: loss = 0.29008
Step 249330: loss = 0.02099
Step 249335: loss = 0.05324
Step 249340: loss = 0.05150
Step 249345: loss = 0.07630
Step 249350: loss = 0.06061
Step 249355: loss = 0.08699
Step 249360: loss = 0.06489
Step 249365: loss = 0.03519
Step 249370: loss = 0.03434
Step 249375: loss = 0.06694
Step 249380: loss = 0.04179
Step 249385: loss = 0.13542
Step 249390: loss = 0.11372
Step 249395: loss = 0.02311
Step 249400: loss = 0.02277
Step 249405: loss = 0.12927
Step 249410: loss = 0.09615
Step 249415: loss = 0.08511
Step 249420: loss = 0.11445
Step 249425: loss = 0.12265
Step 249430: loss = 0.04718
Step 249435: loss = 0.18343
Step 249440: loss = 0.01496
Step 249445: loss = 0.03482
Step 249450: loss = 0.07176
Step 249455: loss = 0.09796
Step 249460: loss = 0.10812
Step 249465: loss = 0.04399
Step 249470: loss = 0.11016
Step 249475: loss = 0.19117
Step 249480: loss = 0.11022
Step 249485: loss = 0.05212
Step 249490: loss = 0.03392
Step 249495: loss = 0.01993
Step 249500: loss = 0.30102
Step 249505: loss = 0.06656
Step 249510: loss = 0.05255
Step 249515: loss = 0.08886
Step 249520: loss = 0.03300
Step 249525: loss = 0.09889
Step 249530: loss = 0.06842
Step 249535: loss = 0.15053
Step 249540: loss = 0.04288
Step 249545: loss = 0.07998
Step 249550: loss = 0.09713
Step 249555: loss = 0.05266
Step 249560: loss = 0.09056
Step 249565: loss = 0.13747
Step 249570: loss = 0.02758
Step 249575: loss = 0.06801
Step 249580: loss = 0.11564
Step 249585: loss = 0.04940
Step 249590: loss = 0.17037
Step 249595: loss = 0.17962
Step 249600: loss = 0.04121
Step 249605: loss = 0.09488
Step 249610: loss = 0.04643
Step 249615: loss = 0.02726
Step 249620: loss = 0.16262
Step 249625: loss = 0.03150
Step 249630: loss = 0.13378
Step 249635: loss = 0.02572
Step 249640: loss = 0.14284
Step 249645: loss = 0.16749
Step 249650: loss = 0.33600
Step 249655: loss = 0.04538
Step 249660: loss = 0.09140
Step 249665: loss = 0.10905
Step 249670: loss = 0.02565
Step 249675: loss = 0.04306
Step 249680: loss = 0.06476
Step 249685: loss = 0.03248
Step 249690: loss = 0.16286
Step 249695: loss = 0.26591
Step 249700: loss = 0.07962
Step 249705: loss = 0.20256
Step 249710: loss = 0.03124
Step 249715: loss = 0.01135
Step 249720: loss = 0.06193
Step 249725: loss = 0.11822
Step 249730: loss = 0.19764
Step 249735: loss = 0.02491
Step 249740: loss = 0.05693
Step 249745: loss = 0.09532
Step 249750: loss = 0.18800
Step 249755: loss = 0.15997
Step 249760: loss = 0.26268
Step 249765: loss = 0.01568
Step 249770: loss = 0.04548
Step 249775: loss = 0.02925
Step 249780: loss = 0.08949
Step 249785: loss = 0.06680
Step 249790: loss = 0.06608
Step 249795: loss = 0.03444
Step 249800: loss = 0.10427
Step 249805: loss = 0.12950
Step 249810: loss = 0.05295
Step 249815: loss = 0.11109
Step 249820: loss = 0.09262
Step 249825: loss = 0.22782
Step 249830: loss = 0.04371
Step 249835: loss = 0.06395
Step 249840: loss = 0.03717
Step 249845: loss = 0.04403
Step 249850: loss = 0.03162
Step 249855: loss = 0.04198
Step 249860: loss = 0.04600
Step 249865: loss = 0.02660
Step 249870: loss = 0.04655
Step 249875: loss = 0.02780
Step 249880: loss = 0.20746
Step 249885: loss = 0.08287
Step 249890: loss = 0.08780
Step 249895: loss = 0.07576
Step 249900: loss = 0.16859
Step 249905: loss = 0.04483
Step 249910: loss = 0.07682
Step 249915: loss = 0.21490
Step 249920: loss = 0.06042
Step 249925: loss = 0.17914
Step 249930: loss = 0.05083
Step 249935: loss = 0.02547
Step 249940: loss = 0.12792
Step 249945: loss = 0.09862
Step 249950: loss = 0.10639
Step 249955: loss = 0.12678
Step 249960: loss = 0.01777
Step 249965: loss = 0.02568
Step 249970: loss = 0.06176
Step 249975: loss = 0.04974
Step 249980: loss = 0.09070
Step 249985: loss = 0.14744
Step 249990: loss = 0.22425
Step 249995: loss = 0.07297
Step 250000: loss = 0.01323
Training Data Eval:
  Num examples: 50000, Num correct: 48512, Precision @ 1: 0.9702
('Testing Data Eval: EPOCH->', 251)
  Num examples: 10000, Num correct: 6698, Precision @ 1: 0.6698
Step 250005: loss = 0.05814
Step 250010: loss = 0.02858
Step 250015: loss = 0.02017
Step 250020: loss = 0.03404
Step 250025: loss = 0.09110
Step 250030: loss = 0.03534
Step 250035: loss = 0.02374
Step 250040: loss = 0.05176
Step 250045: loss = 0.08703
Step 250050: loss = 0.11624
Step 250055: loss = 0.27419
Step 250060: loss = 0.15617
Step 250065: loss = 0.03632
Step 250070: loss = 0.01648
Step 250075: loss = 0.08102
Step 250080: loss = 0.08155
Step 250085: loss = 0.15409
Step 250090: loss = 0.02731
Step 250095: loss = 0.07670
Step 250100: loss = 0.15629
Step 250105: loss = 0.04989
Step 250110: loss = 0.05084
Step 250115: loss = 0.09932
Step 250120: loss = 0.02457
Step 250125: loss = 0.03570
Step 250130: loss = 0.02670
Step 250135: loss = 0.13604
Step 250140: loss = 0.03184
Step 250145: loss = 0.12105
Step 250150: loss = 0.08211
Step 250155: loss = 0.13239
Step 250160: loss = 0.02566
Step 250165: loss = 0.08954
Step 250170: loss = 0.05845
Step 250175: loss = 0.04363
Step 250180: loss = 0.01811
Step 250185: loss = 0.03675
Step 250190: loss = 0.18682
Step 250195: loss = 0.04653
Step 250200: loss = 0.03584
Step 250205: loss = 0.08936
Step 250210: loss = 0.01819
Step 250215: loss = 0.01939
Step 250220: loss = 0.35855
Step 250225: loss = 0.08380
Step 250230: loss = 0.04530
Step 250235: loss = 0.26152
Step 250240: loss = 0.03247
Step 250245: loss = 0.04643
Step 250250: loss = 0.04646
Step 250255: loss = 0.04927
Step 250260: loss = 0.15537
Step 250265: loss = 0.08916
Step 250270: loss = 0.10401
Step 250275: loss = 0.02708
Step 250280: loss = 0.08804
Step 250285: loss = 0.04314
Step 250290: loss = 0.09069
Step 250295: loss = 0.09344
Step 250300: loss = 0.04440
Step 250305: loss = 0.05731
Step 250310: loss = 0.07514
Step 250315: loss = 0.05594
Step 250320: loss = 0.01470
Step 250325: loss = 0.10388
Step 250330: loss = 0.04495
Step 250335: loss = 0.03477
Step 250340: loss = 0.12961
Step 250345: loss = 0.17910
Step 250350: loss = 0.03556
Step 250355: loss = 0.02076
Step 250360: loss = 0.02294
Step 250365: loss = 0.02059
Step 250370: loss = 0.04541
Step 250375: loss = 0.08746
Step 250380: loss = 0.14295
Step 250385: loss = 0.04295
Step 250390: loss = 0.07846
Step 250395: loss = 0.10868
Step 250400: loss = 0.05785
Step 250405: loss = 0.02281
Step 250410: loss = 0.16694
Step 250415: loss = 0.05250
Step 250420: loss = 0.02180
Step 250425: loss = 0.04320
Step 250430: loss = 0.06279
Step 250435: loss = 0.10764
Step 250440: loss = 0.10756
Step 250445: loss = 0.04772
Step 250450: loss = 0.02026
Step 250455: loss = 0.03139
Step 250460: loss = 0.08854
Step 250465: loss = 0.03657
Step 250470: loss = 0.15026
Step 250475: loss = 0.05619
Step 250480: loss = 0.00946
Step 250485: loss = 0.03367
Step 250490: loss = 0.03846
Step 250495: loss = 0.03839
Step 250500: loss = 0.12407
Step 250505: loss = 0.02753
Step 250510: loss = 0.06565
Step 250515: loss = 0.01962
Step 250520: loss = 0.06288
Step 250525: loss = 0.02109
Step 250530: loss = 0.11134
Step 250535: loss = 0.19141
Step 250540: loss = 0.24708
Step 250545: loss = 0.19316
Step 250550: loss = 0.04495
Step 250555: loss = 0.07513
Step 250560: loss = 0.21712
Step 250565: loss = 0.20310
Step 250570: loss = 0.09604
Step 250575: loss = 0.14609
Step 250580: loss = 0.06778
Step 250585: loss = 0.06907
Step 250590: loss = 0.17483
Step 250595: loss = 0.11507
Step 250600: loss = 0.19492
Step 250605: loss = 0.04563
Step 250610: loss = 0.04441
Step 250615: loss = 0.07275
Step 250620: loss = 0.13494
Step 250625: loss = 0.03559
Step 250630: loss = 0.02953
Step 250635: loss = 0.10845
Step 250640: loss = 0.16678
Step 250645: loss = 0.17656
Step 250650: loss = 0.01920
Step 250655: loss = 0.03618
Step 250660: loss = 0.05934
Step 250665: loss = 0.10267
Step 250670: loss = 0.05620
Step 250675: loss = 0.11093
Step 250680: loss = 0.24141
Step 250685: loss = 0.24464
Step 250690: loss = 0.05534
Step 250695: loss = 0.10397
Step 250700: loss = 0.02650
Step 250705: loss = 0.01660
Step 250710: loss = 0.01699
Step 250715: loss = 0.33184
Step 250720: loss = 0.07933
Step 250725: loss = 0.09884
Step 250730: loss = 0.02167
Step 250735: loss = 0.09050
Step 250740: loss = 0.04971
Step 250745: loss = 0.21548
Step 250750: loss = 0.06316
Step 250755: loss = 0.02760
Step 250760: loss = 0.02887
Step 250765: loss = 0.07998
Step 250770: loss = 0.03564
Step 250775: loss = 0.07282
Step 250780: loss = 0.05144
Step 250785: loss = 0.09647
Step 250790: loss = 0.03958
Step 250795: loss = 0.06542
Step 250800: loss = 0.05725
Step 250805: loss = 0.02760
Step 250810: loss = 0.05451
Step 250815: loss = 0.15944
Step 250820: loss = 0.01822
Step 250825: loss = 0.01771
Step 250830: loss = 0.13858
Step 250835: loss = 0.09636
Step 250840: loss = 0.07340
Step 250845: loss = 0.12567
Step 250850: loss = 0.17159
Step 250855: loss = 0.03798
Step 250860: loss = 0.06576
Step 250865: loss = 0.05906
Step 250870: loss = 0.08972
Step 250875: loss = 0.03715
Step 250880: loss = 0.05414
Step 250885: loss = 0.15729
Step 250890: loss = 0.25431
Step 250895: loss = 0.03296
Step 250900: loss = 0.09470
Step 250905: loss = 0.06741
Step 250910: loss = 0.12196
Step 250915: loss = 0.06224
Step 250920: loss = 0.23530
Step 250925: loss = 0.16235
Step 250930: loss = 0.04326
Step 250935: loss = 0.12206
Step 250940: loss = 0.15732
Step 250945: loss = 0.06614
Step 250950: loss = 0.02167
Step 250955: loss = 0.07203
Step 250960: loss = 0.06884
Step 250965: loss = 0.04752
Step 250970: loss = 0.02004
Step 250975: loss = 0.06590
Step 250980: loss = 0.16367
Step 250985: loss = 0.04664
Step 250990: loss = 0.21252
Step 250995: loss = 0.16519
Step 251000: loss = 0.05559
Training Data Eval:
  Num examples: 50000, Num correct: 48472, Precision @ 1: 0.9694
('Testing Data Eval: EPOCH->', 252)
  Num examples: 10000, Num correct: 6738, Precision @ 1: 0.6738
Step 251005: loss = 0.04874
Step 251010: loss = 0.26827
Step 251015: loss = 0.12025
Step 251020: loss = 0.00989
Step 251025: loss = 0.04519
Step 251030: loss = 0.06324
Step 251035: loss = 0.08054
Step 251040: loss = 0.11923
Step 251045: loss = 0.06827
Step 251050: loss = 0.08507
Step 251055: loss = 0.04535
Step 251060: loss = 0.12277
Step 251065: loss = 0.10372
Step 251070: loss = 0.06736
Step 251075: loss = 0.06770
Step 251080: loss = 0.13944
Step 251085: loss = 0.03155
Step 251090: loss = 0.11955
Step 251095: loss = 0.13355
Step 251100: loss = 0.16109
Step 251105: loss = 0.08747
Step 251110: loss = 0.03091
Step 251115: loss = 0.11388
Step 251120: loss = 0.11880
Step 251125: loss = 0.24678
Step 251130: loss = 0.15367
Step 251135: loss = 0.09137
Step 251140: loss = 0.07404
Step 251145: loss = 0.28504
Step 251150: loss = 0.01595
Step 251155: loss = 0.02710
Step 251160: loss = 0.06906
Step 251165: loss = 0.09114
Step 251170: loss = 0.12948
Step 251175: loss = 0.13867
Step 251180: loss = 0.02858
Step 251185: loss = 0.03683
Step 251190: loss = 0.03841
Step 251195: loss = 0.07637
Step 251200: loss = 0.03144
Step 251205: loss = 0.08742
Step 251210: loss = 0.05055
Step 251215: loss = 0.07257
Step 251220: loss = 0.11960
Step 251225: loss = 0.10837
Step 251230: loss = 0.05581
Step 251235: loss = 0.24389
Step 251240: loss = 0.03870
Step 251245: loss = 0.37986
Step 251250: loss = 0.05805
Step 251255: loss = 0.09998
Step 251260: loss = 0.03346
Step 251265: loss = 0.05182
Step 251270: loss = 0.06901
Step 251275: loss = 0.12429
Step 251280: loss = 0.15451
Step 251285: loss = 0.04525
Step 251290: loss = 0.10771
Step 251295: loss = 0.08008
Step 251300: loss = 0.06863
Step 251305: loss = 0.14021
Step 251310: loss = 0.02465
Step 251315: loss = 0.01530
Step 251320: loss = 0.03511
Step 251325: loss = 0.02017
Step 251330: loss = 0.09692
Step 251335: loss = 0.27012
Step 251340: loss = 0.06680
Step 251345: loss = 0.03957
Step 251350: loss = 0.15612
Step 251355: loss = 0.00756
Step 251360: loss = 0.01629
Step 251365: loss = 0.09246
Step 251370: loss = 0.10982
Step 251375: loss = 0.00856
Step 251380: loss = 0.02614
Step 251385: loss = 0.02301
Step 251390: loss = 0.07999
Step 251395: loss = 0.09422
Step 251400: loss = 0.09237
Step 251405: loss = 0.01710
Step 251410: loss = 0.07649
Step 251415: loss = 0.12375
Step 251420: loss = 0.04781
Step 251425: loss = 0.02964
Step 251430: loss = 0.17806
Step 251435: loss = 0.07902
Step 251440: loss = 0.01592
Step 251445: loss = 0.06752
Step 251450: loss = 0.05022
Step 251455: loss = 0.06190
Step 251460: loss = 0.15337
Step 251465: loss = 0.07929
Step 251470: loss = 0.04800
Step 251475: loss = 0.04982
Step 251480: loss = 0.11331
Step 251485: loss = 0.12751
Step 251490: loss = 0.05912
Step 251495: loss = 0.11889
Step 251500: loss = 0.09577
Step 251505: loss = 0.02292
Step 251510: loss = 0.07665
Step 251515: loss = 0.03134
Step 251520: loss = 0.06732
Step 251525: loss = 0.09886
Step 251530: loss = 0.03930
Step 251535: loss = 0.11057
Step 251540: loss = 0.04813
Step 251545: loss = 0.08489
Step 251550: loss = 0.11494
Step 251555: loss = 0.09810
Step 251560: loss = 0.03866
Step 251565: loss = 0.10692
Step 251570: loss = 0.10953
Step 251575: loss = 0.07069
Step 251580: loss = 0.08743
Step 251585: loss = 0.25828
Step 251590: loss = 0.10887
Step 251595: loss = 0.06712
Step 251600: loss = 0.02160
Step 251605: loss = 0.04620
Step 251610: loss = 0.09397
Step 251615: loss = 0.04714
Step 251620: loss = 0.09594
Step 251625: loss = 0.03747
Step 251630: loss = 0.32226
Step 251635: loss = 0.11838
Step 251640: loss = 0.06887
Step 251645: loss = 0.17566
Step 251650: loss = 0.09998
Step 251655: loss = 0.04696
Step 251660: loss = 0.03068
Step 251665: loss = 0.05559
Step 251670: loss = 0.07999
Step 251675: loss = 0.10871
Step 251680: loss = 0.04569
Step 251685: loss = 0.11810
Step 251690: loss = 0.04233
Step 251695: loss = 0.04769
Step 251700: loss = 0.04999
Step 251705: loss = 0.04830
Step 251710: loss = 0.10832
Step 251715: loss = 0.03637
Step 251720: loss = 0.03487
Step 251725: loss = 0.06093
Step 251730: loss = 0.10094
Step 251735: loss = 0.02182
Step 251740: loss = 0.05341
Step 251745: loss = 0.02459
Step 251750: loss = 0.05437
Step 251755: loss = 0.04448
Step 251760: loss = 0.06199
Step 251765: loss = 0.12689
Step 251770: loss = 0.20181
Step 251775: loss = 0.02273
Step 251780: loss = 0.05633
Step 251785: loss = 0.03074
Step 251790: loss = 0.08399
Step 251795: loss = 0.08557
Step 251800: loss = 0.03797
Step 251805: loss = 0.03186
Step 251810: loss = 0.05595
Step 251815: loss = 0.11531
Step 251820: loss = 0.04495
Step 251825: loss = 0.04449
Step 251830: loss = 0.07872
Step 251835: loss = 0.08631
Step 251840: loss = 0.02290
Step 251845: loss = 0.05145
Step 251850: loss = 0.11317
Step 251855: loss = 0.03312
Step 251860: loss = 0.13695
Step 251865: loss = 0.14286
Step 251870: loss = 0.06209
Step 251875: loss = 0.07293
Step 251880: loss = 0.02215
Step 251885: loss = 0.05213
Step 251890: loss = 0.05515
Step 251895: loss = 0.07421
Step 251900: loss = 0.06050
Step 251905: loss = 0.05936
Step 251910: loss = 0.21779
Step 251915: loss = 0.13081
Step 251920: loss = 0.36179
Step 251925: loss = 0.14745
Step 251930: loss = 0.17326
Step 251935: loss = 0.14047
Step 251940: loss = 0.09931
Step 251945: loss = 0.12445
Step 251950: loss = 0.06713
Step 251955: loss = 0.03292
Step 251960: loss = 0.04097
Step 251965: loss = 0.20748
Step 251970: loss = 0.06783
Step 251975: loss = 0.04491
Step 251980: loss = 0.03585
Step 251985: loss = 0.07519
Step 251990: loss = 0.16728
Step 251995: loss = 0.12690
Step 252000: loss = 0.04050
Training Data Eval:
  Num examples: 50000, Num correct: 48394, Precision @ 1: 0.9679
('Testing Data Eval: EPOCH->', 253)
  Num examples: 10000, Num correct: 6730, Precision @ 1: 0.6730
Step 252005: loss = 0.12401
Step 252010: loss = 0.05064
Step 252015: loss = 0.27642
Step 252020: loss = 0.10882
Step 252025: loss = 0.11762
Step 252030: loss = 0.11136
Step 252035: loss = 0.13392
Step 252040: loss = 0.10478
Step 252045: loss = 0.05451
Step 252050: loss = 0.18485
Step 252055: loss = 0.36783
Step 252060: loss = 0.12708
Step 252065: loss = 0.06693
Step 252070: loss = 0.09927
Step 252075: loss = 0.02607
Step 252080: loss = 0.03158
Step 252085: loss = 0.05955
Step 252090: loss = 0.02798
Step 252095: loss = 0.15213
Step 252100: loss = 0.07387
Step 252105: loss = 0.03728
Step 252110: loss = 0.04378
Step 252115: loss = 0.19275
Step 252120: loss = 0.03062
Step 252125: loss = 0.02305
Step 252130: loss = 0.07116
Step 252135: loss = 0.08844
Step 252140: loss = 0.11663
Step 252145: loss = 0.12698
Step 252150: loss = 0.05763
Step 252155: loss = 0.01523
Step 252160: loss = 0.06581
Step 252165: loss = 0.16554
Step 252170: loss = 0.09604
Step 252175: loss = 0.16942
Step 252180: loss = 0.06020
Step 252185: loss = 0.23016
Step 252190: loss = 0.08564
Step 252195: loss = 0.03667
Step 252200: loss = 0.07935
Step 252205: loss = 0.09339
Step 252210: loss = 0.05181
Step 252215: loss = 0.20721
Step 252220: loss = 0.11921
Step 252225: loss = 0.03858
Step 252230: loss = 0.48473
Step 252235: loss = 0.06833
Step 252240: loss = 0.02117
Step 252245: loss = 0.33823
Step 252250: loss = 0.16448
Step 252255: loss = 0.12744
Step 252260: loss = 0.10634
Step 252265: loss = 0.04169
Step 252270: loss = 0.26046
Step 252275: loss = 0.04223
Step 252280: loss = 0.14339
Step 252285: loss = 0.06095
Step 252290: loss = 0.03077
Step 252295: loss = 0.13852
Step 252300: loss = 0.15439
Step 252305: loss = 0.10596
Step 252310: loss = 0.07524
Step 252315: loss = 0.06493
Step 252320: loss = 0.10789
Step 252325: loss = 0.16808
Step 252330: loss = 0.07180
Step 252335: loss = 0.07948
Step 252340: loss = 0.17246
Step 252345: loss = 0.33152
Step 252350: loss = 0.04703
Step 252355: loss = 0.20407
Step 252360: loss = 0.03898
Step 252365: loss = 0.04600
Step 252370: loss = 0.20005
Step 252375: loss = 0.10380
Step 252380: loss = 0.04696
Step 252385: loss = 0.10076
Step 252390: loss = 0.14565
Step 252395: loss = 0.03840
Step 252400: loss = 0.08230
Step 252405: loss = 0.06925
Step 252410: loss = 0.04761
Step 252415: loss = 0.05821
Step 252420: loss = 0.03245
Step 252425: loss = 0.05858
Step 252430: loss = 0.06010
Step 252435: loss = 0.02137
Step 252440: loss = 0.02341
Step 252445: loss = 0.05776
Step 252450: loss = 0.04089
Step 252455: loss = 0.23778
Step 252460: loss = 0.15902
Step 252465: loss = 0.24532
Step 252470: loss = 0.05637
Step 252475: loss = 0.02382
Step 252480: loss = 0.17541
Step 252485: loss = 0.11291
Step 252490: loss = 0.04511
Step 252495: loss = 0.06520
Step 252500: loss = 0.01610
Step 252505: loss = 0.05823
Step 252510: loss = 0.07127
Step 252515: loss = 0.07050
Step 252520: loss = 0.05510
Step 252525: loss = 0.05329
Step 252530: loss = 0.10915
Step 252535: loss = 0.05437
Step 252540: loss = 0.12507
Step 252545: loss = 0.03391
Step 252550: loss = 0.06713
Step 252555: loss = 0.07040
Step 252560: loss = 0.05303
Step 252565: loss = 0.08018
Step 252570: loss = 0.06047
Step 252575: loss = 0.03263
Step 252580: loss = 0.12956
Step 252585: loss = 0.13041
Step 252590: loss = 0.00845
Step 252595: loss = 0.04568
Step 252600: loss = 0.07352
Step 252605: loss = 0.02826
Step 252610: loss = 0.05415
Step 252615: loss = 0.02435
Step 252620: loss = 0.08606
Step 252625: loss = 0.04721
Step 252630: loss = 0.06845
Step 252635: loss = 0.07690
Step 252640: loss = 0.06790
Step 252645: loss = 0.03856
Step 252650: loss = 0.04525
Step 252655: loss = 0.06737
Step 252660: loss = 0.16273
Step 252665: loss = 0.27221
Step 252670: loss = 0.11394
Step 252675: loss = 0.04090
Step 252680: loss = 0.07396
Step 252685: loss = 0.09019
Step 252690: loss = 0.05278
Step 252695: loss = 0.11107
Step 252700: loss = 0.04177
Step 252705: loss = 0.05700
Step 252710: loss = 0.03586
Step 252715: loss = 0.06617
Step 252720: loss = 0.10749
Step 252725: loss = 0.05861
Step 252730: loss = 0.05690
Step 252735: loss = 0.19112
Step 252740: loss = 0.01972
Step 252745: loss = 0.02632
Step 252750: loss = 0.02203
Step 252755: loss = 0.19904
Step 252760: loss = 0.07503
Step 252765: loss = 0.04312
Step 252770: loss = 0.25992
Step 252775: loss = 0.12537
Step 252780: loss = 0.25911
Step 252785: loss = 0.03244
Step 252790: loss = 0.14841
Step 252795: loss = 0.07769
Step 252800: loss = 0.02724
Step 252805: loss = 0.08137
Step 252810: loss = 0.08231
Step 252815: loss = 0.01435
Step 252820: loss = 0.08145
Step 252825: loss = 0.06510
Step 252830: loss = 0.11783
Step 252835: loss = 0.09147
Step 252840: loss = 0.19751
Step 252845: loss = 0.14041
Step 252850: loss = 0.07205
Step 252855: loss = 0.19780
Step 252860: loss = 0.09922
Step 252865: loss = 0.09039
Step 252870: loss = 0.08012
Step 252875: loss = 0.06752
Step 252880: loss = 0.07433
Step 252885: loss = 0.13534
Step 252890: loss = 0.11522
Step 252895: loss = 0.02920
Step 252900: loss = 0.07955
Step 252905: loss = 0.21338
Step 252910: loss = 0.03278
Step 252915: loss = 0.08993
Step 252920: loss = 0.02191
Step 252925: loss = 0.17596
Step 252930: loss = 0.00914
Step 252935: loss = 0.09967
Step 252940: loss = 0.13544
Step 252945: loss = 0.08396
Step 252950: loss = 0.05878
Step 252955: loss = 0.19781
Step 252960: loss = 0.14846
Step 252965: loss = 0.11027
Step 252970: loss = 0.04351
Step 252975: loss = 0.04746
Step 252980: loss = 0.13527
Step 252985: loss = 0.00628
Step 252990: loss = 0.12402
Step 252995: loss = 0.01541
Step 253000: loss = 0.08514
Training Data Eval:
  Num examples: 50000, Num correct: 48169, Precision @ 1: 0.9634
('Testing Data Eval: EPOCH->', 254)
  Num examples: 10000, Num correct: 6643, Precision @ 1: 0.6643
Step 253005: loss = 0.03810
Step 253010: loss = 0.09092
Step 253015: loss = 0.05961
Step 253020: loss = 0.04262
Step 253025: loss = 0.31601
Step 253030: loss = 0.12357
Step 253035: loss = 0.05840
Step 253040: loss = 0.10071
Step 253045: loss = 0.06046
Step 253050: loss = 0.05445
Step 253055: loss = 0.19983
Step 253060: loss = 0.12860
Step 253065: loss = 0.07197
Step 253070: loss = 0.11016
Step 253075: loss = 0.16861
Step 253080: loss = 0.01891
Step 253085: loss = 0.08303
Step 253090: loss = 0.02278
Step 253095: loss = 0.06246
Step 253100: loss = 0.17566
Step 253105: loss = 0.03854
Step 253110: loss = 0.12126
Step 253115: loss = 0.08507
Step 253120: loss = 0.04115
Step 253125: loss = 0.01648
Step 253130: loss = 0.18023
Step 253135: loss = 0.08991
Step 253140: loss = 0.08243
Step 253145: loss = 0.01325
Step 253150: loss = 0.04435
Step 253155: loss = 0.18207
Step 253160: loss = 0.04315
Step 253165: loss = 0.04093
Step 253170: loss = 0.18588
Step 253175: loss = 0.11538
Step 253180: loss = 0.09223
Step 253185: loss = 0.06190
Step 253190: loss = 0.25569
Step 253195: loss = 0.02533
Step 253200: loss = 0.30022
Step 253205: loss = 0.12788
Step 253210: loss = 0.03279
Step 253215: loss = 0.09899
Step 253220: loss = 0.14381
Step 253225: loss = 0.04943
Step 253230: loss = 0.19188
Step 253235: loss = 0.05684
Step 253240: loss = 0.32228
Step 253245: loss = 0.08087
Step 253250: loss = 0.01832
Step 253255: loss = 0.05805
Step 253260: loss = 0.00695
Step 253265: loss = 0.01506
Step 253270: loss = 0.01066
Step 253275: loss = 0.08253
Step 253280: loss = 0.16648
Step 253285: loss = 0.05669
Step 253290: loss = 0.05838
Step 253295: loss = 0.04540
Step 253300: loss = 0.01079
Step 253305: loss = 0.04802
Step 253310: loss = 0.23797
Step 253315: loss = 0.11534
Step 253320: loss = 0.03311
Step 253325: loss = 0.12620
Step 253330: loss = 0.06059
Step 253335: loss = 0.11732
Step 253340: loss = 0.04271
Step 253345: loss = 0.05910
Step 253350: loss = 0.09365
Step 253355: loss = 0.13209
Step 253360: loss = 0.04869
Step 253365: loss = 0.01881
Step 253370: loss = 0.14999
Step 253375: loss = 0.14244
Step 253380: loss = 0.11684
Step 253385: loss = 0.02229
Step 253390: loss = 0.19624
Step 253395: loss = 0.01958
Step 253400: loss = 0.24899
Step 253405: loss = 0.03409
Step 253410: loss = 0.05101
Step 253415: loss = 0.11659
Step 253420: loss = 0.07125
Step 253425: loss = 0.03351
Step 253430: loss = 0.04430
Step 253435: loss = 0.10317
Step 253440: loss = 0.04767
Step 253445: loss = 0.02873
Step 253450: loss = 0.10904
Step 253455: loss = 0.07510
Step 253460: loss = 0.01175
Step 253465: loss = 0.03942
Step 253470: loss = 0.11203
Step 253475: loss = 0.05076
Step 253480: loss = 0.07487
Step 253485: loss = 0.15848
Step 253490: loss = 0.10443
Step 253495: loss = 0.14838
Step 253500: loss = 0.08645
Step 253505: loss = 0.16963
Step 253510: loss = 0.04946
Step 253515: loss = 0.22590
Step 253520: loss = 0.24240
Step 253525: loss = 0.04267
Step 253530: loss = 0.08322
Step 253535: loss = 0.02061
Step 253540: loss = 0.05042
Step 253545: loss = 0.17318
Step 253550: loss = 0.24278
Step 253555: loss = 0.12983
Step 253560: loss = 0.08844
Step 253565: loss = 0.12094
Step 253570: loss = 0.10766
Step 253575: loss = 0.07645
Step 253580: loss = 0.09216
Step 253585: loss = 0.04917
Step 253590: loss = 0.11276
Step 253595: loss = 0.03280
Step 253600: loss = 0.09227
Step 253605: loss = 0.04479
Step 253610: loss = 0.03009
Step 253615: loss = 0.16235
Step 253620: loss = 0.06694
Step 253625: loss = 0.10182
Step 253630: loss = 0.03546
Step 253635: loss = 0.06770
Step 253640: loss = 0.06452
Step 253645: loss = 0.32277
Step 253650: loss = 0.01607
Step 253655: loss = 0.18078
Step 253660: loss = 0.11590
Step 253665: loss = 0.07273
Step 253670: loss = 0.03177
Step 253675: loss = 0.23445
Step 253680: loss = 0.09051
Step 253685: loss = 0.08888
Step 253690: loss = 0.03945
Step 253695: loss = 0.02968
Step 253700: loss = 0.04296
Step 253705: loss = 0.12101
Step 253710: loss = 0.03200
Step 253715: loss = 0.03087
Step 253720: loss = 0.09810
Step 253725: loss = 0.06263
Step 253730: loss = 0.03438
Step 253735: loss = 0.07149
Step 253740: loss = 0.18300
Step 253745: loss = 0.16313
Step 253750: loss = 0.14042
Step 253755: loss = 0.10635
Step 253760: loss = 0.08575
Step 253765: loss = 0.04429
Step 253770: loss = 0.04828
Step 253775: loss = 0.15822
Step 253780: loss = 0.04693
Step 253785: loss = 0.06097
Step 253790: loss = 0.01043
Step 253795: loss = 0.05826
Step 253800: loss = 0.08453
Step 253805: loss = 0.02396
Step 253810: loss = 0.07907
Step 253815: loss = 0.13225
Step 253820: loss = 0.05867
Step 253825: loss = 0.13228
Step 253830: loss = 0.02343
Step 253835: loss = 0.05996
Step 253840: loss = 0.16530
Step 253845: loss = 0.20194
Step 253850: loss = 0.29619
Step 253855: loss = 0.11469
Step 253860: loss = 0.31169
Step 253865: loss = 0.06382
Step 253870: loss = 0.08520
Step 253875: loss = 0.03739
Step 253880: loss = 0.05414
Step 253885: loss = 0.22736
Step 253890: loss = 0.12778
Step 253895: loss = 0.10335
Step 253900: loss = 0.04798
Step 253905: loss = 0.06148
Step 253910: loss = 0.09638
Step 253915: loss = 0.06105
Step 253920: loss = 0.05391
Step 253925: loss = 0.11600
Step 253930: loss = 0.19668
Step 253935: loss = 0.06145
Step 253940: loss = 0.10163
Step 253945: loss = 0.01772
Step 253950: loss = 0.08823
Step 253955: loss = 0.06660
Step 253960: loss = 0.08020
Step 253965: loss = 0.28060
Step 253970: loss = 0.20503
Step 253975: loss = 0.03546
Step 253980: loss = 0.06537
Step 253985: loss = 0.01691
Step 253990: loss = 0.03688
Step 253995: loss = 0.02665
Step 254000: loss = 0.03954
Training Data Eval:
  Num examples: 50000, Num correct: 48540, Precision @ 1: 0.9708
('Testing Data Eval: EPOCH->', 255)
  Num examples: 10000, Num correct: 6722, Precision @ 1: 0.6722
Step 254005: loss = 0.07051
Step 254010: loss = 0.23356
Step 254015: loss = 0.16623
Step 254020: loss = 0.05818
Step 254025: loss = 0.04316
Step 254030: loss = 0.12370
Step 254035: loss = 0.26837
Step 254040: loss = 0.13002
Step 254045: loss = 0.13032
Step 254050: loss = 0.03203
Step 254055: loss = 0.08359
Step 254060: loss = 0.17859
Step 254065: loss = 0.09422
Step 254070: loss = 0.02716
Step 254075: loss = 0.05058
Step 254080: loss = 0.05636
Step 254085: loss = 0.11586
Step 254090: loss = 0.01707
Step 254095: loss = 0.01285
Step 254100: loss = 0.10527
Step 254105: loss = 0.03000
Step 254110: loss = 0.11294
Step 254115: loss = 0.11351
Step 254120: loss = 0.03821
Step 254125: loss = 0.01064
Step 254130: loss = 0.01578
Step 254135: loss = 0.20878
Step 254140: loss = 0.16966
Step 254145: loss = 0.12104
Step 254150: loss = 0.06284
Step 254155: loss = 0.06012
Step 254160: loss = 0.18547
Step 254165: loss = 0.28343
Step 254170: loss = 0.03094
Step 254175: loss = 0.08105
Step 254180: loss = 0.05083
Step 254185: loss = 0.10525
Step 254190: loss = 0.15293
Step 254195: loss = 0.04566
Step 254200: loss = 0.24956
Step 254205: loss = 0.05487
Step 254210: loss = 0.18781
Step 254215: loss = 0.03150
Step 254220: loss = 0.03908
Step 254225: loss = 0.07482
Step 254230: loss = 0.05886
Step 254235: loss = 0.11489
Step 254240: loss = 0.10861
Step 254245: loss = 0.17180
Step 254250: loss = 0.14763
Step 254255: loss = 0.05323
Step 254260: loss = 0.05045
Step 254265: loss = 0.06468
Step 254270: loss = 0.07497
Step 254275: loss = 0.06974
Step 254280: loss = 0.06056
Step 254285: loss = 0.12143
Step 254290: loss = 0.15512
Step 254295: loss = 0.02437
Step 254300: loss = 0.08325
Step 254305: loss = 0.41386
Step 254310: loss = 0.04584
Step 254315: loss = 0.11184
Step 254320: loss = 0.04681
Step 254325: loss = 0.02830
Step 254330: loss = 0.01828
Step 254335: loss = 0.06480
Step 254340: loss = 0.06494
Step 254345: loss = 0.07714
Step 254350: loss = 0.10253
Step 254355: loss = 0.42514
Step 254360: loss = 0.09993
Step 254365: loss = 0.11425
Step 254370: loss = 0.01811
Step 254375: loss = 0.01418
Step 254380: loss = 0.07873
Step 254385: loss = 0.12360
Step 254390: loss = 0.03082
Step 254395: loss = 0.05938
Step 254400: loss = 0.07236
Step 254405: loss = 0.02303
Step 254410: loss = 0.16359
Step 254415: loss = 0.10235
Step 254420: loss = 0.08987
Step 254425: loss = 0.02538
Step 254430: loss = 0.16000
Step 254435: loss = 0.09133
Step 254440: loss = 0.14569
Step 254445: loss = 0.12948
Step 254450: loss = 0.03950
Step 254455: loss = 0.06351
Step 254460: loss = 0.22388
Step 254465: loss = 0.04062
Step 254470: loss = 0.04823
Step 254475: loss = 0.10484
Step 254480: loss = 0.17989
Step 254485: loss = 0.06813
Step 254490: loss = 0.15553
Step 254495: loss = 0.02612
Step 254500: loss = 0.20424
Step 254505: loss = 0.02517
Step 254510: loss = 0.17160
Step 254515: loss = 0.04638
Step 254520: loss = 0.02828
Step 254525: loss = 0.08028
Step 254530: loss = 0.05623
Step 254535: loss = 0.07606
Step 254540: loss = 0.02892
Step 254545: loss = 0.07924
Step 254550: loss = 0.09567
Step 254555: loss = 0.15457
Step 254560: loss = 0.15370
Step 254565: loss = 0.16785
Step 254570: loss = 0.06233
Step 254575: loss = 0.16069
Step 254580: loss = 0.19127
Step 254585: loss = 0.02858
Step 254590: loss = 0.13457
Step 254595: loss = 0.05577
Step 254600: loss = 0.02875
Step 254605: loss = 0.03424
Step 254610: loss = 0.06416
Step 254615: loss = 0.11399
Step 254620: loss = 0.30349
Step 254625: loss = 0.03886
Step 254630: loss = 0.05146
Step 254635: loss = 0.02780
Step 254640: loss = 0.08059
Step 254645: loss = 0.01539
Step 254650: loss = 0.02786
Step 254655: loss = 0.02497
Step 254660: loss = 0.06919
Step 254665: loss = 0.06582
Step 254670: loss = 0.20139
Step 254675: loss = 0.15722
Step 254680: loss = 0.04741
Step 254685: loss = 0.16313
Step 254690: loss = 0.07427
Step 254695: loss = 0.06011
Step 254700: loss = 0.09788
Step 254705: loss = 0.11431
Step 254710: loss = 0.14653
Step 254715: loss = 0.06021
Step 254720: loss = 0.16490
Step 254725: loss = 0.02663
Step 254730: loss = 0.04107
Step 254735: loss = 0.10507
Step 254740: loss = 0.13293
Step 254745: loss = 0.04484
Step 254750: loss = 0.08825
Step 254755: loss = 0.06624
Step 254760: loss = 0.11256
Step 254765: loss = 0.01960
Step 254770: loss = 0.06397
Step 254775: loss = 0.16118
Step 254780: loss = 0.18721
Step 254785: loss = 0.15747
Step 254790: loss = 0.16183
Step 254795: loss = 0.04323
Step 254800: loss = 0.01859
Step 254805: loss = 0.02500
Step 254810: loss = 0.16852
Step 254815: loss = 0.12878
Step 254820: loss = 0.13800
Step 254825: loss = 0.05341
Step 254830: loss = 0.06209
Step 254835: loss = 0.04421
Step 254840: loss = 0.24098
Step 254845: loss = 0.15086
Step 254850: loss = 0.05258
Step 254855: loss = 0.02733
Step 254860: loss = 0.18962
Step 254865: loss = 0.07044
Step 254870: loss = 0.02641
Step 254875: loss = 0.22601
Step 254880: loss = 0.13025
Step 254885: loss = 0.02451
Step 254890: loss = 0.14981
Step 254895: loss = 0.16342
Step 254900: loss = 0.09247
Step 254905: loss = 0.11912
Step 254910: loss = 0.05369
Step 254915: loss = 0.08761
Step 254920: loss = 0.12471
Step 254925: loss = 0.09620
Step 254930: loss = 0.26847
Step 254935: loss = 0.11125
Step 254940: loss = 0.08002
Step 254945: loss = 0.11604
Step 254950: loss = 0.07473
Step 254955: loss = 0.10673
Step 254960: loss = 0.11695
Step 254965: loss = 0.02538
Step 254970: loss = 0.08704
Step 254975: loss = 0.04702
Step 254980: loss = 0.04784
Step 254985: loss = 0.19595
Step 254990: loss = 0.03050
Step 254995: loss = 0.05299
Step 255000: loss = 0.09680
Training Data Eval:
  Num examples: 50000, Num correct: 48580, Precision @ 1: 0.9716
('Testing Data Eval: EPOCH->', 256)
  Num examples: 10000, Num correct: 6740, Precision @ 1: 0.6740
Step 255005: loss = 0.11873
Step 255010: loss = 0.03162
Step 255015: loss = 0.02582
Step 255020: loss = 0.01297
Step 255025: loss = 0.03534
Step 255030: loss = 0.08496
Step 255035: loss = 0.09210
Step 255040: loss = 0.06222
Step 255045: loss = 0.02211
Step 255050: loss = 0.08242
Step 255055: loss = 0.05258
Step 255060: loss = 0.08108
Step 255065: loss = 0.04193
Step 255070: loss = 0.21327
Step 255075: loss = 0.06875
Step 255080: loss = 0.22240
Step 255085: loss = 0.06583
Step 255090: loss = 0.06093
Step 255095: loss = 0.05773
Step 255100: loss = 0.05775
Step 255105: loss = 0.04290
Step 255110: loss = 0.07661
Step 255115: loss = 0.03624
Step 255120: loss = 0.09738
Step 255125: loss = 0.06512
Step 255130: loss = 0.06168
Step 255135: loss = 0.01962
Step 255140: loss = 0.09489
Step 255145: loss = 0.02115
Step 255150: loss = 0.17024
Step 255155: loss = 0.05991
Step 255160: loss = 0.07711
Step 255165: loss = 0.04643
Step 255170: loss = 0.33744
Step 255175: loss = 0.03329
Step 255180: loss = 0.08147
Step 255185: loss = 0.03285
Step 255190: loss = 0.02800
Step 255195: loss = 0.10713
Step 255200: loss = 0.07413
Step 255205: loss = 0.05958
Step 255210: loss = 0.14318
Step 255215: loss = 0.02153
Step 255220: loss = 0.03873
Step 255225: loss = 0.27500
Step 255230: loss = 0.02928
Step 255235: loss = 0.06613
Step 255240: loss = 0.15805
Step 255245: loss = 0.12619
Step 255250: loss = 0.03840
Step 255255: loss = 0.05585
Step 255260: loss = 0.05397
Step 255265: loss = 0.06640
Step 255270: loss = 0.07566
Step 255275: loss = 0.13753
Step 255280: loss = 0.01422
Step 255285: loss = 0.12594
Step 255290: loss = 0.03055
Step 255295: loss = 0.09087
Step 255300: loss = 0.05082
Step 255305: loss = 0.03142
Step 255310: loss = 0.19698
Step 255315: loss = 0.02052
Step 255320: loss = 0.04966
Step 255325: loss = 0.14367
Step 255330: loss = 0.26680
Step 255335: loss = 0.14071
Step 255340: loss = 0.06864
Step 255345: loss = 0.13205
Step 255350: loss = 0.14269
Step 255355: loss = 0.32064
Step 255360: loss = 0.14377
Step 255365: loss = 0.16818
Step 255370: loss = 0.03187
Step 255375: loss = 0.14417
Step 255380: loss = 0.10051
Step 255385: loss = 0.30039
Step 255390: loss = 0.06268
Step 255395: loss = 0.03889
Step 255400: loss = 0.10498
Step 255405: loss = 0.15502
Step 255410: loss = 0.09476
Step 255415: loss = 0.02978
Step 255420: loss = 0.06907
Step 255425: loss = 0.10665
Step 255430: loss = 0.12687
Step 255435: loss = 0.11299
Step 255440: loss = 0.07164
Step 255445: loss = 0.15932
Step 255450: loss = 0.27933
Step 255455: loss = 0.03396
Step 255460: loss = 0.04303
Step 255465: loss = 0.07825
Step 255470: loss = 0.02982
Step 255475: loss = 0.21195
Step 255480: loss = 0.07042
Step 255485: loss = 0.12105
Step 255490: loss = 0.02637
Step 255495: loss = 0.12280
Step 255500: loss = 0.12416
Step 255505: loss = 0.02545
Step 255510: loss = 0.02432
Step 255515: loss = 0.06356
Step 255520: loss = 0.02477
Step 255525: loss = 0.07333
Step 255530: loss = 0.03271
Step 255535: loss = 0.03683
Step 255540: loss = 0.06810
Step 255545: loss = 0.03166
Step 255550: loss = 0.02289
Step 255555: loss = 0.05466
Step 255560: loss = 0.03644
Step 255565: loss = 0.11524
Step 255570: loss = 0.29686
Step 255575: loss = 0.02273
Step 255580: loss = 0.12032
Step 255585: loss = 0.16588
Step 255590: loss = 0.10562
Step 255595: loss = 0.02897
Step 255600: loss = 0.18152
Step 255605: loss = 0.04842
Step 255610: loss = 0.08520
Step 255615: loss = 0.06327
Step 255620: loss = 0.01673
Step 255625: loss = 0.01455
Step 255630: loss = 0.18164
Step 255635: loss = 0.04593
Step 255640: loss = 0.24379
Step 255645: loss = 0.05569
Step 255650: loss = 0.00937
Step 255655: loss = 0.02434
Step 255660: loss = 0.02343
Step 255665: loss = 0.02889
Step 255670: loss = 0.15005
Step 255675: loss = 0.05784
Step 255680: loss = 0.14935
Step 255685: loss = 0.05468
Step 255690: loss = 0.14221
Step 255695: loss = 0.09176
Step 255700: loss = 0.04287
Step 255705: loss = 0.10736
Step 255710: loss = 0.07147
Step 255715: loss = 0.02263
Step 255720: loss = 0.03338
Step 255725: loss = 0.05347
Step 255730: loss = 0.18327
Step 255735: loss = 0.10166
Step 255740: loss = 0.16925
Step 255745: loss = 0.07129
Step 255750: loss = 0.02431
Step 255755: loss = 0.19315
Step 255760: loss = 0.09108
Step 255765: loss = 0.21735
Step 255770: loss = 0.13032
Step 255775: loss = 0.06902
Step 255780: loss = 0.01279
Step 255785: loss = 0.04947
Step 255790: loss = 0.05463
Step 255795: loss = 0.01801
Step 255800: loss = 0.10462
Step 255805: loss = 0.10531
Step 255810: loss = 0.06645
Step 255815: loss = 0.13785
Step 255820: loss = 0.05537
Step 255825: loss = 0.13971
Step 255830: loss = 0.07429
Step 255835: loss = 0.09097
Step 255840: loss = 0.10356
Step 255845: loss = 0.13849
Step 255850: loss = 0.08199
Step 255855: loss = 0.06137
Step 255860: loss = 0.01892
Step 255865: loss = 0.04469
Step 255870: loss = 0.19103
Step 255875: loss = 0.06461
Step 255880: loss = 0.07587
Step 255885: loss = 0.16731
Step 255890: loss = 0.20268
Step 255895: loss = 0.02015
Step 255900: loss = 0.05817
Step 255905: loss = 0.04003
Step 255910: loss = 0.06717
Step 255915: loss = 0.07165
Step 255920: loss = 0.02611
Step 255925: loss = 0.08594
Step 255930: loss = 0.09011
Step 255935: loss = 0.10190
Step 255940: loss = 0.05802
Step 255945: loss = 0.05408
Step 255950: loss = 0.00325
Step 255955: loss = 0.08805
Step 255960: loss = 0.08963
Step 255965: loss = 0.02687
Step 255970: loss = 0.07446
Step 255975: loss = 0.07448
Step 255980: loss = 0.04953
Step 255985: loss = 0.23202
Step 255990: loss = 0.06385
Step 255995: loss = 0.05157
Step 256000: loss = 0.08517
Training Data Eval:
  Num examples: 50000, Num correct: 48550, Precision @ 1: 0.9710
('Testing Data Eval: EPOCH->', 257)
  Num examples: 10000, Num correct: 6735, Precision @ 1: 0.6735
Step 256005: loss = 0.03017
Step 256010: loss = 0.03324
Step 256015: loss = 0.24912
Step 256020: loss = 0.14199
Step 256025: loss = 0.08308
Step 256030: loss = 0.09343
Step 256035: loss = 0.07274
Step 256040: loss = 0.05859
Step 256045: loss = 0.05772
Step 256050: loss = 0.05638
Step 256055: loss = 0.04729
Step 256060: loss = 0.10673
Step 256065: loss = 0.24384
Step 256070: loss = 0.12555
Step 256075: loss = 0.05895
Step 256080: loss = 0.02747
Step 256085: loss = 0.07529
Step 256090: loss = 0.03173
Step 256095: loss = 0.04957
Step 256100: loss = 0.07037
Step 256105: loss = 0.07054
Step 256110: loss = 0.10045
Step 256115: loss = 0.07318
Step 256120: loss = 0.06656
Step 256125: loss = 0.03209
Step 256130: loss = 0.08263
Step 256135: loss = 0.11668
Step 256140: loss = 0.01324
Step 256145: loss = 0.05739
Step 256150: loss = 0.05092
Step 256155: loss = 0.12328
Step 256160: loss = 0.26912
Step 256165: loss = 0.13225
Step 256170: loss = 0.04083
Step 256175: loss = 0.05572
Step 256180: loss = 0.13076
Step 256185: loss = 0.09966
Step 256190: loss = 0.07100
Step 256195: loss = 0.03543
Step 256200: loss = 0.11961
Step 256205: loss = 0.07303
Step 256210: loss = 0.11256
Step 256215: loss = 0.12202
Step 256220: loss = 0.06855
Step 256225: loss = 0.02734
Step 256230: loss = 0.08314
Step 256235: loss = 0.06057
Step 256240: loss = 0.10325
Step 256245: loss = 0.04772
Step 256250: loss = 0.01040
Step 256255: loss = 0.03172
Step 256260: loss = 0.05436
Step 256265: loss = 0.10894
Step 256270: loss = 0.11239
Step 256275: loss = 0.01914
Step 256280: loss = 0.04564
Step 256285: loss = 0.04259
Step 256290: loss = 0.08355
Step 256295: loss = 0.18482
Step 256300: loss = 0.04646
Step 256305: loss = 0.10542
Step 256310: loss = 0.18562
Step 256315: loss = 0.10612
Step 256320: loss = 0.24249
Step 256325: loss = 0.15203
Step 256330: loss = 0.04624
Step 256335: loss = 0.04930
Step 256340: loss = 0.01716
Step 256345: loss = 0.07752
Step 256350: loss = 0.09920
Step 256355: loss = 0.03542
Step 256360: loss = 0.10295
Step 256365: loss = 0.02232
Step 256370: loss = 0.06763
Step 256375: loss = 0.08097
Step 256380: loss = 0.04240
Step 256385: loss = 0.07860
Step 256390: loss = 0.08500
Step 256395: loss = 0.07100
Step 256400: loss = 0.25090
Step 256405: loss = 0.07661
Step 256410: loss = 0.08094
Step 256415: loss = 0.09678
Step 256420: loss = 0.07753
Step 256425: loss = 0.13094
Step 256430: loss = 0.19090
Step 256435: loss = 0.07429
Step 256440: loss = 0.17082
Step 256445: loss = 0.05318
Step 256450: loss = 0.04473
Step 256455: loss = 0.02441
Step 256460: loss = 0.04058
Step 256465: loss = 0.04533
Step 256470: loss = 0.04432
Step 256475: loss = 0.11284
Step 256480: loss = 0.02089
Step 256485: loss = 0.03360
Step 256490: loss = 0.15092
Step 256495: loss = 0.19262
Step 256500: loss = 0.04225
Step 256505: loss = 0.05724
Step 256510: loss = 0.06678
Step 256515: loss = 0.08975
Step 256520: loss = 0.02352
Step 256525: loss = 0.05932
Step 256530: loss = 0.07100
Step 256535: loss = 0.14928
Step 256540: loss = 0.04713
Step 256545: loss = 0.09669
Step 256550: loss = 0.19376
Step 256555: loss = 0.14988
Step 256560: loss = 0.03914
Step 256565: loss = 0.05689
Step 256570: loss = 0.04200
Step 256575: loss = 0.11405
Step 256580: loss = 0.01169
Step 256585: loss = 0.12545
Step 256590: loss = 0.01319
Step 256595: loss = 0.06973
Step 256600: loss = 0.25840
Step 256605: loss = 0.15959
Step 256610: loss = 0.05234
Step 256615: loss = 0.11997
Step 256620: loss = 0.13091
Step 256625: loss = 0.05244
Step 256630: loss = 0.03784
Step 256635: loss = 0.04749
Step 256640: loss = 0.13706
Step 256645: loss = 0.07042
Step 256650: loss = 0.03486
Step 256655: loss = 0.02421
Step 256660: loss = 0.07479
Step 256665: loss = 0.08618
Step 256670: loss = 0.19900
Step 256675: loss = 0.17873
Step 256680: loss = 0.09062
Step 256685: loss = 0.31420
Step 256690: loss = 0.10289
Step 256695: loss = 0.09704
Step 256700: loss = 0.06040
Step 256705: loss = 0.05251
Step 256710: loss = 0.10410
Step 256715: loss = 0.11328
Step 256720: loss = 0.16419
Step 256725: loss = 0.04158
Step 256730: loss = 0.11013
Step 256735: loss = 0.05327
Step 256740: loss = 0.05293
Step 256745: loss = 0.13470
Step 256750: loss = 0.13384
Step 256755: loss = 0.04136
Step 256760: loss = 0.02006
Step 256765: loss = 0.07831
Step 256770: loss = 0.04600
Step 256775: loss = 0.19622
Step 256780: loss = 0.02031
Step 256785: loss = 0.09034
Step 256790: loss = 0.06973
Step 256795: loss = 0.11775
Step 256800: loss = 0.06735
Step 256805: loss = 0.11820
Step 256810: loss = 0.18819
Step 256815: loss = 0.04822
Step 256820: loss = 0.02357
Step 256825: loss = 0.01735
Step 256830: loss = 0.09663
Step 256835: loss = 0.02884
Step 256840: loss = 0.06681
Step 256845: loss = 0.09488
Step 256850: loss = 0.13753
Step 256855: loss = 0.00805
Step 256860: loss = 0.09501
Step 256865: loss = 0.08389
Step 256870: loss = 0.02165
Step 256875: loss = 0.31116
Step 256880: loss = 0.05714
Step 256885: loss = 0.14314
Step 256890: loss = 0.06488
Step 256895: loss = 0.03104
Step 256900: loss = 0.14189
Step 256905: loss = 0.18039
Step 256910: loss = 0.14232
Step 256915: loss = 0.08795
Step 256920: loss = 0.01602
Step 256925: loss = 0.34310
Step 256930: loss = 0.06668
Step 256935: loss = 0.04237
Step 256940: loss = 0.10123
Step 256945: loss = 0.10403
Step 256950: loss = 0.02363
Step 256955: loss = 0.02181
Step 256960: loss = 0.19555
Step 256965: loss = 0.09494
Step 256970: loss = 0.04258
Step 256975: loss = 0.08199
Step 256980: loss = 0.05562
Step 256985: loss = 0.07653
Step 256990: loss = 0.09102
Step 256995: loss = 0.04882
Step 257000: loss = 0.11723
Training Data Eval:
  Num examples: 50000, Num correct: 48711, Precision @ 1: 0.9742
('Testing Data Eval: EPOCH->', 258)
  Num examples: 10000, Num correct: 6786, Precision @ 1: 0.6786
Step 257005: loss = 0.01942
Step 257010: loss = 0.03355
Step 257015: loss = 0.06087
Step 257020: loss = 0.13605
Step 257025: loss = 0.22766
Step 257030: loss = 0.09182
Step 257035: loss = 0.13408
Step 257040: loss = 0.10269
Step 257045: loss = 0.14731
Step 257050: loss = 0.06548
Step 257055: loss = 0.07238
Step 257060: loss = 0.09011
Step 257065: loss = 0.04398
Step 257070: loss = 0.05501
Step 257075: loss = 0.03129
Step 257080: loss = 0.06666
Step 257085: loss = 0.14261
Step 257090: loss = 0.03757
Step 257095: loss = 0.08917
Step 257100: loss = 0.02820
Step 257105: loss = 0.05115
Step 257110: loss = 0.05573
Step 257115: loss = 0.43291
Step 257120: loss = 0.09209
Step 257125: loss = 0.09696
Step 257130: loss = 0.04723
Step 257135: loss = 0.02798
Step 257140: loss = 0.03816
Step 257145: loss = 0.03931
Step 257150: loss = 0.04598
Step 257155: loss = 0.03651
Step 257160: loss = 0.06953
Step 257165: loss = 0.08423
Step 257170: loss = 0.06835
Step 257175: loss = 0.04132
Step 257180: loss = 0.08307
Step 257185: loss = 0.06443
Step 257190: loss = 0.08571
Step 257195: loss = 0.08603
Step 257200: loss = 0.08880
Step 257205: loss = 0.03846
Step 257210: loss = 0.05499
Step 257215: loss = 0.29635
Step 257220: loss = 0.04686
Step 257225: loss = 0.08266
Step 257230: loss = 0.01441
Step 257235: loss = 0.10474
Step 257240: loss = 0.02588
Step 257245: loss = 0.03755
Step 257250: loss = 0.02116
Step 257255: loss = 0.05547
Step 257260: loss = 0.14319
Step 257265: loss = 0.12240
Step 257270: loss = 0.17823
Step 257275: loss = 0.02245
Step 257280: loss = 0.02799
Step 257285: loss = 0.03409
Step 257290: loss = 0.00738
Step 257295: loss = 0.00637
Step 257300: loss = 0.21098
Step 257305: loss = 0.02602
Step 257310: loss = 0.02509
Step 257315: loss = 0.05772
Step 257320: loss = 0.03240
Step 257325: loss = 0.04209
Step 257330: loss = 0.17076
Step 257335: loss = 0.35987
Step 257340: loss = 0.06833
Step 257345: loss = 0.02163
Step 257350: loss = 0.01966
Step 257355: loss = 0.08558
Step 257360: loss = 0.03108
Step 257365: loss = 0.08523
Step 257370: loss = 0.02859
Step 257375: loss = 0.01972
Step 257380: loss = 0.02271
Step 257385: loss = 0.02989
Step 257390: loss = 0.02746
Step 257395: loss = 0.03445
Step 257400: loss = 0.08847
Step 257405: loss = 0.14986
Step 257410: loss = 0.03309
Step 257415: loss = 0.09947
Step 257420: loss = 0.07874
Step 257425: loss = 0.04222
Step 257430: loss = 0.38145
Step 257435: loss = 0.05559
Step 257440: loss = 0.10486
Step 257445: loss = 0.03137
Step 257450: loss = 0.02009
Step 257455: loss = 0.08036
Step 257460: loss = 0.08734
Step 257465: loss = 0.05646
Step 257470: loss = 0.14594
Step 257475: loss = 0.06897
Step 257480: loss = 0.12187
Step 257485: loss = 0.05062
Step 257490: loss = 0.05094
Step 257495: loss = 0.02006
Step 257500: loss = 0.06223
Step 257505: loss = 0.04804
Step 257510: loss = 0.09115
Step 257515: loss = 0.05110
Step 257520: loss = 0.15881
Step 257525: loss = 0.06313
Step 257530: loss = 0.13327
Step 257535: loss = 0.04659
Step 257540: loss = 0.12876
Step 257545: loss = 0.03462
Step 257550: loss = 0.03349
Step 257555: loss = 0.11377
Step 257560: loss = 0.04118
Step 257565: loss = 0.08509
Step 257570: loss = 0.12760
Step 257575: loss = 0.17401
Step 257580: loss = 0.12398
Step 257585: loss = 0.33309
Step 257590: loss = 0.01515
Step 257595: loss = 0.10066
Step 257600: loss = 0.12550
Step 257605: loss = 0.06288
Step 257610: loss = 0.13456
Step 257615: loss = 0.10017
Step 257620: loss = 0.05440
Step 257625: loss = 0.01589
Step 257630: loss = 0.07523
Step 257635: loss = 0.02585
Step 257640: loss = 0.14574
Step 257645: loss = 0.09325
Step 257650: loss = 0.08052
Step 257655: loss = 0.03832
Step 257660: loss = 0.07357
Step 257665: loss = 0.07311
Step 257670: loss = 0.05894
Step 257675: loss = 0.01492
Step 257680: loss = 0.14111
Step 257685: loss = 0.01956
Step 257690: loss = 0.07278
Step 257695: loss = 0.07163
Step 257700: loss = 0.10969
Step 257705: loss = 0.04578
Step 257710: loss = 0.05054
Step 257715: loss = 0.06232
Step 257720: loss = 0.24091
Step 257725: loss = 0.04479
Step 257730: loss = 0.17408
Step 257735: loss = 0.10821
Step 257740: loss = 0.06932
Step 257745: loss = 0.09015
Step 257750: loss = 0.02685
Step 257755: loss = 0.18201
Step 257760: loss = 0.03509
Step 257765: loss = 0.02912
Step 257770: loss = 0.01262
Step 257775: loss = 0.04829
Step 257780: loss = 0.02816
Step 257785: loss = 0.07691
Step 257790: loss = 0.19407
Step 257795: loss = 0.03858
Step 257800: loss = 0.23181
Step 257805: loss = 0.12193
Step 257810: loss = 0.04306
Step 257815: loss = 0.02231
Step 257820: loss = 0.04932
Step 257825: loss = 0.02106
Step 257830: loss = 0.01591
Step 257835: loss = 0.20233
Step 257840: loss = 0.08469
Step 257845: loss = 0.04891
Step 257850: loss = 0.34710
Step 257855: loss = 0.05488
Step 257860: loss = 0.02134
Step 257865: loss = 0.02580
Step 257870: loss = 0.14529
Step 257875: loss = 0.28617
Step 257880: loss = 0.02835
Step 257885: loss = 0.07623
Step 257890: loss = 0.03465
Step 257895: loss = 0.12883
Step 257900: loss = 0.16420
Step 257905: loss = 0.13546
Step 257910: loss = 0.06412
Step 257915: loss = 0.21402
Step 257920: loss = 0.05722
Step 257925: loss = 0.05639
Step 257930: loss = 0.12019
Step 257935: loss = 0.06239
Step 257940: loss = 0.20886
Step 257945: loss = 0.26625
Step 257950: loss = 0.07624
Step 257955: loss = 0.13907
Step 257960: loss = 0.13393
Step 257965: loss = 0.19059
Step 257970: loss = 0.18466
Step 257975: loss = 0.06109
Step 257980: loss = 0.03623
Step 257985: loss = 0.08577
Step 257990: loss = 0.16452
Step 257995: loss = 0.08449
Step 258000: loss = 0.11272
Training Data Eval:
  Num examples: 50000, Num correct: 48493, Precision @ 1: 0.9699
('Testing Data Eval: EPOCH->', 259)
  Num examples: 10000, Num correct: 6821, Precision @ 1: 0.6821
Step 258005: loss = 0.03462
Step 258010: loss = 0.04309
Step 258015: loss = 0.10988
Step 258020: loss = 0.03147
Step 258025: loss = 0.17303
Step 258030: loss = 0.03059
Step 258035: loss = 0.06928
Step 258040: loss = 0.00770
Step 258045: loss = 0.09640
Step 258050: loss = 0.18251
Step 258055: loss = 0.07377
Step 258060: loss = 0.24936
Step 258065: loss = 0.06809
Step 258070: loss = 0.05768
Step 258075: loss = 0.02215
Step 258080: loss = 0.17690
Step 258085: loss = 0.05772
Step 258090: loss = 0.19331
Step 258095: loss = 0.02989
Step 258100: loss = 0.05984
Step 258105: loss = 0.05234
Step 258110: loss = 0.05833
Step 258115: loss = 0.09766
Step 258120: loss = 0.18666
Step 258125: loss = 0.09122
Step 258130: loss = 0.08271
Step 258135: loss = 0.38351
Step 258140: loss = 0.11707
Step 258145: loss = 0.06063
Step 258150: loss = 0.18389
Step 258155: loss = 0.17807
Step 258160: loss = 0.05674
Step 258165: loss = 0.04208
Step 258170: loss = 0.03954
Step 258175: loss = 0.07169
Step 258180: loss = 0.08954
Step 258185: loss = 0.05257
Step 258190: loss = 0.03310
Step 258195: loss = 0.07553
Step 258200: loss = 0.03038
Step 258205: loss = 0.16138
Step 258210: loss = 0.12968
Step 258215: loss = 0.07905
Step 258220: loss = 0.06983
Step 258225: loss = 0.05077
Step 258230: loss = 0.02644
Step 258235: loss = 0.03138
Step 258240: loss = 0.10463
Step 258245: loss = 0.07923
Step 258250: loss = 0.05354
Step 258255: loss = 0.03638
Step 258260: loss = 0.06859
Step 258265: loss = 0.05910
Step 258270: loss = 0.06141
Step 258275: loss = 0.19750
Step 258280: loss = 0.01444
Step 258285: loss = 0.02786
Step 258290: loss = 0.00573
Step 258295: loss = 0.05825
Step 258300: loss = 0.22411
Step 258305: loss = 0.08474
Step 258310: loss = 0.08964
Step 258315: loss = 0.08813
Step 258320: loss = 0.04187
Step 258325: loss = 0.02899
Step 258330: loss = 0.00876
Step 258335: loss = 0.02280
Step 258340: loss = 0.05044
Step 258345: loss = 0.09423
Step 258350: loss = 0.10365
Step 258355: loss = 0.05355
Step 258360: loss = 0.02778
Step 258365: loss = 0.06678
Step 258370: loss = 0.01952
Step 258375: loss = 0.10824
Step 258380: loss = 0.13485
Step 258385: loss = 0.10178
Step 258390: loss = 0.25391
Step 258395: loss = 0.04206
Step 258400: loss = 0.13377
Step 258405: loss = 0.04902
Step 258410: loss = 0.14166
Step 258415: loss = 0.04832
Step 258420: loss = 0.01379
Step 258425: loss = 0.07381
Step 258430: loss = 0.06776
Step 258435: loss = 0.06259
Step 258440: loss = 0.27675
Step 258445: loss = 0.02683
Step 258450: loss = 0.04305
Step 258455: loss = 0.03252
Step 258460: loss = 0.08013
Step 258465: loss = 0.03487
Step 258470: loss = 0.08514
Step 258475: loss = 0.08827
Step 258480: loss = 0.05980
Step 258485: loss = 0.06899
Step 258490: loss = 0.10602
Step 258495: loss = 0.01602
Step 258500: loss = 0.03616
Step 258505: loss = 0.05653
Step 258510: loss = 0.04149
Step 258515: loss = 0.07499
Step 258520: loss = 0.04052
Step 258525: loss = 0.06505
Step 258530: loss = 0.02396
Step 258535: loss = 0.03086
Step 258540: loss = 0.10132
Step 258545: loss = 0.01500
Step 258550: loss = 0.14962
Step 258555: loss = 0.03739
Step 258560: loss = 0.18338
Step 258565: loss = 0.04215
Step 258570: loss = 0.09668
Step 258575: loss = 0.05528
Step 258580: loss = 0.05333
Step 258585: loss = 0.12736
Step 258590: loss = 0.04366
Step 258595: loss = 0.02870
Step 258600: loss = 0.03570
Step 258605: loss = 0.15764
Step 258610: loss = 0.10940
Step 258615: loss = 0.08770
Step 258620: loss = 0.08682
Step 258625: loss = 0.02357
Step 258630: loss = 0.14606
Step 258635: loss = 0.16248
Step 258640: loss = 0.10680
Step 258645: loss = 0.05633
Step 258650: loss = 0.06417
Step 258655: loss = 0.06921
Step 258660: loss = 0.01319
Step 258665: loss = 0.11388
Step 258670: loss = 0.05409
Step 258675: loss = 0.15991
Step 258680: loss = 0.12365
Step 258685: loss = 0.21855
Step 258690: loss = 0.05065
Step 258695: loss = 0.00428
Step 258700: loss = 0.06818
Step 258705: loss = 0.22268
Step 258710: loss = 0.04333
Step 258715: loss = 0.02332
Step 258720: loss = 0.05007
Step 258725: loss = 0.05857
Step 258730: loss = 0.04623
Step 258735: loss = 0.04276
Step 258740: loss = 0.09459
Step 258745: loss = 0.00529
Step 258750: loss = 0.07636
Step 258755: loss = 0.07400
Step 258760: loss = 0.07429
Step 258765: loss = 0.02215
Step 258770: loss = 0.11234
Step 258775: loss = 0.02194
Step 258780: loss = 0.10448
Step 258785: loss = 0.16295
Step 258790: loss = 0.07921
Step 258795: loss = 0.06127
Step 258800: loss = 0.08556
Step 258805: loss = 0.13127
Step 258810: loss = 0.02823
Step 258815: loss = 0.05011
Step 258820: loss = 0.03075
Step 258825: loss = 0.01930
Step 258830: loss = 0.30400
Step 258835: loss = 0.03614
Step 258840: loss = 0.11099
Step 258845: loss = 0.02338
Step 258850: loss = 0.13057
Step 258855: loss = 0.06784
Step 258860: loss = 0.14483
Step 258865: loss = 0.23119
Step 258870: loss = 0.05322
Step 258875: loss = 0.04314
Step 258880: loss = 0.04676
Step 258885: loss = 0.12187
Step 258890: loss = 0.06809
Step 258895: loss = 0.14900
Step 258900: loss = 0.03702
Step 258905: loss = 0.15505
Step 258910: loss = 0.15295
Step 258915: loss = 0.06303
Step 258920: loss = 0.14634
Step 258925: loss = 0.04399
Step 258930: loss = 0.04579
Step 258935: loss = 0.11182
Step 258940: loss = 0.29700
Step 258945: loss = 0.08532
Step 258950: loss = 0.03949
Step 258955: loss = 0.01010
Step 258960: loss = 0.17554
Step 258965: loss = 0.08600
Step 258970: loss = 0.06419
Step 258975: loss = 0.12376
Step 258980: loss = 0.14052
Step 258985: loss = 0.03869
Step 258990: loss = 0.08172
Step 258995: loss = 0.07708
Step 259000: loss = 0.07041
Training Data Eval:
  Num examples: 50000, Num correct: 48384, Precision @ 1: 0.9677
('Testing Data Eval: EPOCH->', 260)
  Num examples: 10000, Num correct: 6761, Precision @ 1: 0.6761
Step 259005: loss = 0.10585
Step 259010: loss = 0.06690
Step 259015: loss = 0.02018
Step 259020: loss = 0.04637
Step 259025: loss = 0.11405
Step 259030: loss = 0.06609
Step 259035: loss = 0.04473
Step 259040: loss = 0.45173
Step 259045: loss = 0.09353
Step 259050: loss = 0.06055
Step 259055: loss = 0.17835
Step 259060: loss = 0.01035
Step 259065: loss = 0.31358
Step 259070: loss = 0.19404
Step 259075: loss = 0.10055
Step 259080: loss = 0.01936
Step 259085: loss = 0.15579
Step 259090: loss = 0.03466
Step 259095: loss = 0.04835
Step 259100: loss = 0.13223
Step 259105: loss = 0.02172
Step 259110: loss = 0.03116
Step 259115: loss = 0.04281
Step 259120: loss = 0.14556
Step 259125: loss = 0.07509
Step 259130: loss = 0.07872
Step 259135: loss = 0.16181
Step 259140: loss = 0.10068
Step 259145: loss = 0.07464
Step 259150: loss = 0.12373
Step 259155: loss = 0.01840
Step 259160: loss = 0.03328
Step 259165: loss = 0.08325
Step 259170: loss = 0.05654
Step 259175: loss = 0.12965
Step 259180: loss = 0.08278
Step 259185: loss = 0.02207
Step 259190: loss = 0.04311
Step 259195: loss = 0.05778
Step 259200: loss = 0.06872
Step 259205: loss = 0.10389
Step 259210: loss = 0.11696
Step 259215: loss = 0.06038
Step 259220: loss = 0.03274
Step 259225: loss = 0.07640
Step 259230: loss = 0.01913
Step 259235: loss = 0.03124
Step 259240: loss = 0.01696
Step 259245: loss = 0.01645
Step 259250: loss = 0.22983
Step 259255: loss = 0.05315
Step 259260: loss = 0.02126
Step 259265: loss = 0.09496
Step 259270: loss = 0.01412
Step 259275: loss = 0.06810
Step 259280: loss = 0.16469
Step 259285: loss = 0.11261
Step 259290: loss = 0.05490
Step 259295: loss = 0.29013
Step 259300: loss = 0.16126
Step 259305: loss = 0.09528
Step 259310: loss = 0.07506
Step 259315: loss = 0.03741
Step 259320: loss = 0.04967
Step 259325: loss = 0.08345
Step 259330: loss = 0.23173
Step 259335: loss = 0.04204
Step 259340: loss = 0.01617
Step 259345: loss = 0.19432
Step 259350: loss = 0.21037
Step 259355: loss = 0.04462
Step 259360: loss = 0.07574
Step 259365: loss = 0.11122
Step 259370: loss = 0.05973
Step 259375: loss = 0.06488
Step 259380: loss = 0.05641
Step 259385: loss = 0.08152
Step 259390: loss = 0.01572
Step 259395: loss = 0.04789
Step 259400: loss = 0.08427
Step 259405: loss = 0.05461
Step 259410: loss = 0.14617
Step 259415: loss = 0.07861
Step 259420: loss = 0.06587
Step 259425: loss = 0.17811
Step 259430: loss = 0.09859
Step 259435: loss = 0.07892
Step 259440: loss = 0.03066
Step 259445: loss = 0.20310
Step 259450: loss = 0.10146
Step 259455: loss = 0.02404
Step 259460: loss = 0.06260
Step 259465: loss = 0.31832
Step 259470: loss = 0.11918
Step 259475: loss = 0.17248
Step 259480: loss = 0.04273
Step 259485: loss = 0.07703
Step 259490: loss = 0.22866
Step 259495: loss = 0.12772
Step 259500: loss = 0.17718
Step 259505: loss = 0.03350
Step 259510: loss = 0.00375
Step 259515: loss = 0.04493
Step 259520: loss = 0.22971
Step 259525: loss = 0.35329
Step 259530: loss = 0.02014
Step 259535: loss = 0.16503
Step 259540: loss = 0.08815
Step 259545: loss = 0.08615
Step 259550: loss = 0.01329
Step 259555: loss = 0.02549
Step 259560: loss = 0.04089
Step 259565: loss = 0.04769
Step 259570: loss = 0.01745
Step 259575: loss = 0.21170
Step 259580: loss = 0.15777
Step 259585: loss = 0.04724
Step 259590: loss = 0.08234
Step 259595: loss = 0.07859
Step 259600: loss = 0.15498
Step 259605: loss = 0.11995
Step 259610: loss = 0.25986
Step 259615: loss = 0.06501
Step 259620: loss = 0.17250
Step 259625: loss = 0.12811
Step 259630: loss = 0.14024
Step 259635: loss = 0.04703
Step 259640: loss = 0.03799
Step 259645: loss = 0.02085
Step 259650: loss = 0.02292
Step 259655: loss = 0.01777
Step 259660: loss = 0.05646
Step 259665: loss = 0.33312
Step 259670: loss = 0.03002
Step 259675: loss = 0.05642
Step 259680: loss = 0.03282
Step 259685: loss = 0.03056
Step 259690: loss = 0.09783
Step 259695: loss = 0.09697
Step 259700: loss = 0.05877
Step 259705: loss = 0.07388
Step 259710: loss = 0.39815
Step 259715: loss = 0.02132
Step 259720: loss = 0.06680
Step 259725: loss = 0.35508
Step 259730: loss = 0.12101
Step 259735: loss = 0.03103
Step 259740: loss = 0.01645
Step 259745: loss = 0.02975
Step 259750: loss = 0.01389
Step 259755: loss = 0.04739
Step 259760: loss = 0.05582
Step 259765: loss = 0.06911
Step 259770: loss = 0.08285
Step 259775: loss = 0.29863
Step 259780: loss = 0.03106
Step 259785: loss = 0.03993
Step 259790: loss = 0.09407
Step 259795: loss = 0.04870
Step 259800: loss = 0.09180
Step 259805: loss = 0.04530
Step 259810: loss = 0.05926
Step 259815: loss = 0.05015
Step 259820: loss = 0.08376
Step 259825: loss = 0.02531
Step 259830: loss = 0.03487
Step 259835: loss = 0.10225
Step 259840: loss = 0.30960
Step 259845: loss = 0.10167
Step 259850: loss = 0.07983
Step 259855: loss = 0.08551
Step 259860: loss = 0.08739
Step 259865: loss = 0.08120
Step 259870: loss = 0.01907
Step 259875: loss = 0.06725
Step 259880: loss = 0.02027
Step 259885: loss = 0.06277
Step 259890: loss = 0.08986
Step 259895: loss = 0.03332
Step 259900: loss = 0.11114
Step 259905: loss = 0.25483
Step 259910: loss = 0.25752
Step 259915: loss = 0.05513
Step 259920: loss = 0.28391
Step 259925: loss = 0.03485
Step 259930: loss = 0.15262
Step 259935: loss = 0.27236
Step 259940: loss = 0.04389
Step 259945: loss = 0.06360
Step 259950: loss = 0.12003
Step 259955: loss = 0.10298
Step 259960: loss = 0.05620
Step 259965: loss = 0.14725
Step 259970: loss = 0.22431
Step 259975: loss = 0.07758
Step 259980: loss = 0.09423
Step 259985: loss = 0.11698
Step 259990: loss = 0.12065
Step 259995: loss = 0.03756
Step 260000: loss = 0.09832
Training Data Eval:
  Num examples: 50000, Num correct: 48553, Precision @ 1: 0.9711
('Testing Data Eval: EPOCH->', 261)
  Num examples: 10000, Num correct: 6760, Precision @ 1: 0.6760
Step 260005: loss = 0.03286
Step 260010: loss = 0.04950
Step 260015: loss = 0.01962
Step 260020: loss = 0.01911
Step 260025: loss = 0.06927
Step 260030: loss = 0.25545
Step 260035: loss = 0.05353
Step 260040: loss = 0.03464
Step 260045: loss = 0.12038
Step 260050: loss = 0.13563
Step 260055: loss = 0.07297
Step 260060: loss = 0.21670
Step 260065: loss = 0.04443
Step 260070: loss = 0.09794
Step 260075: loss = 0.11182
Step 260080: loss = 0.03181
Step 260085: loss = 0.02263
Step 260090: loss = 0.06505
Step 260095: loss = 0.08556
Step 260100: loss = 0.12542
Step 260105: loss = 0.10654
Step 260110: loss = 0.10637
Step 260115: loss = 0.08127
Step 260120: loss = 0.03515
Step 260125: loss = 0.10910
Step 260130: loss = 0.11893
Step 260135: loss = 0.05606
Step 260140: loss = 0.14762
Step 260145: loss = 0.09907
Step 260150: loss = 0.06425
Step 260155: loss = 0.01364
Step 260160: loss = 0.03365
Step 260165: loss = 0.04990
Step 260170: loss = 0.06907
Step 260175: loss = 0.04704
Step 260180: loss = 0.02136
Step 260185: loss = 0.10862
Step 260190: loss = 0.06634
Step 260195: loss = 0.03956
Step 260200: loss = 0.13974
Step 260205: loss = 0.07704
Step 260210: loss = 0.16835
Step 260215: loss = 0.03784
Step 260220: loss = 0.05061
Step 260225: loss = 0.02733
Step 260230: loss = 0.00549
Step 260235: loss = 0.07823
Step 260240: loss = 0.27672
Step 260245: loss = 0.11968
Step 260250: loss = 0.01982
Step 260255: loss = 0.03839
Step 260260: loss = 0.10913
Step 260265: loss = 0.08518
Step 260270: loss = 0.07135
Step 260275: loss = 0.10630
Step 260280: loss = 0.04244
Step 260285: loss = 0.15327
Step 260290: loss = 0.10970
Step 260295: loss = 0.41026
Step 260300: loss = 0.14213
Step 260305: loss = 0.01267
Step 260310: loss = 0.13168
Step 260315: loss = 0.02765
Step 260320: loss = 0.15873
Step 260325: loss = 0.02561
Step 260330: loss = 0.06621
Step 260335: loss = 0.00760
Step 260340: loss = 0.03262
Step 260345: loss = 0.18600
Step 260350: loss = 0.04297
Step 260355: loss = 0.05747
Step 260360: loss = 0.07246
Step 260365: loss = 0.03375
Step 260370: loss = 0.01089
Step 260375: loss = 0.01567
Step 260380: loss = 0.16904
Step 260385: loss = 0.01046
Step 260390: loss = 0.02502
Step 260395: loss = 0.08662
Step 260400: loss = 0.11410
Step 260405: loss = 0.03322
Step 260410: loss = 0.01439
Step 260415: loss = 0.08063
Step 260420: loss = 0.09093
Step 260425: loss = 0.06944
Step 260430: loss = 0.03795
Step 260435: loss = 0.02536
Step 260440: loss = 0.07818
Step 260445: loss = 0.01228
Step 260450: loss = 0.07262
Step 260455: loss = 0.28443
Step 260460: loss = 0.27585
Step 260465: loss = 0.06934
Step 260470: loss = 0.04098
Step 260475: loss = 0.06195
Step 260480: loss = 0.03260
Step 260485: loss = 0.03181
Step 260490: loss = 0.06047
Step 260495: loss = 0.11218
Step 260500: loss = 0.01843
Step 260505: loss = 0.08371
Step 260510: loss = 0.03517
Step 260515: loss = 0.03913
Step 260520: loss = 0.14807
Step 260525: loss = 0.12335
Step 260530: loss = 0.04253
Step 260535: loss = 0.02202
Step 260540: loss = 0.14364
Step 260545: loss = 0.22893
Step 260550: loss = 0.10715
Step 260555: loss = 0.07108
Step 260560: loss = 0.02832
Step 260565: loss = 0.06934
Step 260570: loss = 0.03994
Step 260575: loss = 0.05598
Step 260580: loss = 0.00904
Step 260585: loss = 0.03696
Step 260590: loss = 0.17023
Step 260595: loss = 0.01916
Step 260600: loss = 0.06271
Step 260605: loss = 0.28822
Step 260610: loss = 0.03358
Step 260615: loss = 0.09839
Step 260620: loss = 0.01681
Step 260625: loss = 0.04571
Step 260630: loss = 0.35057
Step 260635: loss = 0.03639
Step 260640: loss = 0.08776
Step 260645: loss = 0.29149
Step 260650: loss = 0.06779
Step 260655: loss = 0.05479
Step 260660: loss = 0.01116
Step 260665: loss = 0.07226
Step 260670: loss = 0.09035
Step 260675: loss = 0.04220
Step 260680: loss = 0.28609
Step 260685: loss = 0.12338
Step 260690: loss = 0.11311
Step 260695: loss = 0.06796
Step 260700: loss = 0.06588
Step 260705: loss = 0.05991
Step 260710: loss = 0.01293
Step 260715: loss = 0.03298
Step 260720: loss = 0.11055
Step 260725: loss = 0.02374
Step 260730: loss = 0.05930
Step 260735: loss = 0.04415
Step 260740: loss = 0.14926
Step 260745: loss = 0.03153
Step 260750: loss = 0.05259
Step 260755: loss = 0.02760
Step 260760: loss = 0.03048
Step 260765: loss = 0.14295
Step 260770: loss = 0.01486
Step 260775: loss = 0.19718
Step 260780: loss = 0.03335
Step 260785: loss = 0.08696
Step 260790: loss = 0.10018
Step 260795: loss = 0.06701
Step 260800: loss = 0.02782
Step 260805: loss = 0.03513
Step 260810: loss = 0.06354
Step 260815: loss = 0.04927
Step 260820: loss = 0.01608
Step 260825: loss = 0.06943
Step 260830: loss = 0.03499
Step 260835: loss = 0.17789
Step 260840: loss = 0.13024
Step 260845: loss = 0.20696
Step 260850: loss = 0.02703
Step 260855: loss = 0.08330
Step 260860: loss = 0.17811
Step 260865: loss = 0.05242
Step 260870: loss = 0.01156
Step 260875: loss = 0.04290
Step 260880: loss = 0.04442
Step 260885: loss = 0.08163
Step 260890: loss = 0.33746
Step 260895: loss = 0.02393
Step 260900: loss = 0.07182
Step 260905: loss = 0.40024
Step 260910: loss = 0.10818
Step 260915: loss = 0.08352
Step 260920: loss = 0.27606
Step 260925: loss = 0.05187
Step 260930: loss = 0.21321
Step 260935: loss = 0.02923
Step 260940: loss = 0.05071
Step 260945: loss = 0.02672
Step 260950: loss = 0.09150
Step 260955: loss = 0.11610
Step 260960: loss = 0.08328
Step 260965: loss = 0.19268
Step 260970: loss = 0.06624
Step 260975: loss = 0.03175
Step 260980: loss = 0.14482
Step 260985: loss = 0.05987
Step 260990: loss = 0.10484
Step 260995: loss = 0.19363
Step 261000: loss = 0.05726
Training Data Eval:
  Num examples: 50000, Num correct: 48683, Precision @ 1: 0.9737
('Testing Data Eval: EPOCH->', 262)
  Num examples: 10000, Num correct: 6805, Precision @ 1: 0.6805
Step 261005: loss = 0.13260
Step 261010: loss = 0.07523
Step 261015: loss = 0.04944
Step 261020: loss = 0.03722
Step 261025: loss = 0.08050
Step 261030: loss = 0.05233
Step 261035: loss = 0.10823
Step 261040: loss = 0.07372
Step 261045: loss = 0.17042
Step 261050: loss = 0.11373
Step 261055: loss = 0.01947
Step 261060: loss = 0.04844
Step 261065: loss = 0.02095
Step 261070: loss = 0.11382
Step 261075: loss = 0.05687
Step 261080: loss = 0.11757
Step 261085: loss = 0.04587
Step 261090: loss = 0.07127
Step 261095: loss = 0.08426
Step 261100: loss = 0.02887
Step 261105: loss = 0.09499
Step 261110: loss = 0.01990
Step 261115: loss = 0.11482
Step 261120: loss = 0.06945
Step 261125: loss = 0.13697
Step 261130: loss = 0.19201
Step 261135: loss = 0.08392
Step 261140: loss = 0.04753
Step 261145: loss = 0.00237
Step 261150: loss = 0.17779
Step 261155: loss = 0.01464
Step 261160: loss = 0.03984
Step 261165: loss = 0.04814
Step 261170: loss = 0.04951
Step 261175: loss = 0.20118
Step 261180: loss = 0.08204
Step 261185: loss = 0.15485
Step 261190: loss = 0.13177
Step 261195: loss = 0.03895
Step 261200: loss = 0.09121
Step 261205: loss = 0.08970
Step 261210: loss = 0.03076
Step 261215: loss = 0.04904
Step 261220: loss = 0.13052
Step 261225: loss = 0.11201
Step 261230: loss = 0.04817
Step 261235: loss = 0.16127
Step 261240: loss = 0.04199
Step 261245: loss = 0.05569
Step 261250: loss = 0.04735
Step 261255: loss = 0.06821
Step 261260: loss = 0.09591
Step 261265: loss = 0.07848
Step 261270: loss = 0.01126
Step 261275: loss = 0.02503
Step 261280: loss = 0.06394
Step 261285: loss = 0.37958
Step 261290: loss = 0.05175
Step 261295: loss = 0.06595
Step 261300: loss = 0.18842
Step 261305: loss = 0.29513
Step 261310: loss = 0.12524
Step 261315: loss = 0.02126
Step 261320: loss = 0.09995
Step 261325: loss = 0.17603
Step 261330: loss = 0.06193
Step 261335: loss = 0.00435
Step 261340: loss = 0.23258
Step 261345: loss = 0.01535
Step 261350: loss = 0.03530
Step 261355: loss = 0.04171
Step 261360: loss = 0.01753
Step 261365: loss = 0.03350
Step 261370: loss = 0.07261
Step 261375: loss = 0.06828
Step 261380: loss = 0.03564
Step 261385: loss = 0.31905
Step 261390: loss = 0.11821
Step 261395: loss = 0.12387
Step 261400: loss = 0.08370
Step 261405: loss = 0.13393
Step 261410: loss = 0.01817
Step 261415: loss = 0.12171
Step 261420: loss = 0.04867
Step 261425: loss = 0.01635
Step 261430: loss = 0.04694
Step 261435: loss = 0.04968
Step 261440: loss = 0.15850
Step 261445: loss = 0.05154
Step 261450: loss = 0.06842
Step 261455: loss = 0.10946
Step 261460: loss = 0.20133
Step 261465: loss = 0.10830
Step 261470: loss = 0.05149
Step 261475: loss = 0.04057
Step 261480: loss = 0.09900
Step 261485: loss = 0.02604
Step 261490: loss = 0.05044
Step 261495: loss = 0.04856
Step 261500: loss = 0.18734
Step 261505: loss = 0.07733
Step 261510: loss = 0.03254
Step 261515: loss = 0.22065
Step 261520: loss = 0.05457
Step 261525: loss = 0.03879
Step 261530: loss = 0.18991
Step 261535: loss = 0.20781
Step 261540: loss = 0.06967
Step 261545: loss = 0.04760
Step 261550: loss = 0.03717
Step 261555: loss = 0.12143
Step 261560: loss = 0.03496
Step 261565: loss = 0.06457
Step 261570: loss = 0.04262
Step 261575: loss = 0.10338
Step 261580: loss = 0.02100
Step 261585: loss = 0.02024
Step 261590: loss = 0.33189
Step 261595: loss = 0.04659
Step 261600: loss = 0.05524
Step 261605: loss = 0.11834
Step 261610: loss = 0.04013
Step 261615: loss = 0.04545
Step 261620: loss = 0.13952
Step 261625: loss = 0.15797
Step 261630: loss = 0.03929
Step 261635: loss = 0.03484
Step 261640: loss = 0.13707
Step 261645: loss = 0.02392
Step 261650: loss = 0.08555
Step 261655: loss = 0.06521
Step 261660: loss = 0.05454
Step 261665: loss = 0.04391
Step 261670: loss = 0.02582
Step 261675: loss = 0.06271
Step 261680: loss = 0.03462
Step 261685: loss = 0.02339
Step 261690: loss = 0.18699
Step 261695: loss = 0.01530
Step 261700: loss = 0.20385
Step 261705: loss = 0.04571
Step 261710: loss = 0.10951
Step 261715: loss = 0.11265
Step 261720: loss = 0.14779
Step 261725: loss = 0.06336
Step 261730: loss = 0.03895
Step 261735: loss = 0.09542
Step 261740: loss = 0.14969
Step 261745: loss = 0.06466
Step 261750: loss = 0.09394
Step 261755: loss = 0.06392
Step 261760: loss = 0.06160
Step 261765: loss = 0.05938
Step 261770: loss = 0.03001
Step 261775: loss = 0.03552
Step 261780: loss = 0.18486
Step 261785: loss = 0.11308
Step 261790: loss = 0.16608
Step 261795: loss = 0.02319
Step 261800: loss = 0.03559
Step 261805: loss = 0.03883
Step 261810: loss = 0.03094
Step 261815: loss = 0.02061
Step 261820: loss = 0.05942
Step 261825: loss = 0.10446
Step 261830: loss = 0.02110
Step 261835: loss = 0.05124
Step 261840: loss = 0.18849
Step 261845: loss = 0.08959
Step 261850: loss = 0.03841
Step 261855: loss = 0.07053
Step 261860: loss = 0.01859
Step 261865: loss = 0.05292
Step 261870: loss = 0.00880
Step 261875: loss = 0.05269
Step 261880: loss = 0.04065
Step 261885: loss = 0.08676
Step 261890: loss = 0.08492
Step 261895: loss = 0.04347
Step 261900: loss = 0.16247
Step 261905: loss = 0.12468
Step 261910: loss = 0.11433
Step 261915: loss = 0.02407
Step 261920: loss = 0.06117
Step 261925: loss = 0.04101
Step 261930: loss = 0.06583
Step 261935: loss = 0.01623
Step 261940: loss = 0.10941
Step 261945: loss = 0.16072
Step 261950: loss = 0.04764
Step 261955: loss = 0.07797
Step 261960: loss = 0.13203
Step 261965: loss = 0.14489
Step 261970: loss = 0.06956
Step 261975: loss = 0.13360
Step 261980: loss = 0.20301
Step 261985: loss = 0.03965
Step 261990: loss = 0.02842
Step 261995: loss = 0.08969
Step 262000: loss = 0.12706
Training Data Eval:
  Num examples: 50000, Num correct: 48570, Precision @ 1: 0.9714
('Testing Data Eval: EPOCH->', 263)
  Num examples: 10000, Num correct: 6647, Precision @ 1: 0.6647
Step 262005: loss = 0.04121
Step 262010: loss = 0.02453
Step 262015: loss = 0.05526
Step 262020: loss = 0.07080
Step 262025: loss = 0.02294
Step 262030: loss = 0.03672
Step 262035: loss = 0.04548
Step 262040: loss = 0.04381
Step 262045: loss = 0.06731
Step 262050: loss = 0.09558
Step 262055: loss = 0.10331
Step 262060: loss = 0.07407
Step 262065: loss = 0.06649
Step 262070: loss = 0.11372
Step 262075: loss = 0.12401
Step 262080: loss = 0.01821
Step 262085: loss = 0.02758
Step 262090: loss = 0.25209
Step 262095: loss = 0.03371
Step 262100: loss = 0.05383
Step 262105: loss = 0.10662
Step 262110: loss = 0.01182
Step 262115: loss = 0.04387
Step 262120: loss = 0.05307
Step 262125: loss = 0.06545
Step 262130: loss = 0.03485
Step 262135: loss = 0.07377
Step 262140: loss = 0.02840
Step 262145: loss = 0.05165
Step 262150: loss = 0.04953
Step 262155: loss = 0.17760
Step 262160: loss = 0.05739
Step 262165: loss = 0.02229
Step 262170: loss = 0.04628
Step 262175: loss = 0.04976
Step 262180: loss = 0.26650
Step 262185: loss = 0.11617
Step 262190: loss = 0.10532
Step 262195: loss = 0.07158
Step 262200: loss = 0.08453
Step 262205: loss = 0.15205
Step 262210: loss = 0.11874
Step 262215: loss = 0.04529
Step 262220: loss = 0.15355
Step 262225: loss = 0.21197
Step 262230: loss = 0.06378
Step 262235: loss = 0.17670
Step 262240: loss = 0.06371
Step 262245: loss = 0.03789
Step 262250: loss = 0.05474
Step 262255: loss = 0.14113
Step 262260: loss = 0.02924
Step 262265: loss = 0.06424
Step 262270: loss = 0.22217
Step 262275: loss = 0.09194
Step 262280: loss = 0.03404
Step 262285: loss = 0.08968
Step 262290: loss = 0.13960
Step 262295: loss = 0.05723
Step 262300: loss = 0.19616
Step 262305: loss = 0.02545
Step 262310: loss = 0.02539
Step 262315: loss = 0.17165
Step 262320: loss = 0.01146
Step 262325: loss = 0.07127
Step 262330: loss = 0.08283
Step 262335: loss = 0.08244
Step 262340: loss = 0.06488
Step 262345: loss = 0.07771
Step 262350: loss = 0.15404
Step 262355: loss = 0.04452
Step 262360: loss = 0.03116
Step 262365: loss = 0.07252
Step 262370: loss = 0.02112
Step 262375: loss = 0.01776
Step 262380: loss = 0.19746
Step 262385: loss = 0.16107
Step 262390: loss = 0.02383
Step 262395: loss = 0.12233
Step 262400: loss = 0.19497
Step 262405: loss = 0.11014
Step 262410: loss = 0.06853
Step 262415: loss = 0.04404
Step 262420: loss = 0.13382
Step 262425: loss = 0.21323
Step 262430: loss = 0.05298
Step 262435: loss = 0.04890
Step 262440: loss = 0.14623
Step 262445: loss = 0.11565
Step 262450: loss = 0.06504
Step 262455: loss = 0.04431
Step 262460: loss = 0.02187
Step 262465: loss = 0.07036
Step 262470: loss = 0.06831
Step 262475: loss = 0.08229
Step 262480: loss = 0.10022
Step 262485: loss = 0.49529
Step 262490: loss = 0.02938
Step 262495: loss = 0.10381
Step 262500: loss = 0.18177
Step 262505: loss = 0.05877
Step 262510: loss = 0.04482
Step 262515: loss = 0.12506
Step 262520: loss = 0.01571
Step 262525: loss = 0.06140
Step 262530: loss = 0.03148
Step 262535: loss = 0.06060
Step 262540: loss = 0.32324
Step 262545: loss = 0.09763
Step 262550: loss = 0.18518
Step 262555: loss = 0.07094
Step 262560: loss = 0.05732
Step 262565: loss = 0.21350
Step 262570: loss = 0.11298
Step 262575: loss = 0.01609
Step 262580: loss = 0.19374
Step 262585: loss = 0.06284
Step 262590: loss = 0.06080
Step 262595: loss = 0.17202
Step 262600: loss = 0.02011
Step 262605: loss = 0.02008
Step 262610: loss = 0.16275
Step 262615: loss = 0.03693
Step 262620: loss = 0.04177
Step 262625: loss = 0.01022
Step 262630: loss = 0.03851
Step 262635: loss = 0.06563
Step 262640: loss = 0.04815
Step 262645: loss = 0.06347
Step 262650: loss = 0.01589
Step 262655: loss = 0.27503
Step 262660: loss = 0.04549
Step 262665: loss = 0.04700
Step 262670: loss = 0.02391
Step 262675: loss = 0.13011
Step 262680: loss = 0.06383
Step 262685: loss = 0.21496
Step 262690: loss = 0.19652
Step 262695: loss = 0.15726
Step 262700: loss = 0.00920
Step 262705: loss = 0.05595
Step 262710: loss = 0.21878
Step 262715: loss = 0.10164
Step 262720: loss = 0.12312
Step 262725: loss = 0.05262
Step 262730: loss = 0.28518
Step 262735: loss = 0.03674
Step 262740: loss = 0.03734
Step 262745: loss = 0.15016
Step 262750: loss = 0.21449
Step 262755: loss = 0.04051
Step 262760: loss = 0.02907
Step 262765: loss = 0.06827
Step 262770: loss = 0.05253
Step 262775: loss = 0.14738
Step 262780: loss = 0.06683
Step 262785: loss = 0.14961
Step 262790: loss = 0.06522
Step 262795: loss = 0.07629
Step 262800: loss = 0.18902
Step 262805: loss = 0.01772
Step 262810: loss = 0.27801
Step 262815: loss = 0.04027
Step 262820: loss = 0.04864
Step 262825: loss = 0.09959
Step 262830: loss = 0.01249
Step 262835: loss = 0.14164
Step 262840: loss = 0.18290
Step 262845: loss = 0.02408
Step 262850: loss = 0.04612
Step 262855: loss = 0.03112
Step 262860: loss = 0.01816
Step 262865: loss = 0.02719
Step 262870: loss = 0.06454
Step 262875: loss = 0.10758
Step 262880: loss = 0.04573
Step 262885: loss = 0.01422
Step 262890: loss = 0.05568
Step 262895: loss = 0.04328
Step 262900: loss = 0.10061
Step 262905: loss = 0.06378
Step 262910: loss = 0.08616
Step 262915: loss = 0.06995
Step 262920: loss = 0.05739
Step 262925: loss = 0.13581
Step 262930: loss = 0.05433
Step 262935: loss = 0.01336
Step 262940: loss = 0.11834
Step 262945: loss = 0.13027
Step 262950: loss = 0.15874
Step 262955: loss = 0.00745
Step 262960: loss = 0.06671
Step 262965: loss = 0.01711
Step 262970: loss = 0.01997
Step 262975: loss = 0.01902
Step 262980: loss = 0.02088
Step 262985: loss = 0.05558
Step 262990: loss = 0.00966
Step 262995: loss = 0.14528
Step 263000: loss = 0.05711
Training Data Eval:
  Num examples: 50000, Num correct: 48863, Precision @ 1: 0.9773
('Testing Data Eval: EPOCH->', 264)
  Num examples: 10000, Num correct: 6739, Precision @ 1: 0.6739
Step 263005: loss = 0.04686
Step 263010: loss = 0.21018
Step 263015: loss = 0.24353
Step 263020: loss = 0.06037
Step 263025: loss = 0.09393
Step 263030: loss = 0.05391
Step 263035: loss = 0.07055
Step 263040: loss = 0.08104
Step 263045: loss = 0.07843
Step 263050: loss = 0.11050
Step 263055: loss = 0.02231
Step 263060: loss = 0.02589
Step 263065: loss = 0.17310
Step 263070: loss = 0.04091
Step 263075: loss = 0.21392
Step 263080: loss = 0.12608
Step 263085: loss = 0.15404
Step 263090: loss = 0.03021
Step 263095: loss = 0.15344
Step 263100: loss = 0.07085
Step 263105: loss = 0.09182
Step 263110: loss = 0.03299
Step 263115: loss = 0.03368
Step 263120: loss = 0.25699
Step 263125: loss = 0.05728
Step 263130: loss = 0.01268
Step 263135: loss = 0.01662
Step 263140: loss = 0.12023
Step 263145: loss = 0.04008
Step 263150: loss = 0.12546
Step 263155: loss = 0.00995
Step 263160: loss = 0.10123
Step 263165: loss = 0.21268
Step 263170: loss = 0.05243
Step 263175: loss = 0.17655
Step 263180: loss = 0.09416
Step 263185: loss = 0.11941
Step 263190: loss = 0.01980
Step 263195: loss = 0.16768
Step 263200: loss = 0.04855
Step 263205: loss = 0.01494
Step 263210: loss = 0.13850
Step 263215: loss = 0.11190
Step 263220: loss = 0.01958
Step 263225: loss = 0.16501
Step 263230: loss = 0.06714
Step 263235: loss = 0.09883
Step 263240: loss = 0.22134
Step 263245: loss = 0.10150
Step 263250: loss = 0.15616
Step 263255: loss = 0.01981
Step 263260: loss = 0.03202
Step 263265: loss = 0.02782
Step 263270: loss = 0.33781
Step 263275: loss = 0.17351
Step 263280: loss = 0.12377
Step 263285: loss = 0.11904
Step 263290: loss = 0.17353
Step 263295: loss = 0.17261
Step 263300: loss = 0.04477
Step 263305: loss = 0.04145
Step 263310: loss = 0.05127
Step 263315: loss = 0.15136
Step 263320: loss = 0.11632
Step 263325: loss = 0.16577
Step 263330: loss = 0.04172
Step 263335: loss = 0.20748
Step 263340: loss = 0.09117
Step 263345: loss = 0.09985
Step 263350: loss = 0.11532
Step 263355: loss = 0.01295
Step 263360: loss = 0.04482
Step 263365: loss = 0.04928
Step 263370: loss = 0.05003
Step 263375: loss = 0.03637
Step 263380: loss = 0.09642
Step 263385: loss = 0.04973
Step 263390: loss = 0.05941
Step 263395: loss = 0.02828
Step 263400: loss = 0.01685
Step 263405: loss = 0.08144
Step 263410: loss = 0.03476
Step 263415: loss = 0.07001
Step 263420: loss = 0.08134
Step 263425: loss = 0.12018
Step 263430: loss = 0.06384
Step 263435: loss = 0.03881
Step 263440: loss = 0.06992
Step 263445: loss = 0.06847
Step 263450: loss = 0.05235
Step 263455: loss = 0.04351
Step 263460: loss = 0.11921
Step 263465: loss = 0.06468
Step 263470: loss = 0.07833
Step 263475: loss = 0.07892
Step 263480: loss = 0.11455
Step 263485: loss = 0.03343
Step 263490: loss = 0.02155
Step 263495: loss = 0.06524
Step 263500: loss = 0.18599
Step 263505: loss = 0.08200
Step 263510: loss = 0.12699
Step 263515: loss = 0.01880
Step 263520: loss = 0.07540
Step 263525: loss = 0.10681
Step 263530: loss = 0.14711
Step 263535: loss = 0.35654
Step 263540: loss = 0.02968
Step 263545: loss = 0.13400
Step 263550: loss = 0.03445
Step 263555: loss = 0.03448
Step 263560: loss = 0.02675
Step 263565: loss = 0.12826
Step 263570: loss = 0.19341
Step 263575: loss = 0.04954
Step 263580: loss = 0.04840
Step 263585: loss = 0.04222
Step 263590: loss = 0.21965
Step 263595: loss = 0.02894
Step 263600: loss = 0.11031
Step 263605: loss = 0.05126
Step 263610: loss = 0.01667
Step 263615: loss = 0.09362
Step 263620: loss = 0.12240
Step 263625: loss = 0.08134
Step 263630: loss = 0.04816
Step 263635: loss = 0.05380
Step 263640: loss = 0.12040
Step 263645: loss = 0.04554
Step 263650: loss = 0.06309
Step 263655: loss = 0.14789
Step 263660: loss = 0.16961
Step 263665: loss = 0.08748
Step 263670: loss = 0.04487
Step 263675: loss = 0.17076
Step 263680: loss = 0.19554
Step 263685: loss = 0.03301
Step 263690: loss = 0.09626
Step 263695: loss = 0.02464
Step 263700: loss = 0.15059
Step 263705: loss = 0.07559
Step 263710: loss = 0.03750
Step 263715: loss = 0.02833
Step 263720: loss = 0.03754
Step 263725: loss = 0.05356
Step 263730: loss = 0.27927
Step 263735: loss = 0.14817
Step 263740: loss = 0.02608
Step 263745: loss = 0.57702
Step 263750: loss = 0.05115
Step 263755: loss = 0.06167
Step 263760: loss = 0.12625
Step 263765: loss = 0.07016
Step 263770: loss = 0.13855
Step 263775: loss = 0.11013
Step 263780: loss = 0.08020
Step 263785: loss = 0.04059
Step 263790: loss = 0.03883
Step 263795: loss = 0.04218
Step 263800: loss = 0.08524
Step 263805: loss = 0.13173
Step 263810: loss = 0.04977
Step 263815: loss = 0.21644
Step 263820: loss = 0.11152
Step 263825: loss = 0.10340
Step 263830: loss = 0.03945
Step 263835: loss = 0.01287
Step 263840: loss = 0.04570
Step 263845: loss = 0.05612
Step 263850: loss = 0.02741
Step 263855: loss = 0.02823
Step 263860: loss = 0.04637
Step 263865: loss = 0.14025
Step 263870: loss = 0.01778
Step 263875: loss = 0.05762
Step 263880: loss = 0.04656
Step 263885: loss = 0.03745
Step 263890: loss = 0.08068
Step 263895: loss = 0.15090
Step 263900: loss = 0.10020
Step 263905: loss = 0.29114
Step 263910: loss = 0.05122
Step 263915: loss = 0.02720
Step 263920: loss = 0.05728
Step 263925: loss = 0.03143
Step 263930: loss = 0.01429
Step 263935: loss = 0.04822
Step 263940: loss = 0.09126
Step 263945: loss = 0.31454
Step 263950: loss = 0.04381
Step 263955: loss = 0.11034
Step 263960: loss = 0.19709
Step 263965: loss = 0.02288
Step 263970: loss = 0.18368
Step 263975: loss = 0.04042
Step 263980: loss = 0.14030
Step 263985: loss = 0.05198
Step 263990: loss = 0.11357
Step 263995: loss = 0.02581
Step 264000: loss = 0.11690
Training Data Eval:
  Num examples: 50000, Num correct: 48647, Precision @ 1: 0.9729
('Testing Data Eval: EPOCH->', 265)
  Num examples: 10000, Num correct: 6841, Precision @ 1: 0.6841
Step 264005: loss = 0.06319
Step 264010: loss = 0.01617
Step 264015: loss = 0.05875
Step 264020: loss = 0.04728
Step 264025: loss = 0.03549
Step 264030: loss = 0.06399
Step 264035: loss = 0.02433
Step 264040: loss = 0.04349
Step 264045: loss = 0.02782
Step 264050: loss = 0.07511
Step 264055: loss = 0.13633
Step 264060: loss = 0.07225
Step 264065: loss = 0.07902
Step 264070: loss = 0.04095
Step 264075: loss = 0.10583
Step 264080: loss = 0.04797
Step 264085: loss = 0.16045
Step 264090: loss = 0.09878
Step 264095: loss = 0.03259
Step 264100: loss = 0.15065
Step 264105: loss = 0.06482
Step 264110: loss = 0.03182
Step 264115: loss = 0.05745
Step 264120: loss = 0.03630
Step 264125: loss = 0.18526
Step 264130: loss = 0.10921
Step 264135: loss = 0.08182
Step 264140: loss = 0.02760
Step 264145: loss = 0.06841
Step 264150: loss = 0.01952
Step 264155: loss = 0.10017
Step 264160: loss = 0.05621
Step 264165: loss = 0.20646
Step 264170: loss = 0.04053
Step 264175: loss = 0.02037
Step 264180: loss = 0.06235
Step 264185: loss = 0.07612
Step 264190: loss = 0.04495
Step 264195: loss = 0.00656
Step 264200: loss = 0.10540
Step 264205: loss = 0.09907
Step 264210: loss = 0.03280
Step 264215: loss = 0.07410
Step 264220: loss = 0.09764
Step 264225: loss = 0.06668
Step 264230: loss = 0.11235
Step 264235: loss = 0.03108
Step 264240: loss = 0.60902
Step 264245: loss = 0.11289
Step 264250: loss = 0.07287
Step 264255: loss = 0.04466
Step 264260: loss = 0.03985
Step 264265: loss = 0.08014
Step 264270: loss = 0.08148
Step 264275: loss = 0.12151
Step 264280: loss = 0.21241
Step 264285: loss = 0.01657
Step 264290: loss = 0.17692
Step 264295: loss = 0.02582
Step 264300: loss = 0.12008
Step 264305: loss = 0.03353
Step 264310: loss = 0.07561
Step 264315: loss = 0.07205
Step 264320: loss = 0.02663
Step 264325: loss = 0.01881
Step 264330: loss = 0.20618
Step 264335: loss = 0.04108
Step 264340: loss = 0.07290
Step 264345: loss = 0.27379
Step 264350: loss = 0.03321
Step 264355: loss = 0.08464
Step 264360: loss = 0.06503
Step 264365: loss = 0.22606
Step 264370: loss = 0.02604
Step 264375: loss = 0.01645
Step 264380: loss = 0.20135
Step 264385: loss = 0.02335
Step 264390: loss = 0.10995
Step 264395: loss = 0.05670
Step 264400: loss = 0.09375
Step 264405: loss = 0.04947
Step 264410: loss = 0.02647
Step 264415: loss = 0.02435
Step 264420: loss = 0.11996
Step 264425: loss = 0.01818
Step 264430: loss = 0.12137
Step 264435: loss = 0.07255
Step 264440: loss = 0.04280
Step 264445: loss = 0.17947
Step 264450: loss = 0.06858
Step 264455: loss = 0.23329
Step 264460: loss = 0.04972
Step 264465: loss = 0.04506
Step 264470: loss = 0.10952
Step 264475: loss = 0.01557
Step 264480: loss = 0.10543
Step 264485: loss = 0.00680
Step 264490: loss = 0.09341
Step 264495: loss = 0.03139
Step 264500: loss = 0.00799
Step 264505: loss = 0.07779
Step 264510: loss = 0.03230
Step 264515: loss = 0.03020
Step 264520: loss = 0.01632
Step 264525: loss = 0.04756
Step 264530: loss = 0.29748
Step 264535: loss = 0.01154
Step 264540: loss = 0.08871
Step 264545: loss = 0.02888
Step 264550: loss = 0.02251
Step 264555: loss = 0.01315
Step 264560: loss = 0.09416
Step 264565: loss = 0.06935
Step 264570: loss = 0.00802
Step 264575: loss = 0.27600
Step 264580: loss = 0.12903
Step 264585: loss = 0.25055
Step 264590: loss = 0.04817
Step 264595: loss = 0.30690
Step 264600: loss = 0.03519
Step 264605: loss = 0.05268
Step 264610: loss = 0.05078
Step 264615: loss = 0.06530
Step 264620: loss = 0.07336
Step 264625: loss = 0.22933
Step 264630: loss = 0.16909
Step 264635: loss = 0.16888
Step 264640: loss = 0.04125
Step 264645: loss = 0.26708
Step 264650: loss = 0.45203
Step 264655: loss = 0.08413
Step 264660: loss = 0.04645
Step 264665: loss = 0.06665
Step 264670: loss = 0.04753
Step 264675: loss = 0.06487
Step 264680: loss = 0.09563
Step 264685: loss = 0.05672
Step 264690: loss = 0.02235
Step 264695: loss = 0.04704
Step 264700: loss = 0.02776
Step 264705: loss = 0.09648
Step 264710: loss = 0.11969
Step 264715: loss = 0.05881
Step 264720: loss = 0.18981
Step 264725: loss = 0.08026
Step 264730: loss = 0.07531
Step 264735: loss = 0.03262
Step 264740: loss = 0.08708
Step 264745: loss = 0.03936
Step 264750: loss = 0.04622
Step 264755: loss = 0.03587
Step 264760: loss = 0.12936
Step 264765: loss = 0.11103
Step 264770: loss = 0.03916
Step 264775: loss = 0.03982
Step 264780: loss = 0.00764
Step 264785: loss = 0.24466
Step 264790: loss = 0.01935
Step 264795: loss = 0.14814
Step 264800: loss = 0.08131
Step 264805: loss = 0.07732
Step 264810: loss = 0.07101
Step 264815: loss = 0.05238
Step 264820: loss = 0.03823
Step 264825: loss = 0.03695
Step 264830: loss = 0.01288
Step 264835: loss = 0.05889
Step 264840: loss = 0.06386
Step 264845: loss = 0.02069
Step 264850: loss = 0.04427
Step 264855: loss = 0.06452
Step 264860: loss = 0.01400
Step 264865: loss = 0.14852
Step 264870: loss = 0.03415
Step 264875: loss = 0.09349
Step 264880: loss = 0.13982
Step 264885: loss = 0.33821
Step 264890: loss = 0.02527
Step 264895: loss = 0.08548
Step 264900: loss = 0.11185
Step 264905: loss = 0.05154
Step 264910: loss = 0.01244
Step 264915: loss = 0.02052
Step 264920: loss = 0.05890
Step 264925: loss = 0.08726
Step 264930: loss = 0.08050
Step 264935: loss = 0.09074
Step 264940: loss = 0.14605
Step 264945: loss = 0.01225
Step 264950: loss = 0.16573
Step 264955: loss = 0.17831
Step 264960: loss = 0.01805
Step 264965: loss = 0.04174
Step 264970: loss = 0.08346
Step 264975: loss = 0.03332
Step 264980: loss = 0.03939
Step 264985: loss = 0.04178
Step 264990: loss = 0.10997
Step 264995: loss = 0.21799
Step 265000: loss = 0.04328
Training Data Eval:
  Num examples: 50000, Num correct: 48727, Precision @ 1: 0.9745
('Testing Data Eval: EPOCH->', 266)
  Num examples: 10000, Num correct: 6742, Precision @ 1: 0.6742
Step 265005: loss = 0.09565
Step 265010: loss = 0.27354
Step 265015: loss = 0.10727
Step 265020: loss = 0.03246
Step 265025: loss = 0.06989
Step 265030: loss = 0.13974
Step 265035: loss = 0.10687
Step 265040: loss = 0.17247
Step 265045: loss = 0.07428
Step 265050: loss = 0.05971
Step 265055: loss = 0.10901
Step 265060: loss = 0.04819
Step 265065: loss = 0.09438
Step 265070: loss = 0.03585
Step 265075: loss = 0.02339
Step 265080: loss = 0.16767
Step 265085: loss = 0.03335
Step 265090: loss = 0.14721
Step 265095: loss = 0.13243
Step 265100: loss = 0.02070
Step 265105: loss = 0.08755
Step 265110: loss = 0.03532
Step 265115: loss = 0.00644
Step 265120: loss = 0.15111
Step 265125: loss = 0.03726
Step 265130: loss = 0.06795
Step 265135: loss = 0.25606
Step 265140: loss = 0.05370
Step 265145: loss = 0.08683
Step 265150: loss = 0.01455
Step 265155: loss = 0.07838
Step 265160: loss = 0.02392
Step 265165: loss = 0.03831
Step 265170: loss = 0.01463
Step 265175: loss = 0.10141
Step 265180: loss = 0.29107
Step 265185: loss = 0.05549
Step 265190: loss = 0.05975
Step 265195: loss = 0.05715
Step 265200: loss = 0.09975
Step 265205: loss = 0.07995
Step 265210: loss = 0.15714
Step 265215: loss = 0.18733
Step 265220: loss = 0.01356
Step 265225: loss = 0.07408
Step 265230: loss = 0.04334
Step 265235: loss = 0.05499
Step 265240: loss = 0.11726
Step 265245: loss = 0.11295
Step 265250: loss = 0.08571
Step 265255: loss = 0.21977
Step 265260: loss = 0.01464
Step 265265: loss = 0.16056
Step 265270: loss = 0.04299
Step 265275: loss = 0.13911
Step 265280: loss = 0.11363
Step 265285: loss = 0.03663
Step 265290: loss = 0.01564
Step 265295: loss = 0.02360
Step 265300: loss = 0.00708
Step 265305: loss = 0.02092
Step 265310: loss = 0.02935
Step 265315: loss = 0.06740
Step 265320: loss = 0.03346
Step 265325: loss = 0.03630
Step 265330: loss = 0.15435
Step 265335: loss = 0.21277
Step 265340: loss = 0.06324
Step 265345: loss = 0.13858
Step 265350: loss = 0.02391
Step 265355: loss = 0.03619
Step 265360: loss = 0.09575
Step 265365: loss = 0.09514
Step 265370: loss = 0.12589
Step 265375: loss = 0.07710
Step 265380: loss = 0.03661
Step 265385: loss = 0.05898
Step 265390: loss = 0.09562
Step 265395: loss = 0.04407
Step 265400: loss = 0.07493
Step 265405: loss = 0.23323
Step 265410: loss = 0.07448
Step 265415: loss = 0.06498
Step 265420: loss = 0.03767
Step 265425: loss = 0.10313
Step 265430: loss = 0.03548
Step 265435: loss = 0.02542
Step 265440: loss = 0.24704
Step 265445: loss = 0.02489
Step 265450: loss = 0.04054
Step 265455: loss = 0.03542
Step 265460: loss = 0.26370
Step 265465: loss = 0.02747
Step 265470: loss = 0.06440
Step 265475: loss = 0.28316
Step 265480: loss = 0.06268
Step 265485: loss = 0.08986
Step 265490: loss = 0.01483
Step 265495: loss = 0.22489
Step 265500: loss = 0.09850
Step 265505: loss = 0.10274
Step 265510: loss = 0.06722
Step 265515: loss = 0.09808
Step 265520: loss = 0.00594
Step 265525: loss = 0.05634
Step 265530: loss = 0.03705
Step 265535: loss = 0.14791
Step 265540: loss = 0.11826
Step 265545: loss = 0.11673
Step 265550: loss = 0.03321
Step 265555: loss = 0.08966
Step 265560: loss = 0.05248
Step 265565: loss = 0.17422
Step 265570: loss = 0.13362
Step 265575: loss = 0.20476
Step 265580: loss = 0.04246
Step 265585: loss = 0.02453
Step 265590: loss = 0.01375
Step 265595: loss = 0.08387
Step 265600: loss = 0.01293
Step 265605: loss = 0.01814
Step 265610: loss = 0.04741
Step 265615: loss = 0.06898
Step 265620: loss = 0.04232
Step 265625: loss = 0.06882
Step 265630: loss = 0.07348
Step 265635: loss = 0.23821
Step 265640: loss = 0.02420
Step 265645: loss = 0.04456
Step 265650: loss = 0.14144
Step 265655: loss = 0.02481
Step 265660: loss = 0.17115
Step 265665: loss = 0.14162
Step 265670: loss = 0.05603
Step 265675: loss = 0.06974
Step 265680: loss = 0.03734
Step 265685: loss = 0.07922
Step 265690: loss = 0.05609
Step 265695: loss = 0.01726
Step 265700: loss = 0.06244
Step 265705: loss = 0.01844
Step 265710: loss = 0.02447
Step 265715: loss = 0.01998
Step 265720: loss = 0.18874
Step 265725: loss = 0.02003
Step 265730: loss = 0.00695
Step 265735: loss = 0.20716
Step 265740: loss = 0.18882
Step 265745: loss = 0.01057
Step 265750: loss = 0.16667
Step 265755: loss = 0.06900
Step 265760: loss = 0.06714
Step 265765: loss = 0.00389
Step 265770: loss = 0.04717
Step 265775: loss = 0.06596
Step 265780: loss = 0.02372
Step 265785: loss = 0.01517
Step 265790: loss = 0.00921
Step 265795: loss = 0.05405
Step 265800: loss = 0.03233
Step 265805: loss = 0.02706
Step 265810: loss = 0.08397
Step 265815: loss = 0.01698
Step 265820: loss = 0.09892
Step 265825: loss = 0.18135
Step 265830: loss = 0.00831
Step 265835: loss = 0.04310
Step 265840: loss = 0.05706
Step 265845: loss = 0.01193
Step 265850: loss = 0.01452
Step 265855: loss = 0.02935
Step 265860: loss = 0.06374
Step 265865: loss = 0.15180
Step 265870: loss = 0.11354
Step 265875: loss = 0.02121
Step 265880: loss = 0.06920
Step 265885: loss = 0.09280
Step 265890: loss = 0.15091
Step 265895: loss = 0.05981
Step 265900: loss = 0.26196
Step 265905: loss = 0.01051
Step 265910: loss = 0.02686
Step 265915: loss = 0.12871
Step 265920: loss = 0.02002
Step 265925: loss = 0.08950
Step 265930: loss = 0.06524
Step 265935: loss = 0.14907
Step 265940: loss = 0.07552
Step 265945: loss = 0.13270
Step 265950: loss = 0.06748
Step 265955: loss = 0.22902
Step 265960: loss = 0.02912
Step 265965: loss = 0.07770
Step 265970: loss = 0.17282
Step 265975: loss = 0.07092
Step 265980: loss = 0.08754
Step 265985: loss = 0.09853
Step 265990: loss = 0.01624
Step 265995: loss = 0.08175
Step 266000: loss = 0.06719
Training Data Eval:
  Num examples: 50000, Num correct: 48652, Precision @ 1: 0.9730
('Testing Data Eval: EPOCH->', 267)
  Num examples: 10000, Num correct: 6803, Precision @ 1: 0.6803
Step 266005: loss = 0.05545
Step 266010: loss = 0.01431
Step 266015: loss = 0.03412
Step 266020: loss = 0.17288
Step 266025: loss = 0.14237
Step 266030: loss = 0.28260
Step 266035: loss = 0.12960
Step 266040: loss = 0.15017
Step 266045: loss = 0.03365
Step 266050: loss = 0.07502
Step 266055: loss = 0.21847
Step 266060: loss = 0.01122
Step 266065: loss = 0.01147
Step 266070: loss = 0.14418
Step 266075: loss = 0.01261
Step 266080: loss = 0.31906
Step 266085: loss = 0.05161
Step 266090: loss = 0.02630
Step 266095: loss = 0.12681
Step 266100: loss = 0.10053
Step 266105: loss = 0.05802
Step 266110: loss = 0.02515
Step 266115: loss = 0.03527
Step 266120: loss = 0.09406
Step 266125: loss = 0.12285
Step 266130: loss = 0.13147
Step 266135: loss = 0.06247
Step 266140: loss = 0.14490
Step 266145: loss = 0.03428
Step 266150: loss = 0.02428
Step 266155: loss = 0.02759
Step 266160: loss = 0.18170
Step 266165: loss = 0.03243
Step 266170: loss = 0.02407
Step 266175: loss = 0.07642
Step 266180: loss = 0.01278
Step 266185: loss = 0.07364
Step 266190: loss = 0.16493
Step 266195: loss = 0.01507
Step 266200: loss = 0.04606
Step 266205: loss = 0.01982
Step 266210: loss = 0.00499
Step 266215: loss = 0.01253
Step 266220: loss = 0.01557
Step 266225: loss = 0.05378
Step 266230: loss = 0.10536
Step 266235: loss = 0.11170
Step 266240: loss = 0.03124
Step 266245: loss = 0.15274
Step 266250: loss = 0.24605
Step 266255: loss = 0.03137
Step 266260: loss = 0.06879
Step 266265: loss = 0.15145
Step 266270: loss = 0.02892
Step 266275: loss = 0.05082
Step 266280: loss = 0.24023
Step 266285: loss = 0.02831
Step 266290: loss = 0.08428
Step 266295: loss = 0.07840
Step 266300: loss = 0.02306
Step 266305: loss = 0.07580
Step 266310: loss = 0.07699
Step 266315: loss = 0.07728
Step 266320: loss = 0.08791
Step 266325: loss = 0.39449
Step 266330: loss = 0.19198
Step 266335: loss = 0.01915
Step 266340: loss = 0.03030
Step 266345: loss = 0.15714
Step 266350: loss = 0.02480
Step 266355: loss = 0.08108
Step 266360: loss = 0.17513
Step 266365: loss = 0.05078
Step 266370: loss = 0.06074
Step 266375: loss = 0.06842
Step 266380: loss = 0.01203
Step 266385: loss = 0.05541
Step 266390: loss = 0.05043
Step 266395: loss = 0.03675
Step 266400: loss = 0.17894
Step 266405: loss = 0.02329
Step 266410: loss = 0.29842
Step 266415: loss = 0.02428
Step 266420: loss = 0.05789
Step 266425: loss = 0.08662
Step 266430: loss = 0.07271
Step 266435: loss = 0.06271
Step 266440: loss = 0.03552
Step 266445: loss = 0.06605
Step 266450: loss = 0.14208
Step 266455: loss = 0.12242
Step 266460: loss = 0.16115
Step 266465: loss = 0.13706
Step 266470: loss = 0.15121
Step 266475: loss = 0.03501
Step 266480: loss = 0.16280
Step 266485: loss = 0.04504
Step 266490: loss = 0.11616
Step 266495: loss = 0.04713
Step 266500: loss = 0.05531
Step 266505: loss = 0.05217
Step 266510: loss = 0.07655
Step 266515: loss = 0.04494
Step 266520: loss = 0.00669
Step 266525: loss = 0.06225
Step 266530: loss = 0.00824
Step 266535: loss = 0.08819
Step 266540: loss = 0.07047
Step 266545: loss = 0.01470
Step 266550: loss = 0.05573
Step 266555: loss = 0.07722
Step 266560: loss = 0.01005
Step 266565: loss = 0.01158
Step 266570: loss = 0.07670
Step 266575: loss = 0.10282
Step 266580: loss = 0.02790
Step 266585: loss = 0.03021
Step 266590: loss = 0.05573
Step 266595: loss = 0.04202
Step 266600: loss = 0.06738
Step 266605: loss = 0.04782
Step 266610: loss = 0.06377
Step 266615: loss = 0.13993
Step 266620: loss = 0.12572
Step 266625: loss = 0.02135
Step 266630: loss = 0.01308
Step 266635: loss = 0.20192
Step 266640: loss = 0.00745
Step 266645: loss = 0.07374
Step 266650: loss = 0.05453
Step 266655: loss = 0.01639
Step 266660: loss = 0.07575
Step 266665: loss = 0.04171
Step 266670: loss = 0.13349
Step 266675: loss = 0.04644
Step 266680: loss = 0.04850
Step 266685: loss = 0.07842
Step 266690: loss = 0.07309
Step 266695: loss = 0.05216
Step 266700: loss = 0.09622
Step 266705: loss = 0.05718
Step 266710: loss = 0.04762
Step 266715: loss = 0.00903
Step 266720: loss = 0.17561
Step 266725: loss = 0.05811
Step 266730: loss = 0.12713
Step 266735: loss = 0.07760
Step 266740: loss = 0.12471
Step 266745: loss = 0.17140
Step 266750: loss = 0.01040
Step 266755: loss = 0.13142
Step 266760: loss = 0.19716
Step 266765: loss = 0.05448
Step 266770: loss = 0.11233
Step 266775: loss = 0.27709
Step 266780: loss = 0.07546
Step 266785: loss = 0.12666
Step 266790: loss = 0.13515
Step 266795: loss = 0.02851
Step 266800: loss = 0.02846
Step 266805: loss = 0.02557
Step 266810: loss = 0.06297
Step 266815: loss = 0.21288
Step 266820: loss = 0.16932
Step 266825: loss = 0.01106
Step 266830: loss = 0.01920
Step 266835: loss = 0.04689
Step 266840: loss = 0.01909
Step 266845: loss = 0.01861
Step 266850: loss = 0.05675
Step 266855: loss = 0.08300
Step 266860: loss = 0.08238
Step 266865: loss = 0.09748
Step 266870: loss = 0.10733
Step 266875: loss = 0.07395
Step 266880: loss = 0.05925
Step 266885: loss = 0.01862
Step 266890: loss = 0.04454
Step 266895: loss = 0.04467
Step 266900: loss = 0.15952
Step 266905: loss = 0.06682
Step 266910: loss = 0.04159
Step 266915: loss = 0.06696
Step 266920: loss = 0.05366
Step 266925: loss = 0.03169
Step 266930: loss = 0.20929
Step 266935: loss = 0.10392
Step 266940: loss = 0.16513
Step 266945: loss = 0.00793
Step 266950: loss = 0.04102
Step 266955: loss = 0.08468
Step 266960: loss = 0.02291
Step 266965: loss = 0.04401
Step 266970: loss = 0.09243
Step 266975: loss = 0.35736
Step 266980: loss = 0.07289
Step 266985: loss = 0.10138
Step 266990: loss = 0.10529
Step 266995: loss = 0.01080
Step 267000: loss = 0.14880
Training Data Eval:
  Num examples: 50000, Num correct: 48869, Precision @ 1: 0.9774
('Testing Data Eval: EPOCH->', 268)
  Num examples: 10000, Num correct: 6752, Precision @ 1: 0.6752
Step 267005: loss = 0.07958
Step 267010: loss = 0.26449
Step 267015: loss = 0.06285
Step 267020: loss = 0.08923
Step 267025: loss = 0.03042
Step 267030: loss = 0.12003
Step 267035: loss = 0.04867
Step 267040: loss = 0.03270
Step 267045: loss = 0.07942
Step 267050: loss = 0.12574
Step 267055: loss = 0.02083
Step 267060: loss = 0.03953
Step 267065: loss = 0.14303
Step 267070: loss = 0.16031
Step 267075: loss = 0.08931
Step 267080: loss = 0.01340
Step 267085: loss = 0.03605
Step 267090: loss = 0.15701
Step 267095: loss = 0.02080
Step 267100: loss = 0.05644
Step 267105: loss = 0.08533
Step 267110: loss = 0.08296
Step 267115: loss = 0.01760
Step 267120: loss = 0.05965
Step 267125: loss = 0.00780
Step 267130: loss = 0.03474
Step 267135: loss = 0.02186
Step 267140: loss = 0.06373
Step 267145: loss = 0.04538
Step 267150: loss = 0.07429
Step 267155: loss = 0.05325
Step 267160: loss = 0.13546
Step 267165: loss = 0.12959
Step 267170: loss = 0.02219
Step 267175: loss = 0.03939
Step 267180: loss = 0.01049
Step 267185: loss = 0.18533
Step 267190: loss = 0.04557
Step 267195: loss = 0.08954
Step 267200: loss = 0.04594
Step 267205: loss = 0.02829
Step 267210: loss = 0.21852
Step 267215: loss = 0.09968
Step 267220: loss = 0.00953
Step 267225: loss = 0.09339
Step 267230: loss = 0.08756
Step 267235: loss = 0.17026
Step 267240: loss = 0.08118
Step 267245: loss = 0.02227
Step 267250: loss = 0.01952
Step 267255: loss = 0.02618
Step 267260: loss = 0.02650
Step 267265: loss = 0.19609
Step 267270: loss = 0.05887
Step 267275: loss = 0.03128
Step 267280: loss = 0.18334
Step 267285: loss = 0.03838
Step 267290: loss = 0.01780
Step 267295: loss = 0.15206
Step 267300: loss = 0.36883
Step 267305: loss = 0.07949
Step 267310: loss = 0.32662
Step 267315: loss = 0.05848
Step 267320: loss = 0.08462
Step 267325: loss = 0.21585
Step 267330: loss = 0.18689
Step 267335: loss = 0.04616
Step 267340: loss = 0.05557
Step 267345: loss = 0.16376
Step 267350: loss = 0.01152
Step 267355: loss = 0.20441
Step 267360: loss = 0.03211
Step 267365: loss = 0.05943
Step 267370: loss = 0.08396
Step 267375: loss = 0.02838
Step 267380: loss = 0.10903
Step 267385: loss = 0.03491
Step 267390: loss = 0.25431
Step 267395: loss = 0.04649
Step 267400: loss = 0.03575
Step 267405: loss = 0.03745
Step 267410: loss = 0.25676
Step 267415: loss = 0.07390
Step 267420: loss = 0.04082
Step 267425: loss = 0.05479
Step 267430: loss = 0.08595
Step 267435: loss = 0.03027
Step 267440: loss = 0.05607
Step 267445: loss = 0.25707
Step 267450: loss = 0.05032
Step 267455: loss = 0.03337
Step 267460: loss = 0.04391
Step 267465: loss = 0.10227
Step 267470: loss = 0.16817
Step 267475: loss = 0.05066
Step 267480: loss = 0.11387
Step 267485: loss = 0.04251
Step 267490: loss = 0.09541
Step 267495: loss = 0.01807
Step 267500: loss = 0.09468
Step 267505: loss = 0.13196
Step 267510: loss = 0.09282
Step 267515: loss = 0.02289
Step 267520: loss = 0.04474
Step 267525: loss = 0.01201
Step 267530: loss = 0.14182
Step 267535: loss = 0.03642
Step 267540: loss = 0.04841
Step 267545: loss = 0.05912
Step 267550: loss = 0.09624
Step 267555: loss = 0.16116
Step 267560: loss = 0.06836
Step 267565: loss = 0.08543
Step 267570: loss = 0.00898
Step 267575: loss = 0.06886
Step 267580: loss = 0.07744
Step 267585: loss = 0.02674
Step 267590: loss = 0.03399
Step 267595: loss = 0.16448
Step 267600: loss = 0.01055
Step 267605: loss = 0.01293
Step 267610: loss = 0.11828
Step 267615: loss = 0.02351
Step 267620: loss = 0.12084
Step 267625: loss = 0.07229
Step 267630: loss = 0.01234
Step 267635: loss = 0.05700
Step 267640: loss = 0.05353
Step 267645: loss = 0.44034
Step 267650: loss = 0.06822
Step 267655: loss = 0.07973
Step 267660: loss = 0.12944
Step 267665: loss = 0.10794
Step 267670: loss = 0.02521
Step 267675: loss = 0.01416
Step 267680: loss = 0.06434
Step 267685: loss = 0.02281
Step 267690: loss = 0.04986
Step 267695: loss = 0.03114
Step 267700: loss = 0.03180
Step 267705: loss = 0.04576
Step 267710: loss = 0.11574
Step 267715: loss = 0.15637
Step 267720: loss = 0.02172
Step 267725: loss = 0.06350
Step 267730: loss = 0.05587
Step 267735: loss = 0.09169
Step 267740: loss = 0.03957
Step 267745: loss = 0.05844
Step 267750: loss = 0.14965
Step 267755: loss = 0.16896
Step 267760: loss = 0.02742
Step 267765: loss = 0.02231
Step 267770: loss = 0.07077
Step 267775: loss = 0.09481
Step 267780: loss = 0.03426
Step 267785: loss = 0.23753
Step 267790: loss = 0.09578
Step 267795: loss = 0.02901
Step 267800: loss = 0.02596
Step 267805: loss = 0.08701
Step 267810: loss = 0.08596
Step 267815: loss = 0.13211
Step 267820: loss = 0.07681
Step 267825: loss = 0.07914
Step 267830: loss = 0.07469
Step 267835: loss = 0.02954
Step 267840: loss = 0.07017
Step 267845: loss = 0.05658
Step 267850: loss = 0.15232
Step 267855: loss = 0.00722
Step 267860: loss = 0.12776
Step 267865: loss = 0.24712
Step 267870: loss = 0.02693
Step 267875: loss = 0.09500
Step 267880: loss = 0.09980
Step 267885: loss = 0.04913
Step 267890: loss = 0.04022
Step 267895: loss = 0.01916
Step 267900: loss = 0.01585
Step 267905: loss = 0.03926
Step 267910: loss = 0.10906
Step 267915: loss = 0.05919
Step 267920: loss = 0.74253
Step 267925: loss = 0.07791
Step 267930: loss = 0.03234
Step 267935: loss = 0.14161
Step 267940: loss = 0.36429
Step 267945: loss = 0.06097
Step 267950: loss = 0.02851
Step 267955: loss = 0.05408
Step 267960: loss = 0.05099
Step 267965: loss = 0.23418
Step 267970: loss = 0.09235
Step 267975: loss = 0.02161
Step 267980: loss = 0.01377
Step 267985: loss = 0.11232
Step 267990: loss = 0.03848
Step 267995: loss = 0.09255
Step 268000: loss = 0.03046
Training Data Eval:
  Num examples: 50000, Num correct: 48596, Precision @ 1: 0.9719
('Testing Data Eval: EPOCH->', 269)
  Num examples: 10000, Num correct: 6859, Precision @ 1: 0.6859
Step 268005: loss = 0.03335
Step 268010: loss = 0.40513
Step 268015: loss = 0.09995
Step 268020: loss = 0.04614
Step 268025: loss = 0.07070
Step 268030: loss = 0.03084
Step 268035: loss = 0.05305
Step 268040: loss = 0.02647
Step 268045: loss = 0.10349
Step 268050: loss = 0.00693
Step 268055: loss = 0.02249
Step 268060: loss = 0.04132
Step 268065: loss = 0.04486
Step 268070: loss = 0.01693
Step 268075: loss = 0.05213
Step 268080: loss = 0.26396
Step 268085: loss = 0.02917
Step 268090: loss = 0.01041
Step 268095: loss = 0.03628
Step 268100: loss = 0.06793
Step 268105: loss = 0.09912
Step 268110: loss = 0.04366
Step 268115: loss = 0.14268
Step 268120: loss = 0.19005
Step 268125: loss = 0.00800
Step 268130: loss = 0.07653
Step 268135: loss = 0.02968
Step 268140: loss = 0.07697
Step 268145: loss = 0.01677
Step 268150: loss = 0.05071
Step 268155: loss = 0.03126
Step 268160: loss = 0.11436
Step 268165: loss = 0.15648
Step 268170: loss = 0.09235
Step 268175: loss = 0.11350
Step 268180: loss = 0.26981
Step 268185: loss = 0.04156
Step 268190: loss = 0.02116
Step 268195: loss = 0.17056
Step 268200: loss = 0.06397
Step 268205: loss = 0.02304
Step 268210: loss = 0.03054
Step 268215: loss = 0.09392
Step 268220: loss = 0.15828
Step 268225: loss = 0.03544
Step 268230: loss = 0.15904
Step 268235: loss = 0.06736
Step 268240: loss = 0.08805
Step 268245: loss = 0.06489
Step 268250: loss = 0.06227
Step 268255: loss = 0.02059
Step 268260: loss = 0.04895
Step 268265: loss = 0.09505
Step 268270: loss = 0.08361
Step 268275: loss = 0.03688
Step 268280: loss = 0.11171
Step 268285: loss = 0.03832
Step 268290: loss = 0.04664
Step 268295: loss = 0.06284
Step 268300: loss = 0.04056
Step 268305: loss = 0.01570
Step 268310: loss = 0.05916
Step 268315: loss = 0.01606
Step 268320: loss = 0.09942
Step 268325: loss = 0.02553
Step 268330: loss = 0.05669
Step 268335: loss = 0.00397
Step 268340: loss = 0.20951
Step 268345: loss = 0.18763
Step 268350: loss = 0.15631
Step 268355: loss = 0.11423
Step 268360: loss = 0.03947
Step 268365: loss = 0.32290
Step 268370: loss = 0.10253
Step 268375: loss = 0.15308
Step 268380: loss = 0.10223
Step 268385: loss = 0.32342
Step 268390: loss = 0.10394
Step 268395: loss = 0.12677
Step 268400: loss = 0.12585
Step 268405: loss = 0.05952
Step 268410: loss = 0.15490
Step 268415: loss = 0.17311
Step 268420: loss = 0.02175
Step 268425: loss = 0.05405
Step 268430: loss = 0.19366
Step 268435: loss = 0.08131
Step 268440: loss = 0.03070
Step 268445: loss = 0.04808
Step 268450: loss = 0.02434
Step 268455: loss = 0.03907
Step 268460: loss = 0.02503
Step 268465: loss = 0.10626
Step 268470: loss = 0.02188
Step 268475: loss = 0.01390
Step 268480: loss = 0.07968
Step 268485: loss = 0.07110
Step 268490: loss = 0.04631
Step 268495: loss = 0.06789
Step 268500: loss = 0.09048
Step 268505: loss = 0.11845
Step 268510: loss = 0.08276
Step 268515: loss = 0.07532
Step 268520: loss = 0.10044
Step 268525: loss = 0.11286
Step 268530: loss = 0.00153
Step 268535: loss = 0.02236
Step 268540: loss = 0.04089
Step 268545: loss = 0.04255
Step 268550: loss = 0.10758
Step 268555: loss = 0.18963
Step 268560: loss = 0.08043
Step 268565: loss = 0.12755
Step 268570: loss = 0.07632
Step 268575: loss = 0.00406
Step 268580: loss = 0.18662
Step 268585: loss = 0.01034
Step 268590: loss = 0.09110
Step 268595: loss = 0.05157
Step 268600: loss = 0.10458
Step 268605: loss = 0.10558
Step 268610: loss = 0.10884
Step 268615: loss = 0.12373
Step 268620: loss = 0.47331
Step 268625: loss = 0.03097
Step 268630: loss = 0.04076
Step 268635: loss = 0.13406
Step 268640: loss = 0.05991
Step 268645: loss = 0.08799
Step 268650: loss = 0.09687
Step 268655: loss = 0.02804
Step 268660: loss = 0.20524
Step 268665: loss = 0.01651
Step 268670: loss = 0.01537
Step 268675: loss = 0.01333
Step 268680: loss = 0.03284
Step 268685: loss = 0.19393
Step 268690: loss = 0.16968
Step 268695: loss = 0.03065
Step 268700: loss = 0.05815
Step 268705: loss = 0.07467
Step 268710: loss = 0.04218
Step 268715: loss = 0.33671
Step 268720: loss = 0.05219
Step 268725: loss = 0.00787
Step 268730: loss = 0.02070
Step 268735: loss = 0.01634
Step 268740: loss = 0.11760
Step 268745: loss = 0.08310
Step 268750: loss = 0.03889
Step 268755: loss = 0.03242
Step 268760: loss = 0.10893
Step 268765: loss = 0.07419
Step 268770: loss = 0.09466
Step 268775: loss = 0.03760
Step 268780: loss = 0.01810
Step 268785: loss = 0.20868
Step 268790: loss = 0.10265
Step 268795: loss = 0.06944
Step 268800: loss = 0.05337
Step 268805: loss = 0.17631
Step 268810: loss = 0.07969
Step 268815: loss = 0.01378
Step 268820: loss = 0.08475
Step 268825: loss = 0.04271
Step 268830: loss = 0.03015
Step 268835: loss = 0.02501
Step 268840: loss = 0.03976
Step 268845: loss = 0.07199
Step 268850: loss = 0.01760
Step 268855: loss = 0.02396
Step 268860: loss = 0.06605
Step 268865: loss = 0.01294
Step 268870: loss = 0.06440
Step 268875: loss = 0.03907
Step 268880: loss = 0.01097
Step 268885: loss = 0.06017
Step 268890: loss = 0.09379
Step 268895: loss = 0.04753
Step 268900: loss = 0.12255
Step 268905: loss = 0.02950
Step 268910: loss = 0.05453
Step 268915: loss = 0.05261
Step 268920: loss = 0.06993
Step 268925: loss = 0.15699
Step 268930: loss = 0.14041
Step 268935: loss = 0.05080
Step 268940: loss = 0.08244
Step 268945: loss = 0.03205
Step 268950: loss = 0.03327
Step 268955: loss = 0.23120
Step 268960: loss = 0.08576
Step 268965: loss = 0.23884
Step 268970: loss = 0.01299
Step 268975: loss = 0.03021
Step 268980: loss = 0.03647
Step 268985: loss = 0.04878
Step 268990: loss = 0.01612
Step 268995: loss = 0.07252
Step 269000: loss = 0.19387
Training Data Eval:
  Num examples: 50000, Num correct: 48820, Precision @ 1: 0.9764
('Testing Data Eval: EPOCH->', 270)
  Num examples: 10000, Num correct: 6750, Precision @ 1: 0.6750
Step 269005: loss = 0.01604
Step 269010: loss = 0.02331
Step 269015: loss = 0.08445
Step 269020: loss = 0.02340
Step 269025: loss = 0.13598
Step 269030: loss = 0.12178
Step 269035: loss = 0.31430
Step 269040: loss = 0.12464
Step 269045: loss = 0.04222
Step 269050: loss = 0.16041
Step 269055: loss = 0.00990
Step 269060: loss = 0.02795
Step 269065: loss = 0.03902
Step 269070: loss = 0.07285
Step 269075: loss = 0.01750
Step 269080: loss = 0.11180
Step 269085: loss = 0.04473
Step 269090: loss = 0.01308
Step 269095: loss = 0.03114
Step 269100: loss = 0.00782
Step 269105: loss = 0.13571
Step 269110: loss = 0.07692
Step 269115: loss = 0.07946
Step 269120: loss = 0.07823
Step 269125: loss = 0.03010
Step 269130: loss = 0.15175
Step 269135: loss = 0.01906
Step 269140: loss = 0.11139
Step 269145: loss = 0.11734
Step 269150: loss = 0.00696
Step 269155: loss = 0.03479
Step 269160: loss = 0.03312
Step 269165: loss = 0.05016
Step 269170: loss = 0.06557
Step 269175: loss = 0.05586
Step 269180: loss = 0.01196
Step 269185: loss = 0.03525
Step 269190: loss = 0.24745
Step 269195: loss = 0.04347
Step 269200: loss = 0.11700
Step 269205: loss = 0.03498
Step 269210: loss = 0.09485
Step 269215: loss = 0.02768
Step 269220: loss = 0.05852
Step 269225: loss = 0.06013
Step 269230: loss = 0.03559
Step 269235: loss = 0.07381
Step 269240: loss = 0.15645
Step 269245: loss = 0.03342
Step 269250: loss = 0.11491
Step 269255: loss = 0.09242
Step 269260: loss = 0.07870
Step 269265: loss = 0.10622
Step 269270: loss = 0.04513
Step 269275: loss = 0.00908
Step 269280: loss = 0.10467
Step 269285: loss = 0.04089
Step 269290: loss = 0.06689
Step 269295: loss = 0.11790
Step 269300: loss = 0.00621
Step 269305: loss = 0.15038
Step 269310: loss = 0.02509
Step 269315: loss = 0.14068
Step 269320: loss = 0.05144
Step 269325: loss = 0.16113
Step 269330: loss = 0.08964
Step 269335: loss = 0.12481
Step 269340: loss = 0.08106
Step 269345: loss = 0.05293
Step 269350: loss = 0.08699
Step 269355: loss = 0.00405
Step 269360: loss = 0.19057
Step 269365: loss = 0.02620
Step 269370: loss = 0.21644
Step 269375: loss = 0.22184
Step 269380: loss = 0.21751
Step 269385: loss = 0.01371
Step 269390: loss = 0.01309
Step 269395: loss = 0.03391
Step 269400: loss = 0.00793
Step 269405: loss = 0.05131
Step 269410: loss = 0.05754
Step 269415: loss = 0.20799
Step 269420: loss = 0.07777
Step 269425: loss = 0.22380
Step 269430: loss = 0.43975
Step 269435: loss = 0.04702
Step 269440: loss = 0.04175
Step 269445: loss = 0.07049
Step 269450: loss = 0.00462
Step 269455: loss = 0.11295
Step 269460: loss = 0.02338
Step 269465: loss = 0.03550
Step 269470: loss = 0.09422
Step 269475: loss = 0.02293
Step 269480: loss = 0.04136
Step 269485: loss = 0.24003
Step 269490: loss = 0.14807
Step 269495: loss = 0.08653
Step 269500: loss = 0.16477
Step 269505: loss = 0.03361
Step 269510: loss = 0.01286
Step 269515: loss = 0.02924
Step 269520: loss = 0.00939
Step 269525: loss = 0.04683
Step 269530: loss = 0.07754
Step 269535: loss = 0.04797
Step 269540: loss = 0.03704
Step 269545: loss = 0.00682
Step 269550: loss = 0.04293
Step 269555: loss = 0.06616
Step 269560: loss = 0.04530
Step 269565: loss = 0.16317
Step 269570: loss = 0.03434
Step 269575: loss = 0.20779
Step 269580: loss = 0.06442
Step 269585: loss = 0.07794
Step 269590: loss = 0.17690
Step 269595: loss = 0.01434
Step 269600: loss = 0.06448
Step 269605: loss = 0.02588
Step 269610: loss = 0.04200
Step 269615: loss = 0.07454
Step 269620: loss = 0.04081
Step 269625: loss = 0.02600
Step 269630: loss = 0.03477
Step 269635: loss = 0.12766
Step 269640: loss = 0.20130
Step 269645: loss = 0.12425
Step 269650: loss = 0.16231
Step 269655: loss = 0.06525
Step 269660: loss = 0.02227
Step 269665: loss = 0.06751
Step 269670: loss = 0.10328
Step 269675: loss = 0.01388
Step 269680: loss = 0.06070
Step 269685: loss = 0.04978
Step 269690: loss = 0.00703
Step 269695: loss = 0.05198
Step 269700: loss = 0.09726
Step 269705: loss = 0.01910
Step 269710: loss = 0.12536
Step 269715: loss = 0.11655
Step 269720: loss = 0.04465
Step 269725: loss = 0.01875
Step 269730: loss = 0.12813
Step 269735: loss = 0.18259
Step 269740: loss = 0.09084
Step 269745: loss = 0.16840
Step 269750: loss = 0.06521
Step 269755: loss = 0.01805
Step 269760: loss = 0.10963
Step 269765: loss = 0.08204
Step 269770: loss = 0.03641
Step 269775: loss = 0.07304
Step 269780: loss = 0.05522
Step 269785: loss = 0.19640
Step 269790: loss = 0.02727
Step 269795: loss = 0.15902
Step 269800: loss = 0.05392
Step 269805: loss = 0.18244
Step 269810: loss = 0.22759
Step 269815: loss = 0.05185
Step 269820: loss = 0.04464
Step 269825: loss = 0.09756
Step 269830: loss = 0.05334
Step 269835: loss = 0.02873
Step 269840: loss = 0.11049
Step 269845: loss = 0.01497
Step 269850: loss = 0.03575
Step 269855: loss = 0.10082
Step 269860: loss = 0.04460
Step 269865: loss = 0.05608
Step 269870: loss = 0.01594
Step 269875: loss = 0.08199
Step 269880: loss = 0.15487
Step 269885: loss = 0.10508
Step 269890: loss = 0.02550
Step 269895: loss = 0.05566
Step 269900: loss = 0.02396
Step 269905: loss = 0.00722
Step 269910: loss = 0.05785
Step 269915: loss = 0.09636
Step 269920: loss = 0.07508
Step 269925: loss = 0.04072
Step 269930: loss = 0.15192
Step 269935: loss = 0.05928
Step 269940: loss = 0.00329
Step 269945: loss = 0.05981
Step 269950: loss = 0.03418
Step 269955: loss = 0.39315
Step 269960: loss = 0.07099
Step 269965: loss = 0.03796
Step 269970: loss = 0.13554
Step 269975: loss = 0.08163
Step 269980: loss = 0.01652
Step 269985: loss = 0.01001
Step 269990: loss = 0.05856
Step 269995: loss = 0.05731
Step 270000: loss = 0.24463
Training Data Eval:
  Num examples: 50000, Num correct: 48421, Precision @ 1: 0.9684
('Testing Data Eval: EPOCH->', 271)
  Num examples: 10000, Num correct: 6731, Precision @ 1: 0.6731
Step 270005: loss = 0.16970
Step 270010: loss = 0.22518
Step 270015: loss = 0.14474
Step 270020: loss = 0.08642
Step 270025: loss = 0.00316
Step 270030: loss = 0.07806
Step 270035: loss = 0.06751
Step 270040: loss = 0.14303
Step 270045: loss = 0.09919
Step 270050: loss = 0.03686
Step 270055: loss = 0.20215
Step 270060: loss = 0.01647
Step 270065: loss = 0.15382
Step 270070: loss = 0.05480
Step 270075: loss = 0.04676
Step 270080: loss = 0.08680
Step 270085: loss = 0.04278
Step 270090: loss = 0.01273
Step 270095: loss = 0.02859
Step 270100: loss = 0.22443
Step 270105: loss = 0.02583
Step 270110: loss = 0.07243
Step 270115: loss = 0.02800
Step 270120: loss = 0.21575
Step 270125: loss = 0.09500
Step 270130: loss = 0.04777
Step 270135: loss = 0.03223
Step 270140: loss = 0.01714
Step 270145: loss = 0.01216
Step 270150: loss = 0.25840
Step 270155: loss = 0.09389
Step 270160: loss = 0.09777
Step 270165: loss = 0.08945
Step 270170: loss = 0.05105
Step 270175: loss = 0.10137
Step 270180: loss = 0.05072
Step 270185: loss = 0.01591
Step 270190: loss = 0.02179
Step 270195: loss = 0.03399
Step 270200: loss = 0.02500
Step 270205: loss = 0.14923
Step 270210: loss = 0.09232
Step 270215: loss = 0.08195
Step 270220: loss = 0.15055
Step 270225: loss = 0.07113
Step 270230: loss = 0.07915
Step 270235: loss = 0.05374
Step 270240: loss = 0.00509
Step 270245: loss = 0.08974
Step 270250: loss = 0.08671
Step 270255: loss = 0.00398
Step 270260: loss = 0.06478
Step 270265: loss = 0.07681
Step 270270: loss = 0.38277
Step 270275: loss = 0.07289
Step 270280: loss = 0.01427
Step 270285: loss = 0.05797
Step 270290: loss = 0.01548
Step 270295: loss = 0.13412
Step 270300: loss = 0.07190
Step 270305: loss = 0.01931
Step 270310: loss = 0.05609
Step 270315: loss = 0.03016
Step 270320: loss = 0.02693
Step 270325: loss = 0.03817
Step 270330: loss = 0.15160
Step 270335: loss = 0.09419
Step 270340: loss = 0.24404
Step 270345: loss = 0.02729
Step 270350: loss = 0.23261
Step 270355: loss = 0.08655
Step 270360: loss = 0.01919
Step 270365: loss = 0.05627
Step 270370: loss = 0.16585
Step 270375: loss = 0.14284
Step 270380: loss = 0.02712
Step 270385: loss = 0.15085
Step 270390: loss = 0.17244
Step 270395: loss = 0.02150
Step 270400: loss = 0.09449
Step 270405: loss = 0.06055
Step 270410: loss = 0.12356
Step 270415: loss = 0.02794
Step 270420: loss = 0.02244
Step 270425: loss = 0.16604
Step 270430: loss = 0.06714
Step 270435: loss = 0.07160
Step 270440: loss = 0.02524
Step 270445: loss = 0.01241
Step 270450: loss = 0.04114
Step 270455: loss = 0.04585
Step 270460: loss = 0.09048
Step 270465: loss = 0.01942
Step 270470: loss = 0.00892
Step 270475: loss = 0.19279
Step 270480: loss = 0.03852
Step 270485: loss = 0.07968
Step 270490: loss = 0.13008
Step 270495: loss = 0.04053
Step 270500: loss = 0.17174
Step 270505: loss = 0.14322
Step 270510: loss = 0.00711
Step 270515: loss = 0.29299
Step 270520: loss = 0.26904
Step 270525: loss = 0.06550
Step 270530: loss = 0.00657
Step 270535: loss = 0.09802
Step 270540: loss = 0.01451
Step 270545: loss = 0.01500
Step 270550: loss = 0.22459
Step 270555: loss = 0.15831
Step 270560: loss = 0.09212
Step 270565: loss = 0.02921
Step 270570: loss = 0.08573
Step 270575: loss = 0.08551
Step 270580: loss = 0.03416
Step 270585: loss = 0.13682
Step 270590: loss = 0.09478
Step 270595: loss = 0.07937
Step 270600: loss = 0.11548
Step 270605: loss = 0.04118
Step 270610: loss = 0.11668
Step 270615: loss = 0.03922
Step 270620: loss = 0.05748
Step 270625: loss = 0.03099
Step 270630: loss = 0.03503
Step 270635: loss = 0.06320
Step 270640: loss = 0.00283
Step 270645: loss = 0.03257
Step 270650: loss = 0.05223
Step 270655: loss = 0.08892
Step 270660: loss = 0.07692
Step 270665: loss = 0.13172
Step 270670: loss = 0.12788
Step 270675: loss = 0.04724
Step 270680: loss = 0.10092
Step 270685: loss = 0.06638
Step 270690: loss = 0.21699
Step 270695: loss = 0.03875
Step 270700: loss = 0.01753
Step 270705: loss = 0.01413
Step 270710: loss = 0.08337
Step 270715: loss = 0.18713
Step 270720: loss = 0.10566
Step 270725: loss = 0.01546
Step 270730: loss = 0.02322
Step 270735: loss = 0.06467
Step 270740: loss = 0.03764
Step 270745: loss = 0.18053
Step 270750: loss = 0.11671
Step 270755: loss = 0.11511
Step 270760: loss = 0.14357
Step 270765: loss = 0.01224
Step 270770: loss = 0.00953
Step 270775: loss = 0.06594
Step 270780: loss = 0.08173
Step 270785: loss = 0.02621
Step 270790: loss = 0.02022
Step 270795: loss = 0.02226
Step 270800: loss = 0.04896
Step 270805: loss = 0.06227
Step 270810: loss = 0.11617
Step 270815: loss = 0.02840
Step 270820: loss = 0.12184
Step 270825: loss = 0.12247
Step 270830: loss = 0.05569
Step 270835: loss = 0.09283
Step 270840: loss = 0.08747
Step 270845: loss = 0.01524
Step 270850: loss = 0.04139
Step 270855: loss = 0.12654
Step 270860: loss = 0.11312
Step 270865: loss = 0.06241
Step 270870: loss = 0.03923
Step 270875: loss = 0.11178
Step 270880: loss = 0.05434
Step 270885: loss = 0.16568
Step 270890: loss = 0.02546
Step 270895: loss = 0.11215
Step 270900: loss = 0.06114
Step 270905: loss = 0.01746
Step 270910: loss = 0.04694
Step 270915: loss = 0.08107
Step 270920: loss = 0.06006
Step 270925: loss = 0.06106
Step 270930: loss = 0.01216
Step 270935: loss = 0.06414
Step 270940: loss = 0.06797
Step 270945: loss = 0.06601
Step 270950: loss = 0.11958
Step 270955: loss = 0.07085
Step 270960: loss = 0.05674
Step 270965: loss = 0.04946
Step 270970: loss = 0.06736
Step 270975: loss = 0.15206
Step 270980: loss = 0.05515
Step 270985: loss = 0.03801
Step 270990: loss = 0.01546
Step 270995: loss = 0.05917
Step 271000: loss = 0.23862
Training Data Eval:
  Num examples: 50000, Num correct: 48685, Precision @ 1: 0.9737
('Testing Data Eval: EPOCH->', 272)
  Num examples: 10000, Num correct: 6650, Precision @ 1: 0.6650
Step 271005: loss = 0.08434
Step 271010: loss = 0.02966
Step 271015: loss = 0.02459
Step 271020: loss = 0.09173
Step 271025: loss = 0.05478
Step 271030: loss = 0.50101
Step 271035: loss = 0.01237
Step 271040: loss = 0.15762
Step 271045: loss = 0.04183
Step 271050: loss = 0.08279
Step 271055: loss = 0.07084
Step 271060: loss = 0.12309
Step 271065: loss = 0.05625
Step 271070: loss = 0.03174
Step 271075: loss = 0.08682
Step 271080: loss = 0.14557
Step 271085: loss = 0.01224
Step 271090: loss = 0.08846
Step 271095: loss = 0.25518
Step 271100: loss = 0.17832
Step 271105: loss = 0.12686
Step 271110: loss = 0.07737
Step 271115: loss = 0.05415
Step 271120: loss = 0.10236
Step 271125: loss = 0.10227
Step 271130: loss = 0.03844
Step 271135: loss = 0.10349
Step 271140: loss = 0.05409
Step 271145: loss = 0.10894
Step 271150: loss = 0.02708
Step 271155: loss = 0.05895
Step 271160: loss = 0.08618
Step 271165: loss = 0.09760
Step 271170: loss = 0.06741
Step 271175: loss = 0.05762
Step 271180: loss = 0.12778
Step 271185: loss = 0.11931
Step 271190: loss = 0.04374
Step 271195: loss = 0.21654
Step 271200: loss = 0.04676
Step 271205: loss = 0.03006
Step 271210: loss = 0.03801
Step 271215: loss = 0.11776
Step 271220: loss = 0.04063
Step 271225: loss = 0.05525
Step 271230: loss = 0.07914
Step 271235: loss = 0.09404
Step 271240: loss = 0.06693
Step 271245: loss = 0.33001
Step 271250: loss = 0.06070
Step 271255: loss = 0.07534
Step 271260: loss = 0.02112
Step 271265: loss = 0.02013
Step 271270: loss = 0.01900
Step 271275: loss = 0.08204
Step 271280: loss = 0.09777
Step 271285: loss = 0.09591
Step 271290: loss = 0.04678
Step 271295: loss = 0.03047
Step 271300: loss = 0.03731
Step 271305: loss = 0.01600
Step 271310: loss = 0.07430
Step 271315: loss = 0.01564
Step 271320: loss = 0.04111
Step 271325: loss = 0.02627
Step 271330: loss = 0.01744
Step 271335: loss = 0.07905
Step 271340: loss = 0.04552
Step 271345: loss = 0.08915
Step 271350: loss = 0.09113
Step 271355: loss = 0.02082
Step 271360: loss = 0.07142
Step 271365: loss = 0.06654
Step 271370: loss = 0.01472
Step 271375: loss = 0.02090
Step 271380: loss = 0.03530
Step 271385: loss = 0.03829
Step 271390: loss = 0.10356
Step 271395: loss = 0.17682
Step 271400: loss = 0.04919
Step 271405: loss = 0.00991
Step 271410: loss = 0.07038
Step 271415: loss = 0.30835
Step 271420: loss = 0.03873
Step 271425: loss = 0.12313
Step 271430: loss = 0.07479
Step 271435: loss = 0.03361
Step 271440: loss = 0.02905
Step 271445: loss = 0.02812
Step 271450: loss = 0.03646
Step 271455: loss = 0.03065
Step 271460: loss = 0.05106
Step 271465: loss = 0.08973
Step 271470: loss = 0.16360
Step 271475: loss = 0.00880
Step 271480: loss = 0.08100
Step 271485: loss = 0.02351
Step 271490: loss = 0.06320
Step 271495: loss = 0.04067
Step 271500: loss = 0.04744
Step 271505: loss = 0.03085
Step 271510: loss = 0.00636
Step 271515: loss = 0.08260
Step 271520: loss = 0.08009
Step 271525: loss = 0.36400
Step 271530: loss = 0.13497
Step 271535: loss = 0.05983
Step 271540: loss = 0.05583
Step 271545: loss = 0.05840
Step 271550: loss = 0.01505
Step 271555: loss = 0.01850
Step 271560: loss = 0.03487
Step 271565: loss = 0.02342
Step 271570: loss = 0.03213
Step 271575: loss = 0.15557
Step 271580: loss = 0.02314
Step 271585: loss = 0.06172
Step 271590: loss = 0.03250
Step 271595: loss = 0.22227
Step 271600: loss = 0.02357
Step 271605: loss = 0.10940
Step 271610: loss = 0.04944
Step 271615: loss = 0.00993
Step 271620: loss = 0.13791
Step 271625: loss = 0.14749
Step 271630: loss = 0.05169
Step 271635: loss = 0.04912
Step 271640: loss = 0.10347
Step 271645: loss = 0.01643
Step 271650: loss = 0.01627
Step 271655: loss = 0.05012
Step 271660: loss = 0.13071
Step 271665: loss = 0.08273
Step 271670: loss = 0.03494
Step 271675: loss = 0.03190
Step 271680: loss = 0.05090
Step 271685: loss = 0.07027
Step 271690: loss = 0.08427
Step 271695: loss = 0.02134
Step 271700: loss = 0.23026
Step 271705: loss = 0.09032
Step 271710: loss = 0.17722
Step 271715: loss = 0.02878
Step 271720: loss = 0.11692
Step 271725: loss = 0.02013
Step 271730: loss = 0.05619
Step 271735: loss = 0.06629
Step 271740: loss = 0.06873
Step 271745: loss = 0.00456
Step 271750: loss = 0.03642
Step 271755: loss = 0.03727
Step 271760: loss = 0.02988
Step 271765: loss = 0.08710
Step 271770: loss = 0.00397
Step 271775: loss = 0.03960
Step 271780: loss = 0.03675
Step 271785: loss = 0.08896
Step 271790: loss = 0.14004
Step 271795: loss = 0.00856
Step 271800: loss = 0.05013
Step 271805: loss = 0.23889
Step 271810: loss = 0.12576
Step 271815: loss = 0.18783
Step 271820: loss = 0.06471
Step 271825: loss = 0.07581
Step 271830: loss = 0.06227
Step 271835: loss = 0.12336
Step 271840: loss = 0.05943
Step 271845: loss = 0.15146
Step 271850: loss = 0.30747
Step 271855: loss = 0.14119
Step 271860: loss = 0.07364
Step 271865: loss = 0.10133
Step 271870: loss = 0.09737
Step 271875: loss = 0.10657
Step 271880: loss = 0.05831
Step 271885: loss = 0.01571
Step 271890: loss = 0.03656
Step 271895: loss = 0.10587
Step 271900: loss = 0.02287
Step 271905: loss = 0.03138
Step 271910: loss = 0.11833
Step 271915: loss = 0.09617
Step 271920: loss = 0.17124
Step 271925: loss = 0.01326
Step 271930: loss = 0.04560
Step 271935: loss = 0.08239
Step 271940: loss = 0.06280
Step 271945: loss = 0.01470
Step 271950: loss = 0.28473
Step 271955: loss = 0.17055
Step 271960: loss = 0.01080
Step 271965: loss = 0.04388
Step 271970: loss = 0.05967
Step 271975: loss = 0.05037
Step 271980: loss = 0.07837
Step 271985: loss = 0.03269
Step 271990: loss = 0.10534
Step 271995: loss = 0.20308
Step 272000: loss = 0.01397
Training Data Eval:
  Num examples: 50000, Num correct: 48721, Precision @ 1: 0.9744
('Testing Data Eval: EPOCH->', 273)
  Num examples: 10000, Num correct: 6824, Precision @ 1: 0.6824
Step 272005: loss = 0.08873
Step 272010: loss = 0.13093
Step 272015: loss = 0.09073
Step 272020: loss = 0.03269
Step 272025: loss = 0.11942
Step 272030: loss = 0.05332
Step 272035: loss = 0.01480
Step 272040: loss = 0.01529
Step 272045: loss = 0.03273
Step 272050: loss = 0.06019
Step 272055: loss = 0.11154
Step 272060: loss = 0.01343
Step 272065: loss = 0.12091
Step 272070: loss = 0.09382
Step 272075: loss = 0.06745
Step 272080: loss = 0.02863
Step 272085: loss = 0.07955
Step 272090: loss = 0.05584
Step 272095: loss = 0.02641
Step 272100: loss = 0.01319
Step 272105: loss = 0.14681
Step 272110: loss = 0.18972
Step 272115: loss = 0.08345
Step 272120: loss = 0.12898
Step 272125: loss = 0.04481
Step 272130: loss = 0.27600
Step 272135: loss = 0.09330
Step 272140: loss = 0.06133
Step 272145: loss = 0.03277
Step 272150: loss = 0.02116
Step 272155: loss = 0.06764
Step 272160: loss = 0.12879
Step 272165: loss = 0.02663
Step 272170: loss = 0.13339
Step 272175: loss = 0.04026
Step 272180: loss = 0.05501
Step 272185: loss = 0.07021
Step 272190: loss = 0.08084
Step 272195: loss = 0.06387
Step 272200: loss = 0.02494
Step 272205: loss = 0.04488
Step 272210: loss = 0.19044
Step 272215: loss = 0.12904
Step 272220: loss = 0.10070
Step 272225: loss = 0.08483
Step 272230: loss = 0.08855
Step 272235: loss = 0.10689
Step 272240: loss = 0.08960
Step 272245: loss = 0.03494
Step 272250: loss = 0.05580
Step 272255: loss = 0.07985
Step 272260: loss = 0.06748
Step 272265: loss = 0.11484
Step 272270: loss = 0.04997
Step 272275: loss = 0.15330
Step 272280: loss = 0.13677
Step 272285: loss = 0.09853
Step 272290: loss = 0.01287
Step 272295: loss = 0.03824
Step 272300: loss = 0.11511
Step 272305: loss = 0.09942
Step 272310: loss = 0.04405
Step 272315: loss = 0.20153
Step 272320: loss = 0.03047
Step 272325: loss = 0.20305
Step 272330: loss = 0.07499
Step 272335: loss = 0.15561
Step 272340: loss = 0.01252
Step 272345: loss = 0.03798
Step 272350: loss = 0.06761
Step 272355: loss = 0.10362
Step 272360: loss = 0.31189
Step 272365: loss = 0.03787
Step 272370: loss = 0.04785
Step 272375: loss = 0.02741
Step 272380: loss = 0.04683
Step 272385: loss = 0.03113
Step 272390: loss = 0.06425
Step 272395: loss = 0.18079
Step 272400: loss = 0.04386
Step 272405: loss = 0.06832
Step 272410: loss = 0.17440
Step 272415: loss = 0.02683
Step 272420: loss = 0.11154
Step 272425: loss = 0.21658
Step 272430: loss = 0.06682
Step 272435: loss = 0.14526
Step 272440: loss = 0.04121
Step 272445: loss = 0.04754
Step 272450: loss = 0.00831
Step 272455: loss = 0.05590
Step 272460: loss = 0.03052
Step 272465: loss = 0.00406
Step 272470: loss = 0.32019
Step 272475: loss = 0.11108
Step 272480: loss = 0.00697
Step 272485: loss = 0.06014
Step 272490: loss = 0.00363
Step 272495: loss = 0.07375
Step 272500: loss = 0.17982
Step 272505: loss = 0.23500
Step 272510: loss = 0.04268
Step 272515: loss = 0.05049
Step 272520: loss = 0.02486
Step 272525: loss = 0.20848
Step 272530: loss = 0.06048
Step 272535: loss = 0.02913
Step 272540: loss = 0.08494
Step 272545: loss = 0.01857
Step 272550: loss = 0.26307
Step 272555: loss = 0.01003
Step 272560: loss = 0.04329
Step 272565: loss = 0.03279
Step 272570: loss = 0.12959
Step 272575: loss = 0.06392
Step 272580: loss = 0.08403
Step 272585: loss = 0.08562
Step 272590: loss = 0.03555
Step 272595: loss = 0.04343
Step 272600: loss = 0.02389
Step 272605: loss = 0.09494
Step 272610: loss = 0.04911
Step 272615: loss = 0.00425
Step 272620: loss = 0.17906
Step 272625: loss = 0.22872
Step 272630: loss = 0.07112
Step 272635: loss = 0.19305
Step 272640: loss = 0.01161
Step 272645: loss = 0.04365
Step 272650: loss = 0.04807
Step 272655: loss = 0.03961
Step 272660: loss = 0.18733
Step 272665: loss = 0.03963
Step 272670: loss = 0.11750
Step 272675: loss = 0.36455
Step 272680: loss = 0.18061
Step 272685: loss = 0.02865
Step 272690: loss = 0.01000
Step 272695: loss = 0.07856
Step 272700: loss = 0.13432
Step 272705: loss = 0.55335
Step 272710: loss = 0.10651
Step 272715: loss = 0.11374
Step 272720: loss = 0.08471
Step 272725: loss = 0.05001
Step 272730: loss = 0.05525
Step 272735: loss = 0.11105
Step 272740: loss = 0.04649
Step 272745: loss = 0.02483
Step 272750: loss = 0.19862
Step 272755: loss = 0.00650
Step 272760: loss = 0.16332
Step 272765: loss = 0.18457
Step 272770: loss = 0.11553
Step 272775: loss = 0.13304
Step 272780: loss = 0.08115
Step 272785: loss = 0.05300
Step 272790: loss = 0.07613
Step 272795: loss = 0.09279
Step 272800: loss = 0.21504
Step 272805: loss = 0.02143
Step 272810: loss = 0.17441
Step 272815: loss = 0.21681
Step 272820: loss = 0.10958
Step 272825: loss = 0.07932
Step 272830: loss = 0.10892
Step 272835: loss = 0.19541
Step 272840: loss = 0.04871
Step 272845: loss = 0.00820
Step 272850: loss = 0.02260
Step 272855: loss = 0.15886
Step 272860: loss = 0.05804
Step 272865: loss = 0.00173
Step 272870: loss = 0.07981
Step 272875: loss = 0.00647
Step 272880: loss = 0.03133
Step 272885: loss = 0.04404
Step 272890: loss = 0.01382
Step 272895: loss = 0.08205
Step 272900: loss = 0.12030
Step 272905: loss = 0.53848
Step 272910: loss = 0.08582
Step 272915: loss = 0.09346
Step 272920: loss = 0.13204
Step 272925: loss = 0.04457
Step 272930: loss = 0.01754
Step 272935: loss = 0.05830
Step 272940: loss = 0.04218
Step 272945: loss = 0.00194
Step 272950: loss = 0.07591
Step 272955: loss = 0.05985
Step 272960: loss = 0.08300
Step 272965: loss = 0.06165
Step 272970: loss = 0.09154
Step 272975: loss = 0.08617
Step 272980: loss = 0.02509
Step 272985: loss = 0.07337
Step 272990: loss = 0.09617
Step 272995: loss = 0.06286
Step 273000: loss = 0.01869
Training Data Eval:
  Num examples: 50000, Num correct: 48887, Precision @ 1: 0.9777
('Testing Data Eval: EPOCH->', 274)
  Num examples: 10000, Num correct: 6797, Precision @ 1: 0.6797
Step 273005: loss = 0.03361
Step 273010: loss = 0.00876
Step 273015: loss = 0.15272
Step 273020: loss = 0.01729
Step 273025: loss = 0.03139
Step 273030: loss = 0.00965
Step 273035: loss = 0.19326
Step 273040: loss = 0.07920
Step 273045: loss = 0.04939
Step 273050: loss = 0.12568
Step 273055: loss = 0.03567
Step 273060: loss = 0.07315
Step 273065: loss = 0.08703
Step 273070: loss = 0.02401
Step 273075: loss = 0.03295
Step 273080: loss = 0.01001
Step 273085: loss = 0.01571
Step 273090: loss = 0.05895
Step 273095: loss = 0.01588
Step 273100: loss = 0.03911
Step 273105: loss = 0.10373
Step 273110: loss = 0.11352
Step 273115: loss = 0.02767
Step 273120: loss = 0.08815
Step 273125: loss = 0.03224
Step 273130: loss = 0.17626
Step 273135: loss = 0.05300
Step 273140: loss = 0.36480
Step 273145: loss = 0.05805
Step 273150: loss = 0.06692
Step 273155: loss = 0.06375
Step 273160: loss = 0.06396
Step 273165: loss = 0.05891
Step 273170: loss = 0.00988
Step 273175: loss = 0.03142
Step 273180: loss = 0.12309
Step 273185: loss = 0.07739
Step 273190: loss = 0.05205
Step 273195: loss = 0.18911
Step 273200: loss = 0.13055
Step 273205: loss = 0.20798
Step 273210: loss = 0.00659
Step 273215: loss = 0.01313
Step 273220: loss = 0.09144
Step 273225: loss = 0.03337
Step 273230: loss = 0.02902
Step 273235: loss = 0.08684
Step 273240: loss = 0.02074
Step 273245: loss = 0.02587
Step 273250: loss = 0.04550
Step 273255: loss = 0.24044
Step 273260: loss = 0.03214
Step 273265: loss = 0.03465
Step 273270: loss = 0.11517
Step 273275: loss = 0.03942
Step 273280: loss = 0.16990
Step 273285: loss = 0.06564
Step 273290: loss = 0.00663
Step 273295: loss = 0.02580
Step 273300: loss = 0.09837
Step 273305: loss = 0.07423
Step 273310: loss = 0.01323
Step 273315: loss = 0.08388
Step 273320: loss = 0.08528
Step 273325: loss = 0.09124
Step 273330: loss = 0.04280
Step 273335: loss = 0.04760
Step 273340: loss = 0.11696
Step 273345: loss = 0.15364
Step 273350: loss = 0.08256
Step 273355: loss = 0.03237
Step 273360: loss = 0.07650
Step 273365: loss = 0.06563
Step 273370: loss = 0.17500
Step 273375: loss = 0.02597
Step 273380: loss = 0.02333
Step 273385: loss = 0.03011
Step 273390: loss = 0.39309
Step 273395: loss = 0.15600
Step 273400: loss = 0.02527
Step 273405: loss = 0.02113
Step 273410: loss = 0.01676
Step 273415: loss = 0.02500
Step 273420: loss = 0.08403
Step 273425: loss = 0.01533
Step 273430: loss = 0.03170
Step 273435: loss = 0.13301
Step 273440: loss = 0.15762
Step 273445: loss = 0.03239
Step 273450: loss = 0.01011
Step 273455: loss = 0.08765
Step 273460: loss = 0.00992
Step 273465: loss = 0.11436
Step 273470: loss = 0.06220
Step 273475: loss = 0.07225
Step 273480: loss = 0.07292
Step 273485: loss = 0.08393
Step 273490: loss = 0.04166
Step 273495: loss = 0.07861
Step 273500: loss = 0.02554
Step 273505: loss = 0.14469
Step 273510: loss = 0.12122
Step 273515: loss = 0.03544
Step 273520: loss = 0.11530
Step 273525: loss = 0.01786
Step 273530: loss = 0.12477
Step 273535: loss = 0.06535
Step 273540: loss = 0.21198
Step 273545: loss = 0.02296
Step 273550: loss = 0.01585
Step 273555: loss = 0.05298
Step 273560: loss = 0.09726
Step 273565: loss = 0.03873
Step 273570: loss = 0.09890
Step 273575: loss = 0.03928
Step 273580: loss = 0.19689
Step 273585: loss = 0.07028
Step 273590: loss = 0.38433
Step 273595: loss = 0.07589
Step 273600: loss = 0.06526
Step 273605: loss = 0.10203
Step 273610: loss = 0.06820
Step 273615: loss = 0.01785
Step 273620: loss = 0.10292
Step 273625: loss = 0.24440
Step 273630: loss = 0.19345
Step 273635: loss = 0.02855
Step 273640: loss = 0.04870
Step 273645: loss = 0.40564
Step 273650: loss = 0.14308
Step 273655: loss = 0.07722
Step 273660: loss = 0.09848
Step 273665: loss = 0.10599
Step 273670: loss = 0.03220
Step 273675: loss = 0.03545
Step 273680: loss = 0.17489
Step 273685: loss = 0.13223
Step 273690: loss = 0.01676
Step 273695: loss = 0.02856
Step 273700: loss = 0.16983
Step 273705: loss = 0.05703
Step 273710: loss = 0.14048
Step 273715: loss = 0.05986
Step 273720: loss = 0.02118
Step 273725: loss = 0.09548
Step 273730: loss = 0.09100
Step 273735: loss = 0.06507
Step 273740: loss = 0.03664
Step 273745: loss = 0.13016
Step 273750: loss = 0.20415
Step 273755: loss = 0.16903
Step 273760: loss = 0.04330
Step 273765: loss = 0.11186
Step 273770: loss = 0.06705
Step 273775: loss = 0.04978
Step 273780: loss = 0.07521
Step 273785: loss = 0.10500
Step 273790: loss = 0.17627
Step 273795: loss = 0.05399
Step 273800: loss = 0.31140
Step 273805: loss = 0.03378
Step 273810: loss = 0.09518
Step 273815: loss = 0.02998
Step 273820: loss = 0.07031
Step 273825: loss = 0.01706
Step 273830: loss = 0.08553
Step 273835: loss = 0.04925
Step 273840: loss = 0.07353
Step 273845: loss = 0.28842
Step 273850: loss = 0.02356
Step 273855: loss = 0.04450
Step 273860: loss = 0.13474
Step 273865: loss = 0.01336
Step 273870: loss = 0.01440
Step 273875: loss = 0.06375
Step 273880: loss = 0.03133
Step 273885: loss = 0.02782
Step 273890: loss = 0.02962
Step 273895: loss = 0.05249
Step 273900: loss = 0.22946
Step 273905: loss = 0.10774
Step 273910: loss = 0.02954
Step 273915: loss = 0.03540
Step 273920: loss = 0.18175
Step 273925: loss = 0.10920
Step 273930: loss = 0.03686
Step 273935: loss = 0.06414
Step 273940: loss = 0.04128
Step 273945: loss = 0.06854
Step 273950: loss = 0.08624
Step 273955: loss = 0.04454
Step 273960: loss = 0.05586
Step 273965: loss = 0.01773
Step 273970: loss = 0.01523
Step 273975: loss = 0.04798
Step 273980: loss = 0.01415
Step 273985: loss = 0.14356
Step 273990: loss = 0.07352
Step 273995: loss = 0.30651
Step 274000: loss = 0.10466
Training Data Eval:
  Num examples: 50000, Num correct: 48766, Precision @ 1: 0.9753
('Testing Data Eval: EPOCH->', 275)
  Num examples: 10000, Num correct: 6826, Precision @ 1: 0.6826
Step 274005: loss = 0.01466
Step 274010: loss = 0.04768
Step 274015: loss = 0.15864
Step 274020: loss = 0.12902
Step 274025: loss = 0.08373
Step 274030: loss = 0.06177
Step 274035: loss = 0.02903
Step 274040: loss = 0.08338
Step 274045: loss = 0.12975
Step 274050: loss = 0.03641
Step 274055: loss = 0.00889
Step 274060: loss = 0.14685
Step 274065: loss = 0.04220
Step 274070: loss = 0.08949
Step 274075: loss = 0.05902
Step 274080: loss = 0.03256
Step 274085: loss = 0.03070
Step 274090: loss = 0.03952
Step 274095: loss = 0.00777
Step 274100: loss = 0.11447
Step 274105: loss = 0.06276
Step 274110: loss = 0.05708
Step 274115: loss = 0.03566
Step 274120: loss = 0.03898
Step 274125: loss = 0.12921
Step 274130: loss = 0.23271
Step 274135: loss = 0.05250
Step 274140: loss = 0.14352
Step 274145: loss = 0.01400
Step 274150: loss = 0.04984
Step 274155: loss = 0.21880
Step 274160: loss = 0.10898
Step 274165: loss = 0.08283
Step 274170: loss = 0.01146
Step 274175: loss = 0.07036
Step 274180: loss = 0.04579
Step 274185: loss = 0.07510
Step 274190: loss = 0.06281
Step 274195: loss = 0.03149
Step 274200: loss = 0.18166
Step 274205: loss = 0.07103
Step 274210: loss = 0.07360
Step 274215: loss = 0.03123
Step 274220: loss = 0.04350
Step 274225: loss = 0.04500
Step 274230: loss = 0.02063
Step 274235: loss = 0.06001
Step 274240: loss = 0.04249
Step 274245: loss = 0.08764
Step 274250: loss = 0.10969
Step 274255: loss = 0.06805
Step 274260: loss = 0.06965
Step 274265: loss = 0.04660
Step 274270: loss = 0.06674
Step 274275: loss = 0.05724
Step 274280: loss = 0.02384
Step 274285: loss = 0.03838
Step 274290: loss = 0.01806
Step 274295: loss = 0.10501
Step 274300: loss = 0.01091
Step 274305: loss = 0.02103
Step 274310: loss = 0.04175
Step 274315: loss = 0.12549
Step 274320: loss = 0.02725
Step 274325: loss = 0.03140
Step 274330: loss = 0.23248
Step 274335: loss = 0.03802
Step 274340: loss = 0.00377
Step 274345: loss = 0.03309
Step 274350: loss = 0.02856
Step 274355: loss = 0.04225
Step 274360: loss = 0.08342
Step 274365: loss = 0.07230
Step 274370: loss = 0.03705
Step 274375: loss = 0.02626
Step 274380: loss = 0.06186
Step 274385: loss = 0.11426
Step 274390: loss = 0.13912
Step 274395: loss = 0.23120
Step 274400: loss = 0.18680
Step 274405: loss = 0.00311
Step 274410: loss = 0.08549
Step 274415: loss = 0.00527
Step 274420: loss = 0.11902
Step 274425: loss = 0.03326
Step 274430: loss = 0.07926
Step 274435: loss = 0.00977
Step 274440: loss = 0.08135
Step 274445: loss = 0.00668
Step 274450: loss = 0.08747
Step 274455: loss = 0.12977
Step 274460: loss = 0.08824
Step 274465: loss = 0.11484
Step 274470: loss = 0.13074
Step 274475: loss = 0.02967
Step 274480: loss = 0.02484
Step 274485: loss = 0.07916
Step 274490: loss = 0.02334
Step 274495: loss = 0.11914
Step 274500: loss = 0.02272
Step 274505: loss = 0.02158
Step 274510: loss = 0.05998
Step 274515: loss = 0.04466
Step 274520: loss = 0.13219
Step 274525: loss = 0.05222
Step 274530: loss = 0.09534
Step 274535: loss = 0.06512
Step 274540: loss = 0.08239
Step 274545: loss = 0.08570
Step 274550: loss = 0.01739
Step 274555: loss = 0.01888
Step 274560: loss = 0.06690
Step 274565: loss = 0.10741
Step 274570: loss = 0.18776
Step 274575: loss = 0.02166
Step 274580: loss = 0.37869
Step 274585: loss = 0.11456
Step 274590: loss = 0.22672
Step 274595: loss = 0.03718
Step 274600: loss = 0.05405
Step 274605: loss = 0.01096
Step 274610: loss = 0.03880
Step 274615: loss = 0.01995
Step 274620: loss = 0.05857
Step 274625: loss = 0.14966
Step 274630: loss = 0.04838
Step 274635: loss = 0.00513
Step 274640: loss = 0.01083
Step 274645: loss = 0.05098
Step 274650: loss = 0.04239
Step 274655: loss = 0.02251
Step 274660: loss = 0.07925
Step 274665: loss = 0.02158
Step 274670: loss = 0.04575
Step 274675: loss = 0.05580
Step 274680: loss = 0.09191
Step 274685: loss = 0.08978
Step 274690: loss = 0.02611
Step 274695: loss = 0.24113
Step 274700: loss = 0.32754
Step 274705: loss = 0.12281
Step 274710: loss = 0.01270
Step 274715: loss = 0.05535
Step 274720: loss = 0.05619
Step 274725: loss = 0.08580
Step 274730: loss = 0.03985
Step 274735: loss = 0.02221
Step 274740: loss = 0.02907
Step 274745: loss = 0.01619
Step 274750: loss = 0.14062
Step 274755: loss = 0.00808
Step 274760: loss = 0.03006
Step 274765: loss = 0.05175
Step 274770: loss = 0.00965
Step 274775: loss = 0.17545
Step 274780: loss = 0.05173
Step 274785: loss = 0.04539
Step 274790: loss = 0.03398
Step 274795: loss = 0.02166
Step 274800: loss = 0.11860
Step 274805: loss = 0.05752
Step 274810: loss = 0.00717
Step 274815: loss = 0.02019
Step 274820: loss = 0.04895
Step 274825: loss = 0.11781
Step 274830: loss = 0.02235
Step 274835: loss = 0.07994
Step 274840: loss = 0.15788
Step 274845: loss = 0.00992
Step 274850: loss = 0.02155
Step 274855: loss = 0.03523
Step 274860: loss = 0.01798
Step 274865: loss = 0.00872
Step 274870: loss = 0.00725
Step 274875: loss = 0.01672
Step 274880: loss = 0.07019
Step 274885: loss = 0.02671
Step 274890: loss = 0.05176
Step 274895: loss = 0.10489
Step 274900: loss = 0.04704
Step 274905: loss = 0.05876
Step 274910: loss = 0.07289
Step 274915: loss = 0.06654
Step 274920: loss = 0.09307
Step 274925: loss = 0.14947
Step 274930: loss = 0.11288
Step 274935: loss = 0.03928
Step 274940: loss = 0.14467
Step 274945: loss = 0.09370
Step 274950: loss = 0.07532
Step 274955: loss = 0.20742
Step 274960: loss = 0.07816
Step 274965: loss = 0.02646
Step 274970: loss = 0.01541
Step 274975: loss = 0.06435
Step 274980: loss = 0.00281
Step 274985: loss = 0.10975
Step 274990: loss = 0.18293
Step 274995: loss = 0.09396
Step 275000: loss = 0.08179
Training Data Eval:
  Num examples: 50000, Num correct: 48906, Precision @ 1: 0.9781
('Testing Data Eval: EPOCH->', 276)
  Num examples: 10000, Num correct: 6802, Precision @ 1: 0.6802
Step 275005: loss = 0.00379
Step 275010: loss = 0.06815
Step 275015: loss = 0.01798
Step 275020: loss = 0.02099
Step 275025: loss = 0.08910
Step 275030: loss = 0.02051
Step 275035: loss = 0.10460
Step 275040: loss = 0.10789
Step 275045: loss = 0.03812
Step 275050: loss = 0.06224
Step 275055: loss = 0.01661
Step 275060: loss = 0.24217
Step 275065: loss = 0.09124
Step 275070: loss = 0.11209
Step 275075: loss = 0.02692
Step 275080: loss = 0.03767
Step 275085: loss = 0.01459
Step 275090: loss = 0.02936
Step 275095: loss = 0.09962
Step 275100: loss = 0.01497
Step 275105: loss = 0.24430
Step 275110: loss = 0.16902
Step 275115: loss = 0.04594
Step 275120: loss = 0.19243
Step 275125: loss = 0.03367
Step 275130: loss = 0.03405
Step 275135: loss = 0.01778
Step 275140: loss = 0.00726
Step 275145: loss = 0.10646
Step 275150: loss = 0.05941
Step 275155: loss = 0.10849
Step 275160: loss = 0.05535
Step 275165: loss = 0.11565
Step 275170: loss = 0.18252
Step 275175: loss = 0.15424
Step 275180: loss = 0.10653
Step 275185: loss = 0.03125
Step 275190: loss = 0.17648
Step 275195: loss = 0.11356
Step 275200: loss = 0.04918
Step 275205: loss = 0.18203
Step 275210: loss = 0.01738
Step 275215: loss = 0.11708
Step 275220: loss = 0.03229
Step 275225: loss = 0.16018
Step 275230: loss = 0.08334
Step 275235: loss = 0.07758
Step 275240: loss = 0.14066
Step 275245: loss = 0.03441
Step 275250: loss = 0.02657
Step 275255: loss = 0.05631
Step 275260: loss = 0.00165
Step 275265: loss = 0.06580
Step 275270: loss = 0.03594
Step 275275: loss = 0.06946
Step 275280: loss = 0.13188
Step 275285: loss = 0.05989
Step 275290: loss = 0.05180
Step 275295: loss = 0.01906
Step 275300: loss = 0.02592
Step 275305: loss = 0.02317
Step 275310: loss = 0.20311
Step 275315: loss = 0.06826
Step 275320: loss = 0.05008
Step 275325: loss = 0.15462
Step 275330: loss = 0.05966
Step 275335: loss = 0.09700
Step 275340: loss = 0.08534
Step 275345: loss = 0.27529
Step 275350: loss = 0.11692
Step 275355: loss = 0.02946
Step 275360: loss = 0.02876
Step 275365: loss = 0.10915
Step 275370: loss = 0.07810
Step 275375: loss = 0.41932
Step 275380: loss = 0.09812
Step 275385: loss = 0.07473
Step 275390: loss = 0.09675
Step 275395: loss = 0.12038
Step 275400: loss = 0.21064
Step 275405: loss = 0.16152
Step 275410: loss = 0.15427
Step 275415: loss = 0.15254
Step 275420: loss = 0.06296
Step 275425: loss = 0.09564
Step 275430: loss = 0.17732
Step 275435: loss = 0.35655
Step 275440: loss = 0.39384
Step 275445: loss = 0.15871
Step 275450: loss = 0.16838
Step 275455: loss = 0.02806
Step 275460: loss = 0.08101
Step 275465: loss = 0.07200
Step 275470: loss = 0.06814
Step 275475: loss = 0.13075
Step 275480: loss = 0.13462
Step 275485: loss = 0.09254
Step 275490: loss = 0.07345
Step 275495: loss = 0.14018
Step 275500: loss = 0.25032
Step 275505: loss = 0.06837
Step 275510: loss = 0.15573
Step 275515: loss = 0.10657
Step 275520: loss = 0.11365
Step 275525: loss = 0.01323
Step 275530: loss = 0.18630
Step 275535: loss = 0.02360
Step 275540: loss = 0.11646
Step 275545: loss = 0.01145
Step 275550: loss = 0.05076
Step 275555: loss = 0.07453
Step 275560: loss = 0.17269
Step 275565: loss = 0.09488
Step 275570: loss = 0.08790
Step 275575: loss = 0.12988
Step 275580: loss = 0.10626
Step 275585: loss = 0.02715
Step 275590: loss = 0.01277
Step 275595: loss = 0.07192
Step 275600: loss = 0.08989
Step 275605: loss = 0.02359
Step 275610: loss = 0.01200
Step 275615: loss = 0.10399
Step 275620: loss = 0.07675
Step 275625: loss = 0.12095
Step 275630: loss = 0.02113
Step 275635: loss = 0.06858
Step 275640: loss = 0.05245
Step 275645: loss = 0.09569
Step 275650: loss = 0.16202
Step 275655: loss = 0.03714
Step 275660: loss = 0.02186
Step 275665: loss = 0.05732
Step 275670: loss = 0.12310
Step 275675: loss = 0.05356
Step 275680: loss = 0.20857
Step 275685: loss = 0.11277
Step 275690: loss = 0.00545
Step 275695: loss = 0.06570
Step 275700: loss = 0.03550
Step 275705: loss = 0.03694
Step 275710: loss = 0.11854
Step 275715: loss = 0.10336
Step 275720: loss = 0.08657
Step 275725: loss = 0.11491
Step 275730: loss = 0.00864
Step 275735: loss = 0.16443
Step 275740: loss = 0.02153
Step 275745: loss = 0.24384
Step 275750: loss = 0.16832
Step 275755: loss = 0.03718
Step 275760: loss = 0.06477
Step 275765: loss = 0.04800
Step 275770: loss = 0.04307
Step 275775: loss = 0.07117
Step 275780: loss = 0.00984
Step 275785: loss = 0.06213
Step 275790: loss = 0.09077
Step 275795: loss = 0.02554
Step 275800: loss = 0.05858
Step 275805: loss = 0.23740
Step 275810: loss = 0.06877
Step 275815: loss = 0.15861
Step 275820: loss = 0.07424
Step 275825: loss = 0.02180
Step 275830: loss = 0.00934
Step 275835: loss = 0.10181
Step 275840: loss = 0.13990
Step 275845: loss = 0.01713
Step 275850: loss = 0.03082
Step 275855: loss = 0.03988
Step 275860: loss = 0.12348
Step 275865: loss = 0.21657
Step 275870: loss = 0.13891
Step 275875: loss = 0.12558
Step 275880: loss = 0.07129
Step 275885: loss = 0.06713
Step 275890: loss = 0.14208
Step 275895: loss = 0.06261
Step 275900: loss = 0.01371
Step 275905: loss = 0.02701
Step 275910: loss = 0.02131
Step 275915: loss = 0.02905
Step 275920: loss = 0.00859
Step 275925: loss = 0.03283
Step 275930: loss = 0.06644
Step 275935: loss = 0.08172
Step 275940: loss = 0.17141
Step 275945: loss = 0.11821
Step 275950: loss = 0.07407
Step 275955: loss = 0.13908
Step 275960: loss = 0.00872
Step 275965: loss = 0.00633
Step 275970: loss = 0.20590
Step 275975: loss = 0.00640
Step 275980: loss = 0.01852
Step 275985: loss = 0.01762
Step 275990: loss = 0.10199
Step 275995: loss = 0.06402
Step 276000: loss = 0.14274
Training Data Eval:
