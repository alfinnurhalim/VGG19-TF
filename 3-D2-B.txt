Teacher
Step 0: loss = 2.35362
Training Data Eval:
  Num examples: 50000, Num correct: 6760, Precision @ 1: 0.1352
('Testing Data Eval: EPOCH->', 1)
  Num examples: 10000, Num correct: 1357, Precision @ 1: 0.1357
Step 5: loss = 2.20279
Step 10: loss = 2.12605
Step 15: loss = 2.06265
Step 20: loss = 2.05261
Step 25: loss = 1.92141
Step 30: loss = 1.99333
Step 35: loss = 1.95948
Step 40: loss = 1.82408
Step 45: loss = 1.86818
Step 50: loss = 1.80197
Step 55: loss = 1.77807
Step 60: loss = 1.76118
Step 65: loss = 1.76645
Step 70: loss = 1.73726
Step 75: loss = 1.65938
Step 80: loss = 1.67642
Step 85: loss = 1.68859
Step 90: loss = 1.68501
Step 95: loss = 1.68764
Step 100: loss = 1.72318
Step 105: loss = 1.64589
Step 110: loss = 1.68324
Step 115: loss = 1.68578
Step 120: loss = 1.64728
Step 125: loss = 1.47539
Step 130: loss = 1.56248
Step 135: loss = 1.61139
Step 140: loss = 1.54112
Step 145: loss = 1.45706
Step 150: loss = 1.71918
Step 155: loss = 1.50749
Step 160: loss = 1.67386
Step 165: loss = 1.63586
Step 170: loss = 1.49692
Step 175: loss = 1.71801
Step 180: loss = 1.54768
Step 185: loss = 1.48617
Step 190: loss = 1.44083
Step 195: loss = 1.49584
Step 200: loss = 1.35766
Step 205: loss = 1.54578
Step 210: loss = 1.30737
Step 215: loss = 1.46514
Step 220: loss = 1.50044
Step 225: loss = 1.31784
Step 230: loss = 1.39018
Step 235: loss = 1.44332
Step 240: loss = 1.51296
Step 245: loss = 1.36254
Step 250: loss = 1.32843
Step 255: loss = 1.28908
Step 260: loss = 1.21196
Step 265: loss = 1.40968
Step 270: loss = 1.21426
Step 275: loss = 1.46170
Step 280: loss = 1.34682
Step 285: loss = 1.45783
Step 290: loss = 1.29570
Step 295: loss = 1.30380
Step 300: loss = 1.19867
Step 305: loss = 1.21025
Step 310: loss = 1.18056
Step 315: loss = 1.43465
Step 320: loss = 1.38580
Step 325: loss = 1.19228
Step 330: loss = 1.27620
Step 335: loss = 1.24693
Step 340: loss = 1.31531
Step 345: loss = 1.24904
Step 350: loss = 1.16776
Step 355: loss = 1.28517
Step 360: loss = 1.36862
Step 365: loss = 1.47614
Step 370: loss = 1.25313
Step 375: loss = 1.54346
Step 380: loss = 1.35326
Step 385: loss = 1.27259
Step 390: loss = 1.39166
Step 395: loss = 1.21666
Step 400: loss = 1.33968
Step 405: loss = 1.31264
Step 410: loss = 1.09689
Step 415: loss = 1.36392
Step 420: loss = 1.28705
Step 425: loss = 1.47126
Step 430: loss = 1.22243
Step 435: loss = 1.16076
Step 440: loss = 1.13802
Step 445: loss = 1.41372
Step 450: loss = 1.24739
Step 455: loss = 1.26226
Step 460: loss = 1.35401
Step 465: loss = 1.28140
Step 470: loss = 1.23760
Step 475: loss = 1.33968
Step 480: loss = 1.19961
Step 485: loss = 1.03651
Step 490: loss = 1.14780
Step 495: loss = 1.30321
Step 500: loss = 1.19052
Step 505: loss = 1.44108
Step 510: loss = 1.16510
Step 515: loss = 1.24110
Step 520: loss = 1.20088
Step 525: loss = 1.26205
Step 530: loss = 1.17094
Step 535: loss = 1.06571
Step 540: loss = 1.29094
Step 545: loss = 1.14077
Step 550: loss = 1.05340
Step 555: loss = 1.26843
Step 560: loss = 1.32411
Step 565: loss = 1.08668
Step 570: loss = 1.36498
Step 575: loss = 1.50441
Step 580: loss = 1.18741
Step 585: loss = 1.19398
Step 590: loss = 1.38714
Step 595: loss = 1.22138
Step 600: loss = 1.03054
Step 605: loss = 1.10044
Step 610: loss = 1.11832
Step 615: loss = 1.40958
Step 620: loss = 1.26757
Step 625: loss = 1.34060
Step 630: loss = 1.22179
Step 635: loss = 1.10012
Step 640: loss = 1.22474
Step 645: loss = 1.49116
Step 650: loss = 1.23439
Step 655: loss = 1.13675
Step 660: loss = 1.09763
Step 665: loss = 1.24706
Step 670: loss = 1.05258
Step 675: loss = 1.13156
Step 680: loss = 1.14769
Step 685: loss = 1.23697
Step 690: loss = 1.24830
Step 695: loss = 1.29878
Step 700: loss = 1.13226
Step 705: loss = 1.11580
Step 710: loss = 1.23479
Step 715: loss = 1.12332
Step 720: loss = 1.38474
Step 725: loss = 1.21796
Step 730: loss = 1.05121
Step 735: loss = 1.38340
Step 740: loss = 1.11111
Step 745: loss = 1.02323
Step 750: loss = 1.19255
Step 755: loss = 1.10148
Step 760: loss = 1.21244
Step 765: loss = 1.22765
Step 770: loss = 1.14047
Step 775: loss = 1.13191
Step 780: loss = 1.14942
Step 785: loss = 1.06455
Step 790: loss = 1.06525
Step 795: loss = 1.16386
Step 800: loss = 1.02960
Step 805: loss = 1.17494
Step 810: loss = 1.37014
Step 815: loss = 1.34306
Step 820: loss = 1.20904
Step 825: loss = 0.84803
Step 830: loss = 0.89658
Step 835: loss = 1.21869
Step 840: loss = 1.10130
Step 845: loss = 1.08868
Step 850: loss = 1.37761
Step 855: loss = 1.20544
Step 860: loss = 1.10954
Step 865: loss = 1.08385
Step 870: loss = 1.13399
Step 875: loss = 1.20293
Step 880: loss = 1.01148
Step 885: loss = 0.95858
Step 890: loss = 1.11317
Step 895: loss = 1.21400
Step 900: loss = 0.96765
Step 905: loss = 1.11848
Step 910: loss = 1.14738
Step 915: loss = 0.92817
Step 920: loss = 0.98840
Step 925: loss = 1.17697
Step 930: loss = 1.04852
Step 935: loss = 0.85182
Step 940: loss = 1.06480
Step 945: loss = 1.10359
Step 950: loss = 0.89710
Step 955: loss = 1.17732
Step 960: loss = 1.14060
Step 965: loss = 1.12397
Step 970: loss = 0.81454
Step 975: loss = 1.05926
Step 980: loss = 1.25608
Step 985: loss = 1.21737
Step 990: loss = 1.08060
Step 995: loss = 1.13183
Step 1000: loss = 0.95220
Training Data Eval:
  Num examples: 50000, Num correct: 32510, Precision @ 1: 0.6502
('Testing Data Eval: EPOCH->', 2)
  Num examples: 10000, Num correct: 6062, Precision @ 1: 0.6062
Step 1005: loss = 0.99752
Step 1010: loss = 1.08712
Step 1015: loss = 0.96359
Step 1020: loss = 0.91508
Step 1025: loss = 1.16605
Step 1030: loss = 0.89602
Step 1035: loss = 1.05035
Step 1040: loss = 0.94557
Step 1045: loss = 1.05181
Step 1050: loss = 0.94033
Step 1055: loss = 0.95537
Step 1060: loss = 1.03379
Step 1065: loss = 1.04016
Step 1070: loss = 1.14966
Step 1075: loss = 0.97892
Step 1080: loss = 1.06330
Step 1085: loss = 1.04970
Step 1090: loss = 1.17082
Step 1095: loss = 1.05979
Step 1100: loss = 0.78844
Step 1105: loss = 1.15147
Step 1110: loss = 0.96035
Step 1115: loss = 1.13928
Step 1120: loss = 1.14581
Step 1125: loss = 1.07360
Step 1130: loss = 1.33168
Step 1135: loss = 0.60465
Step 1140: loss = 0.97982
Step 1145: loss = 0.90410
Step 1150: loss = 1.12838
Step 1155: loss = 0.74460
Step 1160: loss = 0.88712
Step 1165: loss = 1.08542
Step 1170: loss = 1.12779
Step 1175: loss = 1.07965
Step 1180: loss = 0.89976
Step 1185: loss = 0.98022
Step 1190: loss = 0.66158
Step 1195: loss = 0.79404
Step 1200: loss = 0.97084
Step 1205: loss = 1.09529
Step 1210: loss = 0.87118
Step 1215: loss = 0.68497
Step 1220: loss = 1.26261
Step 1225: loss = 1.03413
Step 1230: loss = 1.21887
Step 1235: loss = 1.60482
Step 1240: loss = 1.07191
Step 1245: loss = 1.05482
Step 1250: loss = 1.15002
Step 1255: loss = 0.98577
Step 1260: loss = 0.93177
Step 1265: loss = 0.85850
Step 1270: loss = 0.99404
Step 1275: loss = 1.20912
Step 1280: loss = 1.09359
Step 1285: loss = 1.06056
Step 1290: loss = 0.90907
Step 1295: loss = 0.88925
Step 1300: loss = 1.00595
Step 1305: loss = 1.01034
Step 1310: loss = 0.86368
Step 1315: loss = 0.94573
Step 1320: loss = 1.00946
Step 1325: loss = 1.03356
Step 1330: loss = 1.14194
Step 1335: loss = 1.00002
Step 1340: loss = 0.80198
Step 1345: loss = 1.11539
Step 1350: loss = 0.98157
Step 1355: loss = 0.75146
Step 1360: loss = 0.99271
Step 1365: loss = 0.71052
Step 1370: loss = 1.05070
Step 1375: loss = 0.90898
Step 1380: loss = 1.06630
Step 1385: loss = 1.15772
Step 1390: loss = 1.13274
Step 1395: loss = 1.06314
Step 1400: loss = 1.23631
Step 1405: loss = 0.95864
Step 1410: loss = 0.79373
Step 1415: loss = 1.19363
Step 1420: loss = 0.77410
Step 1425: loss = 1.06196
Step 1430: loss = 0.76359
Step 1435: loss = 0.95802
Step 1440: loss = 0.94122
Step 1445: loss = 0.76954
Step 1450: loss = 1.24229
Step 1455: loss = 1.06820
Step 1460: loss = 0.88455
Step 1465: loss = 0.95263
Step 1470: loss = 0.98853
Step 1475: loss = 1.04011
Step 1480: loss = 0.89546
Step 1485: loss = 1.01584
Step 1490: loss = 0.85255
Step 1495: loss = 1.10961
Step 1500: loss = 0.80834
Step 1505: loss = 0.81098
Step 1510: loss = 1.04508
Step 1515: loss = 0.97951
Step 1520: loss = 0.85393
Step 1525: loss = 1.15609
Step 1530: loss = 1.05062
Step 1535: loss = 1.15182
Step 1540: loss = 1.20929
Step 1545: loss = 1.06854
Step 1550: loss = 1.04817
Step 1555: loss = 1.23587
Step 1560: loss = 0.78996
Step 1565: loss = 1.22843
Step 1570: loss = 1.05034
Step 1575: loss = 0.96516
Step 1580: loss = 1.04700
Step 1585: loss = 0.80163
Step 1590: loss = 1.04332
Step 1595: loss = 0.87568
Step 1600: loss = 1.06386
Step 1605: loss = 0.68171
Step 1610: loss = 0.87150
Step 1615: loss = 0.92983
Step 1620: loss = 1.07080
Step 1625: loss = 0.90356
Step 1630: loss = 0.97585
Step 1635: loss = 1.04707
Step 1640: loss = 1.04237
Step 1645: loss = 0.96029
Step 1650: loss = 0.88945
Step 1655: loss = 0.93272
Step 1660: loss = 0.96748
Step 1665: loss = 1.00803
Step 1670: loss = 0.81719
Step 1675: loss = 0.89715
Step 1680: loss = 0.71892
Step 1685: loss = 0.81408
Step 1690: loss = 0.89086
Step 1695: loss = 1.13128
Step 1700: loss = 1.17174
Step 1705: loss = 0.71436
Step 1710: loss = 0.67799
Step 1715: loss = 0.92489
Step 1720: loss = 0.85163
Step 1725: loss = 0.90541
Step 1730: loss = 1.00427
Step 1735: loss = 0.88671
Step 1740: loss = 1.07697
Step 1745: loss = 0.97023
Step 1750: loss = 0.98342
Step 1755: loss = 0.95616
Step 1760: loss = 0.93421
Step 1765: loss = 1.04247
Step 1770: loss = 1.14518
Step 1775: loss = 0.71748
Step 1780: loss = 0.78202
Step 1785: loss = 0.64242
Step 1790: loss = 0.77407
Step 1795: loss = 0.73581
Step 1800: loss = 1.07742
Step 1805: loss = 0.73074
Step 1810: loss = 0.81835
Step 1815: loss = 1.05914
Step 1820: loss = 0.60064
Step 1825: loss = 0.72433
Step 1830: loss = 0.68273
Step 1835: loss = 0.77984
Step 1840: loss = 0.70746
Step 1845: loss = 0.78911
Step 1850: loss = 0.95547
Step 1855: loss = 1.03586
Step 1860: loss = 0.96760
Step 1865: loss = 0.79851
Step 1870: loss = 0.93678
Step 1875: loss = 0.87248
Step 1880: loss = 0.80630
Step 1885: loss = 0.99727
Step 1890: loss = 0.90106
Step 1895: loss = 0.94832
Step 1900: loss = 0.86472
Step 1905: loss = 0.84118
Step 1910: loss = 1.08296
Step 1915: loss = 0.70010
Step 1920: loss = 0.87104
Step 1925: loss = 0.91403
Step 1930: loss = 0.76526
Step 1935: loss = 0.67011
Step 1940: loss = 1.15852
Step 1945: loss = 0.69840
Step 1950: loss = 0.75938
Step 1955: loss = 1.04594
Step 1960: loss = 0.95825
Step 1965: loss = 0.89546
Step 1970: loss = 1.06358
Step 1975: loss = 1.00327
Step 1980: loss = 1.03180
Step 1985: loss = 0.73576
Step 1990: loss = 0.77296
Step 1995: loss = 1.09511
Step 2000: loss = 0.79505
Training Data Eval:
  Num examples: 50000, Num correct: 35532, Precision @ 1: 0.7106
('Testing Data Eval: EPOCH->', 3)
  Num examples: 10000, Num correct: 6410, Precision @ 1: 0.6410
Step 2005: loss = 0.75329
Step 2010: loss = 0.73476
Step 2015: loss = 0.63717
Step 2020: loss = 0.72037
Step 2025: loss = 0.87486
Step 2030: loss = 0.76111
Step 2035: loss = 0.80478
Step 2040: loss = 0.95061
Step 2045: loss = 0.71573
Step 2050: loss = 1.06089
Step 2055: loss = 0.94118
Step 2060: loss = 0.94054
Step 2065: loss = 0.95357
Step 2070: loss = 1.02432
Step 2075: loss = 0.99729
Step 2080: loss = 0.92466
Step 2085: loss = 0.80167
Step 2090: loss = 0.77833
Step 2095: loss = 0.64775
Step 2100: loss = 0.87434
Step 2105: loss = 0.71689
Step 2110: loss = 0.77697
Step 2115: loss = 0.81320
Step 2120: loss = 0.73545
Step 2125: loss = 0.88102
Step 2130: loss = 1.03649
Step 2135: loss = 0.80937
Step 2140: loss = 0.71875
Step 2145: loss = 0.60562
Step 2150: loss = 0.66007
Step 2155: loss = 0.79010
Step 2160: loss = 0.74279
Step 2165: loss = 0.57565
Step 2170: loss = 0.73101
Step 2175: loss = 0.75737
Step 2180: loss = 0.61377
Step 2185: loss = 0.69823
Step 2190: loss = 0.80723
Step 2195: loss = 0.90445
Step 2200: loss = 0.75755
Step 2205: loss = 0.97861
Step 2210: loss = 0.93614
Step 2215: loss = 0.88225
Step 2220: loss = 0.74872
Step 2225: loss = 0.94060
Step 2230: loss = 0.88275
Step 2235: loss = 0.87660
Step 2240: loss = 0.70423
Step 2245: loss = 0.99106
Step 2250: loss = 0.90818
Step 2255: loss = 0.73181
Step 2260: loss = 0.78473
Step 2265: loss = 0.93966
Step 2270: loss = 0.62080
Step 2275: loss = 0.70237
Step 2280: loss = 0.83094
Step 2285: loss = 0.93480
Step 2290: loss = 0.81010
Step 2295: loss = 0.61974
Step 2300: loss = 0.71470
Step 2305: loss = 0.60158
Step 2310: loss = 0.67284
Step 2315: loss = 0.84568
Step 2320: loss = 0.79229
Step 2325: loss = 1.16159
Step 2330: loss = 1.05195
Step 2335: loss = 0.78768
Step 2340: loss = 0.72492
Step 2345: loss = 0.55506
Step 2350: loss = 1.04254
Step 2355: loss = 0.86082
Step 2360: loss = 0.53642
Step 2365: loss = 0.77202
Step 2370: loss = 0.47443
Step 2375: loss = 1.16407
Step 2380: loss = 0.93290
Step 2385: loss = 0.63687
Step 2390: loss = 0.88192
Step 2395: loss = 0.76900
Step 2400: loss = 0.90267
Step 2405: loss = 0.86510
Step 2410: loss = 0.86229
Step 2415: loss = 1.03799
Step 2420: loss = 0.92893
Step 2425: loss = 0.98723
Step 2430: loss = 0.73646
Step 2435: loss = 0.80999
Step 2440: loss = 0.95151
Step 2445: loss = 1.11280
Step 2450: loss = 0.83697
Step 2455: loss = 0.77015
Step 2460: loss = 0.85629
Step 2465: loss = 0.78307
Step 2470: loss = 0.93396
Step 2475: loss = 0.70003
Step 2480: loss = 0.80675
Step 2485: loss = 0.98113
Step 2490: loss = 0.83425
Step 2495: loss = 0.82471
Step 2500: loss = 0.79673
Step 2505: loss = 0.80138
Step 2510: loss = 1.02356
Step 2515: loss = 0.91172
Step 2520: loss = 0.90850
Step 2525: loss = 0.70396
Step 2530: loss = 0.74691
Step 2535: loss = 0.83838
Step 2540: loss = 1.06665
Step 2545: loss = 0.94650
Step 2550: loss = 0.92229
Step 2555: loss = 0.66712
Step 2560: loss = 0.91643
Step 2565: loss = 0.74734
Step 2570: loss = 0.85637
Step 2575: loss = 0.58020
Step 2580: loss = 0.81402
Step 2585: loss = 0.76125
Step 2590: loss = 0.79773
Step 2595: loss = 0.71468
Step 2600: loss = 0.79218
Step 2605: loss = 0.74941
Step 2610: loss = 0.79941
Step 2615: loss = 0.98745
Step 2620: loss = 0.75536
Step 2625: loss = 0.80185
Step 2630: loss = 0.72071
Step 2635: loss = 0.76503
Step 2640: loss = 0.79293
Step 2645: loss = 0.75538
Step 2650: loss = 0.74822
Step 2655: loss = 0.85630
Step 2660: loss = 0.78588
Step 2665: loss = 0.77925
Step 2670: loss = 0.83210
Step 2675: loss = 0.86827
Step 2680: loss = 1.00772
Step 2685: loss = 0.49309
Step 2690: loss = 0.95508
Step 2695: loss = 0.75531
Step 2700: loss = 0.83908
Step 2705: loss = 0.61466
Step 2710: loss = 0.60468
Step 2715: loss = 0.82558
Step 2720: loss = 0.97455
Step 2725: loss = 0.76749
Step 2730: loss = 0.82499
Step 2735: loss = 0.69391
Step 2740: loss = 0.89919
Step 2745: loss = 0.93608
Step 2750: loss = 0.68473
Step 2755: loss = 0.68417
Step 2760: loss = 0.78025
Step 2765: loss = 0.94792
Step 2770: loss = 0.92738
Step 2775: loss = 1.03481
Step 2780: loss = 0.73719
Step 2785: loss = 0.60066
Step 2790: loss = 0.69553
Step 2795: loss = 0.75463
Step 2800: loss = 0.77775
Step 2805: loss = 0.59608
Step 2810: loss = 0.69694
Step 2815: loss = 0.66810
Step 2820: loss = 0.79385
Step 2825: loss = 0.98273
Step 2830: loss = 0.55383
Step 2835: loss = 0.63975
Step 2840: loss = 0.92133
Step 2845: loss = 0.67385
Step 2850: loss = 0.60934
Step 2855: loss = 0.89231
Step 2860: loss = 0.74371
Step 2865: loss = 0.77193
Step 2870: loss = 0.57208
Step 2875: loss = 0.78280
Step 2880: loss = 0.80068
Step 2885: loss = 1.00825
Step 2890: loss = 0.92237
Step 2895: loss = 0.75279
Step 2900: loss = 0.58443
Step 2905: loss = 0.54360
Step 2910: loss = 0.98155
Step 2915: loss = 0.65690
Step 2920: loss = 0.70380
Step 2925: loss = 0.83782
Step 2930: loss = 0.64436
Step 2935: loss = 0.62684
Step 2940: loss = 0.64590
Step 2945: loss = 1.05822
Step 2950: loss = 0.76604
Step 2955: loss = 1.20141
Step 2960: loss = 0.74903
Step 2965: loss = 0.75296
Step 2970: loss = 0.87285
Step 2975: loss = 0.74444
Step 2980: loss = 0.53732
Step 2985: loss = 0.89019
Step 2990: loss = 1.04244
Step 2995: loss = 0.50603
Step 3000: loss = 0.78185
Training Data Eval:
  Num examples: 50000, Num correct: 37323, Precision @ 1: 0.7465
('Testing Data Eval: EPOCH->', 4)
  Num examples: 10000, Num correct: 6448, Precision @ 1: 0.6448
Step 3005: loss = 0.82588
Step 3010: loss = 0.81794
Step 3015: loss = 0.95076
Step 3020: loss = 0.65742
Step 3025: loss = 0.60977
Step 3030: loss = 0.74918
Step 3035: loss = 0.82944
Step 3040: loss = 0.65599
Step 3045: loss = 0.64339
Step 3050: loss = 0.54088
Step 3055: loss = 0.63861
Step 3060: loss = 0.67860
Step 3065: loss = 0.96768
Step 3070: loss = 0.68872
Step 3075: loss = 0.81116
Step 3080: loss = 0.47009
Step 3085: loss = 0.66276
Step 3090: loss = 0.81578
Step 3095: loss = 0.53903
Step 3100: loss = 0.76203
Step 3105: loss = 0.84339
Step 3110: loss = 0.87248
Step 3115: loss = 0.56986
Step 3120: loss = 0.84357
Step 3125: loss = 0.73941
Step 3130: loss = 0.73234
Step 3135: loss = 0.65630
Step 3140: loss = 0.77391
Step 3145: loss = 0.68482
Step 3150: loss = 0.70406
Step 3155: loss = 0.81861
Step 3160: loss = 0.68889
Step 3165: loss = 0.61371
Step 3170: loss = 0.57121
Step 3175: loss = 1.02296
Step 3180: loss = 0.57326
Step 3185: loss = 0.81282
Step 3190: loss = 0.57819
Step 3195: loss = 1.17517
Step 3200: loss = 0.60548
Step 3205: loss = 0.46172
Step 3210: loss = 0.73019
Step 3215: loss = 0.62232
Step 3220: loss = 0.69577
Step 3225: loss = 0.85989
Step 3230: loss = 0.63204
Step 3235: loss = 0.74247
Step 3240: loss = 0.63835
Step 3245: loss = 0.59476
Step 3250: loss = 0.78010
Step 3255: loss = 0.61564
Step 3260: loss = 0.63785
Step 3265: loss = 0.65626
Step 3270: loss = 0.69766
Step 3275: loss = 0.70040
Step 3280: loss = 0.67077
Step 3285: loss = 0.88137
Step 3290: loss = 0.63784
Step 3295: loss = 0.73817
Step 3300: loss = 0.82735
Step 3305: loss = 0.65952
Step 3310: loss = 0.71692
Step 3315: loss = 0.44241
Step 3320: loss = 0.63749
Step 3325: loss = 0.83403
Step 3330: loss = 0.93365
Step 3335: loss = 0.88658
Step 3340: loss = 0.61604
Step 3345: loss = 0.56728
Step 3350: loss = 0.80994
Step 3355: loss = 0.75749
Step 3360: loss = 0.57103
Step 3365: loss = 0.64536
Step 3370: loss = 0.71976
Step 3375: loss = 0.76145
Step 3380: loss = 0.82684
Step 3385: loss = 0.57895
Step 3390: loss = 0.89129
Step 3395: loss = 0.90273
Step 3400: loss = 0.76151
Step 3405: loss = 0.61304
Step 3410: loss = 0.63339
Step 3415: loss = 0.66663
Step 3420: loss = 0.74197
Step 3425: loss = 0.51334
Step 3430: loss = 1.00781
Step 3435: loss = 0.63140
Step 3440: loss = 0.63799
Step 3445: loss = 0.68444
Step 3450: loss = 0.79302
Step 3455: loss = 0.43209
Step 3460: loss = 0.52554
Step 3465: loss = 0.66371
Step 3470: loss = 0.64615
Step 3475: loss = 0.88092
Step 3480: loss = 0.91412
Step 3485: loss = 0.60635
Step 3490: loss = 0.80730
Step 3495: loss = 0.66715
Step 3500: loss = 0.65781
Step 3505: loss = 0.69912
Step 3510: loss = 0.80804
Step 3515: loss = 0.75625
Step 3520: loss = 0.71770
Step 3525: loss = 0.44596
Step 3530: loss = 0.68569
Step 3535: loss = 0.52912
Step 3540: loss = 0.66534
Step 3545: loss = 0.53480
Step 3550: loss = 0.92597
Step 3555: loss = 0.75586
Step 3560: loss = 0.77657
Step 3565: loss = 0.69169
Step 3570: loss = 0.55130
Step 3575: loss = 0.71786
Step 3580: loss = 0.64016
Step 3585: loss = 0.54064
Step 3590: loss = 0.57785
Step 3595: loss = 0.74570
Step 3600: loss = 0.61371
Step 3605: loss = 0.78169
Step 3610: loss = 0.73766
Step 3615: loss = 0.52858
Step 3620: loss = 0.67997
Step 3625: loss = 0.81803
Step 3630: loss = 0.81948
Step 3635: loss = 0.79880
Step 3640: loss = 0.93843
Step 3645: loss = 0.87317
Step 3650: loss = 0.60727
Step 3655: loss = 0.81395
Step 3660: loss = 0.74260
Step 3665: loss = 0.69656
Step 3670: loss = 0.77595
Step 3675: loss = 0.73968
Step 3680: loss = 0.74169
Step 3685: loss = 0.64837
Step 3690: loss = 0.87303
Step 3695: loss = 0.89864
Step 3700: loss = 0.74740
Step 3705: loss = 0.67270
Step 3710: loss = 0.77984
Step 3715: loss = 0.56635
Step 3720: loss = 0.43682
Step 3725: loss = 0.54049
Step 3730: loss = 0.60282
Step 3735: loss = 0.55101
Step 3740: loss = 0.51126
Step 3745: loss = 0.70781
Step 3750: loss = 0.54585
Step 3755: loss = 0.79375
Step 3760: loss = 0.52335
Step 3765: loss = 0.71186
Step 3770: loss = 0.83647
Step 3775: loss = 0.79423
Step 3780: loss = 0.80082
Step 3785: loss = 0.84136
Step 3790: loss = 0.50733
Step 3795: loss = 0.64243
Step 3800: loss = 0.42125
Step 3805: loss = 0.60985
Step 3810: loss = 1.12775
Step 3815: loss = 0.67613
Step 3820: loss = 0.88260
Step 3825: loss = 0.49087
Step 3830: loss = 0.61376
Step 3835: loss = 0.54846
Step 3840: loss = 0.60981
Step 3845: loss = 0.49425
Step 3850: loss = 0.84909
Step 3855: loss = 0.84065
Step 3860: loss = 0.65224
Step 3865: loss = 0.56482
Step 3870: loss = 0.93271
Step 3875: loss = 0.60563
Step 3880: loss = 0.60015
Step 3885: loss = 0.76095
Step 3890: loss = 0.42805
Step 3895: loss = 0.67502
Step 3900: loss = 0.69204
Step 3905: loss = 0.70547
Step 3910: loss = 0.74432
Step 3915: loss = 0.67184
Step 3920: loss = 0.78352
Step 3925: loss = 0.94180
Step 3930: loss = 0.68113
Step 3935: loss = 0.76670
Step 3940: loss = 0.53848
Step 3945: loss = 0.51598
Step 3950: loss = 0.65592
Step 3955: loss = 0.55628
Step 3960: loss = 0.58645
Step 3965: loss = 0.50459
Step 3970: loss = 0.78253
Step 3975: loss = 0.68999
Step 3980: loss = 0.62279
Step 3985: loss = 0.56386
Step 3990: loss = 0.56812
Step 3995: loss = 1.02568
Step 4000: loss = 0.85439
Training Data Eval:
  Num examples: 50000, Num correct: 39343, Precision @ 1: 0.7869
('Testing Data Eval: EPOCH->', 5)
  Num examples: 10000, Num correct: 6628, Precision @ 1: 0.6628
Step 4005: loss = 0.47639
Step 4010: loss = 0.55729
Step 4015: loss = 0.79386
Step 4020: loss = 0.58616
Step 4025: loss = 0.52471
Step 4030: loss = 0.71888
Step 4035: loss = 0.63106
Step 4040: loss = 0.69548
Step 4045: loss = 0.76490
Step 4050: loss = 0.78953
Step 4055: loss = 0.54890
Step 4060: loss = 0.70553
Step 4065: loss = 0.93425
Step 4070: loss = 0.55806
Step 4075: loss = 0.76918
Step 4080: loss = 0.70623
Step 4085: loss = 0.57763
Step 4090: loss = 0.59313
Step 4095: loss = 0.64374
Step 4100: loss = 0.74659
Step 4105: loss = 0.68567
Step 4110: loss = 0.58072
Step 4115: loss = 0.76035
Step 4120: loss = 0.58060
Step 4125: loss = 0.50069
Step 4130: loss = 0.70380
Step 4135: loss = 0.72234
Step 4140: loss = 0.61633
Step 4145: loss = 0.69951
Step 4150: loss = 0.60434
Step 4155: loss = 0.36655
Step 4160: loss = 0.57323
Step 4165: loss = 0.52274
Step 4170: loss = 0.65734
Step 4175: loss = 0.56098
Step 4180: loss = 0.52295
Step 4185: loss = 0.59202
Step 4190: loss = 0.69242
Step 4195: loss = 0.43797
Step 4200: loss = 0.56144
Step 4205: loss = 0.52368
Step 4210: loss = 0.54335
Step 4215: loss = 0.50627
Step 4220: loss = 0.73537
Step 4225: loss = 0.59480
Step 4230: loss = 0.62165
Step 4235: loss = 0.73135
Step 4240: loss = 0.51560
Step 4245: loss = 0.83958
Step 4250: loss = 0.52043
Step 4255: loss = 0.64672
Step 4260: loss = 0.51595
Step 4265: loss = 0.66309
Step 4270: loss = 0.60602
Step 4275: loss = 0.56302
Step 4280: loss = 0.82826
Step 4285: loss = 0.87108
Step 4290: loss = 0.52281
Step 4295: loss = 0.74057
Step 4300: loss = 0.66912
Step 4305: loss = 0.76820
Step 4310: loss = 0.52443
Step 4315: loss = 0.56294
Step 4320: loss = 0.72398
Step 4325: loss = 0.45116
Step 4330: loss = 0.72754
Step 4335: loss = 0.60468
Step 4340: loss = 0.62101
Step 4345: loss = 0.48530
Step 4350: loss = 0.85212
Step 4355: loss = 0.68682
Step 4360: loss = 0.84718
Step 4365: loss = 0.75520
Step 4370: loss = 0.73035
Step 4375: loss = 0.45079
Step 4380: loss = 0.95774
Step 4385: loss = 0.57753
Step 4390: loss = 0.73995
Step 4395: loss = 0.61264
Step 4400: loss = 0.75700
Step 4405: loss = 0.56110
Step 4410: loss = 0.77512
Step 4415: loss = 0.65849
Step 4420: loss = 0.64439
Step 4425: loss = 0.55081
Step 4430: loss = 0.60517
Step 4435: loss = 0.46001
Step 4440: loss = 0.54581
Step 4445: loss = 0.69639
Step 4450: loss = 0.66554
Step 4455: loss = 0.53261
Step 4460: loss = 0.64131
Step 4465: loss = 0.51682
Step 4470: loss = 0.77794
Step 4475: loss = 0.65904
Step 4480: loss = 0.47895
Step 4485: loss = 0.88034
Step 4490: loss = 0.61286
Step 4495: loss = 0.78100
Step 4500: loss = 0.55001
Step 4505: loss = 0.52896
Step 4510: loss = 0.45991
Step 4515: loss = 0.71624
Step 4520: loss = 0.57272
Step 4525: loss = 0.65644
Step 4530: loss = 0.50542
Step 4535: loss = 0.64912
Step 4540: loss = 0.57952
Step 4545: loss = 0.67342
Step 4550: loss = 0.46145
Step 4555: loss = 0.60357
Step 4560: loss = 0.47188
Step 4565: loss = 0.72592
Step 4570: loss = 0.62328
Step 4575: loss = 0.68649
Step 4580: loss = 0.53941
Step 4585: loss = 0.73727
Step 4590: loss = 0.70544
Step 4595: loss = 0.72381
Step 4600: loss = 0.53446
Step 4605: loss = 0.49500
Step 4610: loss = 0.43552
Step 4615: loss = 0.80131
Step 4620: loss = 0.54212
Step 4625: loss = 0.65126
Step 4630: loss = 0.64047
Step 4635: loss = 0.62348
Step 4640: loss = 0.75361
Step 4645: loss = 0.73674
Step 4650: loss = 0.54363
Step 4655: loss = 0.71573
Step 4660: loss = 0.71744
Step 4665: loss = 0.57816
Step 4670: loss = 0.60182
Step 4675: loss = 0.47468
Step 4680: loss = 0.64606
Step 4685: loss = 0.82553
Step 4690: loss = 0.64700
Step 4695: loss = 0.78092
Step 4700: loss = 0.60563
Step 4705: loss = 0.60974
Step 4710: loss = 0.54619
Step 4715: loss = 0.87564
Step 4720: loss = 0.72971
Step 4725: loss = 0.74006
Step 4730: loss = 0.65891
Step 4735: loss = 0.49803
Step 4740: loss = 0.83718
Step 4745: loss = 0.45863
Step 4750: loss = 0.69759
Step 4755: loss = 0.94849
Step 4760: loss = 0.36829
Step 4765: loss = 0.59420
Step 4770: loss = 0.58871
Step 4775: loss = 0.75546
Step 4780: loss = 0.87021
Step 4785: loss = 0.57139
Step 4790: loss = 0.89658
Step 4795: loss = 0.54303
Step 4800: loss = 0.60894
Step 4805: loss = 0.60615
Step 4810: loss = 0.63533
Step 4815: loss = 0.63061
Step 4820: loss = 0.59430
Step 4825: loss = 0.71611
Step 4830: loss = 0.70851
Step 4835: loss = 0.58114
Step 4840: loss = 0.59132
Step 4845: loss = 0.44374
Step 4850: loss = 0.71984
Step 4855: loss = 0.77017
Step 4860: loss = 0.72337
Step 4865: loss = 0.79320
Step 4870: loss = 0.43268
Step 4875: loss = 0.40241
Step 4880: loss = 0.50520
Step 4885: loss = 0.43965
Step 4890: loss = 0.55692
Step 4895: loss = 0.68331
Step 4900: loss = 0.74400
Step 4905: loss = 0.55765
Step 4910: loss = 0.35302
Step 4915: loss = 0.78362
Step 4920: loss = 0.53527
Step 4925: loss = 0.58611
Step 4930: loss = 0.82736
Step 4935: loss = 0.54151
Step 4940: loss = 0.64096
Step 4945: loss = 0.43357
Step 4950: loss = 0.65606
Step 4955: loss = 0.51940
Step 4960: loss = 0.74237
Step 4965: loss = 0.75950
Step 4970: loss = 0.65471
Step 4975: loss = 0.68560
Step 4980: loss = 0.51423
Step 4985: loss = 0.70120
Step 4990: loss = 0.74537
Step 4995: loss = 0.63891
Step 5000: loss = 0.77195
Training Data Eval:
  Num examples: 50000, Num correct: 41070, Precision @ 1: 0.8214
('Testing Data Eval: EPOCH->', 6)
  Num examples: 10000, Num correct: 6618, Precision @ 1: 0.6618
Step 5005: loss = 0.59900
Step 5010: loss = 0.52632
Step 5015: loss = 0.47747
Step 5020: loss = 0.58299
Step 5025: loss = 0.34109
Step 5030: loss = 0.48465
Step 5035: loss = 0.62890
Step 5040: loss = 0.56096
Step 5045: loss = 0.56621
Step 5050: loss = 0.57296
Step 5055: loss = 0.54464
Step 5060: loss = 0.51020
Step 5065: loss = 0.68443
Step 5070: loss = 0.58487
Step 5075: loss = 0.64423
Step 5080: loss = 0.53692
Step 5085: loss = 0.65389
Step 5090: loss = 0.38113
Step 5095: loss = 0.72547
Step 5100: loss = 0.57979
Step 5105: loss = 0.78993
Step 5110: loss = 0.60413
Step 5115: loss = 0.48733
Step 5120: loss = 0.79735
Step 5125: loss = 0.54574
Step 5130: loss = 0.34407
Step 5135: loss = 0.83948
Step 5140: loss = 0.52922
Step 5145: loss = 0.48474
Step 5150: loss = 0.58173
Step 5155: loss = 0.62682
Step 5160: loss = 0.61056
Step 5165: loss = 0.60052
Step 5170: loss = 0.54847
Step 5175: loss = 0.59197
Step 5180: loss = 0.76235
Step 5185: loss = 0.32537
Step 5190: loss = 0.70301
Step 5195: loss = 0.49408
Step 5200: loss = 0.51095
Step 5205: loss = 0.49601
Step 5210: loss = 0.51117
Step 5215: loss = 0.48517
Step 5220: loss = 0.56867
Step 5225: loss = 0.84121
Step 5230: loss = 0.53618
Step 5235: loss = 0.64321
Step 5240: loss = 0.68789
Step 5245: loss = 0.40823
Step 5250: loss = 0.78895
Step 5255: loss = 0.46637
Step 5260: loss = 0.67095
Step 5265: loss = 0.67555
Step 5270: loss = 0.56251
Step 5275: loss = 0.48209
Step 5280: loss = 0.48884
Step 5285: loss = 0.62935
Step 5290: loss = 0.41491
Step 5295: loss = 0.36211
Step 5300: loss = 0.61631
Step 5305: loss = 0.71534
Step 5310: loss = 0.53559
Step 5315: loss = 0.68336
Step 5320: loss = 0.47105
Step 5325: loss = 0.57026
Step 5330: loss = 0.44283
Step 5335: loss = 0.47593
Step 5340: loss = 0.71545
Step 5345: loss = 0.46836
Step 5350: loss = 0.74737
Step 5355: loss = 0.64929
Step 5360: loss = 0.61684
Step 5365: loss = 0.47300
Step 5370: loss = 0.79637
Step 5375: loss = 0.55236
Step 5380: loss = 0.60967
Step 5385: loss = 0.44201
Step 5390: loss = 0.39919
Step 5395: loss = 0.85696
Step 5400: loss = 0.64745
Step 5405: loss = 0.45970
Step 5410: loss = 0.61033
Step 5415: loss = 0.27761
Step 5420: loss = 0.48976
Step 5425: loss = 0.78695
Step 5430: loss = 0.62895
Step 5435: loss = 0.44288
Step 5440: loss = 0.63946
Step 5445: loss = 0.59457
Step 5450: loss = 0.49245
Step 5455: loss = 0.66944
Step 5460: loss = 0.62505
Step 5465: loss = 0.58937
Step 5470: loss = 0.57554
Step 5475: loss = 0.70283
Step 5480: loss = 0.50213
Step 5485: loss = 0.58041
Step 5490: loss = 0.74534
Step 5495: loss = 0.57286
Step 5500: loss = 0.41840
Step 5505: loss = 0.79226
Step 5510: loss = 0.64133
Step 5515: loss = 0.54373
Step 5520: loss = 0.44076
Step 5525: loss = 0.64481
Step 5530: loss = 0.37935
Step 5535: loss = 0.61309
Step 5540: loss = 0.57346
Step 5545: loss = 0.57921
Step 5550: loss = 0.83370
Step 5555: loss = 0.41173
Step 5560: loss = 0.41143
Step 5565: loss = 0.44918
Step 5570: loss = 0.59851
Step 5575: loss = 0.64641
Step 5580: loss = 0.53785
Step 5585: loss = 0.44012
Step 5590: loss = 0.61832
Step 5595: loss = 0.72256
Step 5600: loss = 0.67218
Step 5605: loss = 0.58925
Step 5610: loss = 0.40712
Step 5615: loss = 0.59722
Step 5620: loss = 0.56526
Step 5625: loss = 0.48564
Step 5630: loss = 0.35475
Step 5635: loss = 0.55989
Step 5640: loss = 0.87070
Step 5645: loss = 0.55661
Step 5650: loss = 0.55500
Step 5655: loss = 0.49139
Step 5660: loss = 0.59679
Step 5665: loss = 0.55033
Step 5670: loss = 0.65028
Step 5675: loss = 0.61953
Step 5680: loss = 0.52227
Step 5685: loss = 0.57119
Step 5690: loss = 0.66031
Step 5695: loss = 0.45416
Step 5700: loss = 0.40241
Step 5705: loss = 0.47891
Step 5710: loss = 0.44806
Step 5715: loss = 0.76536
Step 5720: loss = 0.51391
Step 5725: loss = 0.50504
Step 5730: loss = 0.58013
Step 5735: loss = 0.64711
Step 5740: loss = 0.59857
Step 5745: loss = 0.42687
Step 5750: loss = 0.48330
Step 5755: loss = 0.33082
Step 5760: loss = 0.42577
Step 5765: loss = 0.64792
Step 5770: loss = 0.79450
Step 5775: loss = 0.59802
Step 5780: loss = 0.31516
Step 5785: loss = 0.51966
Step 5790: loss = 0.55500
Step 5795: loss = 0.50830
Step 5800: loss = 0.66769
Step 5805: loss = 0.66231
Step 5810: loss = 0.66877
Step 5815: loss = 0.51343
Step 5820: loss = 0.52044
Step 5825: loss = 0.36213
Step 5830: loss = 0.66051
Step 5835: loss = 0.49903
Step 5840: loss = 0.74689
Step 5845: loss = 0.40977
Step 5850: loss = 0.56063
Step 5855: loss = 0.54469
Step 5860: loss = 0.68549
Step 5865: loss = 0.59724
Step 5870: loss = 0.58928
Step 5875: loss = 0.52051
Step 5880: loss = 0.75508
Step 5885: loss = 0.63143
Step 5890: loss = 0.52434
Step 5895: loss = 0.59270
Step 5900: loss = 0.52890
Step 5905: loss = 0.58315
Step 5910: loss = 0.47620
Step 5915: loss = 0.77136
Step 5920: loss = 0.43978
Step 5925: loss = 0.43348
Step 5930: loss = 0.52845
Step 5935: loss = 0.48519
Step 5940: loss = 0.70320
Step 5945: loss = 0.49478
Step 5950: loss = 0.56253
Step 5955: loss = 0.53448
Step 5960: loss = 0.44810
Step 5965: loss = 0.37327
Step 5970: loss = 0.45437
Step 5975: loss = 0.61167
Step 5980: loss = 0.39085
Step 5985: loss = 0.55539
Step 5990: loss = 0.45986
Step 5995: loss = 0.57534
Step 6000: loss = 0.50276
Training Data Eval:
  Num examples: 50000, Num correct: 41742, Precision @ 1: 0.8348
('Testing Data Eval: EPOCH->', 7)
  Num examples: 10000, Num correct: 6696, Precision @ 1: 0.6696
Step 6005: loss = 0.35508
Step 6010: loss = 0.40143
Step 6015: loss = 0.64606
Step 6020: loss = 0.73618
Step 6025: loss = 0.33766
Step 6030: loss = 0.33336
Step 6035: loss = 0.43768
Step 6040: loss = 0.41531
Step 6045: loss = 0.70335
Step 6050: loss = 0.46727
Step 6055: loss = 0.37770
Step 6060: loss = 0.46699
Step 6065: loss = 0.64712
Step 6070: loss = 0.55108
Step 6075: loss = 0.47375
Step 6080: loss = 0.46982
Step 6085: loss = 0.47167
Step 6090: loss = 0.38373
Step 6095: loss = 0.42986
Step 6100: loss = 0.49276
Step 6105: loss = 0.58861
Step 6110: loss = 0.77723
Step 6115: loss = 0.57172
Step 6120: loss = 0.35681
Step 6125: loss = 0.48464
Step 6130: loss = 0.55007
Step 6135: loss = 0.46305
Step 6140: loss = 0.44272
Step 6145: loss = 0.77224
Step 6150: loss = 0.41352
Step 6155: loss = 0.42150
Step 6160: loss = 0.65984
Step 6165: loss = 0.40622
Step 6170: loss = 0.63155
Step 6175: loss = 0.60846
Step 6180: loss = 0.50154
Step 6185: loss = 0.58889
Step 6190: loss = 0.67225
Step 6195: loss = 0.62153
Step 6200: loss = 0.68094
Step 6205: loss = 0.35185
Step 6210: loss = 0.56588
Step 6215: loss = 0.53465
Step 6220: loss = 0.76747
Step 6225: loss = 0.56913
Step 6230: loss = 0.65364
Step 6235: loss = 0.75796
Step 6240: loss = 0.42908
Step 6245: loss = 0.37798
Step 6250: loss = 0.37918
Step 6255: loss = 0.61861
Step 6260: loss = 0.66571
Step 6265: loss = 0.61974
Step 6270: loss = 0.61697
Step 6275: loss = 0.49124
Step 6280: loss = 0.61603
Step 6285: loss = 0.60973
Step 6290: loss = 0.77262
Step 6295: loss = 0.54538
Step 6300: loss = 0.42166
Step 6305: loss = 0.71396
Step 6310: loss = 0.35232
Step 6315: loss = 0.41997
Step 6320: loss = 0.62982
Step 6325: loss = 0.73723
Step 6330: loss = 0.55279
Step 6335: loss = 0.50819
Step 6340: loss = 0.55540
Step 6345: loss = 0.58062
Step 6350: loss = 0.50494
Step 6355: loss = 0.53460
Step 6360: loss = 0.60442
Step 6365: loss = 0.42051
Step 6370: loss = 0.36273
Step 6375: loss = 0.49998
Step 6380: loss = 0.61113
Step 6385: loss = 0.47915
Step 6390: loss = 0.53139
Step 6395: loss = 0.36200
Step 6400: loss = 0.51514
Step 6405: loss = 0.51283
Step 6410: loss = 0.39764
Step 6415: loss = 0.40451
Step 6420: loss = 0.33579
Step 6425: loss = 0.41320
Step 6430: loss = 0.49476
Step 6435: loss = 0.41770
Step 6440: loss = 0.62790
Step 6445: loss = 0.64276
Step 6450: loss = 0.37784
Step 6455: loss = 0.35655
Step 6460: loss = 0.74128
Step 6465: loss = 0.40892
Step 6470: loss = 0.53849
Step 6475: loss = 0.63325
Step 6480: loss = 0.38782
Step 6485: loss = 0.49267
Step 6490: loss = 0.50551
Step 6495: loss = 0.58576
Step 6500: loss = 0.66180
Step 6505: loss = 0.50412
Step 6510: loss = 0.45593
Step 6515: loss = 0.60302
Step 6520: loss = 0.53085
Step 6525: loss = 0.32904
Step 6530: loss = 0.44427
Step 6535: loss = 0.96073
Step 6540: loss = 0.76190
Step 6545: loss = 0.48372
Step 6550: loss = 0.56161
Step 6555: loss = 0.69289
Step 6560: loss = 0.53445
Step 6565: loss = 0.72910
Step 6570: loss = 0.69175
Step 6575: loss = 0.46545
Step 6580: loss = 0.45188
Step 6585: loss = 0.47220
Step 6590: loss = 0.47500
Step 6595: loss = 0.60014
Step 6600: loss = 0.44427
Step 6605: loss = 0.59394
Step 6610: loss = 0.46692
Step 6615: loss = 0.38877
Step 6620: loss = 0.48748
Step 6625: loss = 0.33913
Step 6630: loss = 0.39570
Step 6635: loss = 0.54364
Step 6640: loss = 0.40121
Step 6645: loss = 0.67368
Step 6650: loss = 0.69452
Step 6655: loss = 0.38272
Step 6660: loss = 0.98462
Step 6665: loss = 0.43984
Step 6670: loss = 0.53309
Step 6675: loss = 0.80718
Step 6680: loss = 0.57473
Step 6685: loss = 0.51296
Step 6690: loss = 0.54889
Step 6695: loss = 0.63624
Step 6700: loss = 0.55763
Step 6705: loss = 0.49232
Step 6710: loss = 0.66685
Step 6715: loss = 0.57029
Step 6720: loss = 0.47308
Step 6725: loss = 0.51165
Step 6730: loss = 0.46632
Step 6735: loss = 0.21951
Step 6740: loss = 0.57633
Step 6745: loss = 0.69517
Step 6750: loss = 0.50611
Step 6755: loss = 0.29141
Step 6760: loss = 0.43468
Step 6765: loss = 0.58140
Step 6770: loss = 0.64028
Step 6775: loss = 0.43000
Step 6780: loss = 0.42157
Step 6785: loss = 0.62366
Step 6790: loss = 0.36928
Step 6795: loss = 0.72375
Step 6800: loss = 0.80668
Step 6805: loss = 0.53880
Step 6810: loss = 0.35455
Step 6815: loss = 0.43374
Step 6820: loss = 0.68611
Step 6825: loss = 0.42618
Step 6830: loss = 0.45462
Step 6835: loss = 0.57845
Step 6840: loss = 0.35372
Step 6845: loss = 0.55007
Step 6850: loss = 0.42424
Step 6855: loss = 0.63763
Step 6860: loss = 0.80057
Step 6865: loss = 0.85569
Step 6870: loss = 0.29413
Step 6875: loss = 0.56850
Step 6880: loss = 0.45625
Step 6885: loss = 0.34470
Step 6890: loss = 0.58961
Step 6895: loss = 0.57713
Step 6900: loss = 0.50472
Step 6905: loss = 0.36431
Step 6910: loss = 0.34606
Step 6915: loss = 0.38460
Step 6920: loss = 0.46295
Step 6925: loss = 0.49439
Step 6930: loss = 0.57008
Step 6935: loss = 0.59978
Step 6940: loss = 0.30607
Step 6945: loss = 0.56079
Step 6950: loss = 0.56176
Step 6955: loss = 0.64991
Step 6960: loss = 0.44420
Step 6965: loss = 0.53687
Step 6970: loss = 0.42584
Step 6975: loss = 0.46998
Step 6980: loss = 0.62648
Step 6985: loss = 0.63176
Step 6990: loss = 0.59110
Step 6995: loss = 0.58262
Step 7000: loss = 0.54229
Training Data Eval:
  Num examples: 50000, Num correct: 42655, Precision @ 1: 0.8531
('Testing Data Eval: EPOCH->', 8)
  Num examples: 10000, Num correct: 6736, Precision @ 1: 0.6736
Step 7005: loss = 0.46959
Step 7010: loss = 0.48002
Step 7015: loss = 0.29115
Step 7020: loss = 0.43263
Step 7025: loss = 0.60493
Step 7030: loss = 0.30577
Step 7035: loss = 0.45513
Step 7040: loss = 0.49300
Step 7045: loss = 0.34425
Step 7050: loss = 0.51983
Step 7055: loss = 0.26473
Step 7060: loss = 0.46747
Step 7065: loss = 0.37500
Step 7070: loss = 0.65941
Step 7075: loss = 0.38933
Step 7080: loss = 0.27420
Step 7085: loss = 0.47358
Step 7090: loss = 0.36749
Step 7095: loss = 0.48745
Step 7100: loss = 0.36212
Step 7105: loss = 0.41120
Step 7110: loss = 0.61426
Step 7115: loss = 0.35290
Step 7120: loss = 0.53229
Step 7125: loss = 0.57486
Step 7130: loss = 0.54717
Step 7135: loss = 0.45084
Step 7140: loss = 0.48409
Step 7145: loss = 0.53429
Step 7150: loss = 0.69525
Step 7155: loss = 0.39284
Step 7160: loss = 0.55452
Step 7165: loss = 0.50974
Step 7170: loss = 0.45691
Step 7175: loss = 0.50339
Step 7180: loss = 0.62479
Step 7185: loss = 0.34357
Step 7190: loss = 0.39009
Step 7195: loss = 0.53370
Step 7200: loss = 0.71861
Step 7205: loss = 0.41601
Step 7210: loss = 0.56805
Step 7215: loss = 0.33408
Step 7220: loss = 0.39509
Step 7225: loss = 0.51021
Step 7230: loss = 0.51851
Step 7235: loss = 0.38818
Step 7240: loss = 0.33181
Step 7245: loss = 0.40070
Step 7250: loss = 0.59157
Step 7255: loss = 0.52872
Step 7260: loss = 0.44091
Step 7265: loss = 0.46692
Step 7270: loss = 0.45691
Step 7275: loss = 0.38420
Step 7280: loss = 0.66114
Step 7285: loss = 0.69534
Step 7290: loss = 0.63458
Step 7295: loss = 0.48828
Step 7300: loss = 0.50704
Step 7305: loss = 0.32908
Step 7310: loss = 0.21822
Step 7315: loss = 0.24998
Step 7320: loss = 0.32178
Step 7325: loss = 0.46485
Step 7330: loss = 0.50550
Step 7335: loss = 0.29968
Step 7340: loss = 0.38393
Step 7345: loss = 0.47617
Step 7350: loss = 0.45985
Step 7355: loss = 0.41300
Step 7360: loss = 0.52389
Step 7365: loss = 0.34728
Step 7370: loss = 0.25846
Step 7375: loss = 0.76448
Step 7380: loss = 0.63453
Step 7385: loss = 0.53227
Step 7390: loss = 0.24894
Step 7395: loss = 0.37639
Step 7400: loss = 0.54749
Step 7405: loss = 0.48535
Step 7410: loss = 0.32920
Step 7415: loss = 0.54468
Step 7420: loss = 0.52847
Step 7425: loss = 0.28716
Step 7430: loss = 0.33223
Step 7435: loss = 0.31376
Step 7440: loss = 0.45346
Step 7445: loss = 0.44998
Step 7450: loss = 0.36823
Step 7455: loss = 0.36534
Step 7460: loss = 0.47647
Step 7465: loss = 0.67869
Step 7470: loss = 0.41055
Step 7475: loss = 0.61288
Step 7480: loss = 0.61277
Step 7485: loss = 0.52550
Step 7490: loss = 0.45885
Step 7495: loss = 0.38293
Step 7500: loss = 0.39945
Step 7505: loss = 0.38502
Step 7510: loss = 0.52704
Step 7515: loss = 0.27011
Step 7520: loss = 0.44697
Step 7525: loss = 0.47147
Step 7530: loss = 0.41737
Step 7535: loss = 0.44618
Step 7540: loss = 0.54254
Step 7545: loss = 0.55920
Step 7550: loss = 0.56471
Step 7555: loss = 0.45158
Step 7560: loss = 0.46561
Step 7565: loss = 0.39666
Step 7570: loss = 0.40786
Step 7575: loss = 0.57712
Step 7580: loss = 0.41627
Step 7585: loss = 0.55765
Step 7590: loss = 0.41604
Step 7595: loss = 0.43710
Step 7600: loss = 0.49611
Step 7605: loss = 0.40753
Step 7610: loss = 0.38728
Step 7615: loss = 0.38780
Step 7620: loss = 0.40755
Step 7625: loss = 0.36041
Step 7630: loss = 0.46124
Step 7635: loss = 0.61556
Step 7640: loss = 0.31792
Step 7645: loss = 0.32910
Step 7650: loss = 0.54287
Step 7655: loss = 0.51348
Step 7660: loss = 0.40178
Step 7665: loss = 0.55062
Step 7670: loss = 0.73466
Step 7675: loss = 0.53496
Step 7680: loss = 0.30277
Step 7685: loss = 0.48858
Step 7690: loss = 0.28183
Step 7695: loss = 0.36978
Step 7700: loss = 0.41728
Step 7705: loss = 0.40537
Step 7710: loss = 0.32632
Step 7715: loss = 0.48135
Step 7720: loss = 0.39184
Step 7725: loss = 0.28400
Step 7730: loss = 0.48650
Step 7735: loss = 0.66112
Step 7740: loss = 0.50696
Step 7745: loss = 0.55343
Step 7750: loss = 0.46519
Step 7755: loss = 0.45714
Step 7760: loss = 0.39267
Step 7765: loss = 0.23798
Step 7770: loss = 0.49833
Step 7775: loss = 0.46612
Step 7780: loss = 0.57043
Step 7785: loss = 0.47911
Step 7790: loss = 0.34331
Step 7795: loss = 0.29766
Step 7800: loss = 0.65437
Step 7805: loss = 0.35497
Step 7810: loss = 0.41569
Step 7815: loss = 0.37309
Step 7820: loss = 0.44390
Step 7825: loss = 0.38611
Step 7830: loss = 0.33833
Step 7835: loss = 0.55979
Step 7840: loss = 0.60302
Step 7845: loss = 0.48146
Step 7850: loss = 0.48301
Step 7855: loss = 0.31633
Step 7860: loss = 0.30975
Step 7865: loss = 0.24308
Step 7870: loss = 0.45987
Step 7875: loss = 0.32901
Step 7880: loss = 0.34790
Step 7885: loss = 0.48583
Step 7890: loss = 0.47321
Step 7895: loss = 0.62828
Step 7900: loss = 0.19297
Step 7905: loss = 0.46094
Step 7910: loss = 0.56687
Step 7915: loss = 0.26372
Step 7920: loss = 0.49943
Step 7925: loss = 0.49984
Step 7930: loss = 0.48046
Step 7935: loss = 0.45106
Step 7940: loss = 0.44779
Step 7945: loss = 0.49954
Step 7950: loss = 0.41275
Step 7955: loss = 0.49873
Step 7960: loss = 0.35693
Step 7965: loss = 0.41110
Step 7970: loss = 0.36665
Step 7975: loss = 0.44732
Step 7980: loss = 0.29311
Step 7985: loss = 0.63244
Step 7990: loss = 0.57300
Step 7995: loss = 0.45306
Step 8000: loss = 0.37231
Training Data Eval:
  Num examples: 50000, Num correct: 43784, Precision @ 1: 0.8757
('Testing Data Eval: EPOCH->', 9)
  Num examples: 10000, Num correct: 6894, Precision @ 1: 0.6894
Step 8005: loss = 0.40425
Step 8010: loss = 0.23660
Step 8015: loss = 0.34000
Step 8020: loss = 0.38941
Step 8025: loss = 0.32399
Step 8030: loss = 0.32657
Step 8035: loss = 0.50676
Step 8040: loss = 0.56397
Step 8045: loss = 0.34098
Step 8050: loss = 0.25558
Step 8055: loss = 0.24892
Step 8060: loss = 0.32488
Step 8065: loss = 0.37365
Step 8070: loss = 0.36094
Step 8075: loss = 0.44972
Step 8080: loss = 0.45894
Step 8085: loss = 0.26510
Step 8090: loss = 0.34593
Step 8095: loss = 0.37935
Step 8100: loss = 0.21613
Step 8105: loss = 0.41734
Step 8110: loss = 0.46572
Step 8115: loss = 0.46341
Step 8120: loss = 0.32701
Step 8125: loss = 0.53056
Step 8130: loss = 0.20852
Step 8135: loss = 0.40327
Step 8140: loss = 0.51659
Step 8145: loss = 0.58020
Step 8150: loss = 0.37163
Step 8155: loss = 0.25486
Step 8160: loss = 0.37848
Step 8165: loss = 0.33781
Step 8170: loss = 0.39382
Step 8175: loss = 0.38317
Step 8180: loss = 0.47207
Step 8185: loss = 0.37719
Step 8190: loss = 0.37834
Step 8195: loss = 0.50590
Step 8200: loss = 0.27955
Step 8205: loss = 0.43550
Step 8210: loss = 0.33293
Step 8215: loss = 0.30456
Step 8220: loss = 0.27899
Step 8225: loss = 0.41769
Step 8230: loss = 0.29611
Step 8235: loss = 0.51721
Step 8240: loss = 0.32502
Step 8245: loss = 0.29071
Step 8250: loss = 0.26157
Step 8255: loss = 0.39986
Step 8260: loss = 0.32504
Step 8265: loss = 0.32965
Step 8270: loss = 0.38369
Step 8275: loss = 0.45877
Step 8280: loss = 0.38787
Step 8285: loss = 0.40597
Step 8290: loss = 0.33825
Step 8295: loss = 0.20637
Step 8300: loss = 0.30593
Step 8305: loss = 0.35506
Step 8310: loss = 0.53441
Step 8315: loss = 0.32121
Step 8320: loss = 0.34629
Step 8325: loss = 0.41887
Step 8330: loss = 0.26145
Step 8335: loss = 0.57940
Step 8340: loss = 0.42384
Step 8345: loss = 0.33698
Step 8350: loss = 0.36961
Step 8355: loss = 0.30477
Step 8360: loss = 0.22208
Step 8365: loss = 0.43742
Step 8370: loss = 0.33276
Step 8375: loss = 0.37086
Step 8380: loss = 0.40725
Step 8385: loss = 0.27391
Step 8390: loss = 0.30779
Step 8395: loss = 0.21550
Step 8400: loss = 0.22289
Step 8405: loss = 0.42590
Step 8410: loss = 0.32850
Step 8415: loss = 0.27249
Step 8420: loss = 0.33126
Step 8425: loss = 0.47117
Step 8430: loss = 0.32338
Step 8435: loss = 0.38921
Step 8440: loss = 0.33200
Step 8445: loss = 0.40967
Step 8450: loss = 0.39200
Step 8455: loss = 0.48246
Step 8460: loss = 0.38656
Step 8465: loss = 0.34050
Step 8470: loss = 0.28829
Step 8475: loss = 0.35090
Step 8480: loss = 0.49114
Step 8485: loss = 0.44496
Step 8490: loss = 0.70142
Step 8495: loss = 0.36018
Step 8500: loss = 0.40522
Step 8505: loss = 0.31224
Step 8510: loss = 0.27078
Step 8515: loss = 0.37303
Step 8520: loss = 0.30094
Step 8525: loss = 0.23164
Step 8530: loss = 0.34305
Step 8535: loss = 0.64033
Step 8540: loss = 0.40936
Step 8545: loss = 0.42140
Step 8550: loss = 0.32275
Step 8555: loss = 0.45461
Step 8560: loss = 0.42998
Step 8565: loss = 0.30719
Step 8570: loss = 0.27373
Step 8575: loss = 0.35709
Step 8580: loss = 0.38438
Step 8585: loss = 0.49281
Step 8590: loss = 0.17046
Step 8595: loss = 0.24962
Step 8600: loss = 0.52907
Step 8605: loss = 0.35706
Step 8610: loss = 0.41915
Step 8615: loss = 0.26992
Step 8620: loss = 0.43373
Step 8625: loss = 0.29529
Step 8630: loss = 0.34908
Step 8635: loss = 0.39538
Step 8640: loss = 0.47502
Step 8645: loss = 0.38886
Step 8650: loss = 0.29846
Step 8655: loss = 0.39930
Step 8660: loss = 0.28560
Step 8665: loss = 0.39933
Step 8670: loss = 0.38289
Step 8675: loss = 0.28166
Step 8680: loss = 0.26730
Step 8685: loss = 0.36335
Step 8690: loss = 0.38104
Step 8695: loss = 0.27668
Step 8700: loss = 0.36737
Step 8705: loss = 0.48643
Step 8710: loss = 0.41457
Step 8715: loss = 0.42509
Step 8720: loss = 0.55523
Step 8725: loss = 0.37110
Step 8730: loss = 0.30265
Step 8735: loss = 0.37503
Step 8740: loss = 0.26539
Step 8745: loss = 0.27428
Step 8750: loss = 0.43434
Step 8755: loss = 0.35047
Step 8760: loss = 0.50430
Step 8765: loss = 0.48732
Step 8770: loss = 0.53043
Step 8775: loss = 0.44581
Step 8780: loss = 0.45508
Step 8785: loss = 0.36420
Step 8790: loss = 0.40860
Step 8795: loss = 0.41599
Step 8800: loss = 0.43842
Step 8805: loss = 0.56152
Step 8810: loss = 0.37130
Step 8815: loss = 0.32973
Step 8820: loss = 0.29461
Step 8825: loss = 0.33496
Step 8830: loss = 0.36731
Step 8835: loss = 0.33535
Step 8840: loss = 0.33188
Step 8845: loss = 0.15976
Step 8850: loss = 0.31965
Step 8855: loss = 0.74848
Step 8860: loss = 0.45253
Step 8865: loss = 0.24122
Step 8870: loss = 0.41108
Step 8875: loss = 0.47620
Step 8880: loss = 0.26647
Step 8885: loss = 0.32101
Step 8890: loss = 0.65535
Step 8895: loss = 0.32997
Step 8900: loss = 0.42722
Step 8905: loss = 0.40944
Step 8910: loss = 0.34874
Step 8915: loss = 0.37249
Step 8920: loss = 0.26840
Step 8925: loss = 0.47240
Step 8930: loss = 0.42146
Step 8935: loss = 0.37260
Step 8940: loss = 0.42302
Step 8945: loss = 0.51128
Step 8950: loss = 0.36978
Step 8955: loss = 0.32230
Step 8960: loss = 0.36823
Step 8965: loss = 0.41160
Step 8970: loss = 0.26950
Step 8975: loss = 0.27090
Step 8980: loss = 0.44792
Step 8985: loss = 0.33020
Step 8990: loss = 0.50084
Step 8995: loss = 0.42625
Step 9000: loss = 0.29321
Training Data Eval:
  Num examples: 50000, Num correct: 45261, Precision @ 1: 0.9052
('Testing Data Eval: EPOCH->', 10)
  Num examples: 10000, Num correct: 6924, Precision @ 1: 0.6924
Step 9005: loss = 0.42144
Step 9010: loss = 0.28416
Step 9015: loss = 0.24844
Step 9020: loss = 0.28814
Step 9025: loss = 0.29706
Step 9030: loss = 0.24246
Step 9035: loss = 0.21255
Step 9040: loss = 0.39219
Step 9045: loss = 0.48977
Step 9050: loss = 0.38696
Step 9055: loss = 0.38939
Step 9060: loss = 0.18401
Step 9065: loss = 0.34468
Step 9070: loss = 0.38628
Step 9075: loss = 0.32374
Step 9080: loss = 0.42380
Step 9085: loss = 0.34607
Step 9090: loss = 0.37286
Step 9095: loss = 0.32871
Step 9100: loss = 0.30203
Step 9105: loss = 0.31218
Step 9110: loss = 0.24748
Step 9115: loss = 0.26917
Step 9120: loss = 0.35362
Step 9125: loss = 0.32644
Step 9130: loss = 0.26232
Step 9135: loss = 0.37943
Step 9140: loss = 0.32344
Step 9145: loss = 0.26098
Step 9150: loss = 0.24231
Step 9155: loss = 0.41580
Step 9160: loss = 0.33249
Step 9165: loss = 0.21942
Step 9170: loss = 0.23498
Step 9175: loss = 0.28917
Step 9180: loss = 0.18957
Step 9185: loss = 0.33592
Step 9190: loss = 0.32489
Step 9195: loss = 0.34922
Step 9200: loss = 0.22852
Step 9205: loss = 0.51601
Step 9210: loss = 0.41585
Step 9215: loss = 0.34620
Step 9220: loss = 0.38478
Step 9225: loss = 0.16840
Step 9230: loss = 0.33940
Step 9235: loss = 0.25703
Step 9240: loss = 0.24298
Step 9245: loss = 0.33067
Step 9250: loss = 0.20260
Step 9255: loss = 0.37645
Step 9260: loss = 0.36541
Step 9265: loss = 0.26342
Step 9270: loss = 0.22977
Step 9275: loss = 0.24746
Step 9280: loss = 0.26372
Step 9285: loss = 0.45168
Step 9290: loss = 0.23206
Step 9295: loss = 0.37980
Step 9300: loss = 0.18216
Step 9305: loss = 0.29591
Step 9310: loss = 0.35230
Step 9315: loss = 0.36763
Step 9320: loss = 0.35885
Step 9325: loss = 0.26056
Step 9330: loss = 0.29875
Step 9335: loss = 0.21525
Step 9340: loss = 0.30789
Step 9345: loss = 0.26185
Step 9350: loss = 0.20561
Step 9355: loss = 0.23812
Step 9360: loss = 0.20291
Step 9365: loss = 0.22917
Step 9370: loss = 0.40982
Step 9375: loss = 0.33087
Step 9380: loss = 0.34389
Step 9385: loss = 0.27960
Step 9390: loss = 0.59603
Step 9395: loss = 0.41074
Step 9400: loss = 0.29212
Step 9405: loss = 0.25034
Step 9410: loss = 0.38949
Step 9415: loss = 0.30727
Step 9420: loss = 0.31629
Step 9425: loss = 0.29858
Step 9430: loss = 0.38439
Step 9435: loss = 0.17315
Step 9440: loss = 0.17433
Step 9445: loss = 0.23952
Step 9450: loss = 0.32145
Step 9455: loss = 0.32170
Step 9460: loss = 0.35677
Step 9465: loss = 0.38197
Step 9470: loss = 0.25019
Step 9475: loss = 0.50070
Step 9480: loss = 0.17466
Step 9485: loss = 0.22660
Step 9490: loss = 0.22490
Step 9495: loss = 0.29555
Step 9500: loss = 0.16198
Step 9505: loss = 0.27479
Step 9510: loss = 0.41240
Step 9515: loss = 0.25063
Step 9520: loss = 0.36251
Step 9525: loss = 0.33055
Step 9530: loss = 0.32706
Step 9535: loss = 0.23684
Step 9540: loss = 0.32929
Step 9545: loss = 0.41407
Step 9550: loss = 0.29916
Step 9555: loss = 0.45535
Step 9560: loss = 0.33695
Step 9565: loss = 0.28816
Step 9570: loss = 0.29752
Step 9575: loss = 0.39283
Step 9580: loss = 0.23146
Step 9585: loss = 0.50496
Step 9590: loss = 0.28584
Step 9595: loss = 0.30183
Step 9600: loss = 0.28804
Step 9605: loss = 0.46789
Step 9610: loss = 0.37133
Step 9615: loss = 0.20895
Step 9620: loss = 0.31600
Step 9625: loss = 0.29199
Step 9630: loss = 0.36874
Step 9635: loss = 0.16509
Step 9640: loss = 0.27594
Step 9645: loss = 0.33856
Step 9650: loss = 0.30098
Step 9655: loss = 0.23457
Step 9660: loss = 0.33789
Step 9665: loss = 0.33477
Step 9670: loss = 0.45079
Step 9675: loss = 0.42022
Step 9680: loss = 0.28991
Step 9685: loss = 0.52995
Step 9690: loss = 0.27063
Step 9695: loss = 0.35384
Step 9700: loss = 0.27640
Step 9705: loss = 0.27881
Step 9710: loss = 0.42081
Step 9715: loss = 0.36430
Step 9720: loss = 0.21460
Step 9725: loss = 0.29068
Step 9730: loss = 0.46427
Step 9735: loss = 0.21086
Step 9740: loss = 0.31321
Step 9745: loss = 0.28794
Step 9750: loss = 0.35673
Step 9755: loss = 0.18986
Step 9760: loss = 0.36588
Step 9765: loss = 0.27295
Step 9770: loss = 0.23587
Step 9775: loss = 0.30591
Step 9780: loss = 0.28394
Step 9785: loss = 0.24588
Step 9790: loss = 0.19905
Step 9795: loss = 0.54936
Step 9800: loss = 0.46450
Step 9805: loss = 0.16070
Step 9810: loss = 0.21169
Step 9815: loss = 0.32235
Step 9820: loss = 0.31194
Step 9825: loss = 0.47916
Step 9830: loss = 0.22783
Step 9835: loss = 0.34148
Step 9840: loss = 0.27903
Step 9845: loss = 0.30537
Step 9850: loss = 0.38216
Step 9855: loss = 0.32308
Step 9860: loss = 0.44439
Step 9865: loss = 0.19451
Step 9870: loss = 0.36620
Step 9875: loss = 0.32149
Step 9880: loss = 0.24097
Step 9885: loss = 0.38039
Step 9890: loss = 0.40623
Step 9895: loss = 0.22486
Step 9900: loss = 0.24527
Step 9905: loss = 0.50060
Step 9910: loss = 0.34827
Step 9915: loss = 0.36521
Step 9920: loss = 0.32069
Step 9925: loss = 0.18792
Step 9930: loss = 0.34213
Step 9935: loss = 0.42351
Step 9940: loss = 0.52137
Step 9945: loss = 0.41694
Step 9950: loss = 0.31982
Step 9955: loss = 0.48183
Step 9960: loss = 0.24380
Step 9965: loss = 0.24710
Step 9970: loss = 0.21145
Step 9975: loss = 0.18246
Step 9980: loss = 0.31517
Step 9985: loss = 0.21354
Step 9990: loss = 0.43833
Step 9995: loss = 0.34138
Step 10000: loss = 0.35056
Training Data Eval:
  Num examples: 50000, Num correct: 46130, Precision @ 1: 0.9226
('Testing Data Eval: EPOCH->', 11)
  Num examples: 10000, Num correct: 6880, Precision @ 1: 0.6880
Step 10005: loss = 0.23059
Step 10010: loss = 0.23477
Step 10015: loss = 0.15235
Step 10020: loss = 0.18298
Step 10025: loss = 0.23275
Step 10030: loss = 0.18557
Step 10035: loss = 0.41584
Step 10040: loss = 0.26910
Step 10045: loss = 0.39068
Step 10050: loss = 0.22740
Step 10055: loss = 0.21484
Step 10060: loss = 0.15648
Step 10065: loss = 0.22215
Step 10070: loss = 0.26403
Step 10075: loss = 0.27011
Step 10080: loss = 0.14344
Step 10085: loss = 0.25204
Step 10090: loss = 0.20843
Step 10095: loss = 0.21724
Step 10100: loss = 0.20340
Step 10105: loss = 0.25148
Step 10110: loss = 0.22055
Step 10115: loss = 0.21580
Step 10120: loss = 0.28665
Step 10125: loss = 0.25317
Step 10130: loss = 0.17868
Step 10135: loss = 0.18473
Step 10140: loss = 0.17350
Step 10145: loss = 0.29818
Step 10150: loss = 0.22969
Step 10155: loss = 0.24181
Step 10160: loss = 0.21758
Step 10165: loss = 0.26712
Step 10170: loss = 0.33041
Step 10175: loss = 0.40750
Step 10180: loss = 0.35800
Step 10185: loss = 0.18904
Step 10190: loss = 0.37556
Step 10195: loss = 0.40001
Step 10200: loss = 0.25223
Step 10205: loss = 0.25133
Step 10210: loss = 0.24911
Step 10215: loss = 0.36157
Step 10220: loss = 0.20900
Step 10225: loss = 0.36572
Step 10230: loss = 0.26811
Step 10235: loss = 0.31662
Step 10240: loss = 0.40454
Step 10245: loss = 0.32888
Step 10250: loss = 0.20447
Step 10255: loss = 0.19611
Step 10260: loss = 0.18523
Step 10265: loss = 0.26630
Step 10270: loss = 0.30906
Step 10275: loss = 0.22810
Step 10280: loss = 0.26548
Step 10285: loss = 0.18706
Step 10290: loss = 0.35035
Step 10295: loss = 0.26949
Step 10300: loss = 0.30124
Step 10305: loss = 0.21675
Step 10310: loss = 0.26823
Step 10315: loss = 0.25460
Step 10320: loss = 0.17849
Step 10325: loss = 0.38847
Step 10330: loss = 0.36825
Step 10335: loss = 0.30046
Step 10340: loss = 0.14372
Step 10345: loss = 0.19000
Step 10350: loss = 0.39941
Step 10355: loss = 0.23033
Step 10360: loss = 0.11114
Step 10365: loss = 0.25192
Step 10370: loss = 0.27799
Step 10375: loss = 0.15518
Step 10380: loss = 0.18932
Step 10385: loss = 0.27356
Step 10390: loss = 0.16186
Step 10395: loss = 0.38234
Step 10400: loss = 0.30806
Step 10405: loss = 0.15987
Step 10410: loss = 0.21151
Step 10415: loss = 0.33715
Step 10420: loss = 0.22886
Step 10425: loss = 0.15496
Step 10430: loss = 0.38197
Step 10435: loss = 0.28617
Step 10440: loss = 0.26958
Step 10445: loss = 0.17310
Step 10450: loss = 0.28244
Step 10455: loss = 0.29450
Step 10460: loss = 0.30572
Step 10465: loss = 0.40320
Step 10470: loss = 0.16330
Step 10475: loss = 0.44723
Step 10480: loss = 0.31844
Step 10485: loss = 0.18920
Step 10490: loss = 0.21525
Step 10495: loss = 0.32543
Step 10500: loss = 0.33961
Step 10505: loss = 0.30445
Step 10510: loss = 0.32267
Step 10515: loss = 0.23369
Step 10520: loss = 0.33542
Step 10525: loss = 0.32345
Step 10530: loss = 0.35490
Step 10535: loss = 0.32994
Step 10540: loss = 0.30312
Step 10545: loss = 0.40204
Step 10550: loss = 0.36089
Step 10555: loss = 0.25237
Step 10560: loss = 0.36565
Step 10565: loss = 0.38548
Step 10570: loss = 0.20500
Step 10575: loss = 0.26726
Step 10580: loss = 0.21504
Step 10585: loss = 0.50552
Step 10590: loss = 0.23980
Step 10595: loss = 0.43261
Step 10600: loss = 0.35825
Step 10605: loss = 0.23850
Step 10610: loss = 0.21265
Step 10615: loss = 0.25444
Step 10620: loss = 0.26268
Step 10625: loss = 0.22191
Step 10630: loss = 0.31376
Step 10635: loss = 0.22452
Step 10640: loss = 0.29471
Step 10645: loss = 0.36241
Step 10650: loss = 0.27023
Step 10655: loss = 0.20852
Step 10660: loss = 0.35497
Step 10665: loss = 0.31868
Step 10670: loss = 0.28779
Step 10675: loss = 0.26745
Step 10680: loss = 0.44595
Step 10685: loss = 0.24499
Step 10690: loss = 0.38590
Step 10695: loss = 0.24921
Step 10700: loss = 0.24704
Step 10705: loss = 0.25146
Step 10710: loss = 0.35931
Step 10715: loss = 0.28481
Step 10720: loss = 0.33236
Step 10725: loss = 0.32417
Step 10730: loss = 0.23525
Step 10735: loss = 0.29368
Step 10740: loss = 0.26279
Step 10745: loss = 0.33430
Step 10750: loss = 0.44745
Step 10755: loss = 0.26062
Step 10760: loss = 0.25822
Step 10765: loss = 0.40169
Step 10770: loss = 0.29504
Step 10775: loss = 0.34309
Step 10780: loss = 0.25268
Step 10785: loss = 0.18920
Step 10790: loss = 0.29964
Step 10795: loss = 0.16153
Step 10800: loss = 0.33706
Step 10805: loss = 0.35113
Step 10810: loss = 0.24895
Step 10815: loss = 0.22272
Step 10820: loss = 0.26912
Step 10825: loss = 0.30659
Step 10830: loss = 0.23477
Step 10835: loss = 0.27589
Step 10840: loss = 0.19275
Step 10845: loss = 0.36468
Step 10850: loss = 0.24788
Step 10855: loss = 0.40624
Step 10860: loss = 0.30075
Step 10865: loss = 0.36418
Step 10870: loss = 0.36925
Step 10875: loss = 0.23588
Step 10880: loss = 0.26398
Step 10885: loss = 0.20259
Step 10890: loss = 0.33370
Step 10895: loss = 0.19504
Step 10900: loss = 0.34278
Step 10905: loss = 0.38935
Step 10910: loss = 0.34542
Step 10915: loss = 0.31841
Step 10920: loss = 0.26143
Step 10925: loss = 0.30967
Step 10930: loss = 0.30774
Step 10935: loss = 0.36637
Step 10940: loss = 0.28977
Step 10945: loss = 0.28189
Step 10950: loss = 0.17680
Step 10955: loss = 0.28353
Step 10960: loss = 0.22005
Step 10965: loss = 0.18145
Step 10970: loss = 0.22480
Step 10975: loss = 0.25970
Step 10980: loss = 0.27618
Step 10985: loss = 0.14761
Step 10990: loss = 0.17242
Step 10995: loss = 0.15845
Step 11000: loss = 0.19192
Training Data Eval:
  Num examples: 50000, Num correct: 46513, Precision @ 1: 0.9303
('Testing Data Eval: EPOCH->', 12)
  Num examples: 10000, Num correct: 6790, Precision @ 1: 0.6790
Step 11005: loss = 0.22673
Step 11010: loss = 0.18100
Step 11015: loss = 0.17367
Step 11020: loss = 0.28053
Step 11025: loss = 0.25897
Step 11030: loss = 0.17480
Step 11035: loss = 0.25280
Step 11040: loss = 0.16521
Step 11045: loss = 0.18980
Step 11050: loss = 0.13211
Step 11055: loss = 0.23086
Step 11060: loss = 0.25941
Step 11065: loss = 0.24978
Step 11070: loss = 0.15368
Step 11075: loss = 0.26345
Step 11080: loss = 0.23959
Step 11085: loss = 0.28632
Step 11090: loss = 0.29097
Step 11095: loss = 0.16191
Step 11100: loss = 0.20555
Step 11105: loss = 0.28597
Step 11110: loss = 0.26447
Step 11115: loss = 0.18053
Step 11120: loss = 0.21931
Step 11125: loss = 0.27294
Step 11130: loss = 0.27081
Step 11135: loss = 0.43631
Step 11140: loss = 0.17443
Step 11145: loss = 0.26870
Step 11150: loss = 0.20207
Step 11155: loss = 0.16903
Step 11160: loss = 0.42424
Step 11165: loss = 0.24125
Step 11170: loss = 0.26221
Step 11175: loss = 0.22625
Step 11180: loss = 0.21480
Step 11185: loss = 0.25886
Step 11190: loss = 0.26373
Step 11195: loss = 0.26101
Step 11200: loss = 0.22484
Step 11205: loss = 0.15940
Step 11210: loss = 0.13696
Step 11215: loss = 0.23275
Step 11220: loss = 0.38806
Step 11225: loss = 0.22949
Step 11230: loss = 0.09379
Step 11235: loss = 0.25317
Step 11240: loss = 0.30590
Step 11245: loss = 0.31471
Step 11250: loss = 0.15076
Step 11255: loss = 0.16439
Step 11260: loss = 0.18973
Step 11265: loss = 0.32370
Step 11270: loss = 0.23504
Step 11275: loss = 0.16433
Step 11280: loss = 0.17576
Step 11285: loss = 0.26617
Step 11290: loss = 0.32426
Step 11295: loss = 0.30957
Step 11300: loss = 0.24404
Step 11305: loss = 0.19836
Step 11310: loss = 0.25252
Step 11315: loss = 0.27798
Step 11320: loss = 0.27869
Step 11325: loss = 0.34747
Step 11330: loss = 0.33759
Step 11335: loss = 0.23541
Step 11340: loss = 0.25045
Step 11345: loss = 0.12282
Step 11350: loss = 0.22150
Step 11355: loss = 0.13038
Step 11360: loss = 0.20533
Step 11365: loss = 0.17621
Step 11370: loss = 0.37710
Step 11375: loss = 0.32200
Step 11380: loss = 0.42413
Step 11385: loss = 0.30228
Step 11390: loss = 0.21358
Step 11395: loss = 0.17385
Step 11400: loss = 0.12817
Step 11405: loss = 0.20348
Step 11410: loss = 0.32983
Step 11415: loss = 0.23742
Step 11420: loss = 0.20268
Step 11425: loss = 0.44468
Step 11430: loss = 0.35141
Step 11435: loss = 0.27355
Step 11440: loss = 0.24130
Step 11445: loss = 0.19314
Step 11450: loss = 0.28217
Step 11455: loss = 0.32625
Step 11460: loss = 0.23023
Step 11465: loss = 0.38503
Step 11470: loss = 0.33275
Step 11475: loss = 0.22142
Step 11480: loss = 0.23660
Step 11485: loss = 0.38508
Step 11490: loss = 0.27535
Step 11495: loss = 0.23960
Step 11500: loss = 0.30171
Step 11505: loss = 0.24310
Step 11510: loss = 0.30058
Step 11515: loss = 0.24310
Step 11520: loss = 0.20940
Step 11525: loss = 0.17909
Step 11530: loss = 0.20218
Step 11535: loss = 0.14530
Step 11540: loss = 0.26015
Step 11545: loss = 0.17062
Step 11550: loss = 0.15688
Step 11555: loss = 0.21643
Step 11560: loss = 0.28815
Step 11565: loss = 0.23618
Step 11570: loss = 0.23219
Step 11575: loss = 0.18455
Step 11580: loss = 0.26028
Step 11585: loss = 0.11293
Step 11590: loss = 0.20678
Step 11595: loss = 0.24441
Step 11600: loss = 0.13881
Step 11605: loss = 0.39818
Step 11610: loss = 0.33379
Step 11615: loss = 0.19319
Step 11620: loss = 0.22497
Step 11625: loss = 0.18090
Step 11630: loss = 0.38516
Step 11635: loss = 0.37154
Step 11640: loss = 0.23973
Step 11645: loss = 0.42539
Step 11650: loss = 0.27562
Step 11655: loss = 0.20641
Step 11660: loss = 0.22453
Step 11665: loss = 0.40869
Step 11670: loss = 0.37893
Step 11675: loss = 0.23193
Step 11680: loss = 0.28290
Step 11685: loss = 0.16533
Step 11690: loss = 0.28436
Step 11695: loss = 0.16151
Step 11700: loss = 0.23848
Step 11705: loss = 0.35434
Step 11710: loss = 0.23245
Step 11715: loss = 0.18521
Step 11720: loss = 0.30840
Step 11725: loss = 0.25489
Step 11730: loss = 0.36451
Step 11735: loss = 0.30201
Step 11740: loss = 0.28857
Step 11745: loss = 0.26211
Step 11750: loss = 0.28103
Step 11755: loss = 0.26048
Step 11760: loss = 0.28575
Step 11765: loss = 0.38974
Step 11770: loss = 0.18616
Step 11775: loss = 0.38553
Step 11780: loss = 0.24753
Step 11785: loss = 0.23407
Step 11790: loss = 0.29721
Step 11795: loss = 0.14593
Step 11800: loss = 0.21411
Step 11805: loss = 0.33402
Step 11810: loss = 0.18239
Step 11815: loss = 0.27597
Step 11820: loss = 0.25501
Step 11825: loss = 0.22665
Step 11830: loss = 0.29115
Step 11835: loss = 0.21016
Step 11840: loss = 0.41031
Step 11845: loss = 0.23403
Step 11850: loss = 0.23608
Step 11855: loss = 0.18851
Step 11860: loss = 0.36383
Step 11865: loss = 0.28784
Step 11870: loss = 0.32465
Step 11875: loss = 0.27612
Step 11880: loss = 0.31909
Step 11885: loss = 0.17585
Step 11890: loss = 0.15350
Step 11895: loss = 0.29609
Step 11900: loss = 0.25241
Step 11905: loss = 0.09896
Step 11910: loss = 0.28401
Step 11915: loss = 0.29741
Step 11920: loss = 0.39328
Step 11925: loss = 0.18088
Step 11930: loss = 0.21532
Step 11935: loss = 0.24798
Step 11940: loss = 0.21963
Step 11945: loss = 0.36013
Step 11950: loss = 0.12977
Step 11955: loss = 0.24702
Step 11960: loss = 0.25616
Step 11965: loss = 0.25834
Step 11970: loss = 0.22101
Step 11975: loss = 0.32004
Step 11980: loss = 0.39478
Step 11985: loss = 0.22480
Step 11990: loss = 0.29299
Step 11995: loss = 0.26436
Step 12000: loss = 0.16241
Training Data Eval:
  Num examples: 50000, Num correct: 46459, Precision @ 1: 0.9292
('Testing Data Eval: EPOCH->', 13)
  Num examples: 10000, Num correct: 6767, Precision @ 1: 0.6767
Step 12005: loss = 0.17334
Step 12010: loss = 0.23772
Step 12015: loss = 0.16300
Step 12020: loss = 0.19986
Step 12025: loss = 0.20549
Step 12030: loss = 0.24184
Step 12035: loss = 0.22502
Step 12040: loss = 0.14771
Step 12045: loss = 0.28363
Step 12050: loss = 0.26654
Step 12055: loss = 0.14988
Step 12060: loss = 0.28637
Step 12065: loss = 0.19499
Step 12070: loss = 0.16377
Step 12075: loss = 0.28827
Step 12080: loss = 0.22971
Step 12085: loss = 0.17349
Step 12090: loss = 0.13231
Step 12095: loss = 0.23419
Step 12100: loss = 0.17403
Step 12105: loss = 0.14771
Step 12110: loss = 0.26938
Step 12115: loss = 0.30915
Step 12120: loss = 0.33339
Step 12125: loss = 0.26156
Step 12130: loss = 0.13851
Step 12135: loss = 0.25495
Step 12140: loss = 0.24746
Step 12145: loss = 0.13679
Step 12150: loss = 0.14804
Step 12155: loss = 0.12925
Step 12160: loss = 0.18726
Step 12165: loss = 0.27697
Step 12170: loss = 0.43052
Step 12175: loss = 0.21017
Step 12180: loss = 0.22942
Step 12185: loss = 0.24962
Step 12190: loss = 0.24292
Step 12195: loss = 0.22025
Step 12200: loss = 0.31921
Step 12205: loss = 0.27050
Step 12210: loss = 0.32043
Step 12215: loss = 0.16733
Step 12220: loss = 0.25404
Step 12225: loss = 0.24519
Step 12230: loss = 0.19037
Step 12235: loss = 0.18093
Step 12240: loss = 0.18090
Step 12245: loss = 0.31542
Step 12250: loss = 0.16252
Step 12255: loss = 0.21974
Step 12260: loss = 0.12051
Step 12265: loss = 0.29442
Step 12270: loss = 0.49694
Step 12275: loss = 0.28220
Step 12280: loss = 0.24577
Step 12285: loss = 0.18513
Step 12290: loss = 0.25900
Step 12295: loss = 0.15182
Step 12300: loss = 0.31863
Step 12305: loss = 0.21110
Step 12310: loss = 0.26819
Step 12315: loss = 0.34261
Step 12320: loss = 0.33205
Step 12325: loss = 0.29539
Step 12330: loss = 0.17499
Step 12335: loss = 0.14840
Step 12340: loss = 0.24153
Step 12345: loss = 0.19051
Step 12350: loss = 0.19833
Step 12355: loss = 0.17348
Step 12360: loss = 0.21864
Step 12365: loss = 0.18502
Step 12370: loss = 0.23123
Step 12375: loss = 0.07804
Step 12380: loss = 0.20051
Step 12385: loss = 0.23058
Step 12390: loss = 0.21165
Step 12395: loss = 0.24835
Step 12400: loss = 0.34286
Step 12405: loss = 0.24021
Step 12410: loss = 0.30228
Step 12415: loss = 0.20978
Step 12420: loss = 0.29614
Step 12425: loss = 0.15449
Step 12430: loss = 0.26937
Step 12435: loss = 0.16285
Step 12440: loss = 0.19425
Step 12445: loss = 0.23821
Step 12450: loss = 0.19712
Step 12455: loss = 0.21000
Step 12460: loss = 0.30135
Step 12465: loss = 0.23494
Step 12470: loss = 0.18431
Step 12475: loss = 0.17790
Step 12480: loss = 0.28087
Step 12485: loss = 0.25819
Step 12490: loss = 0.21748
Step 12495: loss = 0.21181
Step 12500: loss = 0.18544
Step 12505: loss = 0.15661
Step 12510: loss = 0.23140
Step 12515: loss = 0.23470
Step 12520: loss = 0.27949
Step 12525: loss = 0.11949
Step 12530: loss = 0.36141
Step 12535: loss = 0.16372
Step 12540: loss = 0.24478
Step 12545: loss = 0.21883
Step 12550: loss = 0.15193
Step 12555: loss = 0.32560
Step 12560: loss = 0.17746
Step 12565: loss = 0.17044
Step 12570: loss = 0.21672
Step 12575: loss = 0.22005
Step 12580: loss = 0.18060
Step 12585: loss = 0.24593
Step 12590: loss = 0.23729
Step 12595: loss = 0.36921
Step 12600: loss = 0.17427
Step 12605: loss = 0.31046
Step 12610: loss = 0.22029
Step 12615: loss = 0.18164
Step 12620: loss = 0.09345
Step 12625: loss = 0.12197
Step 12630: loss = 0.12866
Step 12635: loss = 0.30700
Step 12640: loss = 0.17627
Step 12645: loss = 0.17415
Step 12650: loss = 0.18396
Step 12655: loss = 0.13867
Step 12660: loss = 0.17894
Step 12665: loss = 0.24360
Step 12670: loss = 0.28649
Step 12675: loss = 0.21255
Step 12680: loss = 0.21133
Step 12685: loss = 0.20144
Step 12690: loss = 0.19716
Step 12695: loss = 0.13022
Step 12700: loss = 0.35549
Step 12705: loss = 0.17409
Step 12710: loss = 0.30639
Step 12715: loss = 0.14667
Step 12720: loss = 0.32231
Step 12725: loss = 0.19537
Step 12730: loss = 0.20729
Step 12735: loss = 0.21864
Step 12740: loss = 0.21886
Step 12745: loss = 0.19696
Step 12750: loss = 0.31209
Step 12755: loss = 0.26353
Step 12760: loss = 0.44138
Step 12765: loss = 0.17069
Step 12770: loss = 0.22947
Step 12775: loss = 0.18768
Step 12780: loss = 0.42190
Step 12785: loss = 0.19702
Step 12790: loss = 0.30494
Step 12795: loss = 0.33187
Step 12800: loss = 0.24636
Step 12805: loss = 0.24796
Step 12810: loss = 0.36819
Step 12815: loss = 0.32186
Step 12820: loss = 0.29976
Step 12825: loss = 0.18454
Step 12830: loss = 0.33471
Step 12835: loss = 0.32185
Step 12840: loss = 0.40669
Step 12845: loss = 0.13926
Step 12850: loss = 0.48164
Step 12855: loss = 0.41203
Step 12860: loss = 0.19517
Step 12865: loss = 0.24031
Step 12870: loss = 0.22556
Step 12875: loss = 0.22763
Step 12880: loss = 0.29949
Step 12885: loss = 0.21478
Step 12890: loss = 0.31910
Step 12895: loss = 0.31344
Step 12900: loss = 0.23275
Step 12905: loss = 0.26566
Step 12910: loss = 0.30223
Step 12915: loss = 0.29017
Step 12920: loss = 0.17737
Step 12925: loss = 0.21658
Step 12930: loss = 0.19388
Step 12935: loss = 0.29659
Step 12940: loss = 0.29804
Step 12945: loss = 0.26077
Step 12950: loss = 0.21628
Step 12955: loss = 0.16546
Step 12960: loss = 0.38387
Step 12965: loss = 0.15697
Step 12970: loss = 0.22181
Step 12975: loss = 0.20304
Step 12980: loss = 0.32599
Step 12985: loss = 0.25643
Step 12990: loss = 0.20298
Step 12995: loss = 0.16469
Step 13000: loss = 0.19219
Training Data Eval:
  Num examples: 50000, Num correct: 47041, Precision @ 1: 0.9408
('Testing Data Eval: EPOCH->', 14)
  Num examples: 10000, Num correct: 6863, Precision @ 1: 0.6863
Step 13005: loss = 0.14139
Step 13010: loss = 0.18179
Step 13015: loss = 0.21036
Step 13020: loss = 0.08985
Step 13025: loss = 0.24426
Step 13030: loss = 0.18140
Step 13035: loss = 0.37805
Step 13040: loss = 0.21228
Step 13045: loss = 0.27809
Step 13050: loss = 0.29652
Step 13055: loss = 0.22213
Step 13060: loss = 0.26732
Step 13065: loss = 0.16676
Step 13070: loss = 0.21469
Step 13075: loss = 0.22197
Step 13080: loss = 0.26445
Step 13085: loss = 0.15708
Step 13090: loss = 0.16891
Step 13095: loss = 0.39499
Step 13100: loss = 0.26267
Step 13105: loss = 0.27938
Step 13110: loss = 0.24776
Step 13115: loss = 0.16086
Step 13120: loss = 0.22853
Step 13125: loss = 0.15374
Step 13130: loss = 0.18668
Step 13135: loss = 0.25840
Step 13140: loss = 0.22172
Step 13145: loss = 0.15447
Step 13150: loss = 0.10470
Step 13155: loss = 0.17125
Step 13160: loss = 0.22089
Step 13165: loss = 0.14249
Step 13170: loss = 0.25709
Step 13175: loss = 0.22918
Step 13180: loss = 0.25447
Step 13185: loss = 0.30404
Step 13190: loss = 0.16315
Step 13195: loss = 0.14487
Step 13200: loss = 0.13332
Step 13205: loss = 0.11393
Step 13210: loss = 0.14669
Step 13215: loss = 0.16797
Step 13220: loss = 0.14105
Step 13225: loss = 0.23464
Step 13230: loss = 0.15237
Step 13235: loss = 0.16843
Step 13240: loss = 0.22943
Step 13245: loss = 0.29405
Step 13250: loss = 0.19458
Step 13255: loss = 0.30107
Step 13260: loss = 0.40634
Step 13265: loss = 0.16848
Step 13270: loss = 0.13617
Step 13275: loss = 0.10774
Step 13280: loss = 0.27703
Step 13285: loss = 0.29520
Step 13290: loss = 0.25666
Step 13295: loss = 0.20057
Step 13300: loss = 0.15688
Step 13305: loss = 0.19706
Step 13310: loss = 0.19198
Step 13315: loss = 0.30684
Step 13320: loss = 0.10607
Step 13325: loss = 0.32874
Step 13330: loss = 0.11537
Step 13335: loss = 0.28358
Step 13340: loss = 0.07456
Step 13345: loss = 0.23743
Step 13350: loss = 0.23320
Step 13355: loss = 0.15663
Step 13360: loss = 0.19305
Step 13365: loss = 0.26203
Step 13370: loss = 0.17560
Step 13375: loss = 0.27300
Step 13380: loss = 0.22430
Step 13385: loss = 0.17138
Step 13390: loss = 0.12836
Step 13395: loss = 0.27321
Step 13400: loss = 0.25318
Step 13405: loss = 0.14988
Step 13410: loss = 0.18206
Step 13415: loss = 0.14711
Step 13420: loss = 0.17913
Step 13425: loss = 0.18720
Step 13430: loss = 0.21864
Step 13435: loss = 0.12615
Step 13440: loss = 0.30947
Step 13445: loss = 0.26714
Step 13450: loss = 0.18626
Step 13455: loss = 0.24805
Step 13460: loss = 0.16092
Step 13465: loss = 0.11321
Step 13470: loss = 0.17893
Step 13475: loss = 0.19055
Step 13480: loss = 0.21167
Step 13485: loss = 0.29385
Step 13490: loss = 0.19189
Step 13495: loss = 0.15020
Step 13500: loss = 0.25360
Step 13505: loss = 0.20226
Step 13510: loss = 0.14124
Step 13515: loss = 0.25834
Step 13520: loss = 0.11706
Step 13525: loss = 0.24939
Step 13530: loss = 0.14847
Step 13535: loss = 0.17577
Step 13540: loss = 0.30829
Step 13545: loss = 0.10033
Step 13550: loss = 0.08570
Step 13555: loss = 0.24407
Step 13560: loss = 0.24218
Step 13565: loss = 0.32280
Step 13570: loss = 0.17160
Step 13575: loss = 0.28338
Step 13580: loss = 0.14967
Step 13585: loss = 0.18097
Step 13590: loss = 0.22281
Step 13595: loss = 0.21223
Step 13600: loss = 0.16966
Step 13605: loss = 0.14715
Step 13610: loss = 0.17360
Step 13615: loss = 0.16004
Step 13620: loss = 0.36663
Step 13625: loss = 0.18795
Step 13630: loss = 0.25890
Step 13635: loss = 0.14904
Step 13640: loss = 0.25000
Step 13645: loss = 0.09759
Step 13650: loss = 0.12979
Step 13655: loss = 0.16309
Step 13660: loss = 0.10608
Step 13665: loss = 0.25759
Step 13670: loss = 0.33765
Step 13675: loss = 0.14731
Step 13680: loss = 0.18664
Step 13685: loss = 0.11429
Step 13690: loss = 0.19790
Step 13695: loss = 0.24257
Step 13700: loss = 0.23781
Step 13705: loss = 0.07520
Step 13710: loss = 0.26802
Step 13715: loss = 0.14836
Step 13720: loss = 0.16793
Step 13725: loss = 0.23936
Step 13730: loss = 0.15217
Step 13735: loss = 0.21880
Step 13740: loss = 0.30988
Step 13745: loss = 0.16283
Step 13750: loss = 0.19639
Step 13755: loss = 0.19766
Step 13760: loss = 0.21186
Step 13765: loss = 0.32605
Step 13770: loss = 0.21006
Step 13775: loss = 0.25245
Step 13780: loss = 0.20328
Step 13785: loss = 0.30706
Step 13790: loss = 0.41072
Step 13795: loss = 0.24738
Step 13800: loss = 0.22433
Step 13805: loss = 0.17792
Step 13810: loss = 0.16480
Step 13815: loss = 0.19522
Step 13820: loss = 0.21472
Step 13825: loss = 0.30933
Step 13830: loss = 0.23668
Step 13835: loss = 0.22594
Step 13840: loss = 0.19266
Step 13845: loss = 0.24129
Step 13850: loss = 0.35206
Step 13855: loss = 0.26183
Step 13860: loss = 0.29446
Step 13865: loss = 0.19831
Step 13870: loss = 0.32119
Step 13875: loss = 0.70435
Step 13880: loss = 0.10294
Step 13885: loss = 0.16371
Step 13890: loss = 0.24911
Step 13895: loss = 0.08418
Step 13900: loss = 0.30295
Step 13905: loss = 0.36991
Step 13910: loss = 0.29383
Step 13915: loss = 0.25712
Step 13920: loss = 0.12045
Step 13925: loss = 0.15717
Step 13930: loss = 0.25641
Step 13935: loss = 0.21632
Step 13940: loss = 0.18058
Step 13945: loss = 0.12384
Step 13950: loss = 0.12074
Step 13955: loss = 0.26753
Step 13960: loss = 0.20625
Step 13965: loss = 0.17800
Step 13970: loss = 0.23731
Step 13975: loss = 0.15138
Step 13980: loss = 0.32331
Step 13985: loss = 0.42342
Step 13990: loss = 0.17806
Step 13995: loss = 0.31196
Step 14000: loss = 0.26469
Training Data Eval:
  Num examples: 50000, Num correct: 47478, Precision @ 1: 0.9496
('Testing Data Eval: EPOCH->', 15)
  Num examples: 10000, Num correct: 6645, Precision @ 1: 0.6645
Step 14005: loss = 0.12314
Step 14010: loss = 0.12319
Step 14015: loss = 0.17487
Step 14020: loss = 0.17087
Step 14025: loss = 0.28609
Step 14030: loss = 0.13803
Step 14035: loss = 0.15510
Step 14040: loss = 0.08953
Step 14045: loss = 0.23916
Step 14050: loss = 0.18541
Step 14055: loss = 0.17568
Step 14060: loss = 0.17253
Step 14065: loss = 0.12003
Step 14070: loss = 0.15033
Step 14075: loss = 0.13987
Step 14080: loss = 0.11509
Step 14085: loss = 0.24416
Step 14090: loss = 0.21087
Step 14095: loss = 0.10573
Step 14100: loss = 0.25870
Step 14105: loss = 0.24989
Step 14110: loss = 0.24257
Step 14115: loss = 0.15816
Step 14120: loss = 0.11009
Step 14125: loss = 0.13740
Step 14130: loss = 0.14163
Step 14135: loss = 0.12435
Step 14140: loss = 0.13630
Step 14145: loss = 0.20272
Step 14150: loss = 0.19739
Step 14155: loss = 0.17063
Step 14160: loss = 0.13364
Step 14165: loss = 0.17219
Step 14170: loss = 0.10286
Step 14175: loss = 0.21966
Step 14180: loss = 0.17072
Step 14185: loss = 0.15639
Step 14190: loss = 0.18322
Step 14195: loss = 0.16939
Step 14200: loss = 0.24668
Step 14205: loss = 0.11592
Step 14210: loss = 0.21820
Step 14215: loss = 0.19069
Step 14220: loss = 0.12840
Step 14225: loss = 0.08949
Step 14230: loss = 0.11187
Step 14235: loss = 0.19168
Step 14240: loss = 0.18601
Step 14245: loss = 0.09143
Step 14250: loss = 0.14400
Step 14255: loss = 0.18673
Step 14260: loss = 0.10099
Step 14265: loss = 0.11863
Step 14270: loss = 0.18148
Step 14275: loss = 0.13134
Step 14280: loss = 0.17426
Step 14285: loss = 0.17624
Step 14290: loss = 0.13519
Step 14295: loss = 0.11913
Step 14300: loss = 0.23993
Step 14305: loss = 0.30671
Step 14310: loss = 0.17205
Step 14315: loss = 0.08150
Step 14320: loss = 0.21426
Step 14325: loss = 0.16834
Step 14330: loss = 0.17675
Step 14335: loss = 0.11735
Step 14340: loss = 0.16907
Step 14345: loss = 0.09639
Step 14350: loss = 0.29814
Step 14355: loss = 0.19743
Step 14360: loss = 0.16051
Step 14365: loss = 0.22742
Step 14370: loss = 0.16174
Step 14375: loss = 0.12560
Step 14380: loss = 0.10269
Step 14385: loss = 0.13622
Step 14390: loss = 0.21453
Step 14395: loss = 0.27015
Step 14400: loss = 0.20420
Step 14405: loss = 0.20042
Step 14410: loss = 0.14930
Step 14415: loss = 0.14029
Step 14420: loss = 0.18260
Step 14425: loss = 0.14645
Step 14430: loss = 0.14082
Step 14435: loss = 0.09225
Step 14440: loss = 0.12885
Step 14445: loss = 0.14661
Step 14450: loss = 0.23920
Step 14455: loss = 0.16799
Step 14460: loss = 0.42308
Step 14465: loss = 0.15602
Step 14470: loss = 0.18938
Step 14475: loss = 0.15228
Step 14480: loss = 0.26530
Step 14485: loss = 0.16491
Step 14490: loss = 0.15597
Step 14495: loss = 0.14381
Step 14500: loss = 0.24498
Step 14505: loss = 0.17710
Step 14510: loss = 0.29537
Step 14515: loss = 0.16105
Step 14520: loss = 0.15326
Step 14525: loss = 0.12819
Step 14530: loss = 0.19944
Step 14535: loss = 0.24992
Step 14540: loss = 0.16739
Step 14545: loss = 0.17290
Step 14550: loss = 0.21759
Step 14555: loss = 0.20430
Step 14560: loss = 0.06219
Step 14565: loss = 0.15518
Step 14570: loss = 0.32086
Step 14575: loss = 0.28485
Step 14580: loss = 0.18182
Step 14585: loss = 0.08409
Step 14590: loss = 0.08591
Step 14595: loss = 0.13625
Step 14600: loss = 0.19728
Step 14605: loss = 0.23998
Step 14610: loss = 0.31773
Step 14615: loss = 0.14643
Step 14620: loss = 0.21914
Step 14625: loss = 0.17532
Step 14630: loss = 0.13490
Step 14635: loss = 0.15917
Step 14640: loss = 0.13310
Step 14645: loss = 0.13847
Step 14650: loss = 0.12956
Step 14655: loss = 0.17505
Step 14660: loss = 0.07370
Step 14665: loss = 0.26084
Step 14670: loss = 0.10565
Step 14675: loss = 0.13823
Step 14680: loss = 0.11427
Step 14685: loss = 0.13415
Step 14690: loss = 0.09271
Step 14695: loss = 0.21103
Step 14700: loss = 0.19563
Step 14705: loss = 0.07634
Step 14710: loss = 0.10421
Step 14715: loss = 0.09925
Step 14720: loss = 0.14802
Step 14725: loss = 0.13289
Step 14730: loss = 0.19334
Step 14735: loss = 0.42767
Step 14740: loss = 0.11867
Step 14745: loss = 0.16392
Step 14750: loss = 0.15367
Step 14755: loss = 0.20582
Step 14760: loss = 0.24182
Step 14765: loss = 0.08899
Step 14770: loss = 0.23294
Step 14775: loss = 0.24063
Step 14780: loss = 0.12948
Step 14785: loss = 0.15173
Step 14790: loss = 0.16977
Step 14795: loss = 0.17860
Step 14800: loss = 0.16150
Step 14805: loss = 0.15360
Step 14810: loss = 0.16673
Step 14815: loss = 0.24583
Step 14820: loss = 0.14023
Step 14825: loss = 0.22528
Step 14830: loss = 0.11554
Step 14835: loss = 0.09074
Step 14840: loss = 0.13235
Step 14845: loss = 0.18913
Step 14850: loss = 0.20328
Step 14855: loss = 0.14374
Step 14860: loss = 0.16782
Step 14865: loss = 0.13069
Step 14870: loss = 0.15551
Step 14875: loss = 0.23737
Step 14880: loss = 0.12923
Step 14885: loss = 0.20889
Step 14890: loss = 0.24579
Step 14895: loss = 0.16125
Step 14900: loss = 0.05100
Step 14905: loss = 0.18367
Step 14910: loss = 0.13949
Step 14915: loss = 0.17892
Step 14920: loss = 0.26813
Step 14925: loss = 0.20288
Step 14930: loss = 0.10684
Step 14935: loss = 0.34822
Step 14940: loss = 0.15599
Step 14945: loss = 0.11972
Step 14950: loss = 0.16514
Step 14955: loss = 0.20766
Step 14960: loss = 0.21637
Step 14965: loss = 0.20132
Step 14970: loss = 0.22268
Step 14975: loss = 0.11512
Step 14980: loss = 0.20538
Step 14985: loss = 0.18402
Step 14990: loss = 0.27192
Step 14995: loss = 0.14178
Step 15000: loss = 0.19944
Training Data Eval:
  Num examples: 50000, Num correct: 47764, Precision @ 1: 0.9553
('Testing Data Eval: EPOCH->', 16)
  Num examples: 10000, Num correct: 6891, Precision @ 1: 0.6891
Step 15005: loss = 0.09117
Step 15010: loss = 0.15267
Step 15015: loss = 0.07551
Step 15020: loss = 0.13664
Step 15025: loss = 0.11472
Step 15030: loss = 0.14361
Step 15035: loss = 0.32938
Step 15040: loss = 0.14054
Step 15045: loss = 0.17627
Step 15050: loss = 0.11543
Step 15055: loss = 0.06047
Step 15060: loss = 0.24380
Step 15065: loss = 0.14352
Step 15070: loss = 0.15635
Step 15075: loss = 0.12249
Step 15080: loss = 0.08816
Step 15085: loss = 0.23015
Step 15090: loss = 0.12940
Step 15095: loss = 0.10644
Step 15100: loss = 0.18518
Step 15105: loss = 0.16255
Step 15110: loss = 0.15689
Step 15115: loss = 0.06230
Step 15120: loss = 0.05192
Step 15125: loss = 0.16443
Step 15130: loss = 0.17629
Step 15135: loss = 0.17353
Step 15140: loss = 0.20451
Step 15145: loss = 0.17006
Step 15150: loss = 0.11570
Step 15155: loss = 0.26942
Step 15160: loss = 0.29158
Step 15165: loss = 0.15551
Step 15170: loss = 0.13090
Step 15175: loss = 0.09637
Step 15180: loss = 0.10841
Step 15185: loss = 0.13271
Step 15190: loss = 0.16753
Step 15195: loss = 0.08824
Step 15200: loss = 0.27532
Step 15205: loss = 0.11492
Step 15210: loss = 0.10284
Step 15215: loss = 0.15883
Step 15220: loss = 0.15920
Step 15225: loss = 0.09744
Step 15230: loss = 0.11140
Step 15235: loss = 0.04977
Step 15240: loss = 0.14338
Step 15245: loss = 0.20640
Step 15250: loss = 0.18152
Step 15255: loss = 0.13407
Step 15260: loss = 0.27839
Step 15265: loss = 0.21728
Step 15270: loss = 0.15619
Step 15275: loss = 0.15933
Step 15280: loss = 0.15731
Step 15285: loss = 0.18936
Step 15290: loss = 0.19700
Step 15295: loss = 0.25325
Step 15300: loss = 0.20643
Step 15305: loss = 0.19901
Step 15310: loss = 0.08618
Step 15315: loss = 0.18356
Step 15320: loss = 0.09204
Step 15325: loss = 0.27199
Step 15330: loss = 0.22139
Step 15335: loss = 0.24516
Step 15340: loss = 0.07706
Step 15345: loss = 0.18894
Step 15350: loss = 0.19849
Step 15355: loss = 0.24980
Step 15360: loss = 0.27909
Step 15365: loss = 0.26190
Step 15370: loss = 0.12882
Step 15375: loss = 0.15350
Step 15380: loss = 0.12816
Step 15385: loss = 0.08704
Step 15390: loss = 0.07631
Step 15395: loss = 0.22504
Step 15400: loss = 0.19228
Step 15405: loss = 0.22613
Step 15410: loss = 0.10496
Step 15415: loss = 0.25931
Step 15420: loss = 0.10433
Step 15425: loss = 0.12368
Step 15430: loss = 0.09984
Step 15435: loss = 0.11818
Step 15440: loss = 0.22045
Step 15445: loss = 0.08683
Step 15450: loss = 0.09143
Step 15455: loss = 0.16992
Step 15460: loss = 0.20433
Step 15465: loss = 0.12722
Step 15470: loss = 0.15741
Step 15475: loss = 0.25753
Step 15480: loss = 0.08555
Step 15485: loss = 0.09610
Step 15490: loss = 0.14340
Step 15495: loss = 0.23775
Step 15500: loss = 0.13777
Step 15505: loss = 0.09285
Step 15510: loss = 0.26780
Step 15515: loss = 0.11886
Step 15520: loss = 0.24511
Step 15525: loss = 0.16360
Step 15530: loss = 0.17906
Step 15535: loss = 0.23851
Step 15540: loss = 0.14793
Step 15545: loss = 0.14426
Step 15550: loss = 0.03934
Step 15555: loss = 0.15209
Step 15560: loss = 0.15386
Step 15565: loss = 0.09286
Step 15570: loss = 0.10065
Step 15575: loss = 0.18375
Step 15580: loss = 0.22636
Step 15585: loss = 0.21823
Step 15590: loss = 0.14844
Step 15595: loss = 0.10963
Step 15600: loss = 0.16913
Step 15605: loss = 0.29107
Step 15610: loss = 0.15594
Step 15615: loss = 0.25037
Step 15620: loss = 0.22881
Step 15625: loss = 0.37612
Step 15630: loss = 0.11505
Step 15635: loss = 0.18590
Step 15640: loss = 0.19828
Step 15645: loss = 0.32940
Step 15650: loss = 0.16622
Step 15655: loss = 0.12640
Step 15660: loss = 0.26160
Step 15665: loss = 0.14744
Step 15670: loss = 0.15898
Step 15675: loss = 0.10641
Step 15680: loss = 0.14784
Step 15685: loss = 0.08866
Step 15690: loss = 0.09205
Step 15695: loss = 0.17210
Step 15700: loss = 0.11320
Step 15705: loss = 0.29194
Step 15710: loss = 0.17799
Step 15715: loss = 0.19060
Step 15720: loss = 0.12914
Step 15725: loss = 0.13580
Step 15730: loss = 0.17091
Step 15735: loss = 0.10533
Step 15740: loss = 0.23141
Step 15745: loss = 0.17611
Step 15750: loss = 0.09956
Step 15755: loss = 0.09711
Step 15760: loss = 0.10483
Step 15765: loss = 0.07759
Step 15770: loss = 0.18544
Step 15775: loss = 0.17709
Step 15780: loss = 0.14778
Step 15785: loss = 0.20356
Step 15790: loss = 0.16477
Step 15795: loss = 0.19077
Step 15800: loss = 0.25190
Step 15805: loss = 0.12183
Step 15810: loss = 0.21543
Step 15815: loss = 0.10311
Step 15820: loss = 0.13061
Step 15825: loss = 0.12214
Step 15830: loss = 0.17816
Step 15835: loss = 0.13067
Step 15840: loss = 0.10949
Step 15845: loss = 0.28812
Step 15850: loss = 0.20940
Step 15855: loss = 0.14257
Step 15860: loss = 0.25767
Step 15865: loss = 0.07124
Step 15870: loss = 0.11377
Step 15875: loss = 0.24167
Step 15880: loss = 0.13862
Step 15885: loss = 0.24382
Step 15890: loss = 0.16505
Step 15895: loss = 0.14794
Step 15900: loss = 0.08573
Step 15905: loss = 0.10644
Step 15910: loss = 0.18327
Step 15915: loss = 0.26623
Step 15920: loss = 0.19517
Step 15925: loss = 0.16953
Step 15930: loss = 0.22326
Step 15935: loss = 0.14020
Step 15940: loss = 0.18892
Step 15945: loss = 0.15389
Step 15950: loss = 0.11240
Step 15955: loss = 0.35743
Step 15960: loss = 0.11501
Step 15965: loss = 0.14095
Step 15970: loss = 0.13228
Step 15975: loss = 0.16080
Step 15980: loss = 0.27014
Step 15985: loss = 0.13593
Step 15990: loss = 0.04756
Step 15995: loss = 0.16780
Step 16000: loss = 0.12706
Training Data Eval:
  Num examples: 50000, Num correct: 47861, Precision @ 1: 0.9572
('Testing Data Eval: EPOCH->', 17)
  Num examples: 10000, Num correct: 6891, Precision @ 1: 0.6891
Step 16005: loss = 0.08094
Step 16010: loss = 0.07803
Step 16015: loss = 0.13921
Step 16020: loss = 0.09886
Step 16025: loss = 0.08469
Step 16030: loss = 0.09903
Step 16035: loss = 0.09987
Step 16040: loss = 0.10123
Step 16045: loss = 0.12182
Step 16050: loss = 0.11546
Step 16055: loss = 0.15132
Step 16060: loss = 0.08327
Step 16065: loss = 0.09422
Step 16070: loss = 0.13343
Step 16075: loss = 0.06479
Step 16080: loss = 0.10144
Step 16085: loss = 0.11700
Step 16090: loss = 0.20615
Step 16095: loss = 0.08135
Step 16100: loss = 0.18859
Step 16105: loss = 0.26057
Step 16110: loss = 0.13163
Step 16115: loss = 0.23678
Step 16120: loss = 0.16080
Step 16125: loss = 0.11984
Step 16130: loss = 0.04788
Step 16135: loss = 0.07467
Step 16140: loss = 0.06437
Step 16145: loss = 0.06713
Step 16150: loss = 0.16497
Step 16155: loss = 0.19696
Step 16160: loss = 0.09197
Step 16165: loss = 0.08160
Step 16170: loss = 0.08845
Step 16175: loss = 0.18487
Step 16180: loss = 0.03894
Step 16185: loss = 0.16822
Step 16190: loss = 0.24613
Step 16195: loss = 0.08553
Step 16200: loss = 0.09790
Step 16205: loss = 0.07223
Step 16210: loss = 0.19953
Step 16215: loss = 0.10779
Step 16220: loss = 0.08155
Step 16225: loss = 0.12152
Step 16230: loss = 0.17111
Step 16235: loss = 0.21682
Step 16240: loss = 0.18081
Step 16245: loss = 0.07464
Step 16250: loss = 0.17793
Step 16255: loss = 0.30575
Step 16260: loss = 0.06794
Step 16265: loss = 0.08141
Step 16270: loss = 0.13125
Step 16275: loss = 0.09109
Step 16280: loss = 0.03586
Step 16285: loss = 0.31783
Step 16290: loss = 0.17914
Step 16295: loss = 0.11227
Step 16300: loss = 0.14782
Step 16305: loss = 0.12140
Step 16310: loss = 0.17004
Step 16315: loss = 0.04698
Step 16320: loss = 0.10697
Step 16325: loss = 0.14657
Step 16330: loss = 0.25137
Step 16335: loss = 0.13006
Step 16340: loss = 0.10196
Step 16345: loss = 0.16191
Step 16350: loss = 0.10139
Step 16355: loss = 0.12529
Step 16360: loss = 0.09464
Step 16365: loss = 0.11953
Step 16370: loss = 0.10660
Step 16375: loss = 0.09116
Step 16380: loss = 0.09112
Step 16385: loss = 0.16004
Step 16390: loss = 0.16316
Step 16395: loss = 0.11688
Step 16400: loss = 0.09554
Step 16405: loss = 0.24239
Step 16410: loss = 0.08889
Step 16415: loss = 0.10585
Step 16420: loss = 0.12401
Step 16425: loss = 0.09999
Step 16430: loss = 0.13581
Step 16435: loss = 0.21896
Step 16440: loss = 0.23341
Step 16445: loss = 0.08377
Step 16450: loss = 0.21695
Step 16455: loss = 0.09693
Step 16460: loss = 0.13280
Step 16465: loss = 0.16525
Step 16470: loss = 0.07934
Step 16475: loss = 0.19468
Step 16480: loss = 0.08866
Step 16485: loss = 0.10261
Step 16490: loss = 0.28258
Step 16495: loss = 0.09502
Step 16500: loss = 0.19219
Step 16505: loss = 0.23454
Step 16510: loss = 0.31893
Step 16515: loss = 0.18838
Step 16520: loss = 0.13603
Step 16525: loss = 0.12746
Step 16530: loss = 0.22620
Step 16535: loss = 0.16799
Step 16540: loss = 0.20073
Step 16545: loss = 0.19508
Step 16550: loss = 0.13260
Step 16555: loss = 0.22182
Step 16560: loss = 0.13825
Step 16565: loss = 0.21695
Step 16570: loss = 0.29595
Step 16575: loss = 0.37452
Step 16580: loss = 0.19790
Step 16585: loss = 0.26869
Step 16590: loss = 0.14094
Step 16595: loss = 0.14117
Step 16600: loss = 0.13562
Step 16605: loss = 0.19958
Step 16610: loss = 0.15419
Step 16615: loss = 0.08433
Step 16620: loss = 0.14254
Step 16625: loss = 0.16535
Step 16630: loss = 0.11166
Step 16635: loss = 0.12656
Step 16640: loss = 0.17736
Step 16645: loss = 0.17132
Step 16650: loss = 0.20186
Step 16655: loss = 0.18115
Step 16660: loss = 0.14325
Step 16665: loss = 0.17341
Step 16670: loss = 0.15061
Step 16675: loss = 0.28475
Step 16680: loss = 0.15095
Step 16685: loss = 0.12474
Step 16690: loss = 0.13891
Step 16695: loss = 0.17033
Step 16700: loss = 0.38389
Step 16705: loss = 0.11966
Step 16710: loss = 0.19420
Step 16715: loss = 0.25072
Step 16720: loss = 0.21163
Step 16725: loss = 0.24019
Step 16730: loss = 0.12229
Step 16735: loss = 0.11776
Step 16740: loss = 0.10872
Step 16745: loss = 0.24302
Step 16750: loss = 0.13817
Step 16755: loss = 0.25303
Step 16760: loss = 0.22180
Step 16765: loss = 0.26043
Step 16770: loss = 0.12814
Step 16775: loss = 0.16316
Step 16780: loss = 0.15658
Step 16785: loss = 0.06759
Step 16790: loss = 0.11497
Step 16795: loss = 0.18053
Step 16800: loss = 0.09477
Step 16805: loss = 0.14808
Step 16810: loss = 0.13474
Step 16815: loss = 0.09795
Step 16820: loss = 0.25542
Step 16825: loss = 0.14582
Step 16830: loss = 0.07887
Step 16835: loss = 0.10855
Step 16840: loss = 0.16164
Step 16845: loss = 0.23101
Step 16850: loss = 0.17240
Step 16855: loss = 0.24386
Step 16860: loss = 0.14961
Step 16865: loss = 0.28334
Step 16870: loss = 0.13166
Step 16875: loss = 0.23198
Step 16880: loss = 0.20005
Step 16885: loss = 0.16572
Step 16890: loss = 0.30660
Step 16895: loss = 0.25399
Step 16900: loss = 0.15421
Step 16905: loss = 0.06459
Step 16910: loss = 0.10661
Step 16915: loss = 0.18757
Step 16920: loss = 0.19384
Step 16925: loss = 0.20193
Step 16930: loss = 0.25495
Step 16935: loss = 0.28268
Step 16940: loss = 0.23267
Step 16945: loss = 0.17901
Step 16950: loss = 0.14164
Step 16955: loss = 0.14086
Step 16960: loss = 0.14424
Step 16965: loss = 0.34882
Step 16970: loss = 0.15179
Step 16975: loss = 0.18340
Step 16980: loss = 0.13705
Step 16985: loss = 0.22261
Step 16990: loss = 0.08033
Step 16995: loss = 0.20602
Step 17000: loss = 0.18916
Training Data Eval:
  Num examples: 50000, Num correct: 47740, Precision @ 1: 0.9548
('Testing Data Eval: EPOCH->', 18)
  Num examples: 10000, Num correct: 6788, Precision @ 1: 0.6788
Step 17005: loss = 0.10781
Step 17010: loss = 0.15312
Step 17015: loss = 0.08957
Step 17020: loss = 0.15303
Step 17025: loss = 0.10805
Step 17030: loss = 0.14246
Step 17035: loss = 0.27058
Step 17040: loss = 0.10712
Step 17045: loss = 0.10588
Step 17050: loss = 0.12336
Step 17055: loss = 0.11434
Step 17060: loss = 0.13965
Step 17065: loss = 0.17513
Step 17070: loss = 0.15749
Step 17075: loss = 0.23444
Step 17080: loss = 0.09793
Step 17085: loss = 0.10203
Step 17090: loss = 0.16197
Step 17095: loss = 0.13915
Step 17100: loss = 0.19559
Step 17105: loss = 0.07028
Step 17110: loss = 0.12351
Step 17115: loss = 0.18730
Step 17120: loss = 0.12520
Step 17125: loss = 0.20824
Step 17130: loss = 0.12557
Step 17135: loss = 0.07718
Step 17140: loss = 0.18862
Step 17145: loss = 0.14703
Step 17150: loss = 0.04537
Step 17155: loss = 0.08879
Step 17160: loss = 0.10653
Step 17165: loss = 0.10236
Step 17170: loss = 0.12273
Step 17175: loss = 0.07274
Step 17180: loss = 0.11485
Step 17185: loss = 0.09351
Step 17190: loss = 0.12800
Step 17195: loss = 0.15663
Step 17200: loss = 0.21127
Step 17205: loss = 0.16947
Step 17210: loss = 0.21024
Step 17215: loss = 0.08455
Step 17220: loss = 0.13773
Step 17225: loss = 0.12326
Step 17230: loss = 0.09543
Step 17235: loss = 0.07397
Step 17240: loss = 0.25525
Step 17245: loss = 0.13282
Step 17250: loss = 0.09839
Step 17255: loss = 0.18204
Step 17260: loss = 0.11463
Step 17265: loss = 0.22559
Step 17270: loss = 0.14702
Step 17275: loss = 0.15043
Step 17280: loss = 0.23865
Step 17285: loss = 0.18003
Step 17290: loss = 0.17143
Step 17295: loss = 0.13833
Step 17300: loss = 0.12146
Step 17305: loss = 0.21663
Step 17310: loss = 0.17145
Step 17315: loss = 0.12921
Step 17320: loss = 0.03004
Step 17325: loss = 0.11433
Step 17330: loss = 0.09192
Step 17335: loss = 0.08969
Step 17340: loss = 0.17020
Step 17345: loss = 0.19651
Step 17350: loss = 0.05572
Step 17355: loss = 0.16122
Step 17360: loss = 0.07881
Step 17365: loss = 0.05925
Step 17370: loss = 0.15083
Step 17375: loss = 0.19071
Step 17380: loss = 0.07562
Step 17385: loss = 0.06540
Step 17390: loss = 0.11799
Step 17395: loss = 0.11772
Step 17400: loss = 0.11037
Step 17405: loss = 0.19597
Step 17410: loss = 0.21761
Step 17415: loss = 0.11080
Step 17420: loss = 0.10481
Step 17425: loss = 0.24180
Step 17430: loss = 0.13615
Step 17435: loss = 0.07275
Step 17440: loss = 0.10961
Step 17445: loss = 0.04885
Step 17450: loss = 0.16427
Step 17455: loss = 0.17147
Step 17460: loss = 0.09026
Step 17465: loss = 0.26373
Step 17470: loss = 0.17685
Step 17475: loss = 0.16500
Step 17480: loss = 0.08076
Step 17485: loss = 0.05136
Step 17490: loss = 0.14661
Step 17495: loss = 0.13127
Step 17500: loss = 0.08234
Step 17505: loss = 0.07250
Step 17510: loss = 0.12001
Step 17515: loss = 0.16805
Step 17520: loss = 0.16420
Step 17525: loss = 0.13742
Step 17530: loss = 0.14243
Step 17535: loss = 0.14141
Step 17540: loss = 0.15590
Step 17545: loss = 0.09962
Step 17550: loss = 0.15362
Step 17555: loss = 0.14508
Step 17560: loss = 0.11152
Step 17565: loss = 0.12021
Step 17570: loss = 0.17568
Step 17575: loss = 0.07173
Step 17580: loss = 0.08349
Step 17585: loss = 0.20561
Step 17590: loss = 0.07112
Step 17595: loss = 0.14960
Step 17600: loss = 0.16276
Step 17605: loss = 0.08142
Step 17610: loss = 0.20473
Step 17615: loss = 0.11873
Step 17620: loss = 0.11704
Step 17625: loss = 0.24906
Step 17630: loss = 0.13222
Step 17635: loss = 0.12984
Step 17640: loss = 0.14668
Step 17645: loss = 0.06141
Step 17650: loss = 0.13331
Step 17655: loss = 0.16251
Step 17660: loss = 0.09657
Step 17665: loss = 0.04566
Step 17670: loss = 0.20851
Step 17675: loss = 0.15390
Step 17680: loss = 0.12526
Step 17685: loss = 0.13535
Step 17690: loss = 0.08807
Step 17695: loss = 0.17102
Step 17700: loss = 0.23196
Step 17705: loss = 0.10197
Step 17710: loss = 0.15544
Step 17715: loss = 0.15913
Step 17720: loss = 0.10040
Step 17725: loss = 0.12105
Step 17730: loss = 0.17267
Step 17735: loss = 0.19646
Step 17740: loss = 0.12929
Step 17745: loss = 0.16929
Step 17750: loss = 0.12444
Step 17755: loss = 0.26523
Step 17760: loss = 0.12533
Step 17765: loss = 0.10653
Step 17770: loss = 0.05695
Step 17775: loss = 0.17298
Step 17780: loss = 0.06036
Step 17785: loss = 0.08131
Step 17790: loss = 0.08691
Step 17795: loss = 0.17524
Step 17800: loss = 0.14690
Step 17805: loss = 0.11516
Step 17810: loss = 0.11891
Step 17815: loss = 0.11853
Step 17820: loss = 0.16179
Step 17825: loss = 0.07599
Step 17830: loss = 0.22185
Step 17835: loss = 0.09957
Step 17840: loss = 0.33003
Step 17845: loss = 0.09371
Step 17850: loss = 0.23281
Step 17855: loss = 0.18089
Step 17860: loss = 0.14940
Step 17865: loss = 0.12925
Step 17870: loss = 0.08609
Step 17875: loss = 0.17255
Step 17880: loss = 0.19816
Step 17885: loss = 0.17604
Step 17890: loss = 0.15367
Step 17895: loss = 0.26298
Step 17900: loss = 0.07714
Step 17905: loss = 0.12283
Step 17910: loss = 0.15353
Step 17915: loss = 0.14649
Step 17920: loss = 0.14325
Step 17925: loss = 0.14768
Step 17930: loss = 0.13324
Step 17935: loss = 0.28540
Step 17940: loss = 0.13103
Step 17945: loss = 0.13040
Step 17950: loss = 0.17972
Step 17955: loss = 0.08923
Step 17960: loss = 0.07886
Step 17965: loss = 0.32301
Step 17970: loss = 0.11227
Step 17975: loss = 0.05214
Step 17980: loss = 0.07153
Step 17985: loss = 0.09023
Step 17990: loss = 0.12676
Step 17995: loss = 0.19055
Step 18000: loss = 0.15548
Training Data Eval:
  Num examples: 50000, Num correct: 48339, Precision @ 1: 0.9668
('Testing Data Eval: EPOCH->', 19)
  Num examples: 10000, Num correct: 6862, Precision @ 1: 0.6862
Step 18005: loss = 0.05329
Step 18010: loss = 0.20834
Step 18015: loss = 0.07161
Step 18020: loss = 0.05270
Step 18025: loss = 0.14235
Step 18030: loss = 0.05717
Step 18035: loss = 0.04234
Step 18040: loss = 0.03277
Step 18045: loss = 0.18808
Step 18050: loss = 0.09882
Step 18055: loss = 0.12799
Step 18060: loss = 0.10460
Step 18065: loss = 0.16327
Step 18070: loss = 0.09231
Step 18075: loss = 0.05830
Step 18080: loss = 0.17625
Step 18085: loss = 0.05122
Step 18090: loss = 0.14007
Step 18095: loss = 0.13194
Step 18100: loss = 0.11132
Step 18105: loss = 0.06710
Step 18110: loss = 0.06778
Step 18115: loss = 0.20227
Step 18120: loss = 0.15239
Step 18125: loss = 0.12536
Step 18130: loss = 0.14172
Step 18135: loss = 0.14972
Step 18140: loss = 0.21845
Step 18145: loss = 0.16200
Step 18150: loss = 0.12522
Step 18155: loss = 0.29538
Step 18160: loss = 0.13879
Step 18165: loss = 0.10375
Step 18170: loss = 0.13002
Step 18175: loss = 0.14168
Step 18180: loss = 0.06948
Step 18185: loss = 0.12225
Step 18190: loss = 0.11196
Step 18195: loss = 0.18813
Step 18200: loss = 0.10519
Step 18205: loss = 0.09453
Step 18210: loss = 0.08487
Step 18215: loss = 0.04543
Step 18220: loss = 0.13157
Step 18225: loss = 0.11731
Step 18230: loss = 0.14982
Step 18235: loss = 0.05714
Step 18240: loss = 0.09828
Step 18245: loss = 0.06344
Step 18250: loss = 0.12249
Step 18255: loss = 0.09126
Step 18260: loss = 0.05881
Step 18265: loss = 0.08501
Step 18270: loss = 0.15600
Step 18275: loss = 0.14687
Step 18280: loss = 0.08013
Step 18285: loss = 0.25824
Step 18290: loss = 0.17408
Step 18295: loss = 0.13842
Step 18300: loss = 0.08035
Step 18305: loss = 0.05617
Step 18310: loss = 0.08090
Step 18315: loss = 0.07993
Step 18320: loss = 0.20370
Step 18325: loss = 0.18341
Step 18330: loss = 0.22613
Step 18335: loss = 0.12865
Step 18340: loss = 0.17215
Step 18345: loss = 0.08452
Step 18350: loss = 0.06101
Step 18355: loss = 0.18108
Step 18360: loss = 0.14137
Step 18365: loss = 0.21403
Step 18370: loss = 0.09449
Step 18375: loss = 0.20320
Step 18380: loss = 0.09456
Step 18385: loss = 0.09577
Step 18390: loss = 0.06100
Step 18395: loss = 0.29777
Step 18400: loss = 0.12073
Step 18405: loss = 0.15240
Step 18410: loss = 0.06112
Step 18415: loss = 0.11439
Step 18420: loss = 0.09751
Step 18425: loss = 0.11470
Step 18430: loss = 0.10960
Step 18435: loss = 0.21377
Step 18440: loss = 0.09098
Step 18445: loss = 0.05675
Step 18450: loss = 0.21942
Step 18455: loss = 0.05703
Step 18460: loss = 0.11935
Step 18465: loss = 0.05442
Step 18470: loss = 0.17150
Step 18475: loss = 0.07292
Step 18480: loss = 0.06102
Step 18485: loss = 0.15852
Step 18490: loss = 0.09190
Step 18495: loss = 0.31667
Step 18500: loss = 0.12247
Step 18505: loss = 0.09534
Step 18510: loss = 0.08838
Step 18515: loss = 0.09651
Step 18520: loss = 0.07217
Step 18525: loss = 0.13650
Step 18530: loss = 0.17451
Step 18535: loss = 0.05817
Step 18540: loss = 0.11635
Step 18545: loss = 0.29784
Step 18550: loss = 0.10077
Step 18555: loss = 0.12952
Step 18560: loss = 0.12767
Step 18565: loss = 0.23133
Step 18570: loss = 0.07937
Step 18575: loss = 0.21854
Step 18580: loss = 0.15218
Step 18585: loss = 0.09193
Step 18590: loss = 0.10443
Step 18595: loss = 0.07059
Step 18600: loss = 0.19675
Step 18605: loss = 0.16480
Step 18610: loss = 0.13033
Step 18615: loss = 0.09501
Step 18620: loss = 0.16008
Step 18625: loss = 0.07164
Step 18630: loss = 0.13822
Step 18635: loss = 0.11272
Step 18640: loss = 0.12080
Step 18645: loss = 0.08373
Step 18650: loss = 0.04524
Step 18655: loss = 0.13817
Step 18660: loss = 0.09531
Step 18665: loss = 0.08905
Step 18670: loss = 0.09808
Step 18675: loss = 0.11281
Step 18680: loss = 0.15076
Step 18685: loss = 0.15296
Step 18690: loss = 0.09242
Step 18695: loss = 0.12885
Step 18700: loss = 0.09412
Step 18705: loss = 0.03701
Step 18710: loss = 0.11479
Step 18715: loss = 0.09516
Step 18720: loss = 0.33173
Step 18725: loss = 0.09540
Step 18730: loss = 0.11533
Step 18735: loss = 0.09633
Step 18740: loss = 0.19456
Step 18745: loss = 0.10995
Step 18750: loss = 0.20196
Step 18755: loss = 0.07762
Step 18760: loss = 0.05774
Step 18765: loss = 0.05292
Step 18770: loss = 0.18428
Step 18775: loss = 0.07294
Step 18780: loss = 0.06858
Step 18785: loss = 0.11754
Step 18790: loss = 0.11365
Step 18795: loss = 0.15387
Step 18800: loss = 0.03906
Step 18805: loss = 0.07847
Step 18810: loss = 0.10363
Step 18815: loss = 0.10157
Step 18820: loss = 0.12263
Step 18825: loss = 0.23964
Step 18830: loss = 0.08980
Step 18835: loss = 0.08280
Step 18840: loss = 0.09679
Step 18845: loss = 0.05753
Step 18850: loss = 0.13057
Step 18855: loss = 0.13120
Step 18860: loss = 0.17056
Step 18865: loss = 0.20710
Step 18870: loss = 0.08615
Step 18875: loss = 0.09016
Step 18880: loss = 0.22457
Step 18885: loss = 0.09540
Step 18890: loss = 0.13628
Step 18895: loss = 0.07071
Step 18900: loss = 0.12345
Step 18905: loss = 0.13062
Step 18910: loss = 0.08120
Step 18915: loss = 0.09095
Step 18920: loss = 0.15828
Step 18925: loss = 0.13706
Step 18930: loss = 0.17504
Step 18935: loss = 0.16849
Step 18940: loss = 0.33379
Step 18945: loss = 0.06976
Step 18950: loss = 0.16845
Step 18955: loss = 0.24940
Step 18960: loss = 0.11051
Step 18965: loss = 0.07185
Step 18970: loss = 0.10957
Step 18975: loss = 0.22713
Step 18980: loss = 0.18832
Step 18985: loss = 0.09987
Step 18990: loss = 0.11418
Step 18995: loss = 0.26970
Step 19000: loss = 0.09936
Training Data Eval:
  Num examples: 50000, Num correct: 48350, Precision @ 1: 0.9670
('Testing Data Eval: EPOCH->', 20)
  Num examples: 10000, Num correct: 6748, Precision @ 1: 0.6748
Step 19005: loss = 0.06448
Step 19010: loss = 0.20997
Step 19015: loss = 0.15949
Step 19020: loss = 0.14667
Step 19025: loss = 0.06301
Step 19030: loss = 0.08082
Step 19035: loss = 0.04196
Step 19040: loss = 0.13743
Step 19045: loss = 0.10216
Step 19050: loss = 0.10913
Step 19055: loss = 0.22591
Step 19060: loss = 0.23729
Step 19065: loss = 0.08734
Step 19070: loss = 0.09744
Step 19075: loss = 0.11240
Step 19080: loss = 0.11725
Step 19085: loss = 0.06913
Step 19090: loss = 0.14181
Step 19095: loss = 0.07950
Step 19100: loss = 0.11812
Step 19105: loss = 0.17668
Step 19110: loss = 0.09370
Step 19115: loss = 0.15479
Step 19120: loss = 0.06254
Step 19125: loss = 0.11942
Step 19130: loss = 0.15203
Step 19135: loss = 0.10043
Step 19140: loss = 0.04443
Step 19145: loss = 0.06196
Step 19150: loss = 0.11646
Step 19155: loss = 0.11298
Step 19160: loss = 0.05837
Step 19165: loss = 0.07397
Step 19170: loss = 0.13766
Step 19175: loss = 0.06109
Step 19180: loss = 0.10678
Step 19185: loss = 0.15057
Step 19190: loss = 0.08141
Step 19195: loss = 0.09988
Step 19200: loss = 0.09939
Step 19205: loss = 0.10278
Step 19210: loss = 0.07817
Step 19215: loss = 0.08975
Step 19220: loss = 0.06644
Step 19225: loss = 0.19190
Step 19230: loss = 0.09539
Step 19235: loss = 0.15594
Step 19240: loss = 0.17674
Step 19245: loss = 0.12399
Step 19250: loss = 0.21329
Step 19255: loss = 0.09435
Step 19260: loss = 0.07122
Step 19265: loss = 0.13437
Step 19270: loss = 0.09005
Step 19275: loss = 0.13161
Step 19280: loss = 0.12201
Step 19285: loss = 0.12414
Step 19290: loss = 0.10428
Step 19295: loss = 0.10545
Step 19300: loss = 0.07984
Step 19305: loss = 0.05444
Step 19310: loss = 0.11582
Step 19315: loss = 0.06801
Step 19320: loss = 0.12265
Step 19325: loss = 0.09881
Step 19330: loss = 0.20399
Step 19335: loss = 0.09466
Step 19340: loss = 0.03508
Step 19345: loss = 0.04840
Step 19350: loss = 0.09005
Step 19355: loss = 0.07197
Step 19360: loss = 0.10909
Step 19365: loss = 0.30986
Step 19370: loss = 0.15318
Step 19375: loss = 0.08618
Step 19380: loss = 0.04645
Step 19385: loss = 0.15733
Step 19390: loss = 0.06616
Step 19395: loss = 0.09982
Step 19400: loss = 0.10504
Step 19405: loss = 0.07872
Step 19410: loss = 0.06700
Step 19415: loss = 0.09112
Step 19420: loss = 0.06575
Step 19425: loss = 0.06454
Step 19430: loss = 0.13737
Step 19435: loss = 0.27242
Step 19440: loss = 0.08994
Step 19445: loss = 0.09475
Step 19450: loss = 0.11975
Step 19455: loss = 0.03285
Step 19460: loss = 0.14737
Step 19465: loss = 0.26917
Step 19470: loss = 0.12864
Step 19475: loss = 0.09334
Step 19480: loss = 0.09315
Step 19485: loss = 0.18562
Step 19490: loss = 0.13180
Step 19495: loss = 0.06521
Step 19500: loss = 0.03751
Step 19505: loss = 0.10643
Step 19510: loss = 0.09832
Step 19515: loss = 0.24514
Step 19520: loss = 0.07780
Step 19525: loss = 0.18569
Step 19530: loss = 0.13151
Step 19535: loss = 0.16550
Step 19540: loss = 0.03709
Step 19545: loss = 0.16969
Step 19550: loss = 0.15742
Step 19555: loss = 0.15276
Step 19560: loss = 0.09780
Step 19565: loss = 0.15104
Step 19570: loss = 0.04171
Step 19575: loss = 0.16756
Step 19580: loss = 0.06309
Step 19585: loss = 0.15463
Step 19590: loss = 0.06600
Step 19595: loss = 0.11492
Step 19600: loss = 0.07031
Step 19605: loss = 0.06715
Step 19610: loss = 0.08197
Step 19615: loss = 0.03612
Step 19620: loss = 0.03169
Step 19625: loss = 0.10364
Step 19630: loss = 0.10142
Step 19635: loss = 0.16144
Step 19640: loss = 0.06260
Step 19645: loss = 0.10721
Step 19650: loss = 0.14358
Step 19655: loss = 0.12345
Step 19660: loss = 0.12772
Step 19665: loss = 0.06072
Step 19670: loss = 0.10733
Step 19675: loss = 0.10090
Step 19680: loss = 0.15450
Step 19685: loss = 0.08270
Step 19690: loss = 0.08219
Step 19695: loss = 0.23616
Step 19700: loss = 0.17244
Step 19705: loss = 0.15976
Step 19710: loss = 0.15145
Step 19715: loss = 0.15505
Step 19720: loss = 0.14162
Step 19725: loss = 0.07066
Step 19730: loss = 0.28667
Step 19735: loss = 0.05855
Step 19740: loss = 0.12153
Step 19745: loss = 0.07308
Step 19750: loss = 0.23096
Step 19755: loss = 0.08358
Step 19760: loss = 0.09193
Step 19765: loss = 0.03484
Step 19770: loss = 0.09913
Step 19775: loss = 0.07556
Step 19780: loss = 0.06609
Step 19785: loss = 0.14635
Step 19790: loss = 0.09771
Step 19795: loss = 0.06724
Step 19800: loss = 0.04047
Step 19805: loss = 0.15858
Step 19810: loss = 0.07979
Step 19815: loss = 0.04156
Step 19820: loss = 0.17975
Step 19825: loss = 0.07047
Step 19830: loss = 0.12940
Step 19835: loss = 0.09304
Step 19840: loss = 0.10813
Step 19845: loss = 0.18189
Step 19850: loss = 0.03036
Step 19855: loss = 0.08783
Step 19860: loss = 0.05445
Step 19865: loss = 0.07955
Step 19870: loss = 0.11997
Step 19875: loss = 0.09652
Step 19880: loss = 0.16046
Step 19885: loss = 0.07824
Step 19890: loss = 0.06461
Step 19895: loss = 0.07688
Step 19900: loss = 0.07202
Step 19905: loss = 0.21898
Step 19910: loss = 0.14671
Step 19915: loss = 0.09412
Step 19920: loss = 0.08192
Step 19925: loss = 0.16870
Step 19930: loss = 0.15158
Step 19935: loss = 0.10456
Step 19940: loss = 0.10051
Step 19945: loss = 0.14763
Step 19950: loss = 0.15403
Step 19955: loss = 0.11994
Step 19960: loss = 0.06422
Step 19965: loss = 0.12592
Step 19970: loss = 0.17222
Step 19975: loss = 0.08425
Step 19980: loss = 0.19983
Step 19985: loss = 0.08625
Step 19990: loss = 0.17935
Step 19995: loss = 0.07223
Step 20000: loss = 0.09403
Training Data Eval:
  Num examples: 50000, Num correct: 48579, Precision @ 1: 0.9716
('Testing Data Eval: EPOCH->', 21)
  Num examples: 10000, Num correct: 6782, Precision @ 1: 0.6782
Step 20005: loss = 0.12581
Step 20010: loss = 0.08228
Step 20015: loss = 0.07814
Step 20020: loss = 0.06084
Step 20025: loss = 0.08959
Step 20030: loss = 0.13247
Step 20035: loss = 0.05683
Step 20040: loss = 0.11426
Step 20045: loss = 0.20798
Step 20050: loss = 0.07568
Step 20055: loss = 0.07920
Step 20060: loss = 0.02790
Step 20065: loss = 0.03498
Step 20070: loss = 0.10038
Step 20075: loss = 0.08113
Step 20080: loss = 0.10606
Step 20085: loss = 0.06339
Step 20090: loss = 0.10645
Step 20095: loss = 0.08782
Step 20100: loss = 0.03938
Step 20105: loss = 0.06532
Step 20110: loss = 0.05701
Step 20115: loss = 0.10132
Step 20120: loss = 0.06472
Step 20125: loss = 0.11773
Step 20130: loss = 0.10271
Step 20135: loss = 0.15193
Step 20140: loss = 0.05951
Step 20145: loss = 0.07878
Step 20150: loss = 0.18384
Step 20155: loss = 0.10805
Step 20160: loss = 0.06502
Step 20165: loss = 0.13655
Step 20170: loss = 0.09581
Step 20175: loss = 0.10387
Step 20180: loss = 0.08223
Step 20185: loss = 0.06616
Step 20190: loss = 0.04594
Step 20195: loss = 0.07985
Step 20200: loss = 0.07480
Step 20205: loss = 0.10751
Step 20210: loss = 0.11761
Step 20215: loss = 0.06874
Step 20220: loss = 0.13608
Step 20225: loss = 0.13402
Step 20230: loss = 0.16921
Step 20235: loss = 0.08213
Step 20240: loss = 0.10532
Step 20245: loss = 0.12509
Step 20250: loss = 0.07709
Step 20255: loss = 0.03185
Step 20260: loss = 0.10241
Step 20265: loss = 0.08738
Step 20270: loss = 0.05752
Step 20275: loss = 0.20476
Step 20280: loss = 0.15844
Step 20285: loss = 0.08437
Step 20290: loss = 0.08339
Step 20295: loss = 0.04897
Step 20300: loss = 0.09152
Step 20305: loss = 0.06405
Step 20310: loss = 0.10631
Step 20315: loss = 0.11426
Step 20320: loss = 0.08806
Step 20325: loss = 0.17399
Step 20330: loss = 0.23244
Step 20335: loss = 0.10520
Step 20340: loss = 0.06664
Step 20345: loss = 0.08638
Step 20350: loss = 0.11783
Step 20355: loss = 0.08490
Step 20360: loss = 0.20407
Step 20365: loss = 0.10637
Step 20370: loss = 0.11019
Step 20375: loss = 0.08863
Step 20380: loss = 0.09978
Step 20385: loss = 0.13673
Step 20390: loss = 0.07723
Step 20395: loss = 0.16616
Step 20400: loss = 0.12688
Step 20405: loss = 0.09809
Step 20410: loss = 0.12660
Step 20415: loss = 0.04106
Step 20420: loss = 0.11654
Step 20425: loss = 0.06928
Step 20430: loss = 0.14522
Step 20435: loss = 0.19525
Step 20440: loss = 0.10731
Step 20445: loss = 0.04736
Step 20450: loss = 0.12828
Step 20455: loss = 0.16343
Step 20460: loss = 0.03698
Step 20465: loss = 0.06943
Step 20470: loss = 0.12827
Step 20475: loss = 0.08296
Step 20480: loss = 0.11992
Step 20485: loss = 0.08772
Step 20490: loss = 0.16336
Step 20495: loss = 0.06546
Step 20500: loss = 0.08482
Step 20505: loss = 0.06796
Step 20510: loss = 0.08563
Step 20515: loss = 0.05577
Step 20520: loss = 0.13181
Step 20525: loss = 0.13361
Step 20530: loss = 0.06683
Step 20535: loss = 0.29112
Step 20540: loss = 0.10143
Step 20545: loss = 0.06998
Step 20550: loss = 0.07961
Step 20555: loss = 0.12244
Step 20560: loss = 0.14673
Step 20565: loss = 0.09499
Step 20570: loss = 0.17327
Step 20575: loss = 0.17021
Step 20580: loss = 0.14726
Step 20585: loss = 0.14689
Step 20590: loss = 0.15667
Step 20595: loss = 0.09752
Step 20600: loss = 0.15139
Step 20605: loss = 0.06256
Step 20610: loss = 0.17895
Step 20615: loss = 0.03448
Step 20620: loss = 0.18397
Step 20625: loss = 0.10798
Step 20630: loss = 0.05041
Step 20635: loss = 0.09728
Step 20640: loss = 0.04913
Step 20645: loss = 0.25015
Step 20650: loss = 0.17311
Step 20655: loss = 0.12224
Step 20660: loss = 0.14181
Step 20665: loss = 0.04783
Step 20670: loss = 0.05346
Step 20675: loss = 0.09687
Step 20680: loss = 0.25431
Step 20685: loss = 0.15172
Step 20690: loss = 0.04472
Step 20695: loss = 0.12967
Step 20700: loss = 0.05930
Step 20705: loss = 0.07189
Step 20710: loss = 0.11771
Step 20715: loss = 0.19388
Step 20720: loss = 0.02325
Step 20725: loss = 0.08270
Step 20730: loss = 0.11785
Step 20735: loss = 0.01893
Step 20740: loss = 0.19770
Step 20745: loss = 0.07513
Step 20750: loss = 0.05032
Step 20755: loss = 0.14726
Step 20760: loss = 0.11934
Step 20765: loss = 0.12618
Step 20770: loss = 0.15239
Step 20775: loss = 0.15902
Step 20780: loss = 0.10544
Step 20785: loss = 0.12459
Step 20790: loss = 0.25889
Step 20795: loss = 0.05108
Step 20800: loss = 0.07587
Step 20805: loss = 0.28414
Step 20810: loss = 0.16976
Step 20815: loss = 0.04280
Step 20820: loss = 0.12299
Step 20825: loss = 0.15332
Step 20830: loss = 0.08634
Step 20835: loss = 0.11203
Step 20840: loss = 0.11063
Step 20845: loss = 0.12127
Step 20850: loss = 0.06423
Step 20855: loss = 0.16971
Step 20860: loss = 0.08051
Step 20865: loss = 0.18756
Step 20870: loss = 0.06669
Step 20875: loss = 0.06260
Step 20880: loss = 0.09121
Step 20885: loss = 0.06162
Step 20890: loss = 0.14507
Step 20895: loss = 0.07095
Step 20900: loss = 0.11669
Step 20905: loss = 0.31001
Step 20910: loss = 0.10566
Step 20915: loss = 0.23640
Step 20920: loss = 0.11157
Step 20925: loss = 0.11441
Step 20930: loss = 0.16467
Step 20935: loss = 0.09358
Step 20940: loss = 0.06611
Step 20945: loss = 0.11277
Step 20950: loss = 0.04988
Step 20955: loss = 0.12221
Step 20960: loss = 0.09149
Step 20965: loss = 0.07238
Step 20970: loss = 0.10639
Step 20975: loss = 0.04824
Step 20980: loss = 0.08846
Step 20985: loss = 0.06543
Step 20990: loss = 0.09901
Step 20995: loss = 0.08602
Step 21000: loss = 0.05172
Training Data Eval:
  Num examples: 50000, Num correct: 48452, Precision @ 1: 0.9690
('Testing Data Eval: EPOCH->', 22)
  Num examples: 10000, Num correct: 6837, Precision @ 1: 0.6837
Step 21005: loss = 0.05832
Step 21010: loss = 0.14254
Step 21015: loss = 0.12150
Step 21020: loss = 0.21172
Step 21025: loss = 0.13649
Step 21030: loss = 0.11012
Step 21035: loss = 0.05842
Step 21040: loss = 0.07778
Step 21045: loss = 0.18867
Step 21050: loss = 0.06339
Step 21055: loss = 0.05894
Step 21060: loss = 0.07228
Step 21065: loss = 0.07416
Step 21070: loss = 0.19127
Step 21075: loss = 0.12528
Step 21080: loss = 0.09849
Step 21085: loss = 0.03484
Step 21090: loss = 0.08458
Step 21095: loss = 0.07078
Step 21100: loss = 0.02870
Step 21105: loss = 0.09008
Step 21110: loss = 0.13062
Step 21115: loss = 0.06498
Step 21120: loss = 0.15888
Step 21125: loss = 0.05619
Step 21130: loss = 0.06756
Step 21135: loss = 0.04654
Step 21140: loss = 0.05453
Step 21145: loss = 0.07320
Step 21150: loss = 0.12345
Step 21155: loss = 0.08896
Step 21160: loss = 0.08011
Step 21165: loss = 0.06943
Step 21170: loss = 0.12743
Step 21175: loss = 0.06635
Step 21180: loss = 0.19048
Step 21185: loss = 0.12528
Step 21190: loss = 0.07474
Step 21195: loss = 0.07555
Step 21200: loss = 0.13071
Step 21205: loss = 0.07508
Step 21210: loss = 0.09419
Step 21215: loss = 0.03371
Step 21220: loss = 0.03853
Step 21225: loss = 0.07845
Step 21230: loss = 0.08558
Step 21235: loss = 0.07628
Step 21240: loss = 0.07529
Step 21245: loss = 0.04815
Step 21250: loss = 0.09334
Step 21255: loss = 0.10531
Step 21260: loss = 0.09270
Step 21265: loss = 0.12394
Step 21270: loss = 0.09593
Step 21275: loss = 0.08259
Step 21280: loss = 0.10191
Step 21285: loss = 0.04926
Step 21290: loss = 0.14049
Step 21295: loss = 0.06665
Step 21300: loss = 0.11351
Step 21305: loss = 0.06324
Step 21310: loss = 0.15154
Step 21315: loss = 0.21852
Step 21320: loss = 0.10073
Step 21325: loss = 0.08832
Step 21330: loss = 0.09965
Step 21335: loss = 0.12759
Step 21340: loss = 0.03832
Step 21345: loss = 0.09444
Step 21350: loss = 0.12726
Step 21355: loss = 0.05677
Step 21360: loss = 0.09048
Step 21365: loss = 0.06217
Step 21370: loss = 0.12693
Step 21375: loss = 0.35417
Step 21380: loss = 0.06436
Step 21385: loss = 0.09210
Step 21390: loss = 0.09079
Step 21395: loss = 0.15338
Step 21400: loss = 0.06365
Step 21405: loss = 0.07141
Step 21410: loss = 0.06557
Step 21415: loss = 0.08520
Step 21420: loss = 0.06652
Step 21425: loss = 0.11902
Step 21430: loss = 0.05454
Step 21435: loss = 0.07913
Step 21440: loss = 0.09533
Step 21445: loss = 0.08527
Step 21450: loss = 0.15865
Step 21455: loss = 0.11926
Step 21460: loss = 0.07794
Step 21465: loss = 0.18948
Step 21470: loss = 0.18768
Step 21475: loss = 0.19601
Step 21480: loss = 0.11369
Step 21485: loss = 0.08795
Step 21490: loss = 0.14004
Step 21495: loss = 0.08869
Step 21500: loss = 0.04379
Step 21505: loss = 0.18072
Step 21510: loss = 0.07341
Step 21515: loss = 0.13372
Step 21520: loss = 0.05164
Step 21525: loss = 0.06801
Step 21530: loss = 0.12406
Step 21535: loss = 0.05873
Step 21540: loss = 0.25814
Step 21545: loss = 0.19397
Step 21550: loss = 0.15149
Step 21555: loss = 0.04281
Step 21560: loss = 0.07558
Step 21565: loss = 0.07975
Step 21570: loss = 0.04011
Step 21575: loss = 0.05714
Step 21580: loss = 0.30314
Step 21585: loss = 0.10591
Step 21590: loss = 0.14575
Step 21595: loss = 0.12997
Step 21600: loss = 0.03473
Step 21605: loss = 0.12986
Step 21610: loss = 0.07659
Step 21615: loss = 0.10221
Step 21620: loss = 0.14698
Step 21625: loss = 0.08632
Step 21630: loss = 0.11743
Step 21635: loss = 0.13227
Step 21640: loss = 0.08134
Step 21645: loss = 0.13871
Step 21650: loss = 0.20312
Step 21655: loss = 0.17417
Step 21660: loss = 0.14194
Step 21665: loss = 0.07316
Step 21670: loss = 0.03170
Step 21675: loss = 0.25421
Step 21680: loss = 0.03438
Step 21685: loss = 0.05675
Step 21690: loss = 0.04095
Step 21695: loss = 0.14497
Step 21700: loss = 0.11522
Step 21705: loss = 0.09149
Step 21710: loss = 0.20845
Step 21715: loss = 0.13734
Step 21720: loss = 0.10554
Step 21725: loss = 0.12369
Step 21730: loss = 0.08920
Step 21735: loss = 0.18499
Step 21740: loss = 0.11668
Step 21745: loss = 0.08948
Step 21750: loss = 0.15605
Step 21755: loss = 0.13481
Step 21760: loss = 0.08959
Step 21765: loss = 0.13493
Step 21770: loss = 0.08243
Step 21775: loss = 0.09893
Step 21780: loss = 0.12732
Step 21785: loss = 0.08922
Step 21790: loss = 0.11992
Step 21795: loss = 0.09079
Step 21800: loss = 0.06991
Step 21805: loss = 0.13021
Step 21810: loss = 0.06492
Step 21815: loss = 0.12169
Step 21820: loss = 0.10298
Step 21825: loss = 0.16596
Step 21830: loss = 0.05478
Step 21835: loss = 0.13346
Step 21840: loss = 0.16734
Step 21845: loss = 0.05516
Step 21850: loss = 0.10317
Step 21855: loss = 0.10241
Step 21860: loss = 0.05537
Step 21865: loss = 0.19660
Step 21870: loss = 0.15666
Step 21875: loss = 0.09648
Step 21880: loss = 0.08371
Step 21885: loss = 0.22758
Step 21890: loss = 0.18191
Step 21895: loss = 0.09541
Step 21900: loss = 0.07940
Step 21905: loss = 0.06255
Step 21910: loss = 0.08027
Step 21915: loss = 0.15714
Step 21920: loss = 0.06469
Step 21925: loss = 0.18259
Step 21930: loss = 0.15525
Step 21935: loss = 0.11227
Step 21940: loss = 0.08779
Step 21945: loss = 0.06960
Step 21950: loss = 0.07782
Step 21955: loss = 0.09164
Step 21960: loss = 0.27605
Step 21965: loss = 0.12202
Step 21970: loss = 0.17404
Step 21975: loss = 0.08165
Step 21980: loss = 0.09956
Step 21985: loss = 0.07845
Step 21990: loss = 0.08951
Step 21995: loss = 0.19553
Step 22000: loss = 0.17248
Training Data Eval:
  Num examples: 50000, Num correct: 48373, Precision @ 1: 0.9675
('Testing Data Eval: EPOCH->', 23)
  Num examples: 10000, Num correct: 6800, Precision @ 1: 0.6800
Step 22005: loss = 0.05691
Step 22010: loss = 0.04396
Step 22015: loss = 0.10219
Step 22020: loss = 0.07583
Step 22025: loss = 0.07458
Step 22030: loss = 0.05240
Step 22035: loss = 0.08361
Step 22040: loss = 0.15910
Step 22045: loss = 0.08741
Step 22050: loss = 0.09068
Step 22055: loss = 0.18346
Step 22060: loss = 0.09819
Step 22065: loss = 0.02055
Step 22070: loss = 0.09679
Step 22075: loss = 0.05900
Step 22080: loss = 0.08385
Step 22085: loss = 0.08674
Step 22090: loss = 0.09568
Step 22095: loss = 0.09390
Step 22100: loss = 0.07358
Step 22105: loss = 0.08087
Step 22110: loss = 0.07073
Step 22115: loss = 0.06507
Step 22120: loss = 0.11071
Step 22125: loss = 0.10961
Step 22130: loss = 0.05436
Step 22135: loss = 0.04602
Step 22140: loss = 0.08634
Step 22145: loss = 0.09281
Step 22150: loss = 0.11116
Step 22155: loss = 0.12785
Step 22160: loss = 0.09895
Step 22165: loss = 0.10008
Step 22170: loss = 0.09104
Step 22175: loss = 0.12644
Step 22180: loss = 0.05895
Step 22185: loss = 0.07494
Step 22190: loss = 0.07506
Step 22195: loss = 0.15703
Step 22200: loss = 0.11774
Step 22205: loss = 0.15796
Step 22210: loss = 0.08974
Step 22215: loss = 0.06180
Step 22220: loss = 0.11085
Step 22225: loss = 0.13959
Step 22230: loss = 0.14433
Step 22235: loss = 0.27804
Step 22240: loss = 0.16198
Step 22245: loss = 0.04720
Step 22250: loss = 0.11788
Step 22255: loss = 0.03616
Step 22260: loss = 0.20808
Step 22265: loss = 0.10615
Step 22270: loss = 0.11398
Step 22275: loss = 0.13495
Step 22280: loss = 0.23139
Step 22285: loss = 0.11242
Step 22290: loss = 0.16407
Step 22295: loss = 0.07821
Step 22300: loss = 0.25985
Step 22305: loss = 0.07572
Step 22310: loss = 0.12226
Step 22315: loss = 0.09477
Step 22320: loss = 0.13161
Step 22325: loss = 0.14966
Step 22330: loss = 0.07894
Step 22335: loss = 0.16345
Step 22340: loss = 0.13448
Step 22345: loss = 0.14775
Step 22350: loss = 0.05245
Step 22355: loss = 0.13095
Step 22360: loss = 0.09896
Step 22365: loss = 0.08408
Step 22370: loss = 0.13170
Step 22375: loss = 0.18991
Step 22380: loss = 0.05656
Step 22385: loss = 0.16224
Step 22390: loss = 0.09656
Step 22395: loss = 0.10747
Step 22400: loss = 0.10257
Step 22405: loss = 0.05676
Step 22410: loss = 0.07070
Step 22415: loss = 0.05893
Step 22420: loss = 0.05120
Step 22425: loss = 0.07222
Step 22430: loss = 0.07464
Step 22435: loss = 0.09622
Step 22440: loss = 0.12919
Step 22445: loss = 0.13037
Step 22450: loss = 0.14022
Step 22455: loss = 0.05626
Step 22460: loss = 0.03251
Step 22465: loss = 0.12299
Step 22470: loss = 0.10256
Step 22475: loss = 0.17918
Step 22480: loss = 0.07278
Step 22485: loss = 0.14718
Step 22490: loss = 0.05603
Step 22495: loss = 0.06295
Step 22500: loss = 0.12655
Step 22505: loss = 0.11223
Step 22510: loss = 0.15267
Step 22515: loss = 0.09694
Step 22520: loss = 0.16306
Step 22525: loss = 0.08079
Step 22530: loss = 0.06031
Step 22535: loss = 0.01785
Step 22540: loss = 0.08862
Step 22545: loss = 0.06523
Step 22550: loss = 0.13575
Step 22555: loss = 0.14131
Step 22560: loss = 0.07150
Step 22565: loss = 0.15360
Step 22570: loss = 0.11067
Step 22575: loss = 0.05466
Step 22580: loss = 0.05997
Step 22585: loss = 0.14411
Step 22590: loss = 0.11597
Step 22595: loss = 0.11737
Step 22600: loss = 0.07940
Step 22605: loss = 0.09320
Step 22610: loss = 0.05980
Step 22615: loss = 0.03221
Step 22620: loss = 0.03468
Step 22625: loss = 0.22755
Step 22630: loss = 0.18506
Step 22635: loss = 0.05954
Step 22640: loss = 0.06953
Step 22645: loss = 0.19986
Step 22650: loss = 0.07261
Step 22655: loss = 0.37077
Step 22660: loss = 0.17596
Step 22665: loss = 0.10214
Step 22670: loss = 0.08646
Step 22675: loss = 0.10875
Step 22680: loss = 0.07585
Step 22685: loss = 0.16891
Step 22690: loss = 0.11607
Step 22695: loss = 0.06671
Step 22700: loss = 0.08242
Step 22705: loss = 0.05802
Step 22710: loss = 0.14208
Step 22715: loss = 0.07273
Step 22720: loss = 0.22322
Step 22725: loss = 0.10576
Step 22730: loss = 0.09208
Step 22735: loss = 0.09166
Step 22740: loss = 0.21005
Step 22745: loss = 0.30773
Step 22750: loss = 0.11734
Step 22755: loss = 0.20633
Step 22760: loss = 0.05913
Step 22765: loss = 0.13098
Step 22770: loss = 0.14430
Step 22775: loss = 0.13874
Step 22780: loss = 0.03049
Step 22785: loss = 0.16521
Step 22790: loss = 0.13621
Step 22795: loss = 0.16292
Step 22800: loss = 0.07750
Step 22805: loss = 0.04787
Step 22810: loss = 0.08358
Step 22815: loss = 0.06979
Step 22820: loss = 0.07541
Step 22825: loss = 0.07226
Step 22830: loss = 0.18167
Step 22835: loss = 0.11966
Step 22840: loss = 0.14597
Step 22845: loss = 0.06105
Step 22850: loss = 0.06728
Step 22855: loss = 0.08982
Step 22860: loss = 0.04535
Step 22865: loss = 0.06236
Step 22870: loss = 0.15614
Step 22875: loss = 0.17836
Step 22880: loss = 0.06421
Step 22885: loss = 0.24500
Step 22890: loss = 0.05747
Step 22895: loss = 0.13961
Step 22900: loss = 0.02943
Step 22905: loss = 0.12705
Step 22910: loss = 0.10944
Step 22915: loss = 0.07050
Step 22920: loss = 0.06464
Step 22925: loss = 0.13425
Step 22930: loss = 0.10440
Step 22935: loss = 0.23195
Step 22940: loss = 0.11639
Step 22945: loss = 0.21702
Step 22950: loss = 0.10951
Step 22955: loss = 0.12166
Step 22960: loss = 0.15770
Step 22965: loss = 0.30031
Step 22970: loss = 0.06329
Step 22975: loss = 0.13385
Step 22980: loss = 0.07799
Step 22985: loss = 0.08918
Step 22990: loss = 0.10992
Step 22995: loss = 0.19956
Step 23000: loss = 0.05104
Training Data Eval:
  Num examples: 50000, Num correct: 48597, Precision @ 1: 0.9719
('Testing Data Eval: EPOCH->', 24)
  Num examples: 10000, Num correct: 6746, Precision @ 1: 0.6746
Step 23005: loss = 0.11984
Step 23010: loss = 0.17039
Step 23015: loss = 0.14558
Step 23020: loss = 0.11076
Step 23025: loss = 0.05840
Step 23030: loss = 0.04661
Step 23035: loss = 0.05090
Step 23040: loss = 0.10530
Step 23045: loss = 0.08464
Step 23050: loss = 0.07484
Step 23055: loss = 0.11721
Step 23060: loss = 0.08316
Step 23065: loss = 0.06347
Step 23070: loss = 0.11137
Step 23075: loss = 0.05916
Step 23080: loss = 0.04542
Step 23085: loss = 0.02538
Step 23090: loss = 0.03918
Step 23095: loss = 0.03874
Step 23100: loss = 0.07600
Step 23105: loss = 0.06897
Step 23110: loss = 0.02198
Step 23115: loss = 0.01508
Step 23120: loss = 0.10648
Step 23125: loss = 0.08694
Step 23130: loss = 0.06080
Step 23135: loss = 0.08427
Step 23140: loss = 0.19000
Step 23145: loss = 0.10670
Step 23150: loss = 0.15959
Step 23155: loss = 0.26059
Step 23160: loss = 0.04251
Step 23165: loss = 0.08949
Step 23170: loss = 0.13819
Step 23175: loss = 0.13587
Step 23180: loss = 0.23539
Step 23185: loss = 0.12487
Step 23190: loss = 0.06000
Step 23195: loss = 0.10097
Step 23200: loss = 0.17382
Step 23205: loss = 0.05449
Step 23210: loss = 0.20893
Step 23215: loss = 0.08845
Step 23220: loss = 0.04808
Step 23225: loss = 0.21484
Step 23230: loss = 0.14124
Step 23235: loss = 0.03282
Step 23240: loss = 0.04951
Step 23245: loss = 0.11272
Step 23250: loss = 0.03758
Step 23255: loss = 0.01569
Step 23260: loss = 0.06479
Step 23265: loss = 0.17260
Step 23270: loss = 0.22556
Step 23275: loss = 0.08593
Step 23280: loss = 0.09156
Step 23285: loss = 0.08025
Step 23290: loss = 0.18059
Step 23295: loss = 0.05312
Step 23300: loss = 0.17513
Step 23305: loss = 0.10444
Step 23310: loss = 0.11082
Step 23315: loss = 0.04861
Step 23320: loss = 0.13444
Step 23325: loss = 0.02522
Step 23330: loss = 0.05711
Step 23335: loss = 0.07586
Step 23340: loss = 0.11102
Step 23345: loss = 0.10039
Step 23350: loss = 0.07140
Step 23355: loss = 0.04208
Step 23360: loss = 0.04330
Step 23365: loss = 0.09065
Step 23370: loss = 0.07713
Step 23375: loss = 0.05040
Step 23380: loss = 0.09114
Step 23385: loss = 0.14586
Step 23390: loss = 0.03670
Step 23395: loss = 0.07117
Step 23400: loss = 0.08835
Step 23405: loss = 0.09964
Step 23410: loss = 0.08871
Step 23415: loss = 0.06739
Step 23420: loss = 0.11327
Step 23425: loss = 0.05243
Step 23430: loss = 0.17217
Step 23435: loss = 0.06523
Step 23440: loss = 0.10067
Step 23445: loss = 0.09674
Step 23450: loss = 0.05485
Step 23455: loss = 0.08990
Step 23460: loss = 0.13072
Step 23465: loss = 0.06563
Step 23470: loss = 0.03444
Step 23475: loss = 0.07172
Step 23480: loss = 0.11272
Step 23485: loss = 0.02049
Step 23490: loss = 0.05468
Step 23495: loss = 0.08551
Step 23500: loss = 0.09779
Step 23505: loss = 0.22930
Step 23510: loss = 0.08251
Step 23515: loss = 0.04951
Step 23520: loss = 0.04042
Step 23525: loss = 0.13283
Step 23530: loss = 0.08289
Step 23535: loss = 0.19273
Step 23540: loss = 0.11712
Step 23545: loss = 0.09228
Step 23550: loss = 0.12753
Step 23555: loss = 0.10699
Step 23560: loss = 0.06515
Step 23565: loss = 0.06773
Step 23570: loss = 0.11744
Step 23575: loss = 0.08552
Step 23580: loss = 0.13157
Step 23585: loss = 0.08576
Step 23590: loss = 0.14433
Step 23595: loss = 0.20048
Step 23600: loss = 0.05022
Step 23605: loss = 0.11090
Step 23610: loss = 0.18575
Step 23615: loss = 0.05999
Step 23620: loss = 0.14053
Step 23625: loss = 0.09795
Step 23630: loss = 0.11918
Step 23635: loss = 0.11786
Step 23640: loss = 0.06148
Step 23645: loss = 0.18178
Step 23650: loss = 0.04800
Step 23655: loss = 0.08997
Step 23660: loss = 0.06501
Step 23665: loss = 0.05282
Step 23670: loss = 0.17299
Step 23675: loss = 0.07996
Step 23680: loss = 0.12823
Step 23685: loss = 0.09548
Step 23690: loss = 0.06379
Step 23695: loss = 0.27182
Step 23700: loss = 0.09124
Step 23705: loss = 0.04467
Step 23710: loss = 0.11476
Step 23715: loss = 0.10046
Step 23720: loss = 0.05683
Step 23725: loss = 0.11041
Step 23730: loss = 0.07796
Step 23735: loss = 0.05544
Step 23740: loss = 0.08184
Step 23745: loss = 0.10215
Step 23750: loss = 0.11258
Step 23755: loss = 0.08714
Step 23760: loss = 0.05202
Step 23765: loss = 0.05610
Step 23770: loss = 0.14389
Step 23775: loss = 0.09834
Step 23780: loss = 0.10415
Step 23785: loss = 0.19586
Step 23790: loss = 0.05667
Step 23795: loss = 0.05381
Step 23800: loss = 0.14149
Step 23805: loss = 0.10028
Step 23810: loss = 0.09162
Step 23815: loss = 0.14626
Step 23820: loss = 0.13230
Step 23825: loss = 0.10635
Step 23830: loss = 0.04855
Step 23835: loss = 0.11445
Step 23840: loss = 0.05249
Step 23845: loss = 0.09871
Step 23850: loss = 0.02037
Step 23855: loss = 0.05376
Step 23860: loss = 0.12084
Step 23865: loss = 0.04259
Step 23870: loss = 0.05933
Step 23875: loss = 0.19337
Step 23880: loss = 0.06784
Step 23885: loss = 0.13201
Step 23890: loss = 0.02911
Step 23895: loss = 0.11634
Step 23900: loss = 0.22858
Step 23905: loss = 0.14688
Step 23910: loss = 0.11893
Step 23915: loss = 0.05453
Step 23920: loss = 0.03639
Step 23925: loss = 0.07717
Step 23930: loss = 0.15624
Step 23935: loss = 0.06163
Step 23940: loss = 0.08983
Step 23945: loss = 0.14731
Step 23950: loss = 0.09892
Step 23955: loss = 0.09909
Step 23960: loss = 0.06996
Step 23965: loss = 0.19985
Step 23970: loss = 0.05420
Step 23975: loss = 0.02960
Step 23980: loss = 0.09482
Step 23985: loss = 0.13267
Step 23990: loss = 0.17470
Step 23995: loss = 0.12908
Step 24000: loss = 0.06019
Training Data Eval:
  Num examples: 50000, Num correct: 48804, Precision @ 1: 0.9761
('Testing Data Eval: EPOCH->', 25)
  Num examples: 10000, Num correct: 6860, Precision @ 1: 0.6860
Step 24005: loss = 0.17143
Step 24010: loss = 0.09307
Step 24015: loss = 0.08532
Step 24020: loss = 0.05764
Step 24025: loss = 0.11776
Step 24030: loss = 0.10156
Step 24035: loss = 0.06921
Step 24040: loss = 0.14982
Step 24045: loss = 0.02914
Step 24050: loss = 0.12944
Step 24055: loss = 0.03759
Step 24060: loss = 0.06550
Step 24065: loss = 0.07555
Step 24070: loss = 0.08882
Step 24075: loss = 0.08305
Step 24080: loss = 0.11427
Step 24085: loss = 0.06165
Step 24090: loss = 0.06397
Step 24095: loss = 0.03137
Step 24100: loss = 0.09121
Step 24105: loss = 0.10079
Step 24110: loss = 0.10530
Step 24115: loss = 0.07567
Step 24120: loss = 0.09970
Step 24125: loss = 0.08742
Step 24130: loss = 0.08623
Step 24135: loss = 0.06210
Step 24140: loss = 0.06781
Step 24145: loss = 0.04026
Step 24150: loss = 0.10437
Step 24155: loss = 0.05028
Step 24160: loss = 0.10351
Step 24165: loss = 0.05334
Step 24170: loss = 0.11145
Step 24175: loss = 0.13561
Step 24180: loss = 0.07259
Step 24185: loss = 0.05155
Step 24190: loss = 0.08143
Step 24195: loss = 0.05084
Step 24200: loss = 0.03625
Step 24205: loss = 0.03217
Step 24210: loss = 0.05256
Step 24215: loss = 0.22715
Step 24220: loss = 0.11647
Step 24225: loss = 0.04423
Step 24230: loss = 0.04138
Step 24235: loss = 0.12865
Step 24240: loss = 0.06467
Step 24245: loss = 0.09505
Step 24250: loss = 0.05732
Step 24255: loss = 0.13884
Step 24260: loss = 0.06359
Step 24265: loss = 0.03728
Step 24270: loss = 0.12293
Step 24275: loss = 0.08565
Step 24280: loss = 0.09488
Step 24285: loss = 0.12062
Step 24290: loss = 0.10265
Step 24295: loss = 0.12321
Step 24300: loss = 0.06046
Step 24305: loss = 0.07343
Step 24310: loss = 0.08229
Step 24315: loss = 0.06821
Step 24320: loss = 0.06091
Step 24325: loss = 0.14822
Step 24330: loss = 0.12711
Step 24335: loss = 0.03828
Step 24340: loss = 0.22338
Step 24345: loss = 0.04322
Step 24350: loss = 0.10609
Step 24355: loss = 0.06990
Step 24360: loss = 0.01675
Step 24365: loss = 0.04961
Step 24370: loss = 0.09238
Step 24375: loss = 0.06134
Step 24380: loss = 0.04876
Step 24385: loss = 0.04195
Step 24390: loss = 0.04850
Step 24395: loss = 0.04658
Step 24400: loss = 0.10027
Step 24405: loss = 0.10405
Step 24410: loss = 0.07460
Step 24415: loss = 0.04350
Step 24420: loss = 0.08520
Step 24425: loss = 0.07192
Step 24430: loss = 0.11716
Step 24435: loss = 0.05306
Step 24440: loss = 0.03748
Step 24445: loss = 0.02663
Step 24450: loss = 0.11403
Step 24455: loss = 0.08465
Step 24460: loss = 0.06941
Step 24465: loss = 0.08397
Step 24470: loss = 0.04770
Step 24475: loss = 0.06189
Step 24480: loss = 0.07500
Step 24485: loss = 0.03672
Step 24490: loss = 0.12684
Step 24495: loss = 0.10383
Step 24500: loss = 0.05730
Step 24505: loss = 0.06044
Step 24510: loss = 0.04248
Step 24515: loss = 0.04611
Step 24520: loss = 0.03726
Step 24525: loss = 0.10788
Step 24530: loss = 0.06927
Step 24535: loss = 0.07284
Step 24540: loss = 0.03444
Step 24545: loss = 0.06505
Step 24550: loss = 0.05952
Step 24555: loss = 0.13254
Step 24560: loss = 0.09203
Step 24565: loss = 0.06469
Step 24570: loss = 0.07294
Step 24575: loss = 0.02856
Step 24580: loss = 0.06400
Step 24585: loss = 0.09604
Step 24590: loss = 0.05996
Step 24595: loss = 0.09022
Step 24600: loss = 0.07617
Step 24605: loss = 0.09365
Step 24610: loss = 0.07325
Step 24615: loss = 0.19507
Step 24620: loss = 0.15968
Step 24625: loss = 0.05688
Step 24630: loss = 0.05184
Step 24635: loss = 0.09738
Step 24640: loss = 0.09121
Step 24645: loss = 0.08910
Step 24650: loss = 0.06035
Step 24655: loss = 0.05101
Step 24660: loss = 0.09512
Step 24665: loss = 0.07118
Step 24670: loss = 0.09764
Step 24675: loss = 0.06229
Step 24680: loss = 0.13523
Step 24685: loss = 0.09159
Step 24690: loss = 0.09995
Step 24695: loss = 0.10926
Step 24700: loss = 0.24227
Step 24705: loss = 0.11560
Step 24710: loss = 0.12503
Step 24715: loss = 0.04052
Step 24720: loss = 0.14687
Step 24725: loss = 0.09912
Step 24730: loss = 0.04019
Step 24735: loss = 0.05092
Step 24740: loss = 0.12783
Step 24745: loss = 0.09749
Step 24750: loss = 0.04895
Step 24755: loss = 0.06394
Step 24760: loss = 0.11869
Step 24765: loss = 0.10450
Step 24770: loss = 0.11140
Step 24775: loss = 0.04396
Step 24780: loss = 0.04437
Step 24785: loss = 0.14424
Step 24790: loss = 0.08598
Step 24795: loss = 0.08031
Step 24800: loss = 0.03735
Step 24805: loss = 0.13591
Step 24810: loss = 0.08469
Step 24815: loss = 0.16556
Step 24820: loss = 0.07375
Step 24825: loss = 0.03444
Step 24830: loss = 0.05649
Step 24835: loss = 0.15577
Step 24840: loss = 0.10275
Step 24845: loss = 0.12367
Step 24850: loss = 0.11853
Step 24855: loss = 0.04907
Step 24860: loss = 0.13043
Step 24865: loss = 0.04501
Step 24870: loss = 0.10671
Step 24875: loss = 0.05651
Step 24880: loss = 0.06735
Step 24885: loss = 0.04228
Step 24890: loss = 0.08890
Step 24895: loss = 0.16043
Step 24900: loss = 0.15085
Step 24905: loss = 0.09533
Step 24910: loss = 0.12088
Step 24915: loss = 0.23395
Step 24920: loss = 0.06746
Step 24925: loss = 0.05365
Step 24930: loss = 0.11068
Step 24935: loss = 0.12891
Step 24940: loss = 0.09952
Step 24945: loss = 0.02339
Step 24950: loss = 0.10305
Step 24955: loss = 0.17849
Step 24960: loss = 0.12761
Step 24965: loss = 0.12401
Step 24970: loss = 0.06828
Step 24975: loss = 0.15428
Step 24980: loss = 0.03057
Step 24985: loss = 0.08940
Step 24990: loss = 0.04738
Step 24995: loss = 0.06504
Step 25000: loss = 0.06713
Training Data Eval:
  Num examples: 50000, Num correct: 48886, Precision @ 1: 0.9777
('Testing Data Eval: EPOCH->', 26)
  Num examples: 10000, Num correct: 6815, Precision @ 1: 0.6815
Step 25005: loss = 0.11686
Step 25010: loss = 0.04808
Step 25015: loss = 0.04344
Step 25020: loss = 0.16656
Step 25025: loss = 0.09059
Step 25030: loss = 0.05044
Step 25035: loss = 0.02686
Step 25040: loss = 0.12451
Step 25045: loss = 0.06773
Step 25050: loss = 0.07699
Step 25055: loss = 0.02727
Step 25060: loss = 0.01952
Step 25065: loss = 0.05685
Step 25070: loss = 0.14395
Step 25075: loss = 0.03665
Step 25080: loss = 0.03127
Step 25085: loss = 0.07250
Step 25090: loss = 0.27503
Step 25095: loss = 0.07943
Step 25100: loss = 0.01419
Step 25105: loss = 0.04797
Step 25110: loss = 0.08791
Step 25115: loss = 0.03405
Step 25120: loss = 0.19117
Step 25125: loss = 0.05049
Step 25130: loss = 0.07514
Step 25135: loss = 0.14433
Step 25140: loss = 0.23013
Step 25145: loss = 0.03864
Step 25150: loss = 0.07721
Step 25155: loss = 0.05382
Step 25160: loss = 0.04083
Step 25165: loss = 0.03281
Step 25170: loss = 0.11624
Step 25175: loss = 0.05267
Step 25180: loss = 0.14982
Step 25185: loss = 0.05069
Step 25190: loss = 0.07336
Step 25195: loss = 0.01894
Step 25200: loss = 0.11662
Step 25205: loss = 0.06116
Step 25210: loss = 0.13712
Step 25215: loss = 0.12212
Step 25220: loss = 0.06532
Step 25225: loss = 0.10113
Step 25230: loss = 0.06105
Step 25235: loss = 0.07954
Step 25240: loss = 0.04716
Step 25245: loss = 0.13891
Step 25250: loss = 0.05463
Step 25255: loss = 0.12406
Step 25260: loss = 0.09502
Step 25265: loss = 0.10010
Step 25270: loss = 0.06839
Step 25275: loss = 0.02572
Step 25280: loss = 0.05171
Step 25285: loss = 0.05999
Step 25290: loss = 0.10989
Step 25295: loss = 0.12303
Step 25300: loss = 0.03711
Step 25305: loss = 0.10651
Step 25310: loss = 0.07941
Step 25315: loss = 0.05663
Step 25320: loss = 0.03243
Step 25325: loss = 0.12278
Step 25330: loss = 0.04889
Step 25335: loss = 0.19137
Step 25340: loss = 0.05242
Step 25345: loss = 0.02736
Step 25350: loss = 0.08082
Step 25355: loss = 0.14780
Step 25360: loss = 0.07447
Step 25365: loss = 0.09221
Step 25370: loss = 0.01525
Step 25375: loss = 0.05691
Step 25380: loss = 0.02718
Step 25385: loss = 0.07117
Step 25390: loss = 0.02631
Step 25395: loss = 0.06677
Step 25400: loss = 0.10184
Step 25405: loss = 0.08914
Step 25410: loss = 0.04271
Step 25415: loss = 0.11999
Step 25420: loss = 0.03384
Step 25425: loss = 0.07195
Step 25430: loss = 0.06295
Step 25435: loss = 0.12304
Step 25440: loss = 0.13850
Step 25445: loss = 0.05928
Step 25450: loss = 0.04918
Step 25455: loss = 0.12637
Step 25460: loss = 0.11852
Step 25465: loss = 0.04055
Step 25470: loss = 0.07065
Step 25475: loss = 0.11273
Step 25480: loss = 0.07091
Step 25485: loss = 0.06741
Step 25490: loss = 0.06846
Step 25495: loss = 0.07580
Step 25500: loss = 0.03615
Step 25505: loss = 0.06389
Step 25510: loss = 0.13376
Step 25515: loss = 0.13392
Step 25520: loss = 0.05728
Step 25525: loss = 0.04607
Step 25530: loss = 0.08723
Step 25535: loss = 0.04736
Step 25540: loss = 0.12336
Step 25545: loss = 0.04618
Step 25550: loss = 0.07128
Step 25555: loss = 0.11916
Step 25560: loss = 0.19775
Step 25565: loss = 0.11035
Step 25570: loss = 0.12181
Step 25575: loss = 0.16907
Step 25580: loss = 0.05091
Step 25585: loss = 0.04812
Step 25590: loss = 0.10646
Step 25595: loss = 0.29833
Step 25600: loss = 0.10463
Step 25605: loss = 0.05595
Step 25610: loss = 0.11764
Step 25615: loss = 0.11433
Step 25620: loss = 0.05350
Step 25625: loss = 0.11784
Step 25630: loss = 0.04533
Step 25635: loss = 0.03890
Step 25640: loss = 0.09557
Step 25645: loss = 0.07741
Step 25650: loss = 0.05979
Step 25655: loss = 0.06448
Step 25660: loss = 0.08942
Step 25665: loss = 0.10860
Step 25670: loss = 0.04876
Step 25675: loss = 0.07395
Step 25680: loss = 0.10559
Step 25685: loss = 0.08140
Step 25690: loss = 0.02077
Step 25695: loss = 0.07279
Step 25700: loss = 0.07470
Step 25705: loss = 0.06420
Step 25710: loss = 0.02709
Step 25715: loss = 0.04962
Step 25720: loss = 0.03074
Step 25725: loss = 0.03788
Step 25730: loss = 0.03724
Step 25735: loss = 0.15944
Step 25740: loss = 0.05424
Step 25745: loss = 0.09757
Step 25750: loss = 0.04023
Step 25755: loss = 0.08133
Step 25760: loss = 0.02434
Step 25765: loss = 0.02352
Step 25770: loss = 0.06399
Step 25775: loss = 0.14001
Step 25780: loss = 0.02577
Step 25785: loss = 0.02623
Step 25790: loss = 0.13495
Step 25795: loss = 0.05675
Step 25800: loss = 0.04894
Step 25805: loss = 0.06579
Step 25810: loss = 0.04827
Step 25815: loss = 0.03969
Step 25820: loss = 0.04810
Step 25825: loss = 0.04301
Step 25830: loss = 0.06812
Step 25835: loss = 0.04146
Step 25840: loss = 0.05028
Step 25845: loss = 0.07239
Step 25850: loss = 0.09998
Step 25855: loss = 0.03457
Step 25860: loss = 0.04166
Step 25865: loss = 0.02515
Step 25870: loss = 0.11074
Step 25875: loss = 0.02164
Step 25880: loss = 0.09016
Step 25885: loss = 0.01959
Step 25890: loss = 0.02920
Step 25895: loss = 0.07550
Step 25900: loss = 0.04922
Step 25905: loss = 0.08248
Step 25910: loss = 0.08810
Step 25915: loss = 0.02888
Step 25920: loss = 0.06427
Step 25925: loss = 0.07002
Step 25930: loss = 0.02616
Step 25935: loss = 0.04618
Step 25940: loss = 0.17140
Step 25945: loss = 0.05098
Step 25950: loss = 0.06105
Step 25955: loss = 0.06775
Step 25960: loss = 0.11891
Step 25965: loss = 0.09017
Step 25970: loss = 0.04272
Step 25975: loss = 0.07785
Step 25980: loss = 0.08881
Step 25985: loss = 0.15580
Step 25990: loss = 0.06452
Step 25995: loss = 0.14386
Step 26000: loss = 0.02081
Training Data Eval:
  Num examples: 50000, Num correct: 48888, Precision @ 1: 0.9778
('Testing Data Eval: EPOCH->', 27)
  Num examples: 10000, Num correct: 6759, Precision @ 1: 0.6759
Step 26005: loss = 0.06177
Step 26010: loss = 0.04051
Step 26015: loss = 0.07386
Step 26020: loss = 0.07768
Step 26025: loss = 0.15616
Step 26030: loss = 0.11447
Step 26035: loss = 0.12713
Step 26040: loss = 0.03034
Step 26045: loss = 0.14187
Step 26050: loss = 0.08107
Step 26055: loss = 0.11711
Step 26060: loss = 0.03285
Step 26065: loss = 0.13140
Step 26070: loss = 0.04091
Step 26075: loss = 0.06980
Step 26080: loss = 0.07822
Step 26085: loss = 0.12504
Step 26090: loss = 0.11632
Step 26095: loss = 0.04460
Step 26100: loss = 0.02382
Step 26105: loss = 0.12101
Step 26110: loss = 0.02201
Step 26115: loss = 0.03423
Step 26120: loss = 0.02095
Step 26125: loss = 0.07376
Step 26130: loss = 0.13269
Step 26135: loss = 0.05104
Step 26140: loss = 0.03478
Step 26145: loss = 0.10339
Step 26150: loss = 0.10878
Step 26155: loss = 0.13933
Step 26160: loss = 0.14676
Step 26165: loss = 0.10026
Step 26170: loss = 0.12147
Step 26175: loss = 0.08660
Step 26180: loss = 0.10482
Step 26185: loss = 0.11934
Step 26190: loss = 0.05931
Step 26195: loss = 0.08985
Step 26200: loss = 0.03737
Step 26205: loss = 0.03627
Step 26210: loss = 0.04282
Step 26215: loss = 0.03938
Step 26220: loss = 0.15181
Step 26225: loss = 0.08463
Step 26230: loss = 0.01885
Step 26235: loss = 0.09749
Step 26240: loss = 0.04207
Step 26245: loss = 0.05644
Step 26250: loss = 0.07860
Step 26255: loss = 0.06038
Step 26260: loss = 0.04376
Step 26265: loss = 0.07080
Step 26270: loss = 0.02914
Step 26275: loss = 0.01764
Step 26280: loss = 0.12324
Step 26285: loss = 0.03064
Step 26290: loss = 0.08499
Step 26295: loss = 0.09943
Step 26300: loss = 0.03631
Step 26305: loss = 0.04480
Step 26310: loss = 0.03266
Step 26315: loss = 0.05968
Step 26320: loss = 0.05855
Step 26325: loss = 0.04960
Step 26330: loss = 0.04964
Step 26335: loss = 0.17774
Step 26340: loss = 0.09171
Step 26345: loss = 0.03975
Step 26350: loss = 0.04395
Step 26355: loss = 0.03145
Step 26360: loss = 0.05181
Step 26365: loss = 0.09025
Step 26370: loss = 0.04101
Step 26375: loss = 0.15544
Step 26380: loss = 0.11968
Step 26385: loss = 0.13065
Step 26390: loss = 0.10611
Step 26395: loss = 0.06431
Step 26400: loss = 0.13919
Step 26405: loss = 0.05546
Step 26410: loss = 0.03261
Step 26415: loss = 0.08187
Step 26420: loss = 0.06748
Step 26425: loss = 0.05864
Step 26430: loss = 0.04178
Step 26435: loss = 0.08874
Step 26440: loss = 0.13325
Step 26445: loss = 0.10314
Step 26450: loss = 0.08851
Step 26455: loss = 0.19328
Step 26460: loss = 0.04210
Step 26465: loss = 0.23407
Step 26470: loss = 0.08818
Step 26475: loss = 0.11411
Step 26480: loss = 0.01416
Step 26485: loss = 0.04215
Step 26490: loss = 0.14044
Step 26495: loss = 0.07864
Step 26500: loss = 0.05768
Step 26505: loss = 0.13823
Step 26510: loss = 0.08074
Step 26515: loss = 0.14794
Step 26520: loss = 0.06582
Step 26525: loss = 0.03209
Step 26530: loss = 0.08157
Step 26535: loss = 0.06057
Step 26540: loss = 0.02673
Step 26545: loss = 0.03954
Step 26550: loss = 0.05787
Step 26555: loss = 0.10352
Step 26560: loss = 0.03382
Step 26565: loss = 0.10721
Step 26570: loss = 0.06304
Step 26575: loss = 0.05568
Step 26580: loss = 0.04775
Step 26585: loss = 0.03853
Step 26590: loss = 0.02355
Step 26595: loss = 0.05812
Step 26600: loss = 0.05198
Step 26605: loss = 0.07318
Step 26610: loss = 0.05687
Step 26615: loss = 0.04667
Step 26620: loss = 0.09869
Step 26625: loss = 0.11569
Step 26630: loss = 0.10702
Step 26635: loss = 0.12073
Step 26640: loss = 0.07740
Step 26645: loss = 0.05393
Step 26650: loss = 0.15003
Step 26655: loss = 0.06870
Step 26660: loss = 0.08864
Step 26665: loss = 0.04358
Step 26670: loss = 0.06721
Step 26675: loss = 0.17363
Step 26680: loss = 0.11860
Step 26685: loss = 0.11215
Step 26690: loss = 0.18806
Step 26695: loss = 0.07722
Step 26700: loss = 0.12408
Step 26705: loss = 0.04946
Step 26710: loss = 0.08266
Step 26715: loss = 0.11699
Step 26720: loss = 0.14931
Step 26725: loss = 0.08552
Step 26730: loss = 0.08176
Step 26735: loss = 0.07063
Step 26740: loss = 0.05538
Step 26745: loss = 0.05474
Step 26750: loss = 0.08607
Step 26755: loss = 0.12987
Step 26760: loss = 0.04663
Step 26765: loss = 0.04000
Step 26770: loss = 0.05751
Step 26775: loss = 0.10585
Step 26780: loss = 0.07201
Step 26785: loss = 0.30552
Step 26790: loss = 0.09464
Step 26795: loss = 0.02785
Step 26800: loss = 0.18132
Step 26805: loss = 0.06252
Step 26810: loss = 0.06887
Step 26815: loss = 0.04372
Step 26820: loss = 0.09844
Step 26825: loss = 0.03281
Step 26830: loss = 0.10570
Step 26835: loss = 0.11224
Step 26840: loss = 0.06733
Step 26845: loss = 0.09848
Step 26850: loss = 0.06912
Step 26855: loss = 0.05985
Step 26860: loss = 0.08263
Step 26865: loss = 0.04985
Step 26870: loss = 0.14012
Step 26875: loss = 0.00864
Step 26880: loss = 0.07717
Step 26885: loss = 0.02864
Step 26890: loss = 0.03534
Step 26895: loss = 0.05802
Step 26900: loss = 0.11779
Step 26905: loss = 0.05876
Step 26910: loss = 0.03485
Step 26915: loss = 0.05630
Step 26920: loss = 0.11272
Step 26925: loss = 0.07565
Step 26930: loss = 0.04159
Step 26935: loss = 0.03692
Step 26940: loss = 0.03299
Step 26945: loss = 0.04781
Step 26950: loss = 0.09900
Step 26955: loss = 0.08969
Step 26960: loss = 0.11797
Step 26965: loss = 0.07860
Step 26970: loss = 0.09061
Step 26975: loss = 0.02938
Step 26980: loss = 0.14056
Step 26985: loss = 0.10004
Step 26990: loss = 0.03283
Step 26995: loss = 0.06279
Step 27000: loss = 0.08043
Training Data Eval:
  Num examples: 50000, Num correct: 49000, Precision @ 1: 0.9800
('Testing Data Eval: EPOCH->', 28)
  Num examples: 10000, Num correct: 6837, Precision @ 1: 0.6837
Step 27005: loss = 0.08620
Step 27010: loss = 0.02772
Step 27015: loss = 0.05177
Step 27020: loss = 0.07391
Step 27025: loss = 0.08854
Step 27030: loss = 0.01970
Step 27035: loss = 0.06665
Step 27040: loss = 0.01891
Step 27045: loss = 0.02866
Step 27050: loss = 0.07827
Step 27055: loss = 0.06797
Step 27060: loss = 0.13231
Step 27065: loss = 0.03749
Step 27070: loss = 0.07192
Step 27075: loss = 0.01905
Step 27080: loss = 0.05754
Step 27085: loss = 0.10156
Step 27090: loss = 0.03312
Step 27095: loss = 0.07014
Step 27100: loss = 0.10218
Step 27105: loss = 0.10283
Step 27110: loss = 0.05037
Step 27115: loss = 0.01009
Step 27120: loss = 0.05238
Step 27125: loss = 0.04644
Step 27130: loss = 0.02926
Step 27135: loss = 0.01900
Step 27140: loss = 0.08231
Step 27145: loss = 0.11805
Step 27150: loss = 0.08821
Step 27155: loss = 0.09009
Step 27160: loss = 0.10589
Step 27165: loss = 0.07247
Step 27170: loss = 0.08957
Step 27175: loss = 0.06948
Step 27180: loss = 0.10865
Step 27185: loss = 0.10981
Step 27190: loss = 0.03011
Step 27195: loss = 0.04114
Step 27200: loss = 0.06499
Step 27205: loss = 0.08875
Step 27210: loss = 0.06451
Step 27215: loss = 0.11104
Step 27220: loss = 0.03775
Step 27225: loss = 0.02770
Step 27230: loss = 0.09794
Step 27235: loss = 0.13384
Step 27240: loss = 0.04394
Step 27245: loss = 0.03192
Step 27250: loss = 0.04459
Step 27255: loss = 0.09298
Step 27260: loss = 0.03498
Step 27265: loss = 0.02454
Step 27270: loss = 0.10183
Step 27275: loss = 0.06659
Step 27280: loss = 0.02535
Step 27285: loss = 0.05063
Step 27290: loss = 0.07953
Step 27295: loss = 0.12030
Step 27300: loss = 0.05377
Step 27305: loss = 0.05072
Step 27310: loss = 0.04869
Step 27315: loss = 0.06303
Step 27320: loss = 0.21122
Step 27325: loss = 0.03430
Step 27330: loss = 0.03240
Step 27335: loss = 0.10200
Step 27340: loss = 0.04256
Step 27345: loss = 0.07323
Step 27350: loss = 0.04543
Step 27355: loss = 0.02258
Step 27360: loss = 0.03765
Step 27365: loss = 0.04966
Step 27370: loss = 0.07448
Step 27375: loss = 0.01304
Step 27380: loss = 0.03946
Step 27385: loss = 0.05699
Step 27390: loss = 0.15270
Step 27395: loss = 0.07338
Step 27400: loss = 0.04778
Step 27405: loss = 0.12310
Step 27410: loss = 0.11982
Step 27415: loss = 0.09386
Step 27420: loss = 0.03274
Step 27425: loss = 0.16139
Step 27430: loss = 0.10427
Step 27435: loss = 0.03146
Step 27440: loss = 0.05787
Step 27445: loss = 0.10118
Step 27450: loss = 0.05207
Step 27455: loss = 0.11173
Step 27460: loss = 0.04114
Step 27465: loss = 0.04741
Step 27470: loss = 0.06397
Step 27475: loss = 0.13639
Step 27480: loss = 0.05221
Step 27485: loss = 0.04560
Step 27490: loss = 0.05390
Step 27495: loss = 0.10269
Step 27500: loss = 0.08844
Step 27505: loss = 0.05660
Step 27510: loss = 0.08257
Step 27515: loss = 0.07116
Step 27520: loss = 0.04767
Step 27525: loss = 0.08270
Step 27530: loss = 0.06805
Step 27535: loss = 0.07324
Step 27540: loss = 0.08192
Step 27545: loss = 0.03466
Step 27550: loss = 0.03012
Step 27555: loss = 0.08963
Step 27560: loss = 0.09339
Step 27565: loss = 0.07909
Step 27570: loss = 0.01715
Step 27575: loss = 0.03644
Step 27580: loss = 0.04629
Step 27585: loss = 0.06100
Step 27590: loss = 0.05060
Step 27595: loss = 0.06264
Step 27600: loss = 0.04930
Step 27605: loss = 0.17396
Step 27610: loss = 0.08551
Step 27615: loss = 0.06006
Step 27620: loss = 0.02576
Step 27625: loss = 0.09735
Step 27630: loss = 0.01667
Step 27635: loss = 0.06826
Step 27640: loss = 0.04443
Step 27645: loss = 0.11377
Step 27650: loss = 0.02733
Step 27655: loss = 0.08941
Step 27660: loss = 0.05644
Step 27665: loss = 0.11340
Step 27670: loss = 0.09746
Step 27675: loss = 0.10474
Step 27680: loss = 0.05068
Step 27685: loss = 0.05216
Step 27690: loss = 0.08686
Step 27695: loss = 0.10454
Step 27700: loss = 0.07356
Step 27705: loss = 0.08791
Step 27710: loss = 0.04317
Step 27715: loss = 0.04550
Step 27720: loss = 0.07545
Step 27725: loss = 0.05723
Step 27730: loss = 0.05942
Step 27735: loss = 0.12090
Step 27740: loss = 0.12252
Step 27745: loss = 0.04537
Step 27750: loss = 0.07315
Step 27755: loss = 0.12797
Step 27760: loss = 0.02063
Step 27765: loss = 0.07965
Step 27770: loss = 0.03834
Step 27775: loss = 0.05099
Step 27780: loss = 0.07093
Step 27785: loss = 0.01946
Step 27790: loss = 0.01638
Step 27795: loss = 0.02308
Step 27800: loss = 0.04164
Step 27805: loss = 0.04736
Step 27810: loss = 0.02558
Step 27815: loss = 0.03187
Step 27820: loss = 0.08030
Step 27825: loss = 0.07352
Step 27830: loss = 0.12618
Step 27835: loss = 0.07164
Step 27840: loss = 0.08226
Step 27845: loss = 0.09792
Step 27850: loss = 0.07346
Step 27855: loss = 0.09259
Step 27860: loss = 0.07469
Step 27865: loss = 0.02546
Step 27870: loss = 0.03650
Step 27875: loss = 0.02850
Step 27880: loss = 0.21296
Step 27885: loss = 0.10636
Step 27890: loss = 0.08145
Step 27895: loss = 0.07678
Step 27900: loss = 0.06358
Step 27905: loss = 0.09802
Step 27910: loss = 0.08315
Step 27915: loss = 0.05761
Step 27920: loss = 0.09016
Step 27925: loss = 0.15161
Step 27930: loss = 0.08742
Step 27935: loss = 0.10025
Step 27940: loss = 0.05054
Step 27945: loss = 0.12568
Step 27950: loss = 0.19954
Step 27955: loss = 0.04921
Step 27960: loss = 0.13629
Step 27965: loss = 0.17281
Step 27970: loss = 0.07083
Step 27975: loss = 0.08494
Step 27980: loss = 0.12235
Step 27985: loss = 0.08102
Step 27990: loss = 0.07427
Step 27995: loss = 0.11972
Step 28000: loss = 0.05224
Training Data Eval:
  Num examples: 50000, Num correct: 49055, Precision @ 1: 0.9811
('Testing Data Eval: EPOCH->', 29)
  Num examples: 10000, Num correct: 6841, Precision @ 1: 0.6841
Step 28005: loss = 0.06292
Step 28010: loss = 0.03999
Step 28015: loss = 0.10261
Step 28020: loss = 0.11094
Step 28025: loss = 0.07087
Step 28030: loss = 0.09597
Step 28035: loss = 0.22623
Step 28040: loss = 0.02501
Step 28045: loss = 0.03044
Step 28050: loss = 0.07733
Step 28055: loss = 0.01159
Step 28060: loss = 0.03113
Step 28065: loss = 0.03116
Step 28070: loss = 0.06735
Step 28075: loss = 0.04976
Step 28080: loss = 0.01410
Step 28085: loss = 0.02602
Step 28090: loss = 0.01314
Step 28095: loss = 0.05720
Step 28100: loss = 0.03635
Step 28105: loss = 0.02745
Step 28110: loss = 0.04371
Step 28115: loss = 0.06241
Step 28120: loss = 0.11290
Step 28125: loss = 0.07808
Step 28130: loss = 0.03751
Step 28135: loss = 0.08878
Step 28140: loss = 0.04093
Step 28145: loss = 0.06385
Step 28150: loss = 0.04555
Step 28155: loss = 0.16240
Step 28160: loss = 0.17120
Step 28165: loss = 0.07681
Step 28170: loss = 0.06232
Step 28175: loss = 0.07953
Step 28180: loss = 0.07130
Step 28185: loss = 0.02351
Step 28190: loss = 0.02921
Step 28195: loss = 0.01984
Step 28200: loss = 0.04469
Step 28205: loss = 0.06128
Step 28210: loss = 0.06610
Step 28215: loss = 0.05938
Step 28220: loss = 0.06767
Step 28225: loss = 0.04010
Step 28230: loss = 0.11198
Step 28235: loss = 0.02724
Step 28240: loss = 0.04377
Step 28245: loss = 0.26133
Step 28250: loss = 0.03442
Step 28255: loss = 0.07577
Step 28260: loss = 0.04134
Step 28265: loss = 0.03925
Step 28270: loss = 0.02859
Step 28275: loss = 0.03089
Step 28280: loss = 0.02247
Step 28285: loss = 0.12381
Step 28290: loss = 0.20556
Step 28295: loss = 0.05674
Step 28300: loss = 0.05183
Step 28305: loss = 0.02973
Step 28310: loss = 0.06734
Step 28315: loss = 0.02991
Step 28320: loss = 0.04606
Step 28325: loss = 0.13639
Step 28330: loss = 0.03009
Step 28335: loss = 0.03295
Step 28340: loss = 0.04049
Step 28345: loss = 0.04402
Step 28350: loss = 0.08868
Step 28355: loss = 0.03530
Step 28360: loss = 0.09443
Step 28365: loss = 0.03807
Step 28370: loss = 0.04861
Step 28375: loss = 0.05203
Step 28380: loss = 0.05733
Step 28385: loss = 0.03899
Step 28390: loss = 0.19428
Step 28395: loss = 0.03212
Step 28400: loss = 0.03083
Step 28405: loss = 0.07379
Step 28410: loss = 0.08248
Step 28415: loss = 0.03203
Step 28420: loss = 0.01982
Step 28425: loss = 0.13232
Step 28430: loss = 0.07936
Step 28435: loss = 0.06340
Step 28440: loss = 0.06814
Step 28445: loss = 0.05692
Step 28450: loss = 0.11752
Step 28455: loss = 0.07898
Step 28460: loss = 0.12056
Step 28465: loss = 0.03297
Step 28470: loss = 0.03266
Step 28475: loss = 0.11855
Step 28480: loss = 0.09598
Step 28485: loss = 0.10282
Step 28490: loss = 0.02252
Step 28495: loss = 0.06851
Step 28500: loss = 0.06571
Step 28505: loss = 0.09525
Step 28510: loss = 0.05908
Step 28515: loss = 0.09403
Step 28520: loss = 0.05647
Step 28525: loss = 0.11784
Step 28530: loss = 0.09137
Step 28535: loss = 0.07483
Step 28540: loss = 0.03795
Step 28545: loss = 0.03645
Step 28550: loss = 0.03986
Step 28555: loss = 0.14897
Step 28560: loss = 0.15966
Step 28565: loss = 0.08729
Step 28570: loss = 0.02881
Step 28575: loss = 0.06173
Step 28580: loss = 0.11217
Step 28585: loss = 0.15047
Step 28590: loss = 0.06845
Step 28595: loss = 0.22537
Step 28600: loss = 0.02021
Step 28605: loss = 0.06662
Step 28610: loss = 0.06107
Step 28615: loss = 0.11526
Step 28620: loss = 0.05880
Step 28625: loss = 0.09440
Step 28630: loss = 0.04909
Step 28635: loss = 0.06293
Step 28640: loss = 0.17481
Step 28645: loss = 0.04113
Step 28650: loss = 0.04562
Step 28655: loss = 0.04324
Step 28660: loss = 0.06240
Step 28665: loss = 0.07188
Step 28670: loss = 0.04874
Step 28675: loss = 0.06025
Step 28680: loss = 0.10904
Step 28685: loss = 0.10727
Step 28690: loss = 0.09087
Step 28695: loss = 0.08291
Step 28700: loss = 0.08231
Step 28705: loss = 0.06855
Step 28710: loss = 0.04444
Step 28715: loss = 0.14588
Step 28720: loss = 0.04358
Step 28725: loss = 0.07665
Step 28730: loss = 0.02523
Step 28735: loss = 0.11483
Step 28740: loss = 0.04178
Step 28745: loss = 0.10379
Step 28750: loss = 0.04591
Step 28755: loss = 0.03301
Step 28760: loss = 0.09209
Step 28765: loss = 0.07620
Step 28770: loss = 0.07891
Step 28775: loss = 0.10096
Step 28780: loss = 0.03172
Step 28785: loss = 0.05278
Step 28790: loss = 0.10397
Step 28795: loss = 0.01873
Step 28800: loss = 0.10510
Step 28805: loss = 0.03955
Step 28810: loss = 0.07820
Step 28815: loss = 0.08032
Step 28820: loss = 0.08412
Step 28825: loss = 0.14990
Step 28830: loss = 0.06732
Step 28835: loss = 0.03683
Step 28840: loss = 0.03987
Step 28845: loss = 0.08672
Step 28850: loss = 0.03436
Step 28855: loss = 0.06139
Step 28860: loss = 0.04512
Step 28865: loss = 0.06260
Step 28870: loss = 0.16215
Step 28875: loss = 0.04205
Step 28880: loss = 0.04470
Step 28885: loss = 0.02074
Step 28890: loss = 0.09773
Step 28895: loss = 0.12031
Step 28900: loss = 0.08217
Step 28905: loss = 0.14468
Step 28910: loss = 0.08839
Step 28915: loss = 0.02913
Step 28920: loss = 0.07198
Step 28925: loss = 0.12925
Step 28930: loss = 0.08656
Step 28935: loss = 0.07842
Step 28940: loss = 0.03950
Step 28945: loss = 0.08085
Step 28950: loss = 0.06340
Step 28955: loss = 0.10281
Step 28960: loss = 0.05258
Step 28965: loss = 0.03174
Step 28970: loss = 0.15379
Step 28975: loss = 0.05769
Step 28980: loss = 0.09365
Step 28985: loss = 0.21379
Step 28990: loss = 0.10621
Step 28995: loss = 0.12962
Step 29000: loss = 0.09888
Training Data Eval:
  Num examples: 50000, Num correct: 49052, Precision @ 1: 0.9810
('Testing Data Eval: EPOCH->', 30)
  Num examples: 10000, Num correct: 6775, Precision @ 1: 0.6775
Step 29005: loss = 0.02058
Step 29010: loss = 0.08316
Step 29015: loss = 0.13717
Step 29020: loss = 0.04589
Step 29025: loss = 0.08636
Step 29030: loss = 0.06988
Step 29035: loss = 0.07799
Step 29040: loss = 0.04194
Step 29045: loss = 0.01743
Step 29050: loss = 0.16519
Step 29055: loss = 0.10120
Step 29060: loss = 0.08879
Step 29065: loss = 0.04560
Step 29070: loss = 0.10810
Step 29075: loss = 0.02583
Step 29080: loss = 0.01752
Step 29085: loss = 0.01698
Step 29090: loss = 0.03271
Step 29095: loss = 0.05916
Step 29100: loss = 0.08845
Step 29105: loss = 0.02845
Step 29110: loss = 0.10298
Step 29115: loss = 0.04179
Step 29120: loss = 0.14907
Step 29125: loss = 0.03396
Step 29130: loss = 0.03335
Step 29135: loss = 0.14368
Step 29140: loss = 0.04185
Step 29145: loss = 0.04844
Step 29150: loss = 0.04170
Step 29155: loss = 0.12274
Step 29160: loss = 0.09878
Step 29165: loss = 0.07278
Step 29170: loss = 0.02437
Step 29175: loss = 0.08243
Step 29180: loss = 0.04035
Step 29185: loss = 0.03848
Step 29190: loss = 0.02949
Step 29195: loss = 0.05215
Step 29200: loss = 0.02939
Step 29205: loss = 0.10455
Step 29210: loss = 0.07999
Step 29215: loss = 0.08938
Step 29220: loss = 0.02044
Step 29225: loss = 0.02296
Step 29230: loss = 0.03404
Step 29235: loss = 0.02148
Step 29240: loss = 0.05458
Step 29245: loss = 0.03749
Step 29250: loss = 0.04536
Step 29255: loss = 0.07963
Step 29260: loss = 0.02450
Step 29265: loss = 0.03543
Step 29270: loss = 0.04534
Step 29275: loss = 0.09131
Step 29280: loss = 0.05999
Step 29285: loss = 0.03463
Step 29290: loss = 0.05742
Step 29295: loss = 0.05989
Step 29300: loss = 0.10503
Step 29305: loss = 0.04878
Step 29310: loss = 0.12267
Step 29315: loss = 0.02630
Step 29320: loss = 0.16558
Step 29325: loss = 0.03465
Step 29330: loss = 0.10289
Step 29335: loss = 0.08319
Step 29340: loss = 0.07251
Step 29345: loss = 0.02206
Step 29350: loss = 0.11012
Step 29355: loss = 0.07453
Step 29360: loss = 0.09937
Step 29365: loss = 0.12758
Step 29370: loss = 0.01945
Step 29375: loss = 0.09650
Step 29380: loss = 0.01824
Step 29385: loss = 0.05691
Step 29390: loss = 0.14578
Step 29395: loss = 0.12422
Step 29400: loss = 0.12935
Step 29405: loss = 0.15816
Step 29410: loss = 0.14028
Step 29415: loss = 0.03744
Step 29420: loss = 0.02764
Step 29425: loss = 0.04471
Step 29430: loss = 0.06558
Step 29435: loss = 0.07623
Step 29440: loss = 0.06409
Step 29445: loss = 0.06090
Step 29450: loss = 0.05582
Step 29455: loss = 0.08962
Step 29460: loss = 0.02956
Step 29465: loss = 0.16758
Step 29470: loss = 0.10077
Step 29475: loss = 0.07717
Step 29480: loss = 0.01312
Step 29485: loss = 0.17239
Step 29490: loss = 0.13205
Step 29495: loss = 0.05026
Step 29500: loss = 0.04072
Step 29505: loss = 0.05357
Step 29510: loss = 0.06745
Step 29515: loss = 0.06191
Step 29520: loss = 0.05355
Step 29525: loss = 0.09097
Step 29530: loss = 0.05743
Step 29535: loss = 0.09747
Step 29540: loss = 0.07091
Step 29545: loss = 0.08590
Step 29550: loss = 0.04814
Step 29555: loss = 0.07489
Step 29560: loss = 0.07499
Step 29565: loss = 0.09509
Step 29570: loss = 0.05473
Step 29575: loss = 0.08163
Step 29580: loss = 0.04919
Step 29585: loss = 0.06161
Step 29590: loss = 0.06237
Step 29595: loss = 0.03188
Step 29600: loss = 0.06163
Step 29605: loss = 0.02332
Step 29610: loss = 0.04041
Step 29615: loss = 0.09450
Step 29620: loss = 0.08120
Step 29625: loss = 0.11017
Step 29630: loss = 0.01966
Step 29635: loss = 0.03924
Step 29640: loss = 0.03512
Step 29645: loss = 0.12588
Step 29650: loss = 0.06111
Step 29655: loss = 0.09610
Step 29660: loss = 0.05582
Step 29665: loss = 0.09125
Step 29670: loss = 0.10146
Step 29675: loss = 0.02726
Step 29680: loss = 0.04168
Step 29685: loss = 0.02277
Step 29690: loss = 0.03469
Step 29695: loss = 0.06552
Step 29700: loss = 0.17580
Step 29705: loss = 0.13774
Step 29710: loss = 0.01650
Step 29715: loss = 0.16064
Step 29720: loss = 0.03738
Step 29725: loss = 0.06056
Step 29730: loss = 0.06736
Step 29735: loss = 0.07702
Step 29740: loss = 0.03743
Step 29745: loss = 0.04284
Step 29750: loss = 0.04019
Step 29755: loss = 0.04381
Step 29760: loss = 0.06340
Step 29765: loss = 0.03525
Step 29770: loss = 0.14624
Step 29775: loss = 0.02889
Step 29780: loss = 0.04625
Step 29785: loss = 0.15083
Step 29790: loss = 0.05577
Step 29795: loss = 0.03621
Step 29800: loss = 0.05543
Step 29805: loss = 0.19014
Step 29810: loss = 0.03703
Step 29815: loss = 0.04859
Step 29820: loss = 0.03681
Step 29825: loss = 0.04171
Step 29830: loss = 0.03679
Step 29835: loss = 0.07674
Step 29840: loss = 0.02248
Step 29845: loss = 0.02394
Step 29850: loss = 0.10912
Step 29855: loss = 0.17947
Step 29860: loss = 0.05422
Step 29865: loss = 0.04415
Step 29870: loss = 0.05977
Step 29875: loss = 0.06294
Step 29880: loss = 0.07506
Step 29885: loss = 0.02747
Step 29890: loss = 0.16201
Step 29895: loss = 0.02204
Step 29900: loss = 0.03816
Step 29905: loss = 0.01247
Step 29910: loss = 0.13778
Step 29915: loss = 0.14256
Step 29920: loss = 0.02178
Step 29925: loss = 0.10242
Step 29930: loss = 0.11425
Step 29935: loss = 0.12603
Step 29940: loss = 0.06498
Step 29945: loss = 0.04248
Step 29950: loss = 0.05850
Step 29955: loss = 0.06297
Step 29960: loss = 0.04671
Step 29965: loss = 0.08729
Step 29970: loss = 0.04791
Step 29975: loss = 0.07220
Step 29980: loss = 0.02404
Step 29985: loss = 0.10145
Step 29990: loss = 0.11875
Step 29995: loss = 0.13563
Step 30000: loss = 0.03115
Training Data Eval:
  Num examples: 50000, Num correct: 48999, Precision @ 1: 0.9800
('Testing Data Eval: EPOCH->', 31)
  Num examples: 10000, Num correct: 6774, Precision @ 1: 0.6774
Step 30005: loss = 0.06158
Step 30010: loss = 0.04083
Step 30015: loss = 0.02863
Step 30020: loss = 0.10575
Step 30025: loss = 0.04619
Step 30030: loss = 0.09100
Step 30035: loss = 0.08010
Step 30040: loss = 0.08429
Step 30045: loss = 0.09755
Step 30050: loss = 0.04481
Step 30055: loss = 0.02172
Step 30060: loss = 0.06402
Step 30065: loss = 0.10565
Step 30070: loss = 0.04785
Step 30075: loss = 0.02313
Step 30080: loss = 0.07906
Step 30085: loss = 0.02287
Step 30090: loss = 0.05622
Step 30095: loss = 0.07729
Step 30100: loss = 0.05957
Step 30105: loss = 0.02798
Step 30110: loss = 0.05565
Step 30115: loss = 0.08047
Step 30120: loss = 0.05165
Step 30125: loss = 0.08778
Step 30130: loss = 0.08616
Step 30135: loss = 0.02699
Step 30140: loss = 0.02120
Step 30145: loss = 0.02269
Step 30150: loss = 0.02205
Step 30155: loss = 0.07524
Step 30160: loss = 0.09503
Step 30165: loss = 0.04482
Step 30170: loss = 0.03629
Step 30175: loss = 0.04177
Step 30180: loss = 0.04413
Step 30185: loss = 0.11700
Step 30190: loss = 0.08187
Step 30195: loss = 0.05263
Step 30200: loss = 0.03937
Step 30205: loss = 0.04006
Step 30210: loss = 0.02928
Step 30215: loss = 0.09458
Step 30220: loss = 0.13379
Step 30225: loss = 0.12253
Step 30230: loss = 0.11053
Step 30235: loss = 0.06589
Step 30240: loss = 0.05409
Step 30245: loss = 0.01741
Step 30250: loss = 0.05942
Step 30255: loss = 0.03444
Step 30260: loss = 0.04342
Step 30265: loss = 0.07688
Step 30270: loss = 0.04228
Step 30275: loss = 0.05481
Step 30280: loss = 0.07552
Step 30285: loss = 0.05851
Step 30290: loss = 0.06129
Step 30295: loss = 0.01919
Step 30300: loss = 0.11479
Step 30305: loss = 0.10895
Step 30310: loss = 0.08674
Step 30315: loss = 0.05478
Step 30320: loss = 0.03739
Step 30325: loss = 0.02548
Step 30330: loss = 0.06845
Step 30335: loss = 0.03837
Step 30340: loss = 0.27719
Step 30345: loss = 0.06293
Step 30350: loss = 0.02284
Step 30355: loss = 0.04268
Step 30360: loss = 0.04145
Step 30365: loss = 0.05384
Step 30370: loss = 0.04302
Step 30375: loss = 0.07472
Step 30380: loss = 0.05626
Step 30385: loss = 0.04027
Step 30390: loss = 0.03151
Step 30395: loss = 0.03637
Step 30400: loss = 0.04382
Step 30405: loss = 0.09550
Step 30410: loss = 0.07081
Step 30415: loss = 0.02248
Step 30420: loss = 0.19408
Step 30425: loss = 0.07238
Step 30430: loss = 0.02640
Step 30435: loss = 0.01729
Step 30440: loss = 0.04842
Step 30445: loss = 0.13205
Step 30450: loss = 0.03436
Step 30455: loss = 0.05617
Step 30460: loss = 0.12781
Step 30465: loss = 0.12286
Step 30470: loss = 0.07852
Step 30475: loss = 0.04492
Step 30480: loss = 0.09965
Step 30485: loss = 0.11213
Step 30490: loss = 0.02308
Step 30495: loss = 0.03558
Step 30500: loss = 0.02003
Step 30505: loss = 0.13497
Step 30510: loss = 0.06855
Step 30515: loss = 0.05503
Step 30520: loss = 0.03727
Step 30525: loss = 0.10644
Step 30530: loss = 0.06295
Step 30535: loss = 0.09177
Step 30540: loss = 0.22830
Step 30545: loss = 0.02847
Step 30550: loss = 0.06923
Step 30555: loss = 0.05704
Step 30560: loss = 0.08317
Step 30565: loss = 0.06396
Step 30570: loss = 0.13825
Step 30575: loss = 0.11222
Step 30580: loss = 0.10783
Step 30585: loss = 0.05617
Step 30590: loss = 0.05744
Step 30595: loss = 0.08129
Step 30600: loss = 0.03758
Step 30605: loss = 0.09679
Step 30610: loss = 0.03498
Step 30615: loss = 0.05659
Step 30620: loss = 0.04468
Step 30625: loss = 0.14578
Step 30630: loss = 0.04188
Step 30635: loss = 0.08773
Step 30640: loss = 0.03552
Step 30645: loss = 0.03519
Step 30650: loss = 0.11842
Step 30655: loss = 0.11081
Step 30660: loss = 0.14127
Step 30665: loss = 0.05804
Step 30670: loss = 0.05052
Step 30675: loss = 0.18044
Step 30680: loss = 0.06033
Step 30685: loss = 0.09265
Step 30690: loss = 0.09572
Step 30695: loss = 0.01491
Step 30700: loss = 0.08673
Step 30705: loss = 0.02609
Step 30710: loss = 0.09976
Step 30715: loss = 0.07504
Step 30720: loss = 0.13098
Step 30725: loss = 0.19812
Step 30730: loss = 0.04766
Step 30735: loss = 0.07026
Step 30740: loss = 0.08589
Step 30745: loss = 0.03689
Step 30750: loss = 0.04136
Step 30755: loss = 0.02162
Step 30760: loss = 0.05475
Step 30765: loss = 0.05420
Step 30770: loss = 0.05236
Step 30775: loss = 0.05313
Step 30780: loss = 0.04731
Step 30785: loss = 0.14333
Step 30790: loss = 0.03007
Step 30795: loss = 0.15326
Step 30800: loss = 0.07867
Step 30805: loss = 0.02305
Step 30810: loss = 0.02355
Step 30815: loss = 0.09871
Step 30820: loss = 0.02501
Step 30825: loss = 0.02353
Step 30830: loss = 0.12192
Step 30835: loss = 0.08460
Step 30840: loss = 0.03717
Step 30845: loss = 0.10024
Step 30850: loss = 0.03651
Step 30855: loss = 0.03472
Step 30860: loss = 0.03297
Step 30865: loss = 0.11020
Step 30870: loss = 0.05051
Step 30875: loss = 0.08083
Step 30880: loss = 0.05835
Step 30885: loss = 0.11784
Step 30890: loss = 0.18154
Step 30895: loss = 0.16071
Step 30900: loss = 0.09300
Step 30905: loss = 0.06122
Step 30910: loss = 0.23889
Step 30915: loss = 0.09849
Step 30920: loss = 0.15131
Step 30925: loss = 0.09454
Step 30930: loss = 0.12561
Step 30935: loss = 0.11679
Step 30940: loss = 0.12124
Step 30945: loss = 0.07138
Step 30950: loss = 0.08713
Step 30955: loss = 0.09727
Step 30960: loss = 0.06163
Step 30965: loss = 0.00881
Step 30970: loss = 0.09603
Step 30975: loss = 0.04652
Step 30980: loss = 0.01573
Step 30985: loss = 0.04382
Step 30990: loss = 0.06695
Step 30995: loss = 0.19721
Step 31000: loss = 0.10043
Training Data Eval:
  Num examples: 50000, Num correct: 48994, Precision @ 1: 0.9799
('Testing Data Eval: EPOCH->', 32)
  Num examples: 10000, Num correct: 6633, Precision @ 1: 0.6633
Step 31005: loss = 0.01167
Step 31010: loss = 0.03173
Step 31015: loss = 0.03001
Step 31020: loss = 0.02586
Step 31025: loss = 0.06213
Step 31030: loss = 0.15690
Step 31035: loss = 0.12956
Step 31040: loss = 0.05229
Step 31045: loss = 0.09636
Step 31050: loss = 0.08720
Step 31055: loss = 0.07998
Step 31060: loss = 0.03905
Step 31065: loss = 0.07365
Step 31070: loss = 0.09580
Step 31075: loss = 0.01814
Step 31080: loss = 0.05476
Step 31085: loss = 0.07488
Step 31090: loss = 0.15256
Step 31095: loss = 0.02595
Step 31100: loss = 0.05826
Step 31105: loss = 0.02684
Step 31110: loss = 0.02146
Step 31115: loss = 0.04069
Step 31120: loss = 0.07039
Step 31125: loss = 0.06148
Step 31130: loss = 0.08275
Step 31135: loss = 0.04161
Step 31140: loss = 0.04423
Step 31145: loss = 0.09926
Step 31150: loss = 0.05925
Step 31155: loss = 0.03994
Step 31160: loss = 0.02977
Step 31165: loss = 0.06473
Step 31170: loss = 0.06800
Step 31175: loss = 0.08181
Step 31180: loss = 0.08335
Step 31185: loss = 0.03789
Step 31190: loss = 0.06356
Step 31195: loss = 0.06687
Step 31200: loss = 0.01890
Step 31205: loss = 0.04741
Step 31210: loss = 0.02919
Step 31215: loss = 0.06711
Step 31220: loss = 0.10350
Step 31225: loss = 0.06333
Step 31230: loss = 0.06989
Step 31235: loss = 0.04221
Step 31240: loss = 0.08475
Step 31245: loss = 0.04512
Step 31250: loss = 0.02208
Step 31255: loss = 0.04485
Step 31260: loss = 0.06785
Step 31265: loss = 0.03781
Step 31270: loss = 0.06160
Step 31275: loss = 0.04774
Step 31280: loss = 0.11896
Step 31285: loss = 0.06937
Step 31290: loss = 0.13607
Step 31295: loss = 0.09391
Step 31300: loss = 0.08407
Step 31305: loss = 0.03108
Step 31310: loss = 0.10753
Step 31315: loss = 0.03276
Step 31320: loss = 0.04893
Step 31325: loss = 0.06476
Step 31330: loss = 0.11414
Step 31335: loss = 0.06232
Step 31340: loss = 0.02585
Step 31345: loss = 0.02597
Step 31350: loss = 0.04621
Step 31355: loss = 0.04583
Step 31360: loss = 0.01574
Step 31365: loss = 0.04584
Step 31370: loss = 0.03930
Step 31375: loss = 0.01898
Step 31380: loss = 0.02532
Step 31385: loss = 0.05503
Step 31390: loss = 0.07307
Step 31395: loss = 0.04287
Step 31400: loss = 0.26935
Step 31405: loss = 0.03895
Step 31410: loss = 0.07191
Step 31415: loss = 0.10810
Step 31420: loss = 0.07992
Step 31425: loss = 0.05198
Step 31430: loss = 0.02332
Step 31435: loss = 0.05036
Step 31440: loss = 0.10141
Step 31445: loss = 0.06181
Step 31450: loss = 0.11309
Step 31455: loss = 0.06430
Step 31460: loss = 0.05509
Step 31465: loss = 0.05697
Step 31470: loss = 0.03404
Step 31475: loss = 0.04579
Step 31480: loss = 0.04454
Step 31485: loss = 0.08175
Step 31490: loss = 0.05831
Step 31495: loss = 0.03277
Step 31500: loss = 0.08059
Step 31505: loss = 0.07093
Step 31510: loss = 0.13175
Step 31515: loss = 0.03056
Step 31520: loss = 0.08985
Step 31525: loss = 0.04116
Step 31530: loss = 0.17191
Step 31535: loss = 0.12437
Step 31540: loss = 0.02494
Step 31545: loss = 0.13386
Step 31550: loss = 0.08118
Step 31555: loss = 0.07162
Step 31560: loss = 0.08921
Step 31565: loss = 0.04426
Step 31570: loss = 0.12622
Step 31575: loss = 0.07494
Step 31580: loss = 0.06601
Step 31585: loss = 0.06069
Step 31590: loss = 0.14214
Step 31595: loss = 0.06106
Step 31600: loss = 0.08655
Step 31605: loss = 0.16082
Step 31610: loss = 0.05995
Step 31615: loss = 0.04962
Step 31620: loss = 0.12503
Step 31625: loss = 0.07792
Step 31630: loss = 0.06487
Step 31635: loss = 0.14131
Step 31640: loss = 0.06337
Step 31645: loss = 0.09442
Step 31650: loss = 0.09290
Step 31655: loss = 0.04970
Step 31660: loss = 0.04713
Step 31665: loss = 0.07384
Step 31670: loss = 0.10138
Step 31675: loss = 0.04065
Step 31680: loss = 0.06829
Step 31685: loss = 0.15858
Step 31690: loss = 0.03437
Step 31695: loss = 0.04470
Step 31700: loss = 0.10008
Step 31705: loss = 0.08049
Step 31710: loss = 0.05537
Step 31715: loss = 0.07739
Step 31720: loss = 0.05454
Step 31725: loss = 0.03944
Step 31730: loss = 0.07764
Step 31735: loss = 0.02133
Step 31740: loss = 0.09330
Step 31745: loss = 0.05722
Step 31750: loss = 0.03206
Step 31755: loss = 0.07668
Step 31760: loss = 0.05375
Step 31765: loss = 0.05233
Step 31770: loss = 0.05938
Step 31775: loss = 0.05089
Step 31780: loss = 0.06307
Step 31785: loss = 0.11776
Step 31790: loss = 0.16138
Step 31795: loss = 0.16041
Step 31800: loss = 0.10498
Step 31805: loss = 0.19417
Step 31810: loss = 0.03763
Step 31815: loss = 0.08507
Step 31820: loss = 0.07063
Step 31825: loss = 0.01802
Step 31830: loss = 0.04139
Step 31835: loss = 0.09539
Step 31840: loss = 0.01078
Step 31845: loss = 0.05055
Step 31850: loss = 0.02491
Step 31855: loss = 0.09902
Step 31860: loss = 0.07338
Step 31865: loss = 0.06158
Step 31870: loss = 0.10567
Step 31875: loss = 0.06874
Step 31880: loss = 0.07119
Step 31885: loss = 0.15243
Step 31890: loss = 0.12247
Step 31895: loss = 0.02920
Step 31900: loss = 0.10200
Step 31905: loss = 0.02353
Step 31910: loss = 0.10654
Step 31915: loss = 0.11419
Step 31920: loss = 0.03185
Step 31925: loss = 0.07091
Step 31930: loss = 0.05798
Step 31935: loss = 0.05792
Step 31940: loss = 0.07006
Step 31945: loss = 0.14228
Step 31950: loss = 0.03390
Step 31955: loss = 0.02637
Step 31960: loss = 0.04608
Step 31965: loss = 0.03311
Step 31970: loss = 0.06006
Step 31975: loss = 0.07726
Step 31980: loss = 0.02240
Step 31985: loss = 0.02361
Step 31990: loss = 0.07338
Step 31995: loss = 0.04026
Step 32000: loss = 0.08411
Training Data Eval:
  Num examples: 50000, Num correct: 48951, Precision @ 1: 0.9790
('Testing Data Eval: EPOCH->', 33)
  Num examples: 10000, Num correct: 6735, Precision @ 1: 0.6735
Step 32005: loss = 0.07646
Step 32010: loss = 0.13166
Step 32015: loss = 0.03471
Step 32020: loss = 0.02761
Step 32025: loss = 0.02916
Step 32030: loss = 0.07728
Step 32035: loss = 0.06927
Step 32040: loss = 0.06845
Step 32045: loss = 0.06363
Step 32050: loss = 0.03463
Step 32055: loss = 0.07143
Step 32060: loss = 0.11688
Step 32065: loss = 0.08582
Step 32070: loss = 0.05726
Step 32075: loss = 0.02744
Step 32080: loss = 0.02990
Step 32085: loss = 0.04122
Step 32090: loss = 0.03984
Step 32095: loss = 0.05560
Step 32100: loss = 0.08459
Step 32105: loss = 0.02435
Step 32110: loss = 0.02131
Step 32115: loss = 0.06992
Step 32120: loss = 0.09577
Step 32125: loss = 0.03967
Step 32130: loss = 0.06131
Step 32135: loss = 0.07251
Step 32140: loss = 0.03252
Step 32145: loss = 0.04510
Step 32150: loss = 0.06781
Step 32155: loss = 0.07201
Step 32160: loss = 0.06115
Step 32165: loss = 0.05389
Step 32170: loss = 0.10204
Step 32175: loss = 0.04827
Step 32180: loss = 0.03016
Step 32185: loss = 0.03534
Step 32190: loss = 0.07679
Step 32195: loss = 0.04289
Step 32200: loss = 0.04508
Step 32205: loss = 0.05415
Step 32210: loss = 0.07217
Step 32215: loss = 0.08558
Step 32220: loss = 0.03744
Step 32225: loss = 0.11815
Step 32230: loss = 0.05125
Step 32235: loss = 0.03021
Step 32240: loss = 0.11251
Step 32245: loss = 0.07780
Step 32250: loss = 0.06107
Step 32255: loss = 0.02544
Step 32260: loss = 0.04339
Step 32265: loss = 0.05583
Step 32270: loss = 0.03327
Step 32275: loss = 0.04947
Step 32280: loss = 0.08189
Step 32285: loss = 0.04114
Step 32290: loss = 0.09559
Step 32295: loss = 0.12082
Step 32300: loss = 0.09215
Step 32305: loss = 0.05840
Step 32310: loss = 0.05123
Step 32315: loss = 0.03477
Step 32320: loss = 0.02492
Step 32325: loss = 0.14567
Step 32330: loss = 0.05883
Step 32335: loss = 0.06542
Step 32340: loss = 0.04678
Step 32345: loss = 0.02910
Step 32350: loss = 0.08757
Step 32355: loss = 0.02303
Step 32360: loss = 0.09825
Step 32365: loss = 0.08060
Step 32370: loss = 0.01842
Step 32375: loss = 0.05504
Step 32380: loss = 0.02967
Step 32385: loss = 0.05944
Step 32390: loss = 0.09823
Step 32395: loss = 0.03845
Step 32400: loss = 0.09452
Step 32405: loss = 0.09527
Step 32410: loss = 0.04924
Step 32415: loss = 0.05089
Step 32420: loss = 0.03980
Step 32425: loss = 0.08090
Step 32430: loss = 0.04847
Step 32435: loss = 0.05667
Step 32440: loss = 0.03326
Step 32445: loss = 0.04631
Step 32450: loss = 0.03382
Step 32455: loss = 0.04961
Step 32460: loss = 0.06393
Step 32465: loss = 0.06259
Step 32470: loss = 0.10502
Step 32475: loss = 0.04109
Step 32480: loss = 0.03150
Step 32485: loss = 0.03995
Step 32490: loss = 0.16041
Step 32495: loss = 0.30949
Step 32500: loss = 0.02306
Step 32505: loss = 0.04968
Step 32510: loss = 0.25343
Step 32515: loss = 0.06861
Step 32520: loss = 0.17103
Step 32525: loss = 0.13474
Step 32530: loss = 0.02792
Step 32535: loss = 0.10881
Step 32540: loss = 0.12056
Step 32545: loss = 0.07837
Step 32550: loss = 0.07902
Step 32555: loss = 0.05925
Step 32560: loss = 0.11006
Step 32565: loss = 0.10012
Step 32570: loss = 0.13377
Step 32575: loss = 0.04962
Step 32580: loss = 0.05080
Step 32585: loss = 0.05081
Step 32590: loss = 0.12425
Step 32595: loss = 0.05809
Step 32600: loss = 0.06131
Step 32605: loss = 0.12744
Step 32610: loss = 0.07048
Step 32615: loss = 0.01714
Step 32620: loss = 0.21256
Step 32625: loss = 0.06291
Step 32630: loss = 0.06526
Step 32635: loss = 0.03744
Step 32640: loss = 0.02369
Step 32645: loss = 0.07165
Step 32650: loss = 0.11680
Step 32655: loss = 0.12461
Step 32660: loss = 0.07413
Step 32665: loss = 0.08071
Step 32670: loss = 0.14954
Step 32675: loss = 0.02962
Step 32680: loss = 0.06724
Step 32685: loss = 0.08316
Step 32690: loss = 0.04055
Step 32695: loss = 0.08443
Step 32700: loss = 0.04306
Step 32705: loss = 0.13079
Step 32710: loss = 0.05086
Step 32715: loss = 0.04191
Step 32720: loss = 0.01758
Step 32725: loss = 0.03482
Step 32730: loss = 0.02033
Step 32735: loss = 0.06010
Step 32740: loss = 0.07402
Step 32745: loss = 0.06043
Step 32750: loss = 0.06339
Step 32755: loss = 0.04650
Step 32760: loss = 0.08406
Step 32765: loss = 0.05932
Step 32770: loss = 0.03330
Step 32775: loss = 0.03002
Step 32780: loss = 0.09712
Step 32785: loss = 0.05939
Step 32790: loss = 0.02959
Step 32795: loss = 0.10047
Step 32800: loss = 0.03891
Step 32805: loss = 0.13068
Step 32810: loss = 0.07199
Step 32815: loss = 0.09792
Step 32820: loss = 0.08966
Step 32825: loss = 0.20042
Step 32830: loss = 0.05684
Step 32835: loss = 0.02226
Step 32840: loss = 0.02901
Step 32845: loss = 0.03828
Step 32850: loss = 0.11834
Step 32855: loss = 0.06696
Step 32860: loss = 0.04682
Step 32865: loss = 0.06238
Step 32870: loss = 0.04058
Step 32875: loss = 0.03939
Step 32880: loss = 0.06662
Step 32885: loss = 0.03127
Step 32890: loss = 0.11657
Step 32895: loss = 0.08339
Step 32900: loss = 0.05917
Step 32905: loss = 0.06411
Step 32910: loss = 0.05578
Step 32915: loss = 0.00935
Step 32920: loss = 0.03868
Step 32925: loss = 0.18054
Step 32930: loss = 0.06677
Step 32935: loss = 0.02035
Step 32940: loss = 0.07672
Step 32945: loss = 0.04074
Step 32950: loss = 0.02899
Step 32955: loss = 0.06643
Step 32960: loss = 0.06634
Step 32965: loss = 0.03368
Step 32970: loss = 0.02937
Step 32975: loss = 0.05673
Step 32980: loss = 0.04396
Step 32985: loss = 0.06962
Step 32990: loss = 0.09136
Step 32995: loss = 0.05950
Step 33000: loss = 0.07353
Training Data Eval:
  Num examples: 50000, Num correct: 49216, Precision @ 1: 0.9843
('Testing Data Eval: EPOCH->', 34)
  Num examples: 10000, Num correct: 6861, Precision @ 1: 0.6861
Step 33005: loss = 0.06571
Step 33010: loss = 0.10553
Step 33015: loss = 0.03174
Step 33020: loss = 0.04236
Step 33025: loss = 0.04861
Step 33030: loss = 0.09192
Step 33035: loss = 0.05489
Step 33040: loss = 0.01795
Step 33045: loss = 0.03628
Step 33050: loss = 0.01235
Step 33055: loss = 0.07375
Step 33060: loss = 0.03336
Step 33065: loss = 0.02568
Step 33070: loss = 0.25262
Step 33075: loss = 0.04629
Step 33080: loss = 0.04150
Step 33085: loss = 0.01995
Step 33090: loss = 0.01621
Step 33095: loss = 0.02093
Step 33100: loss = 0.06766
Step 33105: loss = 0.02456
Step 33110: loss = 0.01614
Step 33115: loss = 0.11133
Step 33120: loss = 0.02667
Step 33125: loss = 0.02467
Step 33130: loss = 0.08532
Step 33135: loss = 0.02063
Step 33140: loss = 0.09709
Step 33145: loss = 0.02762
Step 33150: loss = 0.11211
Step 33155: loss = 0.08138
Step 33160: loss = 0.05586
Step 33165: loss = 0.03331
Step 33170: loss = 0.03337
Step 33175: loss = 0.01958
Step 33180: loss = 0.03725
Step 33185: loss = 0.03487
Step 33190: loss = 0.07950
Step 33195: loss = 0.13064
Step 33200: loss = 0.03759
Step 33205: loss = 0.02403
Step 33210: loss = 0.10375
Step 33215: loss = 0.04656
Step 33220: loss = 0.03858
Step 33225: loss = 0.00994
Step 33230: loss = 0.07533
Step 33235: loss = 0.02730
Step 33240: loss = 0.06767
Step 33245: loss = 0.08921
Step 33250: loss = 0.03551
Step 33255: loss = 0.01939
Step 33260: loss = 0.05736
Step 33265: loss = 0.05652
Step 33270: loss = 0.06624
Step 33275: loss = 0.03258
Step 33280: loss = 0.04285
Step 33285: loss = 0.10057
Step 33290: loss = 0.02897
Step 33295: loss = 0.14062
Step 33300: loss = 0.09132
Step 33305: loss = 0.09831
Step 33310: loss = 0.00856
Step 33315: loss = 0.06313
Step 33320: loss = 0.03199
Step 33325: loss = 0.09334
Step 33330: loss = 0.02609
Step 33335: loss = 0.03173
Step 33340: loss = 0.04003
Step 33345: loss = 0.00937
Step 33350: loss = 0.05229
Step 33355: loss = 0.00604
Step 33360: loss = 0.06562
Step 33365: loss = 0.12229
Step 33370: loss = 0.09033
Step 33375: loss = 0.02730
Step 33380: loss = 0.06657
Step 33385: loss = 0.09406
Step 33390: loss = 0.07518
Step 33395: loss = 0.01591
Step 33400: loss = 0.03409
Step 33405: loss = 0.05981
Step 33410: loss = 0.00961
Step 33415: loss = 0.13781
Step 33420: loss = 0.10336
Step 33425: loss = 0.12675
Step 33430: loss = 0.05591
Step 33435: loss = 0.08851
Step 33440: loss = 0.14984
Step 33445: loss = 0.02510
Step 33450: loss = 0.01187
Step 33455: loss = 0.07796
Step 33460: loss = 0.06180
Step 33465: loss = 0.12328
Step 33470: loss = 0.08815
Step 33475: loss = 0.07574
Step 33480: loss = 0.05470
Step 33485: loss = 0.03214
Step 33490: loss = 0.02570
Step 33495: loss = 0.11923
Step 33500: loss = 0.01621
Step 33505: loss = 0.06928
Step 33510: loss = 0.03427
Step 33515: loss = 0.03009
Step 33520: loss = 0.09513
Step 33525: loss = 0.04777
Step 33530: loss = 0.02953
Step 33535: loss = 0.03418
Step 33540: loss = 0.06906
Step 33545: loss = 0.01256
Step 33550: loss = 0.04733
Step 33555: loss = 0.03748
Step 33560: loss = 0.09627
Step 33565: loss = 0.02484
Step 33570: loss = 0.02374
Step 33575: loss = 0.01215
Step 33580: loss = 0.01318
Step 33585: loss = 0.06062
Step 33590: loss = 0.04656
Step 33595: loss = 0.10095
Step 33600: loss = 0.04618
Step 33605: loss = 0.05798
Step 33610: loss = 0.13193
Step 33615: loss = 0.03857
Step 33620: loss = 0.02169
Step 33625: loss = 0.03305
Step 33630: loss = 0.11379
Step 33635: loss = 0.05812
Step 33640: loss = 0.07305
Step 33645: loss = 0.05964
Step 33650: loss = 0.02511
Step 33655: loss = 0.02181
Step 33660: loss = 0.05461
Step 33665: loss = 0.22411
Step 33670: loss = 0.02825
Step 33675: loss = 0.04224
Step 33680: loss = 0.04759
Step 33685: loss = 0.09549
Step 33690: loss = 0.04175
Step 33695: loss = 0.10239
Step 33700: loss = 0.03573
Step 33705: loss = 0.04792
Step 33710: loss = 0.05313
Step 33715: loss = 0.12589
Step 33720: loss = 0.14299
Step 33725: loss = 0.00907
Step 33730: loss = 0.08078
Step 33735: loss = 0.07506
Step 33740: loss = 0.10480
Step 33745: loss = 0.05695
Step 33750: loss = 0.19390
Step 33755: loss = 0.04057
Step 33760: loss = 0.08684
Step 33765: loss = 0.06153
Step 33770: loss = 0.12292
Step 33775: loss = 0.14851
Step 33780: loss = 0.08116
Step 33785: loss = 0.02113
Step 33790: loss = 0.12534
Step 33795: loss = 0.02234
Step 33800: loss = 0.11766
Step 33805: loss = 0.14179
Step 33810: loss = 0.07779
Step 33815: loss = 0.04747
Step 33820: loss = 0.06912
Step 33825: loss = 0.06289
Step 33830: loss = 0.04224
Step 33835: loss = 0.03456
Step 33840: loss = 0.01356
Step 33845: loss = 0.03182
Step 33850: loss = 0.05145
Step 33855: loss = 0.05618
Step 33860: loss = 0.03462
Step 33865: loss = 0.02802
Step 33870: loss = 0.05225
Step 33875: loss = 0.08393
Step 33880: loss = 0.02409
Step 33885: loss = 0.09239
Step 33890: loss = 0.23526
Step 33895: loss = 0.09140
Step 33900: loss = 0.08666
Step 33905: loss = 0.02884
Step 33910: loss = 0.13914
Step 33915: loss = 0.01630
Step 33920: loss = 0.14105
Step 33925: loss = 0.13607
Step 33930: loss = 0.04518
Step 33935: loss = 0.08435
Step 33940: loss = 0.05234
Step 33945: loss = 0.03971
Step 33950: loss = 0.08591
Step 33955: loss = 0.12831
Step 33960: loss = 0.04673
Step 33965: loss = 0.09875
Step 33970: loss = 0.01350
Step 33975: loss = 0.07162
Step 33980: loss = 0.23312
Step 33985: loss = 0.04619
Step 33990: loss = 0.05498
Step 33995: loss = 0.05608
Step 34000: loss = 0.07760
Training Data Eval:
  Num examples: 50000, Num correct: 49060, Precision @ 1: 0.9812
('Testing Data Eval: EPOCH->', 35)
  Num examples: 10000, Num correct: 6735, Precision @ 1: 0.6735
Step 34005: loss = 0.08532
Step 34010: loss = 0.04861
Step 34015: loss = 0.07571
Step 34020: loss = 0.00943
Step 34025: loss = 0.04271
Step 34030: loss = 0.03401
Step 34035: loss = 0.03221
Step 34040: loss = 0.03806
Step 34045: loss = 0.08379
Step 34050: loss = 0.05652
Step 34055: loss = 0.02449
Step 34060: loss = 0.01182
Step 34065: loss = 0.04438
Step 34070: loss = 0.03011
Step 34075: loss = 0.08348
Step 34080: loss = 0.04982
Step 34085: loss = 0.02002
Step 34090: loss = 0.02304
Step 34095: loss = 0.02013
Step 34100: loss = 0.12371
Step 34105: loss = 0.03400
Step 34110: loss = 0.11658
Step 34115: loss = 0.13707
Step 34120: loss = 0.04222
Step 34125: loss = 0.03149
Step 34130: loss = 0.09522
Step 34135: loss = 0.19165
Step 34140: loss = 0.09511
Step 34145: loss = 0.04459
Step 34150: loss = 0.04073
Step 34155: loss = 0.10987
Step 34160: loss = 0.05394
Step 34165: loss = 0.00852
Step 34170: loss = 0.02189
Step 34175: loss = 0.08404
Step 34180: loss = 0.06981
Step 34185: loss = 0.10105
Step 34190: loss = 0.09223
Step 34195: loss = 0.04001
Step 34200: loss = 0.07276
Step 34205: loss = 0.07001
Step 34210: loss = 0.05003
Step 34215: loss = 0.04660
Step 34220: loss = 0.08758
Step 34225: loss = 0.06756
Step 34230: loss = 0.01645
Step 34235: loss = 0.09185
Step 34240: loss = 0.02023
Step 34245: loss = 0.03492
Step 34250: loss = 0.03402
Step 34255: loss = 0.07643
Step 34260: loss = 0.09659
Step 34265: loss = 0.07332
Step 34270: loss = 0.06541
Step 34275: loss = 0.08061
Step 34280: loss = 0.04552
Step 34285: loss = 0.05172
Step 34290: loss = 0.08507
Step 34295: loss = 0.15798
Step 34300: loss = 0.03025
Step 34305: loss = 0.04143
Step 34310: loss = 0.04024
Step 34315: loss = 0.04768
Step 34320: loss = 0.07073
Step 34325: loss = 0.06177
Step 34330: loss = 0.03134
Step 34335: loss = 0.03704
Step 34340: loss = 0.03605
Step 34345: loss = 0.03327
Step 34350: loss = 0.06828
Step 34355: loss = 0.02690
Step 34360: loss = 0.03457
Step 34365: loss = 0.25325
Step 34370: loss = 0.06558
Step 34375: loss = 0.12490
Step 34380: loss = 0.13432
Step 34385: loss = 0.06495
Step 34390: loss = 0.07501
Step 34395: loss = 0.05947
Step 34400: loss = 0.06834
Step 34405: loss = 0.05242
Step 34410: loss = 0.05240
Step 34415: loss = 0.10431
Step 34420: loss = 0.06397
Step 34425: loss = 0.03753
Step 34430: loss = 0.03046
Step 34435: loss = 0.03578
Step 34440: loss = 0.02263
Step 34445: loss = 0.17830
Step 34450: loss = 0.06883
Step 34455: loss = 0.06146
Step 34460: loss = 0.08196
Step 34465: loss = 0.01709
Step 34470: loss = 0.05545
Step 34475: loss = 0.02559
Step 34480: loss = 0.01778
Step 34485: loss = 0.02545
Step 34490: loss = 0.13334
Step 34495: loss = 0.06459
Step 34500: loss = 0.07198
Step 34505: loss = 0.02146
Step 34510: loss = 0.08199
Step 34515: loss = 0.02582
Step 34520: loss = 0.08895
Step 34525: loss = 0.08784
Step 34530: loss = 0.03196
Step 34535: loss = 0.05152
Step 34540: loss = 0.16984
Step 34545: loss = 0.08246
Step 34550: loss = 0.06728
Step 34555: loss = 0.01933
Step 34560: loss = 0.05209
Step 34565: loss = 0.03124
Step 34570: loss = 0.03230
Step 34575: loss = 0.03424
Step 34580: loss = 0.02566
Step 34585: loss = 0.09900
Step 34590: loss = 0.06144
Step 34595: loss = 0.01973
Step 34600: loss = 0.03361
Step 34605: loss = 0.03516
Step 34610: loss = 0.11251
Step 34615: loss = 0.07076
Step 34620: loss = 0.08796
Step 34625: loss = 0.03394
Step 34630: loss = 0.07067
Step 34635: loss = 0.01571
Step 34640: loss = 0.01265
Step 34645: loss = 0.03400
Step 34650: loss = 0.07568
Step 34655: loss = 0.06971
Step 34660: loss = 0.09821
Step 34665: loss = 0.09443
Step 34670: loss = 0.05600
Step 34675: loss = 0.09047
Step 34680: loss = 0.04991
Step 34685: loss = 0.05167
Step 34690: loss = 0.06926
Step 34695: loss = 0.00998
Step 34700: loss = 0.04472
Step 34705: loss = 0.03477
Step 34710: loss = 0.02040
Step 34715: loss = 0.03891
Step 34720: loss = 0.04807
Step 34725: loss = 0.11146
Step 34730: loss = 0.05527
Step 34735: loss = 0.01558
Step 34740: loss = 0.10867
Step 34745: loss = 0.05697
Step 34750: loss = 0.03205
Step 34755: loss = 0.11664
Step 34760: loss = 0.03247
Step 34765: loss = 0.05127
Step 34770: loss = 0.10916
Step 34775: loss = 0.11590
Step 34780: loss = 0.02563
Step 34785: loss = 0.07650
Step 34790: loss = 0.04917
Step 34795: loss = 0.09244
Step 34800: loss = 0.04500
Step 34805: loss = 0.16448
Step 34810: loss = 0.04334
Step 34815: loss = 0.10928
Step 34820: loss = 0.05761
Step 34825: loss = 0.05192
Step 34830: loss = 0.12305
Step 34835: loss = 0.05707
Step 34840: loss = 0.06178
Step 34845: loss = 0.04168
Step 34850: loss = 0.04546
Step 34855: loss = 0.04234
Step 34860: loss = 0.07931
Step 34865: loss = 0.04187
Step 34870: loss = 0.03540
Step 34875: loss = 0.03415
Step 34880: loss = 0.06557
Step 34885: loss = 0.08949
Step 34890: loss = 0.05367
Step 34895: loss = 0.03069
Step 34900: loss = 0.09619
Step 34905: loss = 0.13507
Step 34910: loss = 0.07535
Step 34915: loss = 0.01846
Step 34920: loss = 0.08326
Step 34925: loss = 0.04320
Step 34930: loss = 0.03859
Step 34935: loss = 0.05209
Step 34940: loss = 0.01555
Step 34945: loss = 0.03351
Step 34950: loss = 0.12334
Step 34955: loss = 0.04591
Step 34960: loss = 0.04838
Step 34965: loss = 0.04720
Step 34970: loss = 0.04405
Step 34975: loss = 0.02818
Step 34980: loss = 0.04131
Step 34985: loss = 0.03347
Step 34990: loss = 0.02875
Step 34995: loss = 0.07604
Step 35000: loss = 0.11107
Training Data Eval:
  Num examples: 50000, Num correct: 49283, Precision @ 1: 0.9857
('Testing Data Eval: EPOCH->', 36)
  Num examples: 10000, Num correct: 6819, Precision @ 1: 0.6819
Step 35005: loss = 0.04688
Step 35010: loss = 0.01729
Step 35015: loss = 0.01709
Step 35020: loss = 0.03839
Step 35025: loss = 0.06568
Step 35030: loss = 0.04651
Step 35035: loss = 0.03481
Step 35040: loss = 0.03862
Step 35045: loss = 0.06475
Step 35050: loss = 0.03760
Step 35055: loss = 0.05494
Step 35060: loss = 0.03008
Step 35065: loss = 0.01460
Step 35070: loss = 0.13410
Step 35075: loss = 0.01693
Step 35080: loss = 0.02659
Step 35085: loss = 0.02818
Step 35090: loss = 0.02725
Step 35095: loss = 0.08997
Step 35100: loss = 0.01966
Step 35105: loss = 0.04116
Step 35110: loss = 0.01603
Step 35115: loss = 0.06663
Step 35120: loss = 0.15838
Step 35125: loss = 0.04376
Step 35130: loss = 0.10141
Step 35135: loss = 0.04073
Step 35140: loss = 0.03012
Step 35145: loss = 0.03943
Step 35150: loss = 0.10991
Step 35155: loss = 0.03399
Step 35160: loss = 0.10190
Step 35165: loss = 0.01696
Step 35170: loss = 0.04150
Step 35175: loss = 0.04250
Step 35180: loss = 0.06116
Step 35185: loss = 0.06316
Step 35190: loss = 0.05056
Step 35195: loss = 0.04179
Step 35200: loss = 0.05298
Step 35205: loss = 0.05449
Step 35210: loss = 0.09312
Step 35215: loss = 0.02436
Step 35220: loss = 0.06574
Step 35225: loss = 0.02583
Step 35230: loss = 0.06398
Step 35235: loss = 0.01947
Step 35240: loss = 0.02203
Step 35245: loss = 0.07237
Step 35250: loss = 0.01695
Step 35255: loss = 0.05293
Step 35260: loss = 0.02894
Step 35265: loss = 0.06587
Step 35270: loss = 0.08187
Step 35275: loss = 0.02630
Step 35280: loss = 0.07798
Step 35285: loss = 0.02307
Step 35290: loss = 0.13016
Step 35295: loss = 0.13885
Step 35300: loss = 0.06632
Step 35305: loss = 0.08406
Step 35310: loss = 0.16506
Step 35315: loss = 0.07759
Step 35320: loss = 0.03456
Step 35325: loss = 0.06867
Step 35330: loss = 0.06567
Step 35335: loss = 0.07018
Step 35340: loss = 0.02830
Step 35345: loss = 0.15667
Step 35350: loss = 0.04947
Step 35355: loss = 0.01333
Step 35360: loss = 0.08270
Step 35365: loss = 0.03262
Step 35370: loss = 0.19950
Step 35375: loss = 0.07265
Step 35380: loss = 0.09175
Step 35385: loss = 0.08919
Step 35390: loss = 0.05262
Step 35395: loss = 0.00773
Step 35400: loss = 0.08399
Step 35405: loss = 0.03657
Step 35410: loss = 0.05596
Step 35415: loss = 0.06356
Step 35420: loss = 0.06376
Step 35425: loss = 0.02077
Step 35430: loss = 0.09744
Step 35435: loss = 0.07605
Step 35440: loss = 0.04508
Step 35445: loss = 0.04015
Step 35450: loss = 0.03854
Step 35455: loss = 0.09632
Step 35460: loss = 0.01171
Step 35465: loss = 0.03700
Step 35470: loss = 0.02939
Step 35475: loss = 0.08300
Step 35480: loss = 0.02127
Step 35485: loss = 0.03598
Step 35490: loss = 0.04679
Step 35495: loss = 0.03938
Step 35500: loss = 0.15957
Step 35505: loss = 0.04884
Step 35510: loss = 0.04328
Step 35515: loss = 0.07455
Step 35520: loss = 0.04581
Step 35525: loss = 0.01540
Step 35530: loss = 0.01449
Step 35535: loss = 0.00846
Step 35540: loss = 0.08061
Step 35545: loss = 0.09061
Step 35550: loss = 0.03496
Step 35555: loss = 0.06700
Step 35560: loss = 0.04205
Step 35565: loss = 0.02063
Step 35570: loss = 0.04413
Step 35575: loss = 0.01878
Step 35580: loss = 0.04504
Step 35585: loss = 0.09642
Step 35590: loss = 0.06088
Step 35595: loss = 0.04113
Step 35600: loss = 0.01679
Step 35605: loss = 0.03262
Step 35610: loss = 0.06515
Step 35615: loss = 0.09708
Step 35620: loss = 0.02247
Step 35625: loss = 0.06508
Step 35630: loss = 0.04768
Step 35635: loss = 0.11745
Step 35640: loss = 0.14126
Step 35645: loss = 0.02141
Step 35650: loss = 0.01615
Step 35655: loss = 0.02578
Step 35660: loss = 0.07231
Step 35665: loss = 0.03608
Step 35670: loss = 0.01311
Step 35675: loss = 0.03674
Step 35680: loss = 0.04195
Step 35685: loss = 0.02426
Step 35690: loss = 0.03413
Step 35695: loss = 0.13239
Step 35700: loss = 0.04430
Step 35705: loss = 0.03601
Step 35710: loss = 0.06108
Step 35715: loss = 0.01420
Step 35720: loss = 0.03377
Step 35725: loss = 0.03714
Step 35730: loss = 0.02446
Step 35735: loss = 0.04616
Step 35740: loss = 0.02908
Step 35745: loss = 0.03857
Step 35750: loss = 0.01228
Step 35755: loss = 0.03836
Step 35760: loss = 0.03719
Step 35765: loss = 0.02725
Step 35770: loss = 0.06942
Step 35775: loss = 0.02025
Step 35780: loss = 0.00897
Step 35785: loss = 0.02840
Step 35790: loss = 0.01706
Step 35795: loss = 0.09947
Step 35800: loss = 0.14258
Step 35805: loss = 0.07004
Step 35810: loss = 0.02992
Step 35815: loss = 0.00698
Step 35820: loss = 0.07993
Step 35825: loss = 0.11661
Step 35830: loss = 0.07018
Step 35835: loss = 0.07901
Step 35840: loss = 0.06541
Step 35845: loss = 0.06883
Step 35850: loss = 0.05497
Step 35855: loss = 0.01367
Step 35860: loss = 0.04287
Step 35865: loss = 0.00790
Step 35870: loss = 0.21882
Step 35875: loss = 0.14431
Step 35880: loss = 0.01406
Step 35885: loss = 0.01855
Step 35890: loss = 0.02868
Step 35895: loss = 0.02768
Step 35900: loss = 0.05329
Step 35905: loss = 0.04248
Step 35910: loss = 0.08720
Step 35915: loss = 0.02242
Step 35920: loss = 0.04883
Step 35925: loss = 0.03331
Step 35930: loss = 0.04557
Step 35935: loss = 0.06260
Step 35940: loss = 0.07833
Step 35945: loss = 0.04605
Step 35950: loss = 0.02077
Step 35955: loss = 0.02359
Step 35960: loss = 0.01323
Step 35965: loss = 0.09345
Step 35970: loss = 0.06573
Step 35975: loss = 0.06612
Step 35980: loss = 0.10558
Step 35985: loss = 0.14109
Step 35990: loss = 0.03515
Step 35995: loss = 0.04119
Step 36000: loss = 0.07266
Training Data Eval:
  Num examples: 50000, Num correct: 49071, Precision @ 1: 0.9814
('Testing Data Eval: EPOCH->', 37)
  Num examples: 10000, Num correct: 6753, Precision @ 1: 0.6753
Step 36005: loss = 0.06290
Step 36010: loss = 0.05723
Step 36015: loss = 0.07495
Step 36020: loss = 0.05096
Step 36025: loss = 0.09130
Step 36030: loss = 0.05968
Step 36035: loss = 0.02660
Step 36040: loss = 0.03839
Step 36045: loss = 0.12196
Step 36050: loss = 0.08954
Step 36055: loss = 0.11615
Step 36060: loss = 0.00670
Step 36065: loss = 0.06653
Step 36070: loss = 0.02949
Step 36075: loss = 0.02112
Step 36080: loss = 0.06436
Step 36085: loss = 0.02926
Step 36090: loss = 0.02379
Step 36095: loss = 0.04095
Step 36100: loss = 0.05455
Step 36105: loss = 0.05038
Step 36110: loss = 0.08941
Step 36115: loss = 0.02606
Step 36120: loss = 0.01824
Step 36125: loss = 0.06476
Step 36130: loss = 0.01587
Step 36135: loss = 0.03717
Step 36140: loss = 0.02930
Step 36145: loss = 0.08152
Step 36150: loss = 0.07139
Step 36155: loss = 0.08583
Step 36160: loss = 0.06658
Step 36165: loss = 0.08263
Step 36170: loss = 0.05636
Step 36175: loss = 0.03298
Step 36180: loss = 0.03793
Step 36185: loss = 0.04115
Step 36190: loss = 0.03268
Step 36195: loss = 0.05888
Step 36200: loss = 0.01613
Step 36205: loss = 0.05731
Step 36210: loss = 0.02698
Step 36215: loss = 0.02975
Step 36220: loss = 0.04175
Step 36225: loss = 0.02778
Step 36230: loss = 0.03518
Step 36235: loss = 0.03165
Step 36240: loss = 0.00768
Step 36245: loss = 0.08737
Step 36250: loss = 0.07672
Step 36255: loss = 0.04667
Step 36260: loss = 0.02707
Step 36265: loss = 0.03384
Step 36270: loss = 0.02005
Step 36275: loss = 0.11638
Step 36280: loss = 0.17938
Step 36285: loss = 0.02982
Step 36290: loss = 0.03126
Step 36295: loss = 0.14904
Step 36300: loss = 0.01711
Step 36305: loss = 0.09921
Step 36310: loss = 0.02120
Step 36315: loss = 0.01473
Step 36320: loss = 0.10503
Step 36325: loss = 0.05875
Step 36330: loss = 0.06839
Step 36335: loss = 0.02641
Step 36340: loss = 0.06098
Step 36345: loss = 0.07564
Step 36350: loss = 0.03922
Step 36355: loss = 0.01358
Step 36360: loss = 0.12987
Step 36365: loss = 0.05809
Step 36370: loss = 0.03854
Step 36375: loss = 0.11310
Step 36380: loss = 0.02888
Step 36385: loss = 0.01118
Step 36390: loss = 0.10761
Step 36395: loss = 0.10090
Step 36400: loss = 0.03179
Step 36405: loss = 0.01622
Step 36410: loss = 0.01237
Step 36415: loss = 0.02744
Step 36420: loss = 0.05774
Step 36425: loss = 0.04444
Step 36430: loss = 0.04179
Step 36435: loss = 0.04167
Step 36440: loss = 0.12073
Step 36445: loss = 0.07525
Step 36450: loss = 0.02268
Step 36455: loss = 0.03902
Step 36460: loss = 0.04409
Step 36465: loss = 0.02563
Step 36470: loss = 0.02970
Step 36475: loss = 0.04748
Step 36480: loss = 0.05384
Step 36485: loss = 0.05164
Step 36490: loss = 0.08880
Step 36495: loss = 0.01636
Step 36500: loss = 0.04037
Step 36505: loss = 0.09007
Step 36510: loss = 0.05846
Step 36515: loss = 0.02715
Step 36520: loss = 0.02912
Step 36525: loss = 0.02507
Step 36530: loss = 0.25828
Step 36535: loss = 0.03742
Step 36540: loss = 0.02331
Step 36545: loss = 0.01471
Step 36550: loss = 0.03109
Step 36555: loss = 0.04907
Step 36560: loss = 0.04356
Step 36565: loss = 0.02666
Step 36570: loss = 0.01212
Step 36575: loss = 0.07132
Step 36580: loss = 0.02525
Step 36585: loss = 0.03782
Step 36590: loss = 0.02065
Step 36595: loss = 0.05040
Step 36600: loss = 0.03841
Step 36605: loss = 0.22441
Step 36610: loss = 0.07394
Step 36615: loss = 0.04031
Step 36620: loss = 0.09006
Step 36625: loss = 0.01544
Step 36630: loss = 0.02132
Step 36635: loss = 0.03413
Step 36640: loss = 0.05340
Step 36645: loss = 0.00669
Step 36650: loss = 0.03431
Step 36655: loss = 0.01410
Step 36660: loss = 0.01633
Step 36665: loss = 0.04599
Step 36670: loss = 0.06376
Step 36675: loss = 0.01403
Step 36680: loss = 0.03255
Step 36685: loss = 0.03239
Step 36690: loss = 0.05771
Step 36695: loss = 0.02617
Step 36700: loss = 0.02971
Step 36705: loss = 0.01400
Step 36710: loss = 0.03262
Step 36715: loss = 0.02380
Step 36720: loss = 0.07378
Step 36725: loss = 0.06161
Step 36730: loss = 0.02540
Step 36735: loss = 0.05312
Step 36740: loss = 0.06956
Step 36745: loss = 0.05498
Step 36750: loss = 0.02919
Step 36755: loss = 0.11846
Step 36760: loss = 0.02793
Step 36765: loss = 0.07302
Step 36770: loss = 0.05787
Step 36775: loss = 0.07501
Step 36780: loss = 0.01248
Step 36785: loss = 0.03385
Step 36790: loss = 0.04871
Step 36795: loss = 0.02174
Step 36800: loss = 0.02126
Step 36805: loss = 0.05658
Step 36810: loss = 0.02056
Step 36815: loss = 0.08939
Step 36820: loss = 0.03413
Step 36825: loss = 0.04072
Step 36830: loss = 0.03543
Step 36835: loss = 0.03253
Step 36840: loss = 0.14403
Step 36845: loss = 0.00761
Step 36850: loss = 0.05516
Step 36855: loss = 0.03702
Step 36860: loss = 0.01137
Step 36865: loss = 0.01482
Step 36870: loss = 0.05190
Step 36875: loss = 0.01979
Step 36880: loss = 0.07558
Step 36885: loss = 0.03452
Step 36890: loss = 0.10799
Step 36895: loss = 0.04350
Step 36900: loss = 0.04139
Step 36905: loss = 0.02599
Step 36910: loss = 0.07868
Step 36915: loss = 0.02262
Step 36920: loss = 0.05941
Step 36925: loss = 0.02590
Step 36930: loss = 0.07799
Step 36935: loss = 0.03522
Step 36940: loss = 0.04145
Step 36945: loss = 0.09837
Step 36950: loss = 0.07490
Step 36955: loss = 0.04213
Step 36960: loss = 0.08334
Step 36965: loss = 0.07353
Step 36970: loss = 0.03120
Step 36975: loss = 0.02877
Step 36980: loss = 0.04010
Step 36985: loss = 0.06379
Step 36990: loss = 0.09748
Step 36995: loss = 0.03831
Step 37000: loss = 0.01681
Training Data Eval:
  Num examples: 50000, Num correct: 49424, Precision @ 1: 0.9885
('Testing Data Eval: EPOCH->', 38)
  Num examples: 10000, Num correct: 6735, Precision @ 1: 0.6735
Step 37005: loss = 0.00833
Step 37010: loss = 0.03212
Step 37015: loss = 0.07397
Step 37020: loss = 0.02377
Step 37025: loss = 0.02819
Step 37030: loss = 0.06755
Step 37035: loss = 0.02540
Step 37040: loss = 0.01068
Step 37045: loss = 0.02922
Step 37050: loss = 0.02102
Step 37055: loss = 0.06358
Step 37060: loss = 0.03705
Step 37065: loss = 0.02350
Step 37070: loss = 0.03580
Step 37075: loss = 0.01299
Step 37080: loss = 0.04921
Step 37085: loss = 0.02064
Step 37090: loss = 0.03567
Step 37095: loss = 0.01274
Step 37100: loss = 0.05066
Step 37105: loss = 0.02565
Step 37110: loss = 0.03918
Step 37115: loss = 0.02812
Step 37120: loss = 0.02800
Step 37125: loss = 0.05921
Step 37130: loss = 0.01691
Step 37135: loss = 0.04545
Step 37140: loss = 0.02615
Step 37145: loss = 0.04285
Step 37150: loss = 0.05296
Step 37155: loss = 0.07236
Step 37160: loss = 0.10068
Step 37165: loss = 0.07090
Step 37170: loss = 0.04591
Step 37175: loss = 0.02076
Step 37180: loss = 0.10936
Step 37185: loss = 0.04221
Step 37190: loss = 0.06693
Step 37195: loss = 0.08604
Step 37200: loss = 0.02510
Step 37205: loss = 0.00513
Step 37210: loss = 0.02651
Step 37215: loss = 0.07321
Step 37220: loss = 0.03881
Step 37225: loss = 0.09883
Step 37230: loss = 0.03524
Step 37235: loss = 0.03502
Step 37240: loss = 0.05122
Step 37245: loss = 0.07025
Step 37250: loss = 0.02020
Step 37255: loss = 0.03499
Step 37260: loss = 0.02927
Step 37265: loss = 0.01955
Step 37270: loss = 0.05825
Step 37275: loss = 0.07187
Step 37280: loss = 0.03095
Step 37285: loss = 0.04321
Step 37290: loss = 0.03707
Step 37295: loss = 0.03347
Step 37300: loss = 0.02985
Step 37305: loss = 0.02270
Step 37310: loss = 0.03904
Step 37315: loss = 0.04309
Step 37320: loss = 0.03429
Step 37325: loss = 0.02231
Step 37330: loss = 0.13796
Step 37335: loss = 0.03084
Step 37340: loss = 0.02535
Step 37345: loss = 0.04940
Step 37350: loss = 0.02901
Step 37355: loss = 0.02313
Step 37360: loss = 0.04910
Step 37365: loss = 0.15330
Step 37370: loss = 0.04963
Step 37375: loss = 0.05251
Step 37380: loss = 0.05164
Step 37385: loss = 0.05294
Step 37390: loss = 0.07374
Step 37395: loss = 0.21555
Step 37400: loss = 0.02372
Step 37405: loss = 0.03393
Step 37410: loss = 0.07513
Step 37415: loss = 0.06654
Step 37420: loss = 0.10630
Step 37425: loss = 0.04068
Step 37430: loss = 0.04625
Step 37435: loss = 0.01560
Step 37440: loss = 0.03591
Step 37445: loss = 0.07228
Step 37450: loss = 0.02652
Step 37455: loss = 0.05318
Step 37460: loss = 0.11012
Step 37465: loss = 0.02331
Step 37470: loss = 0.09185
Step 37475: loss = 0.00834
Step 37480: loss = 0.04492
Step 37485: loss = 0.07878
Step 37490: loss = 0.05975
Step 37495: loss = 0.06549
Step 37500: loss = 0.03061
Step 37505: loss = 0.10924
Step 37510: loss = 0.04426
Step 37515: loss = 0.01468
Step 37520: loss = 0.03602
Step 37525: loss = 0.03059
Step 37530: loss = 0.02438
Step 37535: loss = 0.03945
Step 37540: loss = 0.00865
Step 37545: loss = 0.01678
Step 37550: loss = 0.00903
Step 37555: loss = 0.00195
Step 37560: loss = 0.05137
Step 37565: loss = 0.04781
Step 37570: loss = 0.01849
Step 37575: loss = 0.14836
Step 37580: loss = 0.01440
Step 37585: loss = 0.02676
Step 37590: loss = 0.07373
Step 37595: loss = 0.03062
Step 37600: loss = 0.04253
Step 37605: loss = 0.06555
Step 37610: loss = 0.11032
Step 37615: loss = 0.05694
Step 37620: loss = 0.03694
Step 37625: loss = 0.01784
Step 37630: loss = 0.02207
Step 37635: loss = 0.01266
Step 37640: loss = 0.03978
Step 37645: loss = 0.03444
Step 37650: loss = 0.00768
Step 37655: loss = 0.02541
Step 37660: loss = 0.03185
Step 37665: loss = 0.09046
Step 37670: loss = 0.08117
Step 37675: loss = 0.07024
Step 37680: loss = 0.02521
Step 37685: loss = 0.02095
Step 37690: loss = 0.06887
Step 37695: loss = 0.02883
Step 37700: loss = 0.06147
Step 37705: loss = 0.01859
Step 37710: loss = 0.02591
Step 37715: loss = 0.16840
Step 37720: loss = 0.05763
Step 37725: loss = 0.05299
Step 37730: loss = 0.02146
Step 37735: loss = 0.03516
Step 37740: loss = 0.03387
Step 37745: loss = 0.04934
Step 37750: loss = 0.03598
Step 37755: loss = 0.03448
Step 37760: loss = 0.04297
Step 37765: loss = 0.05919
Step 37770: loss = 0.07247
Step 37775: loss = 0.03988
Step 37780: loss = 0.01691
Step 37785: loss = 0.02789
Step 37790: loss = 0.01719
Step 37795: loss = 0.07309
Step 37800: loss = 0.02613
Step 37805: loss = 0.06102
Step 37810: loss = 0.06859
Step 37815: loss = 0.09886
Step 37820: loss = 0.04812
Step 37825: loss = 0.03759
Step 37830: loss = 0.04655
Step 37835: loss = 0.01450
Step 37840: loss = 0.06642
Step 37845: loss = 0.13384
Step 37850: loss = 0.02297
Step 37855: loss = 0.04141
Step 37860: loss = 0.05666
Step 37865: loss = 0.03888
Step 37870: loss = 0.08728
Step 37875: loss = 0.03065
Step 37880: loss = 0.06775
Step 37885: loss = 0.03752
Step 37890: loss = 0.32948
Step 37895: loss = 0.03631
Step 37900: loss = 0.08293
Step 37905: loss = 0.10355
Step 37910: loss = 0.00940
Step 37915: loss = 0.09430
Step 37920: loss = 0.03050
Step 37925: loss = 0.03942
Step 37930: loss = 0.11328
Step 37935: loss = 0.11980
Step 37940: loss = 0.15294
Step 37945: loss = 0.11693
Step 37950: loss = 0.03791
Step 37955: loss = 0.04271
Step 37960: loss = 0.02432
Step 37965: loss = 0.08430
Step 37970: loss = 0.17823
Step 37975: loss = 0.05152
Step 37980: loss = 0.03745
Step 37985: loss = 0.07807
Step 37990: loss = 0.04913
Step 37995: loss = 0.01301
Step 38000: loss = 0.02836
Training Data Eval:
  Num examples: 50000, Num correct: 49195, Precision @ 1: 0.9839
('Testing Data Eval: EPOCH->', 39)
  Num examples: 10000, Num correct: 6825, Precision @ 1: 0.6825
Step 38005: loss = 0.02663
Step 38010: loss = 0.05634
Step 38015: loss = 0.02986
Step 38020: loss = 0.03552
Step 38025: loss = 0.04337
Step 38030: loss = 0.01031
Step 38035: loss = 0.00937
Step 38040: loss = 0.00989
Step 38045: loss = 0.08558
Step 38050: loss = 0.06290
Step 38055: loss = 0.00679
Step 38060: loss = 0.11581
Step 38065: loss = 0.04087
Step 38070: loss = 0.06065
Step 38075: loss = 0.08458
Step 38080: loss = 0.06939
Step 38085: loss = 0.04760
Step 38090: loss = 0.03659
Step 38095: loss = 0.09360
Step 38100: loss = 0.01352
Step 38105: loss = 0.06494
Step 38110: loss = 0.03344
Step 38115: loss = 0.03907
Step 38120: loss = 0.02535
Step 38125: loss = 0.07612
Step 38130: loss = 0.01358
Step 38135: loss = 0.06561
Step 38140: loss = 0.01353
Step 38145: loss = 0.03792
Step 38150: loss = 0.11283
Step 38155: loss = 0.04004
Step 38160: loss = 0.01660
Step 38165: loss = 0.05563
Step 38170: loss = 0.01458
Step 38175: loss = 0.02624
Step 38180: loss = 0.04756
Step 38185: loss = 0.02807
Step 38190: loss = 0.03397
Step 38195: loss = 0.08465
Step 38200: loss = 0.03315
Step 38205: loss = 0.01727
Step 38210: loss = 0.01342
Step 38215: loss = 0.03681
Step 38220: loss = 0.05447
Step 38225: loss = 0.02663
Step 38230: loss = 0.07254
Step 38235: loss = 0.02441
Step 38240: loss = 0.09225
Step 38245: loss = 0.06581
Step 38250: loss = 0.05225
Step 38255: loss = 0.04956
Step 38260: loss = 0.01299
Step 38265: loss = 0.05620
Step 38270: loss = 0.02577
Step 38275: loss = 0.00890
Step 38280: loss = 0.08438
Step 38285: loss = 0.06465
Step 38290: loss = 0.02672
Step 38295: loss = 0.04185
Step 38300: loss = 0.02948
Step 38305: loss = 0.06931
Step 38310: loss = 0.02030
Step 38315: loss = 0.04368
Step 38320: loss = 0.04504
Step 38325: loss = 0.05369
Step 38330: loss = 0.04909
Step 38335: loss = 0.04969
Step 38340: loss = 0.06857
Step 38345: loss = 0.02157
Step 38350: loss = 0.08044
Step 38355: loss = 0.01054
Step 38360: loss = 0.02764
Step 38365: loss = 0.03088
Step 38370: loss = 0.07256
Step 38375: loss = 0.04166
Step 38380: loss = 0.01771
Step 38385: loss = 0.02173
Step 38390: loss = 0.07657
Step 38395: loss = 0.02011
Step 38400: loss = 0.04288
Step 38405: loss = 0.07506
Step 38410: loss = 0.01759
Step 38415: loss = 0.03370
Step 38420: loss = 0.03929
Step 38425: loss = 0.01366
Step 38430: loss = 0.04402
Step 38435: loss = 0.05920
Step 38440: loss = 0.03176
Step 38445: loss = 0.04500
Step 38450: loss = 0.02585
Step 38455: loss = 0.01519
Step 38460: loss = 0.09086
Step 38465: loss = 0.04364
Step 38470: loss = 0.07803
Step 38475: loss = 0.00985
Step 38480: loss = 0.04967
Step 38485: loss = 0.05433
Step 38490: loss = 0.02984
Step 38495: loss = 0.06824
Step 38500: loss = 0.08769
Step 38505: loss = 0.07668
Step 38510: loss = 0.01388
Step 38515: loss = 0.13004
Step 38520: loss = 0.04810
Step 38525: loss = 0.11094
Step 38530: loss = 0.01780
Step 38535: loss = 0.04889
Step 38540: loss = 0.04286
Step 38545: loss = 0.01462
Step 38550: loss = 0.05477
Step 38555: loss = 0.03979
Step 38560: loss = 0.07988
Step 38565: loss = 0.04875
Step 38570: loss = 0.04485
Step 38575: loss = 0.02671
Step 38580: loss = 0.04954
Step 38585: loss = 0.05911
Step 38590: loss = 0.00942
Step 38595: loss = 0.03860
Step 38600: loss = 0.02470
Step 38605: loss = 0.01972
Step 38610: loss = 0.03300
Step 38615: loss = 0.01130
Step 38620: loss = 0.08627
Step 38625: loss = 0.04569
Step 38630: loss = 0.04928
Step 38635: loss = 0.03231
Step 38640: loss = 0.03196
Step 38645: loss = 0.02006
Step 38650: loss = 0.09287
Step 38655: loss = 0.10449
Step 38660: loss = 0.06266
Step 38665: loss = 0.03025
Step 38670: loss = 0.01710
Step 38675: loss = 0.01497
Step 38680: loss = 0.15041
Step 38685: loss = 0.03484
Step 38690: loss = 0.01297
Step 38695: loss = 0.03382
Step 38700: loss = 0.07375
Step 38705: loss = 0.05137
Step 38710: loss = 0.02464
Step 38715: loss = 0.03594
Step 38720: loss = 0.03093
Step 38725: loss = 0.07304
Step 38730: loss = 0.07482
Step 38735: loss = 0.04103
Step 38740: loss = 0.02778
Step 38745: loss = 0.05162
Step 38750: loss = 0.06394
Step 38755: loss = 0.05576
Step 38760: loss = 0.22087
Step 38765: loss = 0.08154
Step 38770: loss = 0.02307
Step 38775: loss = 0.01784
Step 38780: loss = 0.02373
Step 38785: loss = 0.00734
Step 38790: loss = 0.01281
Step 38795: loss = 0.01378
Step 38800: loss = 0.04368
Step 38805: loss = 0.04745
Step 38810: loss = 0.04636
Step 38815: loss = 0.00588
Step 38820: loss = 0.00871
Step 38825: loss = 0.14305
Step 38830: loss = 0.03324
Step 38835: loss = 0.03876
Step 38840: loss = 0.10145
Step 38845: loss = 0.03665
Step 38850: loss = 0.01200
Step 38855: loss = 0.03358
Step 38860: loss = 0.04188
Step 38865: loss = 0.09219
Step 38870: loss = 0.03131
Step 38875: loss = 0.04122
Step 38880: loss = 0.05740
Step 38885: loss = 0.03156
Step 38890: loss = 0.09978
Step 38895: loss = 0.18556
Step 38900: loss = 0.07575
Step 38905: loss = 0.01990
Step 38910: loss = 0.05856
Step 38915: loss = 0.06706
Step 38920: loss = 0.04756
Step 38925: loss = 0.05477
Step 38930: loss = 0.06023
Step 38935: loss = 0.07752
Step 38940: loss = 0.05677
Step 38945: loss = 0.08242
Step 38950: loss = 0.05096
Step 38955: loss = 0.12893
Step 38960: loss = 0.07452
Step 38965: loss = 0.06011
Step 38970: loss = 0.01833
Step 38975: loss = 0.01540
Step 38980: loss = 0.08463
Step 38985: loss = 0.01822
Step 38990: loss = 0.07923
Step 38995: loss = 0.05166
Step 39000: loss = 0.03044
Training Data Eval:
  Num examples: 50000, Num correct: 49349, Precision @ 1: 0.9870
('Testing Data Eval: EPOCH->', 40)
  Num examples: 10000, Num correct: 6742, Precision @ 1: 0.6742
Step 39005: loss = 0.01953
Step 39010: loss = 0.00373
Step 39015: loss = 0.04451
Step 39020: loss = 0.03304
Step 39025: loss = 0.02330
Step 39030: loss = 0.02073
Step 39035: loss = 0.07976
Step 39040: loss = 0.01812
Step 39045: loss = 0.03044
Step 39050: loss = 0.07495
Step 39055: loss = 0.02007
Step 39060: loss = 0.08931
Step 39065: loss = 0.02795
Step 39070: loss = 0.04465
Step 39075: loss = 0.00949
Step 39080: loss = 0.01421
Step 39085: loss = 0.07109
Step 39090: loss = 0.06079
Step 39095: loss = 0.06630
Step 39100: loss = 0.05773
Step 39105: loss = 0.03590
Step 39110: loss = 0.01768
Step 39115: loss = 0.01855
Step 39120: loss = 0.03904
Step 39125: loss = 0.02539
Step 39130: loss = 0.10229
Step 39135: loss = 0.01440
Step 39140: loss = 0.01789
Step 39145: loss = 0.03962
Step 39150: loss = 0.03689
Step 39155: loss = 0.06298
Step 39160: loss = 0.07754
Step 39165: loss = 0.04282
Step 39170: loss = 0.05061
Step 39175: loss = 0.05526
Step 39180: loss = 0.00788
Step 39185: loss = 0.07538
Step 39190: loss = 0.04305
Step 39195: loss = 0.01810
Step 39200: loss = 0.02938
Step 39205: loss = 0.04775
Step 39210: loss = 0.06292
Step 39215: loss = 0.02194
Step 39220: loss = 0.06097
Step 39225: loss = 0.02876
Step 39230: loss = 0.02725
Step 39235: loss = 0.03110
Step 39240: loss = 0.02449
Step 39245: loss = 0.03148
Step 39250: loss = 0.08311
Step 39255: loss = 0.10533
Step 39260: loss = 0.03092
Step 39265: loss = 0.03248
Step 39270: loss = 0.03931
Step 39275: loss = 0.03670
Step 39280: loss = 0.04019
Step 39285: loss = 0.02162
Step 39290: loss = 0.01005
Step 39295: loss = 0.12842
Step 39300: loss = 0.01217
Step 39305: loss = 0.06981
Step 39310: loss = 0.03112
Step 39315: loss = 0.11560
Step 39320: loss = 0.04138
Step 39325: loss = 0.03014
Step 39330: loss = 0.02660
Step 39335: loss = 0.02683
Step 39340: loss = 0.01137
Step 39345: loss = 0.01705
Step 39350: loss = 0.04187
Step 39355: loss = 0.01182
Step 39360: loss = 0.02031
Step 39365: loss = 0.03754
Step 39370: loss = 0.05095
Step 39375: loss = 0.04175
Step 39380: loss = 0.02607
Step 39385: loss = 0.04662
Step 39390: loss = 0.03995
Step 39395: loss = 0.05964
Step 39400: loss = 0.03309
Step 39405: loss = 0.02390
Step 39410: loss = 0.02364
Step 39415: loss = 0.05280
Step 39420: loss = 0.01047
Step 39425: loss = 0.00577
Step 39430: loss = 0.00899
Step 39435: loss = 0.05070
Step 39440: loss = 0.04479
Step 39445: loss = 0.03413
Step 39450: loss = 0.02478
Step 39455: loss = 0.04539
Step 39460: loss = 0.04536
Step 39465: loss = 0.00587
Step 39470: loss = 0.02672
Step 39475: loss = 0.07636
Step 39480: loss = 0.09414
Step 39485: loss = 0.02373
Step 39490: loss = 0.07585
Step 39495: loss = 0.06922
Step 39500: loss = 0.11486
Step 39505: loss = 0.03794
Step 39510: loss = 0.03285
Step 39515: loss = 0.02863
Step 39520: loss = 0.02116
Step 39525: loss = 0.05599
Step 39530: loss = 0.05720
Step 39535: loss = 0.02051
Step 39540: loss = 0.05995
Step 39545: loss = 0.04518
Step 39550: loss = 0.10116
Step 39555: loss = 0.07616
Step 39560: loss = 0.04813
Step 39565: loss = 0.00625
Step 39570: loss = 0.05875
Step 39575: loss = 0.10172
Step 39580: loss = 0.03337
Step 39585: loss = 0.01137
Step 39590: loss = 0.02416
Step 39595: loss = 0.06268
Step 39600: loss = 0.10121
Step 39605: loss = 0.01649
Step 39610: loss = 0.01519
Step 39615: loss = 0.03184
Step 39620: loss = 0.06363
Step 39625: loss = 0.02275
Step 39630: loss = 0.02109
Step 39635: loss = 0.06969
Step 39640: loss = 0.03273
Step 39645: loss = 0.02912
Step 39650: loss = 0.09415
Step 39655: loss = 0.11208
Step 39660: loss = 0.01426
Step 39665: loss = 0.03560
Step 39670: loss = 0.02139
Step 39675: loss = 0.11946
Step 39680: loss = 0.06539
Step 39685: loss = 0.00821
Step 39690: loss = 0.08985
Step 39695: loss = 0.03462
Step 39700: loss = 0.10347
Step 39705: loss = 0.04137
Step 39710: loss = 0.04838
Step 39715: loss = 0.05755
Step 39720: loss = 0.01085
Step 39725: loss = 0.03152
Step 39730: loss = 0.08197
Step 39735: loss = 0.03737
Step 39740: loss = 0.01127
Step 39745: loss = 0.00922
Step 39750: loss = 0.02045
Step 39755: loss = 0.03383
Step 39760: loss = 0.05331
Step 39765: loss = 0.03652
Step 39770: loss = 0.05193
Step 39775: loss = 0.10762
Step 39780: loss = 0.10776
Step 39785: loss = 0.07249
Step 39790: loss = 0.02229
Step 39795: loss = 0.11274
Step 39800: loss = 0.04948
Step 39805: loss = 0.01220
Step 39810: loss = 0.05176
Step 39815: loss = 0.09441
Step 39820: loss = 0.07125
Step 39825: loss = 0.05781
Step 39830: loss = 0.14976
Step 39835: loss = 0.08172
Step 39840: loss = 0.11922
Step 39845: loss = 0.02521
Step 39850: loss = 0.00858
Step 39855: loss = 0.01251
Step 39860: loss = 0.00998
Step 39865: loss = 0.02810
Step 39870: loss = 0.02517
Step 39875: loss = 0.06372
Step 39880: loss = 0.04924
Step 39885: loss = 0.07101
Step 39890: loss = 0.05203
Step 39895: loss = 0.08215
Step 39900: loss = 0.05331
Step 39905: loss = 0.04297
Step 39910: loss = 0.07209
Step 39915: loss = 0.01953
Step 39920: loss = 0.08071
Step 39925: loss = 0.05514
Step 39930: loss = 0.13133
Step 39935: loss = 0.16565
Step 39940: loss = 0.02020
Step 39945: loss = 0.01394
Step 39950: loss = 0.02052
Step 39955: loss = 0.00910
Step 39960: loss = 0.03383
Step 39965: loss = 0.02787
Step 39970: loss = 0.07042
Step 39975: loss = 0.00851
Step 39980: loss = 0.02661
Step 39985: loss = 0.07779
Step 39990: loss = 0.04259
Step 39995: loss = 0.05791
Step 40000: loss = 0.03080
Training Data Eval:
  Num examples: 50000, Num correct: 49343, Precision @ 1: 0.9869
('Testing Data Eval: EPOCH->', 41)
  Num examples: 10000, Num correct: 6789, Precision @ 1: 0.6789
Step 40005: loss = 0.10708
Step 40010: loss = 0.04914
Step 40015: loss = 0.01932
Step 40020: loss = 0.02933
Step 40025: loss = 0.05210
Step 40030: loss = 0.02329
Step 40035: loss = 0.10559
Step 40040: loss = 0.16624
Step 40045: loss = 0.10165
Step 40050: loss = 0.08773
Step 40055: loss = 0.02920
Step 40060: loss = 0.01466
Step 40065: loss = 0.03124
Step 40070: loss = 0.03834
Step 40075: loss = 0.04024
Step 40080: loss = 0.03009
Step 40085: loss = 0.04507
Step 40090: loss = 0.03669
Step 40095: loss = 0.03775
Step 40100: loss = 0.02883
Step 40105: loss = 0.05591
Step 40110: loss = 0.08574
Step 40115: loss = 0.03341
Step 40120: loss = 0.04687
Step 40125: loss = 0.03089
Step 40130: loss = 0.03111
Step 40135: loss = 0.02268
Step 40140: loss = 0.14271
Step 40145: loss = 0.00750
Step 40150: loss = 0.02795
Step 40155: loss = 0.05919
Step 40160: loss = 0.05676
Step 40165: loss = 0.01814
Step 40170: loss = 0.04061
Step 40175: loss = 0.01035
Step 40180: loss = 0.15721
Step 40185: loss = 0.02841
Step 40190: loss = 0.04955
Step 40195: loss = 0.09275
Step 40200: loss = 0.01792
Step 40205: loss = 0.13124
Step 40210: loss = 0.04027
Step 40215: loss = 0.14069
Step 40220: loss = 0.04224
Step 40225: loss = 0.09039
Step 40230: loss = 0.01773
Step 40235: loss = 0.01728
Step 40240: loss = 0.01865
Step 40245: loss = 0.02961
Step 40250: loss = 0.08131
Step 40255: loss = 0.08804
Step 40260: loss = 0.05374
Step 40265: loss = 0.04362
Step 40270: loss = 0.02929
Step 40275: loss = 0.06959
Step 40280: loss = 0.05266
Step 40285: loss = 0.03189
Step 40290: loss = 0.08101
Step 40295: loss = 0.10957
Step 40300: loss = 0.06020
Step 40305: loss = 0.03585
Step 40310: loss = 0.04493
Step 40315: loss = 0.03195
Step 40320: loss = 0.02472
Step 40325: loss = 0.04757
Step 40330: loss = 0.02159
Step 40335: loss = 0.07258
Step 40340: loss = 0.07185
Step 40345: loss = 0.13932
Step 40350: loss = 0.04756
Step 40355: loss = 0.09269
Step 40360: loss = 0.01442
Step 40365: loss = 0.11806
Step 40370: loss = 0.01948
Step 40375: loss = 0.03439
Step 40380: loss = 0.09564
Step 40385: loss = 0.02644
Step 40390: loss = 0.08126
Step 40395: loss = 0.02818
Step 40400: loss = 0.02316
Step 40405: loss = 0.11840
Step 40410: loss = 0.02925
Step 40415: loss = 0.11927
Step 40420: loss = 0.05842
Step 40425: loss = 0.03377
Step 40430: loss = 0.09867
Step 40435: loss = 0.11293
Step 40440: loss = 0.04707
Step 40445: loss = 0.09549
Step 40450: loss = 0.08033
Step 40455: loss = 0.03511
Step 40460: loss = 0.08038
Step 40465: loss = 0.01719
Step 40470: loss = 0.09065
Step 40475: loss = 0.01993
Step 40480: loss = 0.00890
Step 40485: loss = 0.08342
Step 40490: loss = 0.09312
Step 40495: loss = 0.01211
Step 40500: loss = 0.02737
Step 40505: loss = 0.07491
Step 40510: loss = 0.04298
Step 40515: loss = 0.04776
Step 40520: loss = 0.01308
Step 40525: loss = 0.04648
Step 40530: loss = 0.19377
Step 40535: loss = 0.08841
Step 40540: loss = 0.03989
Step 40545: loss = 0.08662
Step 40550: loss = 0.02322
Step 40555: loss = 0.00608
Step 40560: loss = 0.02785
Step 40565: loss = 0.07525
Step 40570: loss = 0.02512
Step 40575: loss = 0.01293
Step 40580: loss = 0.02555
Step 40585: loss = 0.06536
Step 40590: loss = 0.02350
Step 40595: loss = 0.03432
Step 40600: loss = 0.08959
Step 40605: loss = 0.02130
Step 40610: loss = 0.03635
Step 40615: loss = 0.05294
Step 40620: loss = 0.06144
Step 40625: loss = 0.03194
Step 40630: loss = 0.06945
Step 40635: loss = 0.13345
Step 40640: loss = 0.06189
Step 40645: loss = 0.03215
Step 40650: loss = 0.04439
Step 40655: loss = 0.04620
Step 40660: loss = 0.01785
Step 40665: loss = 0.05189
Step 40670: loss = 0.05206
Step 40675: loss = 0.04280
Step 40680: loss = 0.02000
Step 40685: loss = 0.02745
Step 40690: loss = 0.05105
Step 40695: loss = 0.07280
Step 40700: loss = 0.02283
Step 40705: loss = 0.04764
Step 40710: loss = 0.02586
Step 40715: loss = 0.07349
Step 40720: loss = 0.01721
Step 40725: loss = 0.01353
Step 40730: loss = 0.01394
Step 40735: loss = 0.08166
Step 40740: loss = 0.03678
Step 40745: loss = 0.02746
Step 40750: loss = 0.11267
Step 40755: loss = 0.00623
Step 40760: loss = 0.03658
Step 40765: loss = 0.04543
Step 40770: loss = 0.08645
Step 40775: loss = 0.05402
Step 40780: loss = 0.01940
Step 40785: loss = 0.02407
Step 40790: loss = 0.03700
Step 40795: loss = 0.03889
Step 40800: loss = 0.01741
Step 40805: loss = 0.02978
Step 40810: loss = 0.09240
Step 40815: loss = 0.06817
Step 40820: loss = 0.07376
Step 40825: loss = 0.11927
Step 40830: loss = 0.02753
Step 40835: loss = 0.07929
Step 40840: loss = 0.03624
Step 40845: loss = 0.05480
Step 40850: loss = 0.03577
Step 40855: loss = 0.03195
Step 40860: loss = 0.04552
Step 40865: loss = 0.02208
Step 40870: loss = 0.03928
Step 40875: loss = 0.05385
Step 40880: loss = 0.01788
Step 40885: loss = 0.09332
Step 40890: loss = 0.06110
Step 40895: loss = 0.24207
Step 40900: loss = 0.02059
Step 40905: loss = 0.03555
Step 40910: loss = 0.04546
Step 40915: loss = 0.05613
Step 40920: loss = 0.03203
Step 40925: loss = 0.08489
Step 40930: loss = 0.04626
Step 40935: loss = 0.02589
Step 40940: loss = 0.04698
Step 40945: loss = 0.07744
Step 40950: loss = 0.05390
Step 40955: loss = 0.04516
Step 40960: loss = 0.08016
Step 40965: loss = 0.06445
Step 40970: loss = 0.01623
Step 40975: loss = 0.04075
Step 40980: loss = 0.03450
Step 40985: loss = 0.02722
Step 40990: loss = 0.07580
Step 40995: loss = 0.16767
Step 41000: loss = 0.07655
Training Data Eval:
  Num examples: 50000, Num correct: 49276, Precision @ 1: 0.9855
('Testing Data Eval: EPOCH->', 42)
  Num examples: 10000, Num correct: 6785, Precision @ 1: 0.6785
Step 41005: loss = 0.07731
Step 41010: loss = 0.03448
Step 41015: loss = 0.01590
Step 41020: loss = 0.01622
Step 41025: loss = 0.04252
Step 41030: loss = 0.03098
Step 41035: loss = 0.01815
Step 41040: loss = 0.04019
Step 41045: loss = 0.02386
Step 41050: loss = 0.02324
Step 41055: loss = 0.03396
Step 41060: loss = 0.01327
Step 41065: loss = 0.05993
Step 41070: loss = 0.04704
Step 41075: loss = 0.07741
Step 41080: loss = 0.01265
Step 41085: loss = 0.01150
Step 41090: loss = 0.03789
Step 41095: loss = 0.01179
Step 41100: loss = 0.03211
Step 41105: loss = 0.13792
Step 41110: loss = 0.01975
Step 41115: loss = 0.05732
Step 41120: loss = 0.07780
Step 41125: loss = 0.02433
Step 41130: loss = 0.03231
Step 41135: loss = 0.03036
Step 41140: loss = 0.01717
Step 41145: loss = 0.04103
Step 41150: loss = 0.02772
Step 41155: loss = 0.06055
Step 41160: loss = 0.02690
Step 41165: loss = 0.05395
Step 41170: loss = 0.05239
Step 41175: loss = 0.04200
Step 41180: loss = 0.01787
Step 41185: loss = 0.01763
Step 41190: loss = 0.01789
Step 41195: loss = 0.12017
Step 41200: loss = 0.03335
Step 41205: loss = 0.01820
Step 41210: loss = 0.04274
Step 41215: loss = 0.01633
Step 41220: loss = 0.13012
Step 41225: loss = 0.03931
Step 41230: loss = 0.07254
Step 41235: loss = 0.03614
Step 41240: loss = 0.01696
Step 41245: loss = 0.02848
Step 41250: loss = 0.03382
Step 41255: loss = 0.02921
Step 41260: loss = 0.01900
Step 41265: loss = 0.05684
Step 41270: loss = 0.01110
Step 41275: loss = 0.13394
Step 41280: loss = 0.04450
Step 41285: loss = 0.03586
Step 41290: loss = 0.06184
Step 41295: loss = 0.07095
Step 41300: loss = 0.07867
Step 41305: loss = 0.02587
Step 41310: loss = 0.02905
Step 41315: loss = 0.04907
Step 41320: loss = 0.13710
Step 41325: loss = 0.01471
Step 41330: loss = 0.02087
Step 41335: loss = 0.01628
Step 41340: loss = 0.00897
Step 41345: loss = 0.10996
Step 41350: loss = 0.01720
Step 41355: loss = 0.03149
Step 41360: loss = 0.11548
Step 41365: loss = 0.00935
Step 41370: loss = 0.02919
Step 41375: loss = 0.05409
Step 41380: loss = 0.05262
Step 41385: loss = 0.08919
Step 41390: loss = 0.02319
Step 41395: loss = 0.05875
Step 41400: loss = 0.03581
Step 41405: loss = 0.10576
Step 41410: loss = 0.06727
Step 41415: loss = 0.12788
Step 41420: loss = 0.04685
Step 41425: loss = 0.03747
Step 41430: loss = 0.04046
Step 41435: loss = 0.02369
Step 41440: loss = 0.10998
Step 41445: loss = 0.18235
Step 41450: loss = 0.05954
Step 41455: loss = 0.05427
Step 41460: loss = 0.05071
Step 41465: loss = 0.05145
Step 41470: loss = 0.09635
Step 41475: loss = 0.03671
Step 41480: loss = 0.06459
Step 41485: loss = 0.10083
Step 41490: loss = 0.04284
Step 41495: loss = 0.05141
Step 41500: loss = 0.05619
Step 41505: loss = 0.02815
Step 41510: loss = 0.02651
Step 41515: loss = 0.02547
Step 41520: loss = 0.09738
Step 41525: loss = 0.02060
Step 41530: loss = 0.04362
Step 41535: loss = 0.02404
Step 41540: loss = 0.09749
Step 41545: loss = 0.02999
Step 41550: loss = 0.04133
Step 41555: loss = 0.04324
Step 41560: loss = 0.08422
Step 41565: loss = 0.08082
Step 41570: loss = 0.02560
Step 41575: loss = 0.03835
Step 41580: loss = 0.05846
Step 41585: loss = 0.03691
Step 41590: loss = 0.01911
Step 41595: loss = 0.08628
Step 41600: loss = 0.04559
Step 41605: loss = 0.05916
Step 41610: loss = 0.04814
Step 41615: loss = 0.02430
Step 41620: loss = 0.08723
Step 41625: loss = 0.05371
Step 41630: loss = 0.08422
Step 41635: loss = 0.04573
Step 41640: loss = 0.03766
Step 41645: loss = 0.03946
Step 41650: loss = 0.07077
Step 41655: loss = 0.01211
Step 41660: loss = 0.15062
Step 41665: loss = 0.14356
Step 41670: loss = 0.03181
Step 41675: loss = 0.06785
Step 41680: loss = 0.05407
Step 41685: loss = 0.05211
Step 41690: loss = 0.03801
Step 41695: loss = 0.00917
Step 41700: loss = 0.05192
Step 41705: loss = 0.09480
Step 41710: loss = 0.02624
Step 41715: loss = 0.01783
Step 41720: loss = 0.16238
Step 41725: loss = 0.05153
Step 41730: loss = 0.01042
Step 41735: loss = 0.08949
Step 41740: loss = 0.00860
Step 41745: loss = 0.03246
Step 41750: loss = 0.04712
Step 41755: loss = 0.01781
Step 41760: loss = 0.01814
Step 41765: loss = 0.05700
Step 41770: loss = 0.03132
Step 41775: loss = 0.09220
Step 41780: loss = 0.05283
Step 41785: loss = 0.05529
Step 41790: loss = 0.05459
Step 41795: loss = 0.06393
Step 41800: loss = 0.04167
Step 41805: loss = 0.02838
Step 41810: loss = 0.03596
Step 41815: loss = 0.02410
Step 41820: loss = 0.01367
Step 41825: loss = 0.03070
Step 41830: loss = 0.02901
Step 41835: loss = 0.02370
Step 41840: loss = 0.03453
Step 41845: loss = 0.02432
Step 41850: loss = 0.04077
Step 41855: loss = 0.11145
Step 41860: loss = 0.02556
Step 41865: loss = 0.02746
Step 41870: loss = 0.07228
Step 41875: loss = 0.02694
Step 41880: loss = 0.12855
Step 41885: loss = 0.02597
Step 41890: loss = 0.04387
Step 41895: loss = 0.03898
Step 41900: loss = 0.04951
Step 41905: loss = 0.03707
Step 41910: loss = 0.08081
Step 41915: loss = 0.06429
Step 41920: loss = 0.03667
Step 41925: loss = 0.05307
Step 41930: loss = 0.02443
Step 41935: loss = 0.04595
Step 41940: loss = 0.07922
Step 41945: loss = 0.03098
Step 41950: loss = 0.01464
Step 41955: loss = 0.11765
Step 41960: loss = 0.05932
Step 41965: loss = 0.01194
Step 41970: loss = 0.06399
Step 41975: loss = 0.01295
Step 41980: loss = 0.09881
Step 41985: loss = 0.10887
Step 41990: loss = 0.08416
Step 41995: loss = 0.06094
Step 42000: loss = 0.12829
Training Data Eval:
  Num examples: 50000, Num correct: 49351, Precision @ 1: 0.9870
('Testing Data Eval: EPOCH->', 43)
  Num examples: 10000, Num correct: 6728, Precision @ 1: 0.6728
Step 42005: loss = 0.03149
Step 42010: loss = 0.13108
Step 42015: loss = 0.04212
Step 42020: loss = 0.08120
Step 42025: loss = 0.05026
Step 42030: loss = 0.01924
Step 42035: loss = 0.01511
Step 42040: loss = 0.03853
Step 42045: loss = 0.02869
Step 42050: loss = 0.03561
Step 42055: loss = 0.04298
Step 42060: loss = 0.02747
Step 42065: loss = 0.05602
Step 42070: loss = 0.01125
Step 42075: loss = 0.01582
Step 42080: loss = 0.05230
Step 42085: loss = 0.03167
Step 42090: loss = 0.07854
Step 42095: loss = 0.06389
Step 42100: loss = 0.13439
Step 42105: loss = 0.05141
Step 42110: loss = 0.04680
Step 42115: loss = 0.10045
Step 42120: loss = 0.05651
Step 42125: loss = 0.07080
Step 42130: loss = 0.02079
Step 42135: loss = 0.01256
Step 42140: loss = 0.03349
Step 42145: loss = 0.02881
Step 42150: loss = 0.04593
Step 42155: loss = 0.03268
Step 42160: loss = 0.07243
Step 42165: loss = 0.11008
Step 42170: loss = 0.06592
Step 42175: loss = 0.01459
Step 42180: loss = 0.03677
Step 42185: loss = 0.04054
Step 42190: loss = 0.03066
Step 42195: loss = 0.01185
Step 42200: loss = 0.02741
Step 42205: loss = 0.01432
Step 42210: loss = 0.11378
Step 42215: loss = 0.07145
Step 42220: loss = 0.01654
Step 42225: loss = 0.02730
Step 42230: loss = 0.03410
Step 42235: loss = 0.04006
Step 42240: loss = 0.09353
Step 42245: loss = 0.02419
Step 42250: loss = 0.02574
Step 42255: loss = 0.06293
Step 42260: loss = 0.00664
Step 42265: loss = 0.03062
Step 42270: loss = 0.06250
Step 42275: loss = 0.02243
Step 42280: loss = 0.04407
Step 42285: loss = 0.03915
Step 42290: loss = 0.02076
Step 42295: loss = 0.02275
Step 42300: loss = 0.05105
Step 42305: loss = 0.04577
Step 42310: loss = 0.02203
Step 42315: loss = 0.05167
Step 42320: loss = 0.03515
Step 42325: loss = 0.04436
Step 42330: loss = 0.02043
Step 42335: loss = 0.05759
Step 42340: loss = 0.03269
Step 42345: loss = 0.05684
Step 42350: loss = 0.02562
Step 42355: loss = 0.03399
Step 42360: loss = 0.06514
Step 42365: loss = 0.04684
Step 42370: loss = 0.01629
Step 42375: loss = 0.02786
Step 42380: loss = 0.03898
Step 42385: loss = 0.02461
Step 42390: loss = 0.05803
Step 42395: loss = 0.07895
Step 42400: loss = 0.02900
Step 42405: loss = 0.01785
Step 42410: loss = 0.04202
Step 42415: loss = 0.02177
Step 42420: loss = 0.03215
Step 42425: loss = 0.03870
Step 42430: loss = 0.01278
Step 42435: loss = 0.01923
Step 42440: loss = 0.03480
Step 42445: loss = 0.06031
Step 42450: loss = 0.01517
Step 42455: loss = 0.08264
Step 42460: loss = 0.11528
Step 42465: loss = 0.18376
Step 42470: loss = 0.05757
Step 42475: loss = 0.02010
Step 42480: loss = 0.08236
Step 42485: loss = 0.07626
Step 42490: loss = 0.02932
Step 42495: loss = 0.02576
Step 42500: loss = 0.10077
Step 42505: loss = 0.00970
Step 42510: loss = 0.01265
Step 42515: loss = 0.01941
Step 42520: loss = 0.06381
Step 42525: loss = 0.01776
Step 42530: loss = 0.03106
Step 42535: loss = 0.06007
Step 42540: loss = 0.00954
Step 42545: loss = 0.02115
Step 42550: loss = 0.03295
Step 42555: loss = 0.05038
Step 42560: loss = 0.02128
Step 42565: loss = 0.04559
Step 42570: loss = 0.01990
Step 42575: loss = 0.02389
Step 42580: loss = 0.03105
Step 42585: loss = 0.01457
Step 42590: loss = 0.01471
Step 42595: loss = 0.09153
Step 42600: loss = 0.04731
Step 42605: loss = 0.01707
Step 42610: loss = 0.03939
Step 42615: loss = 0.03499
Step 42620: loss = 0.15034
Step 42625: loss = 0.02922
Step 42630: loss = 0.01577
Step 42635: loss = 0.03249
Step 42640: loss = 0.09576
Step 42645: loss = 0.00732
Step 42650: loss = 0.02670
Step 42655: loss = 0.04356
Step 42660: loss = 0.03143
Step 42665: loss = 0.03772
Step 42670: loss = 0.02444
Step 42675: loss = 0.03705
Step 42680: loss = 0.01935
Step 42685: loss = 0.03245
Step 42690: loss = 0.02750
Step 42695: loss = 0.11530
Step 42700: loss = 0.00889
Step 42705: loss = 0.05915
Step 42710: loss = 0.00461
Step 42715: loss = 0.01479
Step 42720: loss = 0.01390
Step 42725: loss = 0.05336
Step 42730: loss = 0.01193
Step 42735: loss = 0.02226
Step 42740: loss = 0.02781
Step 42745: loss = 0.08217
Step 42750: loss = 0.03232
Step 42755: loss = 0.05403
Step 42760: loss = 0.01340
Step 42765: loss = 0.00653
Step 42770: loss = 0.01416
Step 42775: loss = 0.02012
Step 42780: loss = 0.02875
Step 42785: loss = 0.04208
Step 42790: loss = 0.04096
Step 42795: loss = 0.00614
Step 42800: loss = 0.08097
Step 42805: loss = 0.17363
Step 42810: loss = 0.03000
Step 42815: loss = 0.02651
Step 42820: loss = 0.05170
Step 42825: loss = 0.03627
Step 42830: loss = 0.03055
Step 42835: loss = 0.04179
Step 42840: loss = 0.03976
Step 42845: loss = 0.00315
Step 42850: loss = 0.01152
Step 42855: loss = 0.09612
Step 42860: loss = 0.03375
Step 42865: loss = 0.02171
Step 42870: loss = 0.03339
Step 42875: loss = 0.02854
Step 42880: loss = 0.08572
Step 42885: loss = 0.01544
Step 42890: loss = 0.01057
Step 42895: loss = 0.04655
Step 42900: loss = 0.03226
Step 42905: loss = 0.01298
Step 42910: loss = 0.02077
Step 42915: loss = 0.02062
Step 42920: loss = 0.05212
Step 42925: loss = 0.01957
Step 42930: loss = 0.10571
Step 42935: loss = 0.00932
Step 42940: loss = 0.18397
Step 42945: loss = 0.07361
Step 42950: loss = 0.04365
Step 42955: loss = 0.06991
Step 42960: loss = 0.08849
Step 42965: loss = 0.04124
Step 42970: loss = 0.07582
Step 42975: loss = 0.04253
Step 42980: loss = 0.07588
Step 42985: loss = 0.01277
Step 42990: loss = 0.04970
Step 42995: loss = 0.03542
Step 43000: loss = 0.02795
Training Data Eval:
  Num examples: 50000, Num correct: 49394, Precision @ 1: 0.9879
('Testing Data Eval: EPOCH->', 44)
  Num examples: 10000, Num correct: 6743, Precision @ 1: 0.6743
Step 43005: loss = 0.03372
Step 43010: loss = 0.05900
Step 43015: loss = 0.04007
Step 43020: loss = 0.03492
Step 43025: loss = 0.03915
Step 43030: loss = 0.01827
Step 43035: loss = 0.00707
Step 43040: loss = 0.08753
Step 43045: loss = 0.02001
Step 43050: loss = 0.01746
Step 43055: loss = 0.03060
Step 43060: loss = 0.01609
Step 43065: loss = 0.04301
Step 43070: loss = 0.01702
Step 43075: loss = 0.04296
Step 43080: loss = 0.06373
Step 43085: loss = 0.00752
Step 43090: loss = 0.00982
Step 43095: loss = 0.06172
Step 43100: loss = 0.00758
Step 43105: loss = 0.10304
Step 43110: loss = 0.09347
Step 43115: loss = 0.12863
Step 43120: loss = 0.04006
Step 43125: loss = 0.02186
Step 43130: loss = 0.04175
Step 43135: loss = 0.02073
Step 43140: loss = 0.02942
Step 43145: loss = 0.06724
Step 43150: loss = 0.02004
Step 43155: loss = 0.02064
Step 43160: loss = 0.08773
Step 43165: loss = 0.03602
Step 43170: loss = 0.01241
Step 43175: loss = 0.02385
Step 43180: loss = 0.01251
Step 43185: loss = 0.01083
Step 43190: loss = 0.01881
Step 43195: loss = 0.10221
Step 43200: loss = 0.01574
Step 43205: loss = 0.02631
Step 43210: loss = 0.03539
Step 43215: loss = 0.06031
Step 43220: loss = 0.02098
Step 43225: loss = 0.01541
Step 43230: loss = 0.05223
Step 43235: loss = 0.03945
Step 43240: loss = 0.00685
Step 43245: loss = 0.09364
Step 43250: loss = 0.03244
Step 43255: loss = 0.01618
Step 43260: loss = 0.01628
Step 43265: loss = 0.03075
Step 43270: loss = 0.09951
Step 43275: loss = 0.08220
Step 43280: loss = 0.03654
Step 43285: loss = 0.03041
Step 43290: loss = 0.02341
Step 43295: loss = 0.03209
Step 43300: loss = 0.04075
Step 43305: loss = 0.00798
Step 43310: loss = 0.01549
Step 43315: loss = 0.03076
Step 43320: loss = 0.01271
Step 43325: loss = 0.02597
Step 43330: loss = 0.01703
Step 43335: loss = 0.07548
Step 43340: loss = 0.02817
Step 43345: loss = 0.02430
Step 43350: loss = 0.01863
Step 43355: loss = 0.19406
Step 43360: loss = 0.03614
Step 43365: loss = 0.06577
Step 43370: loss = 0.05994
Step 43375: loss = 0.06211
Step 43380: loss = 0.02994
Step 43385: loss = 0.07196
Step 43390: loss = 0.04993
Step 43395: loss = 0.02094
Step 43400: loss = 0.02944
Step 43405: loss = 0.11593
Step 43410: loss = 0.01876
Step 43415: loss = 0.06169
Step 43420: loss = 0.00525
Step 43425: loss = 0.06065
Step 43430: loss = 0.08288
Step 43435: loss = 0.05060
Step 43440: loss = 0.01715
Step 43445: loss = 0.02625
Step 43450: loss = 0.03579
Step 43455: loss = 0.02869
Step 43460: loss = 0.02885
Step 43465: loss = 0.05444
Step 43470: loss = 0.01119
Step 43475: loss = 0.04767
Step 43480: loss = 0.03982
Step 43485: loss = 0.08226
Step 43490: loss = 0.05335
Step 43495: loss = 0.04799
Step 43500: loss = 0.08266
Step 43505: loss = 0.08373
Step 43510: loss = 0.01637
Step 43515: loss = 0.03053
Step 43520: loss = 0.05675
Step 43525: loss = 0.01139
Step 43530: loss = 0.02737
Step 43535: loss = 0.06994
Step 43540: loss = 0.02114
Step 43545: loss = 0.09608
Step 43550: loss = 0.03287
Step 43555: loss = 0.02468
Step 43560: loss = 0.05277
Step 43565: loss = 0.06439
Step 43570: loss = 0.05472
Step 43575: loss = 0.05289
Step 43580: loss = 0.04070
Step 43585: loss = 0.02013
Step 43590: loss = 0.12090
Step 43595: loss = 0.04223
Step 43600: loss = 0.07343
Step 43605: loss = 0.00611
Step 43610: loss = 0.07165
Step 43615: loss = 0.01765
Step 43620: loss = 0.11005
Step 43625: loss = 0.08552
Step 43630: loss = 0.03393
Step 43635: loss = 0.02273
Step 43640: loss = 0.00981
Step 43645: loss = 0.02112
Step 43650: loss = 0.03893
Step 43655: loss = 0.04548
Step 43660: loss = 0.04839
Step 43665: loss = 0.01933
Step 43670: loss = 0.03288
Step 43675: loss = 0.01323
Step 43680: loss = 0.01629
Step 43685: loss = 0.01344
Step 43690: loss = 0.02350
Step 43695: loss = 0.01567
Step 43700: loss = 0.02692
Step 43705: loss = 0.14272
Step 43710: loss = 0.02529
Step 43715: loss = 0.03401
Step 43720: loss = 0.04519
Step 43725: loss = 0.07987
Step 43730: loss = 0.03192
Step 43735: loss = 0.03967
Step 43740: loss = 0.06646
Step 43745: loss = 0.01792
Step 43750: loss = 0.00652
Step 43755: loss = 0.03042
Step 43760: loss = 0.08122
Step 43765: loss = 0.04075
Step 43770: loss = 0.05704
Step 43775: loss = 0.02189
Step 43780: loss = 0.06392
Step 43785: loss = 0.15541
Step 43790: loss = 0.01188
Step 43795: loss = 0.02808
Step 43800: loss = 0.02649
Step 43805: loss = 0.08898
Step 43810: loss = 0.01974
Step 43815: loss = 0.07324
Step 43820: loss = 0.02321
Step 43825: loss = 0.02534
Step 43830: loss = 0.07406
Step 43835: loss = 0.04062
Step 43840: loss = 0.02660
Step 43845: loss = 0.05132
Step 43850: loss = 0.03742
Step 43855: loss = 0.00916
Step 43860: loss = 0.01533
Step 43865: loss = 0.07794
Step 43870: loss = 0.04436
Step 43875: loss = 0.04725
Step 43880: loss = 0.01863
Step 43885: loss = 0.06530
Step 43890: loss = 0.06177
Step 43895: loss = 0.03460
Step 43900: loss = 0.06979
Step 43905: loss = 0.01329
Step 43910: loss = 0.02624
Step 43915: loss = 0.08623
Step 43920: loss = 0.09602
Step 43925: loss = 0.05347
Step 43930: loss = 0.03374
Step 43935: loss = 0.01618
Step 43940: loss = 0.01387
Step 43945: loss = 0.00422
Step 43950: loss = 0.01696
Step 43955: loss = 0.02429
Step 43960: loss = 0.01882
Step 43965: loss = 0.01317
Step 43970: loss = 0.06570
Step 43975: loss = 0.01884
Step 43980: loss = 0.03364
Step 43985: loss = 0.04354
Step 43990: loss = 0.05835
Step 43995: loss = 0.00823
Step 44000: loss = 0.12005
Training Data Eval:
  Num examples: 50000, Num correct: 49524, Precision @ 1: 0.9905
('Testing Data Eval: EPOCH->', 45)
  Num examples: 10000, Num correct: 6718, Precision @ 1: 0.6718
Step 44005: loss = 0.02725
Step 44010: loss = 0.01215
Step 44015: loss = 0.04492
Step 44020: loss = 0.05329
Step 44025: loss = 0.01296
Step 44030: loss = 0.09043
Step 44035: loss = 0.12574
Step 44040: loss = 0.01641
Step 44045: loss = 0.09633
Step 44050: loss = 0.03456
Step 44055: loss = 0.02828
Step 44060: loss = 0.05577
Step 44065: loss = 0.04407
Step 44070: loss = 0.01227
Step 44075: loss = 0.08920
Step 44080: loss = 0.01433
Step 44085: loss = 0.08658
Step 44090: loss = 0.02973
Step 44095: loss = 0.03479
Step 44100: loss = 0.01109
Step 44105: loss = 0.07724
Step 44110: loss = 0.02705
Step 44115: loss = 0.04261
Step 44120: loss = 0.00583
Step 44125: loss = 0.01162
Step 44130: loss = 0.08072
Step 44135: loss = 0.03400
Step 44140: loss = 0.03814
Step 44145: loss = 0.02338
Step 44150: loss = 0.02106
Step 44155: loss = 0.00979
Step 44160: loss = 0.05853
Step 44165: loss = 0.10178
Step 44170: loss = 0.00734
Step 44175: loss = 0.02092
Step 44180: loss = 0.02610
Step 44185: loss = 0.03009
Step 44190: loss = 0.01860
Step 44195: loss = 0.03600
Step 44200: loss = 0.05803
Step 44205: loss = 0.04218
Step 44210: loss = 0.04876
Step 44215: loss = 0.02141
Step 44220: loss = 0.01606
Step 44225: loss = 0.00668
Step 44230: loss = 0.06352
Step 44235: loss = 0.03855
Step 44240: loss = 0.02731
Step 44245: loss = 0.01999
Step 44250: loss = 0.03202
Step 44255: loss = 0.15048
Step 44260: loss = 0.01763
Step 44265: loss = 0.01416
Step 44270: loss = 0.02364
Step 44275: loss = 0.04078
Step 44280: loss = 0.02214
Step 44285: loss = 0.00654
Step 44290: loss = 0.05776
Step 44295: loss = 0.04446
Step 44300: loss = 0.04066
Step 44305: loss = 0.07519
Step 44310: loss = 0.02694
Step 44315: loss = 0.06682
Step 44320: loss = 0.05115
Step 44325: loss = 0.06581
Step 44330: loss = 0.04043
Step 44335: loss = 0.01636
Step 44340: loss = 0.01896
Step 44345: loss = 0.00316
Step 44350: loss = 0.02580
Step 44355: loss = 0.08414
Step 44360: loss = 0.00595
Step 44365: loss = 0.06807
Step 44370: loss = 0.02848
Step 44375: loss = 0.01518
Step 44380: loss = 0.05454
Step 44385: loss = 0.01900
Step 44390: loss = 0.00530
Step 44395: loss = 0.03096
Step 44400: loss = 0.02034
Step 44405: loss = 0.06875
Step 44410: loss = 0.08110
Step 44415: loss = 0.03672
Step 44420: loss = 0.01697
Step 44425: loss = 0.00751
Step 44430: loss = 0.06619
Step 44435: loss = 0.04933
Step 44440: loss = 0.01775
Step 44445: loss = 0.02526
Step 44450: loss = 0.05157
Step 44455: loss = 0.05618
Step 44460: loss = 0.04090
Step 44465: loss = 0.01722
Step 44470: loss = 0.01525
Step 44475: loss = 0.02642
Step 44480: loss = 0.01998
Step 44485: loss = 0.01073
Step 44490: loss = 0.02691
Step 44495: loss = 0.02999
Step 44500: loss = 0.00998
Step 44505: loss = 0.03321
Step 44510: loss = 0.02137
Step 44515: loss = 0.04943
Step 44520: loss = 0.07219
Step 44525: loss = 0.10684
Step 44530: loss = 0.01447
Step 44535: loss = 0.03970
Step 44540: loss = 0.02783
Step 44545: loss = 0.03474
Step 44550: loss = 0.01978
Step 44555: loss = 0.01692
Step 44560: loss = 0.00881
Step 44565: loss = 0.04439
Step 44570: loss = 0.00506
Step 44575: loss = 0.06490
Step 44580: loss = 0.04240
Step 44585: loss = 0.00165
Step 44590: loss = 0.02742
Step 44595: loss = 0.01996
Step 44600: loss = 0.05615
Step 44605: loss = 0.01849
Step 44610: loss = 0.09009
Step 44615: loss = 0.02493
Step 44620: loss = 0.05083
Step 44625: loss = 0.06290
Step 44630: loss = 0.01222
Step 44635: loss = 0.01027
Step 44640: loss = 0.05447
Step 44645: loss = 0.03147
Step 44650: loss = 0.01628
Step 44655: loss = 0.00725
Step 44660: loss = 0.01200
Step 44665: loss = 0.07801
Step 44670: loss = 0.04235
Step 44675: loss = 0.01232
Step 44680: loss = 0.10273
Step 44685: loss = 0.05207
Step 44690: loss = 0.03835
Step 44695: loss = 0.01087
Step 44700: loss = 0.04226
Step 44705: loss = 0.03343
Step 44710: loss = 0.02228
Step 44715: loss = 0.02834
Step 44720: loss = 0.01404
Step 44725: loss = 0.02061
Step 44730: loss = 0.01450
Step 44735: loss = 0.05255
Step 44740: loss = 0.03130
Step 44745: loss = 0.04110
Step 44750: loss = 0.02652
Step 44755: loss = 0.01245
Step 44760: loss = 0.02123
Step 44765: loss = 0.00978
Step 44770: loss = 0.01811
Step 44775: loss = 0.08245
Step 44780: loss = 0.08061
Step 44785: loss = 0.12718
Step 44790: loss = 0.01204
Step 44795: loss = 0.03603
Step 44800: loss = 0.05083
Step 44805: loss = 0.04280
Step 44810: loss = 0.02314
Step 44815: loss = 0.08380
Step 44820: loss = 0.01315
Step 44825: loss = 0.01815
Step 44830: loss = 0.04529
Step 44835: loss = 0.02535
Step 44840: loss = 0.06442
Step 44845: loss = 0.01097
Step 44850: loss = 0.09003
Step 44855: loss = 0.03450
Step 44860: loss = 0.03784
Step 44865: loss = 0.05493
Step 44870: loss = 0.00802
Step 44875: loss = 0.01098
Step 44880: loss = 0.01221
Step 44885: loss = 0.01847
Step 44890: loss = 0.02059
Step 44895: loss = 0.05028
Step 44900: loss = 0.02847
Step 44905: loss = 0.01485
Step 44910: loss = 0.04274
Step 44915: loss = 0.02693
Step 44920: loss = 0.10442
Step 44925: loss = 0.03233
Step 44930: loss = 0.04549
Step 44935: loss = 0.02361
Step 44940: loss = 0.00965
Step 44945: loss = 0.07004
Step 44950: loss = 0.07157
Step 44955: loss = 0.02577
Step 44960: loss = 0.05025
Step 44965: loss = 0.03031
Step 44970: loss = 0.04323
Step 44975: loss = 0.00235
Step 44980: loss = 0.01150
Step 44985: loss = 0.04650
Step 44990: loss = 0.03371
Step 44995: loss = 0.07063
Step 45000: loss = 0.01921
Training Data Eval:
  Num examples: 50000, Num correct: 49555, Precision @ 1: 0.9911
('Testing Data Eval: EPOCH->', 46)
  Num examples: 10000, Num correct: 6832, Precision @ 1: 0.6832
Step 45005: loss = 0.01817
Step 45010: loss = 0.00872
Step 45015: loss = 0.19641
Step 45020: loss = 0.03740
Step 45025: loss = 0.02194
Step 45030: loss = 0.03011
Step 45035: loss = 0.02056
Step 45040: loss = 0.02387
Step 45045: loss = 0.03489
Step 45050: loss = 0.02946
Step 45055: loss = 0.02583
Step 45060: loss = 0.03975
Step 45065: loss = 0.01778
Step 45070: loss = 0.13150
Step 45075: loss = 0.04413
Step 45080: loss = 0.08616
Step 45085: loss = 0.01061
Step 45090: loss = 0.02982
Step 45095: loss = 0.00661
Step 45100: loss = 0.02568
Step 45105: loss = 0.01923
Step 45110: loss = 0.02413
Step 45115: loss = 0.03355
Step 45120: loss = 0.01294
Step 45125: loss = 0.13563
Step 45130: loss = 0.03303
Step 45135: loss = 0.01904
Step 45140: loss = 0.07323
Step 45145: loss = 0.01641
Step 45150: loss = 0.00448
Step 45155: loss = 0.01668
Step 45160: loss = 0.08412
Step 45165: loss = 0.00615
Step 45170: loss = 0.04312
Step 45175: loss = 0.00838
Step 45180: loss = 0.02153
Step 45185: loss = 0.04837
Step 45190: loss = 0.06548
Step 45195: loss = 0.01695
Step 45200: loss = 0.05000
Step 45205: loss = 0.03802
Step 45210: loss = 0.00922
Step 45215: loss = 0.02297
Step 45220: loss = 0.03235
Step 45225: loss = 0.13092
Step 45230: loss = 0.03294
Step 45235: loss = 0.00930
Step 45240: loss = 0.02540
Step 45245: loss = 0.01220
Step 45250: loss = 0.01776
Step 45255: loss = 0.03842
Step 45260: loss = 0.05778
Step 45265: loss = 0.01894
Step 45270: loss = 0.14075
Step 45275: loss = 0.02969
Step 45280: loss = 0.01181
Step 45285: loss = 0.01636
Step 45290: loss = 0.06354
Step 45295: loss = 0.04399
Step 45300: loss = 0.01281
Step 45305: loss = 0.12163
Step 45310: loss = 0.01221
Step 45315: loss = 0.05343
Step 45320: loss = 0.01564
Step 45325: loss = 0.00907
Step 45330: loss = 0.05400
Step 45335: loss = 0.10194
Step 45340: loss = 0.04102
Step 45345: loss = 0.00820
Step 45350: loss = 0.02417
Step 45355: loss = 0.02491
Step 45360: loss = 0.03773
Step 45365: loss = 0.01692
Step 45370: loss = 0.01755
Step 45375: loss = 0.03024
Step 45380: loss = 0.03962
Step 45385: loss = 0.04313
Step 45390: loss = 0.07612
Step 45395: loss = 0.06626
Step 45400: loss = 0.02535
Step 45405: loss = 0.01407
Step 45410: loss = 0.02850
Step 45415: loss = 0.01425
Step 45420: loss = 0.06227
Step 45425: loss = 0.09038
Step 45430: loss = 0.05963
Step 45435: loss = 0.04167
Step 45440: loss = 0.01488
Step 45445: loss = 0.00746
Step 45450: loss = 0.03251
Step 45455: loss = 0.01742
Step 45460: loss = 0.00806
Step 45465: loss = 0.06177
Step 45470: loss = 0.01910
Step 45475: loss = 0.04462
Step 45480: loss = 0.04528
Step 45485: loss = 0.08954
Step 45490: loss = 0.05967
Step 45495: loss = 0.03067
Step 45500: loss = 0.02871
Step 45505: loss = 0.02348
Step 45510: loss = 0.08376
Step 45515: loss = 0.02643
Step 45520: loss = 0.01889
Step 45525: loss = 0.04786
Step 45530: loss = 0.02533
Step 45535: loss = 0.01561
Step 45540: loss = 0.01076
Step 45545: loss = 0.06767
Step 45550: loss = 0.01399
Step 45555: loss = 0.01929
Step 45560: loss = 0.01430
Step 45565: loss = 0.01874
Step 45570: loss = 0.01187
Step 45575: loss = 0.01684
Step 45580: loss = 0.03274
Step 45585: loss = 0.02839
Step 45590: loss = 0.02597
Step 45595: loss = 0.05230
Step 45600: loss = 0.03907
Step 45605: loss = 0.04380
Step 45610: loss = 0.02703
Step 45615: loss = 0.02793
Step 45620: loss = 0.03638
Step 45625: loss = 0.01531
Step 45630: loss = 0.03252
Step 45635: loss = 0.05301
Step 45640: loss = 0.04330
Step 45645: loss = 0.04257
Step 45650: loss = 0.01077
Step 45655: loss = 0.03521
Step 45660: loss = 0.04729
Step 45665: loss = 0.00477
Step 45670: loss = 0.06536
Step 45675: loss = 0.00179
Step 45680: loss = 0.01192
Step 45685: loss = 0.04371
Step 45690: loss = 0.02360
Step 45695: loss = 0.04775
Step 45700: loss = 0.02510
Step 45705: loss = 0.00723
Step 45710: loss = 0.03257
Step 45715: loss = 0.01454
Step 45720: loss = 0.02977
Step 45725: loss = 0.03173
Step 45730: loss = 0.01147
Step 45735: loss = 0.00694
Step 45740: loss = 0.06001
Step 45745: loss = 0.02690
Step 45750: loss = 0.01142
Step 45755: loss = 0.07636
Step 45760: loss = 0.03984
Step 45765: loss = 0.03429
Step 45770: loss = 0.04741
Step 45775: loss = 0.07114
Step 45780: loss = 0.05664
Step 45785: loss = 0.01651
Step 45790: loss = 0.00409
Step 45795: loss = 0.01268
Step 45800: loss = 0.05969
Step 45805: loss = 0.02468
Step 45810: loss = 0.01712
Step 45815: loss = 0.01265
Step 45820: loss = 0.00763
Step 45825: loss = 0.04049
Step 45830: loss = 0.01904
Step 45835: loss = 0.06881
Step 45840: loss = 0.02328
Step 45845: loss = 0.04998
Step 45850: loss = 0.01569
Step 45855: loss = 0.01169
Step 45860: loss = 0.02268
Step 45865: loss = 0.03021
Step 45870: loss = 0.01832
Step 45875: loss = 0.02497
Step 45880: loss = 0.03098
Step 45885: loss = 0.03429
Step 45890: loss = 0.07242
Step 45895: loss = 0.01432
Step 45900: loss = 0.01095
Step 45905: loss = 0.03781
Step 45910: loss = 0.03297
Step 45915: loss = 0.04965
Step 45920: loss = 0.03729
Step 45925: loss = 0.04649
Step 45930: loss = 0.03053
Step 45935: loss = 0.02286
Step 45940: loss = 0.07990
Step 45945: loss = 0.01686
Step 45950: loss = 0.03602
Step 45955: loss = 0.01236
Step 45960: loss = 0.04850
Step 45965: loss = 0.03261
Step 45970: loss = 0.05720
Step 45975: loss = 0.03523
Step 45980: loss = 0.07775
Step 45985: loss = 0.03225
Step 45990: loss = 0.03691
Step 45995: loss = 0.01084
Step 46000: loss = 0.03367
Training Data Eval:
  Num examples: 50000, Num correct: 49437, Precision @ 1: 0.9887
('Testing Data Eval: EPOCH->', 47)
  Num examples: 10000, Num correct: 6788, Precision @ 1: 0.6788
Step 46005: loss = 0.01389
Step 46010: loss = 0.02847
Step 46015: loss = 0.02832
Step 46020: loss = 0.00712
Step 46025: loss = 0.02438
Step 46030: loss = 0.06555
Step 46035: loss = 0.03445
Step 46040: loss = 0.03607
Step 46045: loss = 0.02407
Step 46050: loss = 0.10313
Step 46055: loss = 0.01632
Step 46060: loss = 0.04315
Step 46065: loss = 0.00629
Step 46070: loss = 0.01542
Step 46075: loss = 0.01043
Step 46080: loss = 0.01983
Step 46085: loss = 0.01207
Step 46090: loss = 0.02057
Step 46095: loss = 0.01621
Step 46100: loss = 0.01258
Step 46105: loss = 0.04682
Step 46110: loss = 0.07479
Step 46115: loss = 0.03950
Step 46120: loss = 0.02261
Step 46125: loss = 0.04864
Step 46130: loss = 0.01658
Step 46135: loss = 0.05551
Step 46140: loss = 0.04561
Step 46145: loss = 0.01599
Step 46150: loss = 0.04679
Step 46155: loss = 0.01310
Step 46160: loss = 0.07674
Step 46165: loss = 0.02807
Step 46170: loss = 0.03037
Step 46175: loss = 0.02774
Step 46180: loss = 0.02057
Step 46185: loss = 0.07560
Step 46190: loss = 0.07077
Step 46195: loss = 0.01983
Step 46200: loss = 0.01536
Step 46205: loss = 0.01941
Step 46210: loss = 0.01504
Step 46215: loss = 0.03447
Step 46220: loss = 0.04681
Step 46225: loss = 0.01175
Step 46230: loss = 0.02448
Step 46235: loss = 0.01004
Step 46240: loss = 0.04664
Step 46245: loss = 0.02989
Step 46250: loss = 0.04556
Step 46255: loss = 0.04050
Step 46260: loss = 0.22598
Step 46265: loss = 0.01687
Step 46270: loss = 0.02159
Step 46275: loss = 0.04835
Step 46280: loss = 0.00781
Step 46285: loss = 0.01509
Step 46290: loss = 0.06525
Step 46295: loss = 0.04095
Step 46300: loss = 0.02586
Step 46305: loss = 0.01708
Step 46310: loss = 0.05066
Step 46315: loss = 0.03139
Step 46320: loss = 0.07331
Step 46325: loss = 0.04424
Step 46330: loss = 0.01271
Step 46335: loss = 0.01764
Step 46340: loss = 0.02876
Step 46345: loss = 0.10364
Step 46350: loss = 0.05598
Step 46355: loss = 0.01107
Step 46360: loss = 0.04460
Step 46365: loss = 0.02692
Step 46370: loss = 0.04264
Step 46375: loss = 0.01781
Step 46380: loss = 0.02315
Step 46385: loss = 0.00685
Step 46390: loss = 0.13051
Step 46395: loss = 0.03687
Step 46400: loss = 0.05417
Step 46405: loss = 0.02869
Step 46410: loss = 0.00851
Step 46415: loss = 0.02167
Step 46420: loss = 0.01261
Step 46425: loss = 0.10483
Step 46430: loss = 0.01989
Step 46435: loss = 0.02011
Step 46440: loss = 0.02275
Step 46445: loss = 0.07485
Step 46450: loss = 0.11912
Step 46455: loss = 0.02019
Step 46460: loss = 0.09300
Step 46465: loss = 0.01886
Step 46470: loss = 0.01003
Step 46475: loss = 0.05516
Step 46480: loss = 0.03610
Step 46485: loss = 0.03277
Step 46490: loss = 0.01361
Step 46495: loss = 0.01779
Step 46500: loss = 0.12216
Step 46505: loss = 0.01898
Step 46510: loss = 0.02378
Step 46515: loss = 0.02528
Step 46520: loss = 0.07655
Step 46525: loss = 0.01525
Step 46530: loss = 0.01257
Step 46535: loss = 0.03220
Step 46540: loss = 0.03297
Step 46545: loss = 0.06434
Step 46550: loss = 0.08816
Step 46555: loss = 0.03876
Step 46560: loss = 0.01967
Step 46565: loss = 0.02054
Step 46570: loss = 0.06877
Step 46575: loss = 0.06168
Step 46580: loss = 0.13764
Step 46585: loss = 0.01502
Step 46590: loss = 0.07048
Step 46595: loss = 0.02662
Step 46600: loss = 0.02563
Step 46605: loss = 0.03627
Step 46610: loss = 0.01495
Step 46615: loss = 0.06660
Step 46620: loss = 0.02173
Step 46625: loss = 0.03187
Step 46630: loss = 0.00795
Step 46635: loss = 0.02510
Step 46640: loss = 0.03187
Step 46645: loss = 0.03325
Step 46650: loss = 0.07147
Step 46655: loss = 0.02872
Step 46660: loss = 0.02827
Step 46665: loss = 0.02540
Step 46670: loss = 0.08513
Step 46675: loss = 0.04650
Step 46680: loss = 0.01607
Step 46685: loss = 0.09630
Step 46690: loss = 0.01073
Step 46695: loss = 0.02149
Step 46700: loss = 0.01979
Step 46705: loss = 0.10918
Step 46710: loss = 0.03589
Step 46715: loss = 0.03271
Step 46720: loss = 0.01635
Step 46725: loss = 0.03096
Step 46730: loss = 0.05752
Step 46735: loss = 0.04506
Step 46740: loss = 0.03659
Step 46745: loss = 0.03448
Step 46750: loss = 0.04342
Step 46755: loss = 0.01330
Step 46760: loss = 0.07103
Step 46765: loss = 0.01688
Step 46770: loss = 0.06270
Step 46775: loss = 0.02975
Step 46780: loss = 0.07625
Step 46785: loss = 0.04649
Step 46790: loss = 0.00404
Step 46795: loss = 0.01180
Step 46800: loss = 0.02790
Step 46805: loss = 0.12071
Step 46810: loss = 0.02286
Step 46815: loss = 0.00984
Step 46820: loss = 0.08618
Step 46825: loss = 0.04819
Step 46830: loss = 0.04981
Step 46835: loss = 0.03081
Step 46840: loss = 0.03070
Step 46845: loss = 0.07152
Step 46850: loss = 0.01886
Step 46855: loss = 0.00833
Step 46860: loss = 0.10449
Step 46865: loss = 0.02167
Step 46870: loss = 0.02529
Step 46875: loss = 0.01362
Step 46880: loss = 0.00744
Step 46885: loss = 0.01496
Step 46890: loss = 0.04678
Step 46895: loss = 0.10264
Step 46900: loss = 0.06029
Step 46905: loss = 0.05124
Step 46910: loss = 0.01298
Step 46915: loss = 0.03438
Step 46920: loss = 0.03790
Step 46925: loss = 0.06912
Step 46930: loss = 0.01643
Step 46935: loss = 0.01322
Step 46940: loss = 0.02485
Step 46945: loss = 0.14782
Step 46950: loss = 0.06293
Step 46955: loss = 0.03654
Step 46960: loss = 0.09636
Step 46965: loss = 0.03435
Step 46970: loss = 0.01282
Step 46975: loss = 0.00974
Step 46980: loss = 0.05819
Step 46985: loss = 0.04097
Step 46990: loss = 0.05754
Step 46995: loss = 0.03104
Step 47000: loss = 0.01211
Training Data Eval:
  Num examples: 50000, Num correct: 49503, Precision @ 1: 0.9901
('Testing Data Eval: EPOCH->', 48)
  Num examples: 10000, Num correct: 6732, Precision @ 1: 0.6732
Step 47005: loss = 0.01488
Step 47010: loss = 0.01178
Step 47015: loss = 0.09428
Step 47020: loss = 0.01210
Step 47025: loss = 0.00347
Step 47030: loss = 0.08357
Step 47035: loss = 0.01755
Step 47040: loss = 0.02024
Step 47045: loss = 0.00539
Step 47050: loss = 0.02179
Step 47055: loss = 0.01179
Step 47060: loss = 0.02555
Step 47065: loss = 0.03186
Step 47070: loss = 0.00976
Step 47075: loss = 0.01682
Step 47080: loss = 0.00434
Step 47085: loss = 0.14094
Step 47090: loss = 0.03145
Step 47095: loss = 0.02921
Step 47100: loss = 0.12483
Step 47105: loss = 0.05778
Step 47110: loss = 0.03033
Step 47115: loss = 0.02929
Step 47120: loss = 0.05221
Step 47125: loss = 0.13630
Step 47130: loss = 0.01970
Step 47135: loss = 0.01729
Step 47140: loss = 0.02873
Step 47145: loss = 0.03159
Step 47150: loss = 0.05645
Step 47155: loss = 0.08457
Step 47160: loss = 0.00895
Step 47165: loss = 0.01071
Step 47170: loss = 0.02207
Step 47175: loss = 0.01458
Step 47180: loss = 0.02964
Step 47185: loss = 0.03786
Step 47190: loss = 0.01548
Step 47195: loss = 0.00699
Step 47200: loss = 0.02323
Step 47205: loss = 0.01259
Step 47210: loss = 0.09442
Step 47215: loss = 0.05140
Step 47220: loss = 0.02081
Step 47225: loss = 0.03360
Step 47230: loss = 0.01357
Step 47235: loss = 0.01135
Step 47240: loss = 0.01809
Step 47245: loss = 0.01085
Step 47250: loss = 0.13352
Step 47255: loss = 0.03241
Step 47260: loss = 0.00733
Step 47265: loss = 0.01988
Step 47270: loss = 0.01029
Step 47275: loss = 0.04129
Step 47280: loss = 0.02989
Step 47285: loss = 0.01863
Step 47290: loss = 0.01738
Step 47295: loss = 0.04974
Step 47300: loss = 0.01760
Step 47305: loss = 0.05386
Step 47310: loss = 0.04063
Step 47315: loss = 0.02079
Step 47320: loss = 0.03808
Step 47325: loss = 0.01566
Step 47330: loss = 0.02324
Step 47335: loss = 0.02947
Step 47340: loss = 0.01107
Step 47345: loss = 0.01836
Step 47350: loss = 0.07358
Step 47355: loss = 0.02462
Step 47360: loss = 0.02323
Step 47365: loss = 0.05006
Step 47370: loss = 0.03149
Step 47375: loss = 0.05696
Step 47380: loss = 0.02569
Step 47385: loss = 0.02584
Step 47390: loss = 0.05015
Step 47395: loss = 0.07796
Step 47400: loss = 0.02048
Step 47405: loss = 0.03937
Step 47410: loss = 0.01309
Step 47415: loss = 0.08754
Step 47420: loss = 0.21563
Step 47425: loss = 0.01019
Step 47430: loss = 0.02779
Step 47435: loss = 0.07248
Step 47440: loss = 0.02816
Step 47445: loss = 0.02083
Step 47450: loss = 0.02877
Step 47455: loss = 0.01008
Step 47460: loss = 0.03596
Step 47465: loss = 0.02762
Step 47470: loss = 0.00561
Step 47475: loss = 0.05329
Step 47480: loss = 0.04192
Step 47485: loss = 0.05573
Step 47490: loss = 0.03097
Step 47495: loss = 0.01733
Step 47500: loss = 0.03954
Step 47505: loss = 0.12886
Step 47510: loss = 0.02880
Step 47515: loss = 0.01935
Step 47520: loss = 0.00485
Step 47525: loss = 0.09093
Step 47530: loss = 0.02537
Step 47535: loss = 0.02547
Step 47540: loss = 0.02699
Step 47545: loss = 0.00681
Step 47550: loss = 0.01887
Step 47555: loss = 0.07096
Step 47560: loss = 0.14799
Step 47565: loss = 0.03908
Step 47570: loss = 0.02780
Step 47575: loss = 0.07478
Step 47580: loss = 0.06582
Step 47585: loss = 0.00813
Step 47590: loss = 0.00585
Step 47595: loss = 0.01595
Step 47600: loss = 0.08080
Step 47605: loss = 0.04235
Step 47610: loss = 0.08269
Step 47615: loss = 0.06568
Step 47620: loss = 0.00783
Step 47625: loss = 0.05216
Step 47630: loss = 0.02022
Step 47635: loss = 0.02086
Step 47640: loss = 0.02071
Step 47645: loss = 0.03845
Step 47650: loss = 0.09782
Step 47655: loss = 0.01855
Step 47660: loss = 0.02470
Step 47665: loss = 0.08037
Step 47670: loss = 0.09989
Step 47675: loss = 0.00695
Step 47680: loss = 0.01566
Step 47685: loss = 0.03353
Step 47690: loss = 0.02909
Step 47695: loss = 0.01739
Step 47700: loss = 0.04849
Step 47705: loss = 0.05922
Step 47710: loss = 0.03128
Step 47715: loss = 0.12964
Step 47720: loss = 0.01170
Step 47725: loss = 0.06802
Step 47730: loss = 0.01808
Step 47735: loss = 0.06118
Step 47740: loss = 0.12276
Step 47745: loss = 0.01836
Step 47750: loss = 0.02569
Step 47755: loss = 0.01284
Step 47760: loss = 0.08097
Step 47765: loss = 0.02073
Step 47770: loss = 0.01431
Step 47775: loss = 0.03972
Step 47780: loss = 0.01172
Step 47785: loss = 0.05873
Step 47790: loss = 0.02390
Step 47795: loss = 0.03560
Step 47800: loss = 0.06151
Step 47805: loss = 0.01945
Step 47810: loss = 0.01510
Step 47815: loss = 0.02542
Step 47820: loss = 0.01742
Step 47825: loss = 0.01217
Step 47830: loss = 0.01993
Step 47835: loss = 0.00906
Step 47840: loss = 0.05340
Step 47845: loss = 0.08202
Step 47850: loss = 0.04344
Step 47855: loss = 0.01095
Step 47860: loss = 0.03956
Step 47865: loss = 0.02153
Step 47870: loss = 0.05107
Step 47875: loss = 0.10337
Step 47880: loss = 0.04431
Step 47885: loss = 0.03035
Step 47890: loss = 0.04395
Step 47895: loss = 0.14718
Step 47900: loss = 0.06501
Step 47905: loss = 0.06290
Step 47910: loss = 0.06928
Step 47915: loss = 0.04615
Step 47920: loss = 0.07835
Step 47925: loss = 0.01634
Step 47930: loss = 0.05575
Step 47935: loss = 0.01061
Step 47940: loss = 0.01612
Step 47945: loss = 0.09918
Step 47950: loss = 0.00439
Step 47955: loss = 0.03831
Step 47960: loss = 0.05952
Step 47965: loss = 0.05187
Step 47970: loss = 0.07823
Step 47975: loss = 0.01459
Step 47980: loss = 0.14279
Step 47985: loss = 0.02228
Step 47990: loss = 0.04729
Step 47995: loss = 0.09112
Step 48000: loss = 0.03163
Training Data Eval:
  Num examples: 50000, Num correct: 49392, Precision @ 1: 0.9878
('Testing Data Eval: EPOCH->', 49)
  Num examples: 10000, Num correct: 6709, Precision @ 1: 0.6709
Step 48005: loss = 0.02339
Step 48010: loss = 0.13228
Step 48015: loss = 0.04930
Step 48020: loss = 0.01267
Step 48025: loss = 0.01063
Step 48030: loss = 0.01283
Step 48035: loss = 0.03626
Step 48040: loss = 0.02785
Step 48045: loss = 0.05544
Step 48050: loss = 0.09162
Step 48055: loss = 0.02260
Step 48060: loss = 0.01029
Step 48065: loss = 0.02590
Step 48070: loss = 0.00532
Step 48075: loss = 0.01518
Step 48080: loss = 0.01773
Step 48085: loss = 0.01021
Step 48090: loss = 0.03744
Step 48095: loss = 0.02457
Step 48100: loss = 0.04365
Step 48105: loss = 0.05722
Step 48110: loss = 0.02279
Step 48115: loss = 0.05491
Step 48120: loss = 0.19092
Step 48125: loss = 0.07371
Step 48130: loss = 0.02789
Step 48135: loss = 0.02686
Step 48140: loss = 0.01842
Step 48145: loss = 0.03722
Step 48150: loss = 0.05356
Step 48155: loss = 0.07333
Step 48160: loss = 0.03324
Step 48165: loss = 0.03089
Step 48170: loss = 0.09671
Step 48175: loss = 0.08607
Step 48180: loss = 0.05454
Step 48185: loss = 0.04364
Step 48190: loss = 0.02723
Step 48195: loss = 0.04069
Step 48200: loss = 0.01254
Step 48205: loss = 0.04478
Step 48210: loss = 0.03226
Step 48215: loss = 0.01677
Step 48220: loss = 0.01852
Step 48225: loss = 0.01138
Step 48230: loss = 0.02031
Step 48235: loss = 0.03392
Step 48240: loss = 0.02042
Step 48245: loss = 0.00962
Step 48250: loss = 0.01179
Step 48255: loss = 0.12772
Step 48260: loss = 0.02657
Step 48265: loss = 0.02973
Step 48270: loss = 0.02666
Step 48275: loss = 0.00999
Step 48280: loss = 0.10742
Step 48285: loss = 0.16367
Step 48290: loss = 0.01321
Step 48295: loss = 0.02072
Step 48300: loss = 0.04079
Step 48305: loss = 0.04103
Step 48310: loss = 0.06993
Step 48315: loss = 0.17822
Step 48320: loss = 0.02800
Step 48325: loss = 0.02714
Step 48330: loss = 0.03798
Step 48335: loss = 0.00854
Step 48340: loss = 0.04215
Step 48345: loss = 0.01452
Step 48350: loss = 0.02890
Step 48355: loss = 0.06748
Step 48360: loss = 0.03053
Step 48365: loss = 0.01765
Step 48370: loss = 0.04417
Step 48375: loss = 0.06417
Step 48380: loss = 0.09802
Step 48385: loss = 0.07650
Step 48390: loss = 0.06654
Step 48395: loss = 0.03901
Step 48400: loss = 0.04785
Step 48405: loss = 0.02811
Step 48410: loss = 0.02923
Step 48415: loss = 0.02837
Step 48420: loss = 0.04861
Step 48425: loss = 0.03285
Step 48430: loss = 0.02546
Step 48435: loss = 0.07623
Step 48440: loss = 0.02018
Step 48445: loss = 0.04168
Step 48450: loss = 0.02665
Step 48455: loss = 0.02896
Step 48460: loss = 0.10769
Step 48465: loss = 0.12070
Step 48470: loss = 0.02236
Step 48475: loss = 0.01240
Step 48480: loss = 0.02089
Step 48485: loss = 0.07116
Step 48490: loss = 0.08059
Step 48495: loss = 0.03548
Step 48500: loss = 0.02502
Step 48505: loss = 0.01256
Step 48510: loss = 0.01168
Step 48515: loss = 0.05245
Step 48520: loss = 0.01057
Step 48525: loss = 0.02993
Step 48530: loss = 0.01209
Step 48535: loss = 0.03405
Step 48540: loss = 0.07665
Step 48545: loss = 0.02133
Step 48550: loss = 0.07386
Step 48555: loss = 0.02491
Step 48560: loss = 0.00485
Step 48565: loss = 0.00849
Step 48570: loss = 0.02719
Step 48575: loss = 0.04063
Step 48580: loss = 0.08749
Step 48585: loss = 0.11556
Step 48590: loss = 0.06024
Step 48595: loss = 0.02713
Step 48600: loss = 0.03799
Step 48605: loss = 0.04861
Step 48610: loss = 0.00340
Step 48615: loss = 0.06216
Step 48620: loss = 0.05506
Step 48625: loss = 0.01378
Step 48630: loss = 0.00783
Step 48635: loss = 0.01857
Step 48640: loss = 0.02499
Step 48645: loss = 0.02940
Step 48650: loss = 0.02469
Step 48655: loss = 0.03668
Step 48660: loss = 0.06069
Step 48665: loss = 0.02859
Step 48670: loss = 0.02491
Step 48675: loss = 0.01784
Step 48680: loss = 0.07558
Step 48685: loss = 0.05395
Step 48690: loss = 0.01570
Step 48695: loss = 0.02410
Step 48700: loss = 0.00865
Step 48705: loss = 0.03157
Step 48710: loss = 0.08104
Step 48715: loss = 0.02654
Step 48720: loss = 0.13337
Step 48725: loss = 0.03080
Step 48730: loss = 0.06302
Step 48735: loss = 0.01337
Step 48740: loss = 0.08034
Step 48745: loss = 0.01088
Step 48750: loss = 0.04015
Step 48755: loss = 0.05826
Step 48760: loss = 0.03027
Step 48765: loss = 0.05343
Step 48770: loss = 0.02968
Step 48775: loss = 0.10978
Step 48780: loss = 0.02377
Step 48785: loss = 0.03356
Step 48790: loss = 0.07549
Step 48795: loss = 0.06775
Step 48800: loss = 0.03277
Step 48805: loss = 0.05551
Step 48810: loss = 0.03216
Step 48815: loss = 0.13898
Step 48820: loss = 0.01550
Step 48825: loss = 0.08065
Step 48830: loss = 0.09534
Step 48835: loss = 0.00954
Step 48840: loss = 0.02604
Step 48845: loss = 0.03557
Step 48850: loss = 0.02060
Step 48855: loss = 0.00914
Step 48860: loss = 0.01982
Step 48865: loss = 0.08412
Step 48870: loss = 0.01374
Step 48875: loss = 0.11958
Step 48880: loss = 0.03842
Step 48885: loss = 0.09806
Step 48890: loss = 0.02828
Step 48895: loss = 0.03263
Step 48900: loss = 0.06869
Step 48905: loss = 0.02941
Step 48910: loss = 0.04247
Step 48915: loss = 0.01282
Step 48920: loss = 0.00663
Step 48925: loss = 0.06843
Step 48930: loss = 0.05064
Step 48935: loss = 0.04889
Step 48940: loss = 0.04652
Step 48945: loss = 0.03794
Step 48950: loss = 0.06011
Step 48955: loss = 0.02125
Step 48960: loss = 0.03105
Step 48965: loss = 0.05064
Step 48970: loss = 0.02385
Step 48975: loss = 0.03000
Step 48980: loss = 0.06676
Step 48985: loss = 0.06954
Step 48990: loss = 0.07405
Step 48995: loss = 0.03410
Step 49000: loss = 0.03546
Training Data Eval:
  Num examples: 50000, Num correct: 49481, Precision @ 1: 0.9896
('Testing Data Eval: EPOCH->', 50)
  Num examples: 10000, Num correct: 6753, Precision @ 1: 0.6753
Step 49005: loss = 0.03302
Step 49010: loss = 0.03589
Step 49015: loss = 0.04353
Step 49020: loss = 0.05061
Step 49025: loss = 0.06702
Step 49030: loss = 0.04525
Step 49035: loss = 0.00843
Step 49040: loss = 0.04449
Step 49045: loss = 0.01393
Step 49050: loss = 0.01180
Step 49055: loss = 0.02394
Step 49060: loss = 0.01800
Step 49065: loss = 0.03141
Step 49070: loss = 0.05042
Step 49075: loss = 0.04346
Step 49080: loss = 0.02649
Step 49085: loss = 0.00337
Step 49090: loss = 0.07248
Step 49095: loss = 0.02085
Step 49100: loss = 0.01711
Step 49105: loss = 0.03064
Step 49110: loss = 0.06705
Step 49115: loss = 0.00986
Step 49120: loss = 0.07370
Step 49125: loss = 0.07428
Step 49130: loss = 0.01163
Step 49135: loss = 0.08034
Step 49140: loss = 0.04023
Step 49145: loss = 0.05754
Step 49150: loss = 0.01190
Step 49155: loss = 0.01534
Step 49160: loss = 0.02880
Step 49165: loss = 0.02287
Step 49170: loss = 0.03216
Step 49175: loss = 0.00877
Step 49180: loss = 0.03722
Step 49185: loss = 0.01960
Step 49190: loss = 0.04229
Step 49195: loss = 0.01214
Step 49200: loss = 0.00919
Step 49205: loss = 0.04695
Step 49210: loss = 0.05606
Step 49215: loss = 0.04901
Step 49220: loss = 0.13038
Step 49225: loss = 0.00655
Step 49230: loss = 0.03692
Step 49235: loss = 0.01587
Step 49240: loss = 0.10687
Step 49245: loss = 0.04804
Step 49250: loss = 0.02967
Step 49255: loss = 0.01106
Step 49260: loss = 0.00684
Step 49265: loss = 0.08103
Step 49270: loss = 0.02339
Step 49275: loss = 0.00952
Step 49280: loss = 0.00767
Step 49285: loss = 0.02626
Step 49290: loss = 0.00914
Step 49295: loss = 0.00763
Step 49300: loss = 0.06302
Step 49305: loss = 0.11063
Step 49310: loss = 0.02680
Step 49315: loss = 0.06745
Step 49320: loss = 0.03408
Step 49325: loss = 0.03099
Step 49330: loss = 0.01896
Step 49335: loss = 0.07154
Step 49340: loss = 0.03160
Step 49345: loss = 0.05271
Step 49350: loss = 0.06112
Step 49355: loss = 0.06264
Step 49360: loss = 0.04409
Step 49365: loss = 0.01555
Step 49370: loss = 0.18558
Step 49375: loss = 0.10080
Step 49380: loss = 0.00866
Step 49385: loss = 0.02062
Step 49390: loss = 0.00905
Step 49395: loss = 0.07437
Step 49400: loss = 0.03670
Step 49405: loss = 0.05802
Step 49410: loss = 0.06288
Step 49415: loss = 0.09881
Step 49420: loss = 0.01200
Step 49425: loss = 0.02723
Step 49430: loss = 0.07365
Step 49435: loss = 0.03540
Step 49440: loss = 0.01683
Step 49445: loss = 0.01146
Step 49450: loss = 0.10002
Step 49455: loss = 0.03260
Step 49460: loss = 0.02675
Step 49465: loss = 0.01290
Step 49470: loss = 0.04452
Step 49475: loss = 0.07237
Step 49480: loss = 0.01602
Step 49485: loss = 0.01617
Step 49490: loss = 0.03476
Step 49495: loss = 0.05956
Step 49500: loss = 0.01385
Step 49505: loss = 0.01477
Step 49510: loss = 0.03053
Step 49515: loss = 0.02807
Step 49520: loss = 0.01971
Step 49525: loss = 0.07533
Step 49530: loss = 0.02526
Step 49535: loss = 0.02459
Step 49540: loss = 0.02077
Step 49545: loss = 0.09584
Step 49550: loss = 0.03114
Step 49555: loss = 0.02928
Step 49560: loss = 0.08130
Step 49565: loss = 0.07655
Step 49570: loss = 0.03804
Step 49575: loss = 0.00738
Step 49580: loss = 0.01799
Step 49585: loss = 0.04594
Step 49590: loss = 0.02488
Step 49595: loss = 0.01454
Step 49600: loss = 0.04719
Step 49605: loss = 0.05172
Step 49610: loss = 0.09239
Step 49615: loss = 0.01139
Step 49620: loss = 0.03868
Step 49625: loss = 0.05515
Step 49630: loss = 0.05586
Step 49635: loss = 0.05363
Step 49640: loss = 0.01062
Step 49645: loss = 0.10679
Step 49650: loss = 0.04748
Step 49655: loss = 0.00846
Step 49660: loss = 0.00596
Step 49665: loss = 0.01054
Step 49670: loss = 0.01838
Step 49675: loss = 0.00486
Step 49680: loss = 0.02877
Step 49685: loss = 0.03753
Step 49690: loss = 0.03875
Step 49695: loss = 0.08308
Step 49700: loss = 0.01231
Step 49705: loss = 0.01285
Step 49710: loss = 0.00573
Step 49715: loss = 0.01696
Step 49720: loss = 0.05766
Step 49725: loss = 0.03755
Step 49730: loss = 0.09926
Step 49735: loss = 0.02087
Step 49740: loss = 0.03279
Step 49745: loss = 0.02316
Step 49750: loss = 0.02598
Step 49755: loss = 0.01523
Step 49760: loss = 0.01690
Step 49765: loss = 0.04414
Step 49770: loss = 0.09943
Step 49775: loss = 0.02465
Step 49780: loss = 0.01974
Step 49785: loss = 0.02017
Step 49790: loss = 0.01955
Step 49795: loss = 0.00521
Step 49800: loss = 0.04170
Step 49805: loss = 0.07271
Step 49810: loss = 0.01874
Step 49815: loss = 0.01556
Step 49820: loss = 0.08729
Step 49825: loss = 0.01438
Step 49830: loss = 0.08934
Step 49835: loss = 0.08150
Step 49840: loss = 0.01740
Step 49845: loss = 0.03189
Step 49850: loss = 0.03095
Step 49855: loss = 0.01729
Step 49860: loss = 0.04415
Step 49865: loss = 0.02085
Step 49870: loss = 0.04345
Step 49875: loss = 0.09366
Step 49880: loss = 0.02914
Step 49885: loss = 0.05088
Step 49890: loss = 0.04058
Step 49895: loss = 0.02856
Step 49900: loss = 0.00682
Step 49905: loss = 0.08735
Step 49910: loss = 0.01780
Step 49915: loss = 0.02770
Step 49920: loss = 0.08031
Step 49925: loss = 0.09143
Step 49930: loss = 0.04029
Step 49935: loss = 0.03794
Step 49940: loss = 0.06883
Step 49945: loss = 0.08242
Step 49950: loss = 0.02288
Step 49955: loss = 0.02536
Step 49960: loss = 0.06025
Step 49965: loss = 0.08614
Step 49970: loss = 0.04467
Step 49975: loss = 0.08928
Step 49980: loss = 0.02832
Step 49985: loss = 0.06556
Step 49990: loss = 0.02189
Step 49995: loss = 0.04200
Step 50000: loss = 0.03841
Training Data Eval:
  Num examples: 50000, Num correct: 49351, Precision @ 1: 0.9870
('Testing Data Eval: EPOCH->', 51)
  Num examples: 10000, Num correct: 6708, Precision @ 1: 0.6708
Step 50005: loss = 0.01033
Step 50010: loss = 0.00954
Step 50015: loss = 0.07512
Step 50020: loss = 0.00290
Step 50025: loss = 0.05985
Step 50030: loss = 0.01154
Step 50035: loss = 0.01244
Step 50040: loss = 0.01520
Step 50045: loss = 0.00704
Step 50050: loss = 0.01601
Step 50055: loss = 0.04439
Step 50060: loss = 0.03477
Step 50065: loss = 0.01937
Step 50070: loss = 0.10065
Step 50075: loss = 0.06826
Step 50080: loss = 0.03272
Step 50085: loss = 0.01516
Step 50090: loss = 0.09345
Step 50095: loss = 0.02399
Step 50100: loss = 0.01713
Step 50105: loss = 0.04013
Step 50110: loss = 0.02896
Step 50115: loss = 0.02827
Step 50120: loss = 0.02431
Step 50125: loss = 0.02164
Step 50130: loss = 0.01582
Step 50135: loss = 0.00638
Step 50140: loss = 0.01774
Step 50145: loss = 0.00646
Step 50150: loss = 0.07555
Step 50155: loss = 0.02426
Step 50160: loss = 0.01555
Step 50165: loss = 0.03761
Step 50170: loss = 0.02035
Step 50175: loss = 0.05853
Step 50180: loss = 0.12720
Step 50185: loss = 0.06684
Step 50190: loss = 0.01681
Step 50195: loss = 0.00623
Step 50200: loss = 0.00548
Step 50205: loss = 0.02595
Step 50210: loss = 0.00976
Step 50215: loss = 0.07483
Step 50220: loss = 0.02410
Step 50225: loss = 0.02194
Step 50230: loss = 0.02994
Step 50235: loss = 0.03418
Step 50240: loss = 0.01695
Step 50245: loss = 0.05380
Step 50250: loss = 0.06163
Step 50255: loss = 0.01427
Step 50260: loss = 0.08388
Step 50265: loss = 0.01365
Step 50270: loss = 0.03115
Step 50275: loss = 0.01006
Step 50280: loss = 0.00668
Step 50285: loss = 0.00817
Step 50290: loss = 0.06539
Step 50295: loss = 0.03716
Step 50300: loss = 0.03501
Step 50305: loss = 0.01962
Step 50310: loss = 0.01944
Step 50315: loss = 0.00620
Step 50320: loss = 0.01919
Step 50325: loss = 0.01831
Step 50330: loss = 0.02866
Step 50335: loss = 0.04197
Step 50340: loss = 0.01454
Step 50345: loss = 0.01862
Step 50350: loss = 0.11130
Step 50355: loss = 0.02213
Step 50360: loss = 0.02271
Step 50365: loss = 0.01918
Step 50370: loss = 0.02964
Step 50375: loss = 0.01924
Step 50380: loss = 0.01830
Step 50385: loss = 0.02496
Step 50390: loss = 0.00606
Step 50395: loss = 0.00314
Step 50400: loss = 0.04352
Step 50405: loss = 0.06155
Step 50410: loss = 0.02620
Step 50415: loss = 0.04624
Step 50420: loss = 0.11693
Step 50425: loss = 0.04830
Step 50430: loss = 0.10076
Step 50435: loss = 0.04128
Step 50440: loss = 0.00451
Step 50445: loss = 0.09163
Step 50450: loss = 0.01535
Step 50455: loss = 0.12423
Step 50460: loss = 0.01069
Step 50465: loss = 0.06041
Step 50470: loss = 0.03594
Step 50475: loss = 0.01048
Step 50480: loss = 0.02823
Step 50485: loss = 0.01072
Step 50490: loss = 0.04266
Step 50495: loss = 0.08994
Step 50500: loss = 0.08999
Step 50505: loss = 0.10798
Step 50510: loss = 0.16478
Step 50515: loss = 0.01955
Step 50520: loss = 0.03580
Step 50525: loss = 0.05499
Step 50530: loss = 0.02102
Step 50535: loss = 0.03945
Step 50540: loss = 0.01688
Step 50545: loss = 0.02317
Step 50550: loss = 0.02808
Step 50555: loss = 0.01356
Step 50560: loss = 0.06416
Step 50565: loss = 0.05544
Step 50570: loss = 0.01009
Step 50575: loss = 0.01133
Step 50580: loss = 0.02979
Step 50585: loss = 0.04528
Step 50590: loss = 0.04429
Step 50595: loss = 0.01485
Step 50600: loss = 0.02972
Step 50605: loss = 0.01552
Step 50610: loss = 0.08274
Step 50615: loss = 0.01723
Step 50620: loss = 0.06821
Step 50625: loss = 0.00945
Step 50630: loss = 0.02016
Step 50635: loss = 0.04084
Step 50640: loss = 0.01956
Step 50645: loss = 0.08826
Step 50650: loss = 0.04780
Step 50655: loss = 0.00743
Step 50660: loss = 0.02943
Step 50665: loss = 0.09563
Step 50670: loss = 0.07148
Step 50675: loss = 0.03656
Step 50680: loss = 0.03715
Step 50685: loss = 0.01607
Step 50690: loss = 0.02513
Step 50695: loss = 0.06513
Step 50700: loss = 0.01890
Step 50705: loss = 0.06809
Step 50710: loss = 0.00969
Step 50715: loss = 0.00776
Step 50720: loss = 0.00578
Step 50725: loss = 0.02964
Step 50730: loss = 0.01123
Step 50735: loss = 0.03601
Step 50740: loss = 0.04687
Step 50745: loss = 0.05539
Step 50750: loss = 0.09957
Step 50755: loss = 0.01278
Step 50760: loss = 0.02666
Step 50765: loss = 0.02613
Step 50770: loss = 0.05286
Step 50775: loss = 0.04675
Step 50780: loss = 0.03771
Step 50785: loss = 0.03821
Step 50790: loss = 0.01260
Step 50795: loss = 0.02398
Step 50800: loss = 0.00967
Step 50805: loss = 0.03572
Step 50810: loss = 0.03554
Step 50815: loss = 0.03898
Step 50820: loss = 0.07619
Step 50825: loss = 0.02684
Step 50830: loss = 0.10228
Step 50835: loss = 0.05316
Step 50840: loss = 0.08137
Step 50845: loss = 0.00931
Step 50850: loss = 0.01663
Step 50855: loss = 0.07856
Step 50860: loss = 0.05502
Step 50865: loss = 0.00604
Step 50870: loss = 0.03550
Step 50875: loss = 0.05041
Step 50880: loss = 0.06021
Step 50885: loss = 0.05363
Step 50890: loss = 0.02081
Step 50895: loss = 0.02793
Step 50900: loss = 0.04080
Step 50905: loss = 0.03620
Step 50910: loss = 0.03732
Step 50915: loss = 0.01594
Step 50920: loss = 0.06499
Step 50925: loss = 0.05286
Step 50930: loss = 0.01563
Step 50935: loss = 0.09473
Step 50940: loss = 0.02184
Step 50945: loss = 0.05391
Step 50950: loss = 0.03159
Step 50955: loss = 0.00774
Step 50960: loss = 0.03989
Step 50965: loss = 0.08056
Step 50970: loss = 0.01367
Step 50975: loss = 0.03514
Step 50980: loss = 0.03743
Step 50985: loss = 0.00683
Step 50990: loss = 0.01724
Step 50995: loss = 0.08753
Step 51000: loss = 0.01604
Training Data Eval:
  Num examples: 50000, Num correct: 49535, Precision @ 1: 0.9907
('Testing Data Eval: EPOCH->', 52)
  Num examples: 10000, Num correct: 6738, Precision @ 1: 0.6738
Step 51005: loss = 0.02654
Step 51010: loss = 0.01175
Step 51015: loss = 0.03692
Step 51020: loss = 0.00953
Step 51025: loss = 0.05432
Step 51030: loss = 0.04340
Step 51035: loss = 0.01829
Step 51040: loss = 0.00756
Step 51045: loss = 0.00573
Step 51050: loss = 0.00619
Step 51055: loss = 0.01590
Step 51060: loss = 0.05569
Step 51065: loss = 0.01123
Step 51070: loss = 0.05206
Step 51075: loss = 0.02125
Step 51080: loss = 0.03803
Step 51085: loss = 0.01739
Step 51090: loss = 0.05402
Step 51095: loss = 0.02007
Step 51100: loss = 0.00767
Step 51105: loss = 0.02547
Step 51110: loss = 0.01991
Step 51115: loss = 0.12507
Step 51120: loss = 0.01749
Step 51125: loss = 0.00434
Step 51130: loss = 0.04199
Step 51135: loss = 0.00400
Step 51140: loss = 0.01135
Step 51145: loss = 0.02091
Step 51150: loss = 0.02144
Step 51155: loss = 0.03110
Step 51160: loss = 0.02033
Step 51165: loss = 0.02741
Step 51170: loss = 0.01230
Step 51175: loss = 0.00693
Step 51180: loss = 0.03439
Step 51185: loss = 0.03408
Step 51190: loss = 0.01162
Step 51195: loss = 0.01014
Step 51200: loss = 0.00849
Step 51205: loss = 0.01013
Step 51210: loss = 0.01140
Step 51215: loss = 0.10470
Step 51220: loss = 0.02145
Step 51225: loss = 0.01725
Step 51230: loss = 0.03765
Step 51235: loss = 0.02826
Step 51240: loss = 0.00858
Step 51245: loss = 0.03011
Step 51250: loss = 0.02851
Step 51255: loss = 0.01373
Step 51260: loss = 0.01622
Step 51265: loss = 0.00752
Step 51270: loss = 0.02199
Step 51275: loss = 0.01403
Step 51280: loss = 0.01766
Step 51285: loss = 0.07049
Step 51290: loss = 0.01904
Step 51295: loss = 0.01750
Step 51300: loss = 0.04979
Step 51305: loss = 0.08745
Step 51310: loss = 0.12638
Step 51315: loss = 0.01711
Step 51320: loss = 0.00612
Step 51325: loss = 0.03179
Step 51330: loss = 0.04590
Step 51335: loss = 0.03506
Step 51340: loss = 0.05220
Step 51345: loss = 0.00954
Step 51350: loss = 0.02079
Step 51355: loss = 0.06863
Step 51360: loss = 0.00665
Step 51365: loss = 0.02427
Step 51370: loss = 0.01868
Step 51375: loss = 0.00876
Step 51380: loss = 0.00982
Step 51385: loss = 0.00793
Step 51390: loss = 0.04383
Step 51395: loss = 0.00348
Step 51400: loss = 0.03365
Step 51405: loss = 0.02887
Step 51410: loss = 0.01298
Step 51415: loss = 0.00234
Step 51420: loss = 0.03638
Step 51425: loss = 0.01532
Step 51430: loss = 0.00781
Step 51435: loss = 0.00824
Step 51440: loss = 0.00976
Step 51445: loss = 0.09566
Step 51450: loss = 0.01019
Step 51455: loss = 0.03818
Step 51460: loss = 0.02508
Step 51465: loss = 0.00993
Step 51470: loss = 0.05044
Step 51475: loss = 0.01524
Step 51480: loss = 0.00288
Step 51485: loss = 0.01460
Step 51490: loss = 0.03052
Step 51495: loss = 0.01509
Step 51500: loss = 0.02858
Step 51505: loss = 0.01513
Step 51510: loss = 0.00749
Step 51515: loss = 0.00975
Step 51520: loss = 0.03421
Step 51525: loss = 0.05374
Step 51530: loss = 0.03916
Step 51535: loss = 0.08073
Step 51540: loss = 0.01456
Step 51545: loss = 0.07234
Step 51550: loss = 0.11745
Step 51555: loss = 0.03803
Step 51560: loss = 0.02369
Step 51565: loss = 0.04616
Step 51570: loss = 0.02583
Step 51575: loss = 0.03220
Step 51580: loss = 0.01504
Step 51585: loss = 0.00729
Step 51590: loss = 0.01444
Step 51595: loss = 0.04405
Step 51600: loss = 0.02769
Step 51605: loss = 0.01336
Step 51610: loss = 0.02062
Step 51615: loss = 0.03875
Step 51620: loss = 0.06495
Step 51625: loss = 0.06121
Step 51630: loss = 0.01257
Step 51635: loss = 0.10935
Step 51640: loss = 0.03495
Step 51645: loss = 0.03658
Step 51650: loss = 0.02528
Step 51655: loss = 0.09816
Step 51660: loss = 0.04760
Step 51665: loss = 0.01072
Step 51670: loss = 0.02497
Step 51675: loss = 0.02427
Step 51680: loss = 0.03331
Step 51685: loss = 0.02458
Step 51690: loss = 0.05726
Step 51695: loss = 0.01625
Step 51700: loss = 0.02172
Step 51705: loss = 0.05259
Step 51710: loss = 0.02045
Step 51715: loss = 0.05572
Step 51720: loss = 0.00711
Step 51725: loss = 0.05989
Step 51730: loss = 0.01487
Step 51735: loss = 0.02233
Step 51740: loss = 0.01778
Step 51745: loss = 0.01524
Step 51750: loss = 0.01505
Step 51755: loss = 0.01070
Step 51760: loss = 0.11489
Step 51765: loss = 0.02639
Step 51770: loss = 0.00875
Step 51775: loss = 0.09958
Step 51780: loss = 0.03395
Step 51785: loss = 0.01555
Step 51790: loss = 0.01932
Step 51795: loss = 0.01519
Step 51800: loss = 0.06093
Step 51805: loss = 0.01280
Step 51810: loss = 0.04083
Step 51815: loss = 0.00742
Step 51820: loss = 0.00612
Step 51825: loss = 0.01020
Step 51830: loss = 0.10101
Step 51835: loss = 0.01147
Step 51840: loss = 0.00810
Step 51845: loss = 0.05869
Step 51850: loss = 0.04078
Step 51855: loss = 0.06813
Step 51860: loss = 0.06579
Step 51865: loss = 0.03477
Step 51870: loss = 0.02219
Step 51875: loss = 0.01761
Step 51880: loss = 0.11268
Step 51885: loss = 0.03259
Step 51890: loss = 0.00586
Step 51895: loss = 0.01008
Step 51900: loss = 0.07708
Step 51905: loss = 0.04474
Step 51910: loss = 0.03273
Step 51915: loss = 0.04611
Step 51920: loss = 0.01900
Step 51925: loss = 0.00583
Step 51930: loss = 0.00793
Step 51935: loss = 0.03173
Step 51940: loss = 0.05694
Step 51945: loss = 0.02159
Step 51950: loss = 0.01485
Step 51955: loss = 0.03568
Step 51960: loss = 0.08367
Step 51965: loss = 0.00665
Step 51970: loss = 0.03683
Step 51975: loss = 0.04996
Step 51980: loss = 0.03315
Step 51985: loss = 0.07481
Step 51990: loss = 0.05989
Step 51995: loss = 0.04783
Step 52000: loss = 0.00703
Training Data Eval:
  Num examples: 50000, Num correct: 49563, Precision @ 1: 0.9913
('Testing Data Eval: EPOCH->', 53)
  Num examples: 10000, Num correct: 6834, Precision @ 1: 0.6834
Step 52005: loss = 0.00527
Step 52010: loss = 0.01003
Step 52015: loss = 0.15195
Step 52020: loss = 0.01677
Step 52025: loss = 0.02639
Step 52030: loss = 0.05497
Step 52035: loss = 0.03851
Step 52040: loss = 0.01225
Step 52045: loss = 0.02550
Step 52050: loss = 0.00598
Step 52055: loss = 0.02483
Step 52060: loss = 0.01536
Step 52065: loss = 0.02628
Step 52070: loss = 0.00943
Step 52075: loss = 0.09745
Step 52080: loss = 0.01077
Step 52085: loss = 0.02139
Step 52090: loss = 0.02749
Step 52095: loss = 0.04606
Step 52100: loss = 0.03345
Step 52105: loss = 0.05475
Step 52110: loss = 0.04496
Step 52115: loss = 0.00410
Step 52120: loss = 0.00341
Step 52125: loss = 0.02182
Step 52130: loss = 0.02778
Step 52135: loss = 0.02142
Step 52140: loss = 0.03177
Step 52145: loss = 0.12256
Step 52150: loss = 0.01686
Step 52155: loss = 0.01493
Step 52160: loss = 0.00808
Step 52165: loss = 0.08105
Step 52170: loss = 0.02822
Step 52175: loss = 0.04442
Step 52180: loss = 0.01340
Step 52185: loss = 0.02745
Step 52190: loss = 0.01235
Step 52195: loss = 0.01948
Step 52200: loss = 0.04021
Step 52205: loss = 0.03244
Step 52210: loss = 0.01080
Step 52215: loss = 0.07682
Step 52220: loss = 0.01147
Step 52225: loss = 0.03408
Step 52230: loss = 0.03658
Step 52235: loss = 0.01435
Step 52240: loss = 0.04038
Step 52245: loss = 0.03056
Step 52250: loss = 0.01294
Step 52255: loss = 0.05881
Step 52260: loss = 0.06974
Step 52265: loss = 0.06602
Step 52270: loss = 0.02844
Step 52275: loss = 0.02500
Step 52280: loss = 0.01504
Step 52285: loss = 0.04174
Step 52290: loss = 0.01602
Step 52295: loss = 0.00397
Step 52300: loss = 0.02193
Step 52305: loss = 0.02328
Step 52310: loss = 0.02701
Step 52315: loss = 0.07771
Step 52320: loss = 0.00888
Step 52325: loss = 0.01072
Step 52330: loss = 0.01423
Step 52335: loss = 0.07325
Step 52340: loss = 0.02905
Step 52345: loss = 0.03078
Step 52350: loss = 0.02923
Step 52355: loss = 0.04055
Step 52360: loss = 0.03178
Step 52365: loss = 0.04260
Step 52370: loss = 0.02206
Step 52375: loss = 0.12106
Step 52380: loss = 0.01879
Step 52385: loss = 0.02077
Step 52390: loss = 0.00813
Step 52395: loss = 0.01225
Step 52400: loss = 0.01067
Step 52405: loss = 0.01148
Step 52410: loss = 0.00914
Step 52415: loss = 0.01201
Step 52420: loss = 0.02028
Step 52425: loss = 0.01275
Step 52430: loss = 0.01086
Step 52435: loss = 0.03287
Step 52440: loss = 0.01714
Step 52445: loss = 0.02805
Step 52450: loss = 0.04008
Step 52455: loss = 0.06390
Step 52460: loss = 0.04871
Step 52465: loss = 0.05908
Step 52470: loss = 0.01698
Step 52475: loss = 0.00831
Step 52480: loss = 0.03805
Step 52485: loss = 0.07404
Step 52490: loss = 0.01455
Step 52495: loss = 0.06807
Step 52500: loss = 0.01639
Step 52505: loss = 0.00565
Step 52510: loss = 0.03100
Step 52515: loss = 0.05387
Step 52520: loss = 0.04680
Step 52525: loss = 0.05506
Step 52530: loss = 0.02651
Step 52535: loss = 0.02205
Step 52540: loss = 0.05869
Step 52545: loss = 0.01133
Step 52550: loss = 0.07776
Step 52555: loss = 0.01132
Step 52560: loss = 0.02325
Step 52565: loss = 0.01279
Step 52570: loss = 0.01119
Step 52575: loss = 0.02854
Step 52580: loss = 0.08658
Step 52585: loss = 0.04675
Step 52590: loss = 0.02650
Step 52595: loss = 0.03999
Step 52600: loss = 0.01922
Step 52605: loss = 0.01675
Step 52610: loss = 0.02822
Step 52615: loss = 0.05140
Step 52620: loss = 0.01732
Step 52625: loss = 0.02270
Step 52630: loss = 0.00728
Step 52635: loss = 0.01494
Step 52640: loss = 0.04064
Step 52645: loss = 0.01950
Step 52650: loss = 0.02851
Step 52655: loss = 0.00719
Step 52660: loss = 0.07717
Step 52665: loss = 0.01781
Step 52670: loss = 0.04297
Step 52675: loss = 0.06745
Step 52680: loss = 0.01688
Step 52685: loss = 0.03869
Step 52690: loss = 0.00341
Step 52695: loss = 0.01362
Step 52700: loss = 0.01972
Step 52705: loss = 0.00223
Step 52710: loss = 0.01485
Step 52715: loss = 0.01171
Step 52720: loss = 0.00476
Step 52725: loss = 0.01508
Step 52730: loss = 0.01150
Step 52735: loss = 0.04372
Step 52740: loss = 0.03111
Step 52745: loss = 0.10794
Step 52750: loss = 0.01084
Step 52755: loss = 0.01253
Step 52760: loss = 0.01205
Step 52765: loss = 0.01143
Step 52770: loss = 0.04436
Step 52775: loss = 0.01066
Step 52780: loss = 0.04499
Step 52785: loss = 0.01207
Step 52790: loss = 0.08824
Step 52795: loss = 0.03169
Step 52800: loss = 0.01648
Step 52805: loss = 0.06996
Step 52810: loss = 0.01914
Step 52815: loss = 0.04011
Step 52820: loss = 0.01704
Step 52825: loss = 0.03811
Step 52830: loss = 0.02462
Step 52835: loss = 0.00915
Step 52840: loss = 0.02852
Step 52845: loss = 0.01758
Step 52850: loss = 0.01227
Step 52855: loss = 0.00459
Step 52860: loss = 0.01236
Step 52865: loss = 0.02255
Step 52870: loss = 0.01382
Step 52875: loss = 0.04326
Step 52880: loss = 0.08183
Step 52885: loss = 0.04822
Step 52890: loss = 0.01812
Step 52895: loss = 0.15135
Step 52900: loss = 0.04710
Step 52905: loss = 0.01705
Step 52910: loss = 0.01591
Step 52915: loss = 0.03521
Step 52920: loss = 0.00982
Step 52925: loss = 0.02315
Step 52930: loss = 0.02148
Step 52935: loss = 0.04869
Step 52940: loss = 0.09923
Step 52945: loss = 0.04273
Step 52950: loss = 0.01597
Step 52955: loss = 0.00469
Step 52960: loss = 0.07998
Step 52965: loss = 0.04602
Step 52970: loss = 0.03616
Step 52975: loss = 0.02703
Step 52980: loss = 0.01176
Step 52985: loss = 0.01492
Step 52990: loss = 0.00879
Step 52995: loss = 0.01815
Step 53000: loss = 0.01950
Training Data Eval:
  Num examples: 50000, Num correct: 49561, Precision @ 1: 0.9912
('Testing Data Eval: EPOCH->', 54)
  Num examples: 10000, Num correct: 6874, Precision @ 1: 0.6874
Step 53005: loss = 0.00542
Step 53010: loss = 0.02244
Step 53015: loss = 0.05427
Step 53020: loss = 0.01646
Step 53025: loss = 0.00717
Step 53030: loss = 0.05980
Step 53035: loss = 0.02470
Step 53040: loss = 0.07854
Step 53045: loss = 0.03785
Step 53050: loss = 0.01871
Step 53055: loss = 0.02195
Step 53060: loss = 0.02229
Step 53065: loss = 0.01202
Step 53070: loss = 0.02524
Step 53075: loss = 0.00974
Step 53080: loss = 0.02339
Step 53085: loss = 0.01535
Step 53090: loss = 0.00942
Step 53095: loss = 0.01524
Step 53100: loss = 0.00880
Step 53105: loss = 0.00642
Step 53110: loss = 0.00274
Step 53115: loss = 0.00626
Step 53120: loss = 0.03940
Step 53125: loss = 0.00809
Step 53130: loss = 0.00966
Step 53135: loss = 0.06213
Step 53140: loss = 0.04704
Step 53145: loss = 0.02009
Step 53150: loss = 0.02078
Step 53155: loss = 0.02150
Step 53160: loss = 0.00481
Step 53165: loss = 0.01696
Step 53170: loss = 0.02388
Step 53175: loss = 0.01264
Step 53180: loss = 0.02358
Step 53185: loss = 0.03947
Step 53190: loss = 0.04491
Step 53195: loss = 0.03094
Step 53200: loss = 0.01478
Step 53205: loss = 0.01703
Step 53210: loss = 0.03460
Step 53215: loss = 0.03099
Step 53220: loss = 0.06205
Step 53225: loss = 0.13302
Step 53230: loss = 0.01525
Step 53235: loss = 0.00272
Step 53240: loss = 0.03574
Step 53245: loss = 0.01707
Step 53250: loss = 0.04244
Step 53255: loss = 0.00780
Step 53260: loss = 0.02213
Step 53265: loss = 0.02051
Step 53270: loss = 0.02616
Step 53275: loss = 0.01780
Step 53280: loss = 0.01165
Step 53285: loss = 0.02452
Step 53290: loss = 0.00949
Step 53295: loss = 0.03380
Step 53300: loss = 0.04317
Step 53305: loss = 0.01925
Step 53310: loss = 0.01952
Step 53315: loss = 0.01168
Step 53320: loss = 0.04919
Step 53325: loss = 0.04132
Step 53330: loss = 0.02664
Step 53335: loss = 0.08096
Step 53340: loss = 0.01507
Step 53345: loss = 0.05213
Step 53350: loss = 0.03173
Step 53355: loss = 0.04831
Step 53360: loss = 0.02406
Step 53365: loss = 0.02188
Step 53370: loss = 0.01890
Step 53375: loss = 0.02236
Step 53380: loss = 0.00207
Step 53385: loss = 0.01791
Step 53390: loss = 0.04897
Step 53395: loss = 0.00679
Step 53400: loss = 0.00909
Step 53405: loss = 0.00684
Step 53410: loss = 0.01743
Step 53415: loss = 0.03774
Step 53420: loss = 0.03803
Step 53425: loss = 0.02913
Step 53430: loss = 0.00670
Step 53435: loss = 0.01963
Step 53440: loss = 0.01236
Step 53445: loss = 0.00890
Step 53450: loss = 0.02182
Step 53455: loss = 0.06653
Step 53460: loss = 0.02485
Step 53465: loss = 0.01892
Step 53470: loss = 0.00388
Step 53475: loss = 0.02326
Step 53480: loss = 0.02729
Step 53485: loss = 0.02299
Step 53490: loss = 0.05285
Step 53495: loss = 0.01568
Step 53500: loss = 0.00690
Step 53505: loss = 0.00859
Step 53510: loss = 0.00611
Step 53515: loss = 0.01549
Step 53520: loss = 0.05241
Step 53525: loss = 0.02375
Step 53530: loss = 0.00681
Step 53535: loss = 0.01820
Step 53540: loss = 0.06973
Step 53545: loss = 0.01546
Step 53550: loss = 0.00507
Step 53555: loss = 0.05902
Step 53560: loss = 0.00740
Step 53565: loss = 0.01674
Step 53570: loss = 0.00416
Step 53575: loss = 0.01336
Step 53580: loss = 0.02075
Step 53585: loss = 0.01476
Step 53590: loss = 0.00480
Step 53595: loss = 0.01399
Step 53600: loss = 0.06150
Step 53605: loss = 0.00735
Step 53610: loss = 0.01894
Step 53615: loss = 0.02513
Step 53620: loss = 0.14470
Step 53625: loss = 0.02132
Step 53630: loss = 0.04919
Step 53635: loss = 0.01882
Step 53640: loss = 0.11968
Step 53645: loss = 0.00320
Step 53650: loss = 0.02567
Step 53655: loss = 0.02387
Step 53660: loss = 0.01585
Step 53665: loss = 0.02346
Step 53670: loss = 0.00814
Step 53675: loss = 0.03394
Step 53680: loss = 0.00817
Step 53685: loss = 0.01162
Step 53690: loss = 0.02546
Step 53695: loss = 0.07172
Step 53700: loss = 0.05006
Step 53705: loss = 0.05001
Step 53710: loss = 0.00989
Step 53715: loss = 0.08516
Step 53720: loss = 0.03598
Step 53725: loss = 0.04621
Step 53730: loss = 0.03219
Step 53735: loss = 0.11694
Step 53740: loss = 0.05744
Step 53745: loss = 0.01813
Step 53750: loss = 0.07547
Step 53755: loss = 0.01027
Step 53760: loss = 0.01856
Step 53765: loss = 0.01509
Step 53770: loss = 0.00705
Step 53775: loss = 0.01877
Step 53780: loss = 0.00841
Step 53785: loss = 0.01828
Step 53790: loss = 0.04657
Step 53795: loss = 0.03072
Step 53800: loss = 0.06048
Step 53805: loss = 0.10579
Step 53810: loss = 0.03926
Step 53815: loss = 0.04800
Step 53820: loss = 0.02798
Step 53825: loss = 0.00944
Step 53830: loss = 0.03584
Step 53835: loss = 0.07045
Step 53840: loss = 0.01161
Step 53845: loss = 0.02489
Step 53850: loss = 0.00890
Step 53855: loss = 0.00422
Step 53860: loss = 0.03888
Step 53865: loss = 0.00962
Step 53870: loss = 0.02105
Step 53875: loss = 0.07056
Step 53880: loss = 0.01252
Step 53885: loss = 0.01136
Step 53890: loss = 0.02003
Step 53895: loss = 0.04463
Step 53900: loss = 0.01812
Step 53905: loss = 0.04998
Step 53910: loss = 0.04750
Step 53915: loss = 0.00680
Step 53920: loss = 0.01250
Step 53925: loss = 0.01426
Step 53930: loss = 0.08613
Step 53935: loss = 0.06552
Step 53940: loss = 0.04828
Step 53945: loss = 0.02882
Step 53950: loss = 0.00895
Step 53955: loss = 0.02255
Step 53960: loss = 0.06860
Step 53965: loss = 0.02330
Step 53970: loss = 0.06530
Step 53975: loss = 0.00706
Step 53980: loss = 0.06102
Step 53985: loss = 0.00676
Step 53990: loss = 0.01310
Step 53995: loss = 0.03037
Step 54000: loss = 0.01210
Training Data Eval:
